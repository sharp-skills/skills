{"d": [{"type_of": "article", "id": 3275346, "title": "LangChain vs LlamaIndex: RAG Latency on 10K Documents", "description": "RAG frameworks promise the same thing: retrieve relevant context, feed it to an LLM, get...", "readable_publish_date": "Feb 22", "slug": "langchain-vs-llamaindex-rag-latency-on-10k-documents-178j", "path": "/tildalice/langchain-vs-llamaindex-rag-latency-on-10k-documents-178j", "url": "https://dev.to/tildalice/langchain-vs-llamaindex-rag-latency-on-10k-documents-178j", "comments_count": 0, "public_reactions_count": 1, "collection_id": null, "published_timestamp": "2026-02-22T15:04:59Z", "language": "en", "subforem_id": 1, "positive_reactions_count": 1, "cover_image": null, "social_image": "https://media2.dev.to/dynamic/image/width=1000,height=500,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F0ojj1g93syynde09619i.png", "canonical_url": "https://tildalice.io/langchain-llamaindex-rag-latency-benchmark/", "created_at": "2026-02-22T15:04:59Z", "edited_at": null, "crossposted_at": null, "published_at": "2026-02-22T15:04:59Z", "last_comment_at": "2026-02-22T15:04:59Z", "reading_time_minutes": 1, "tag_list": ["langchain", "llamaindex", "rag", "vectorsearch"], "tags": "langchain, llamaindex, rag, vectorsearch", "user": {"name": "TildAlice", "username": "tildalice", "twitter_username": null, "github_username": "DrunkJin", "user_id": 3755725, "website_url": null, "profile_image": "https://media2.dev.to/dynamic/image/width=640,height=640,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Fuser%2Fprofile_image%2F3755725%2Fed8d5042-b5bb-495f-b8f6-9d8b470e1d46.png", "profile_image_90": "https://media2.dev.to/dynamic/image/width=90,height=90,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Fuser%2Fprofile_image%2F3755725%2Fed8d5042-b5bb-495f-b8f6-9d8b470e1d46.png"}}]}