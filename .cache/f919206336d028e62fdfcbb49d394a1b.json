{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "AbduNebu"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jira", "production"], "value": "Show HN: Afelyon \u2013 Turns <em>Jira</em> tickets into <em>production</em>-ready PRs (multi-repo)"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://afelyon.com/"}}, "_tags": ["story", "author_AbduNebu", "story_46921888", "show_hn"], "author": "AbduNebu", "created_at": "2026-02-07T06:56:53Z", "created_at_i": 1770447413, "num_comments": 0, "objectID": "46921888", "points": 1, "story_id": 46921888, "title": "Show HN: Afelyon \u2013 Turns Jira tickets into production-ready PRs (multi-repo)", "updated_at": "2026-02-07T07:01:23Z", "url": "https://afelyon.com/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "konstantina_ps"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jira", "production"], "value": "Today we launched the <em>Jira</em> for 3D <em>production</em> and called it Flow 3D.<p>We built Flow because 3D content teams were stuck managing <em>production</em> across 5\u20136 different tools\u2014Slack, spreadsheets, ShotGrid, <em>Jira</em>, email threads\u2026 you name it. That constant jumping between platforms slowed teams down and made creative work feel chaotic.<p>Over the past 5 years, there is one thing I\u2019ve been hearing over and over as I chat with founders, producers, art directors and artists in Gaming:\n&quot;our workflows are a nightmare \u2014 we hate ShotGrid, we need to update statuses in <em>Jira</em>, speadsheets, ShotGrid, Perforce as well as ping our team members on Slack to get things reviewed and moved along the pipeline&quot;<p>I always thought that was crazy. And what\u2019s even crazier? NONE of that software has the functionality for VIEWING a 3D model  wth<p>With Flow, we\u2019re bringing the entire 3D <em>production</em> pipeline into one place. Unlike <em>Jira</em> or ShotGrid, which were never designed for artists, Flow is built specifically for 3D teams. You can orchestrate your pipeline, track every asset\u2019s stage, and keep your team fully in sync\u2014without losing the creative flow.<p>Here\u2019s what\u2019s launching today:\n\u2022 Assigning tasks to team members\n\u2022 Sharing progress for a 3D asset\n\u2022 Real-time reviews \u2014 with revisions, approvals, and progress tracking all in one view.\n\u2022 Create saved views and filters to track every asset and keep projects moving with clarity.<p>What's coming next:\n\u2022 Build milestones, set deadlines, and design custom workflows tailored to your productions.<p>Flow is all about giving 3D artists and studios a modern, purpose-built alternative for managing 3D <em>production</em> workflows, offering clarity, speed, and fewer tools to juggle.<p>What do you think of this launch? We\u2019re always open to feedback\u2014drop a comment and we\u2019ll work to build the features you\u2019d love to see."}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jira", "production"], "value": "Show HN: <em>Jira</em> for 3D <em>Production</em> Management"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://www.kaedim3d.com/flow"}}, "_tags": ["story", "author_konstantina_ps", "story_45375890", "show_hn"], "author": "konstantina_ps", "created_at": "2025-09-25T17:22:54Z", "created_at_i": 1758820974, "num_comments": 0, "objectID": "45375890", "points": 1, "story_id": 45375890, "story_text": "Today we launched the Jira for 3D production and called it Flow 3D.<p>We built Flow because 3D content teams were stuck managing production across 5\u20136 different tools\u2014Slack, spreadsheets, ShotGrid, Jira, email threads\u2026 you name it. That constant jumping between platforms slowed teams down and made creative work feel chaotic.<p>Over the past 5 years, there is one thing I\u2019ve been hearing over and over as I chat with founders, producers, art directors and artists in Gaming:\n&quot;our workflows are a nightmare \u2014 we hate ShotGrid, we need to update statuses in Jira, speadsheets, ShotGrid, Perforce as well as ping our team members on Slack to get things reviewed and moved along the pipeline&quot;<p>I always thought that was crazy. And what\u2019s even crazier? NONE of that software has the functionality for VIEWING a 3D model  wth<p>With Flow, we\u2019re bringing the entire 3D production pipeline into one place. Unlike Jira or ShotGrid, which were never designed for artists, Flow is built specifically for 3D teams. You can orchestrate your pipeline, track every asset\u2019s stage, and keep your team fully in sync\u2014without losing the creative flow.<p>Here\u2019s what\u2019s launching today:\n\u2022 Assigning tasks to team members\n\u2022 Sharing progress for a 3D asset\n\u2022 Real-time reviews \u2014 with revisions, approvals, and progress tracking all in one view.\n\u2022 Create saved views and filters to track every asset and keep projects moving with clarity.<p>What&#x27;s coming next:\n\u2022 Build milestones, set deadlines, and design custom workflows tailored to your productions.<p>Flow is all about giving 3D artists and studios a modern, purpose-built alternative for managing 3D production workflows, offering clarity, speed, and fewer tools to juggle.<p>What do you think of this launch? We\u2019re always open to feedback\u2014drop a comment and we\u2019ll work to build the features you\u2019d love to see.", "title": "Show HN: Jira for 3D Production Management", "updated_at": "2025-09-25T17:28:22Z", "url": "https://www.kaedim3d.com/flow"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "tintinwinata"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["jira"], "value": "Auto-<em>Jira</em>: AI that detects errors, diagnoses root causes, and files <em>Jira</em> tickets"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jira", "production"], "value": "https://medium.com/@tintinwinata/built-an-ai-that-auto-creates-<em>jira</em>-tickets-from-<em>production</em>-errors-and-won-1st-place-doing-it-79b4d83feb88"}}, "_tags": ["story", "author_tintinwinata", "story_46871254"], "author": "tintinwinata", "children": [46871255], "created_at": "2026-02-03T14:16:55Z", "created_at_i": 1770128215, "num_comments": 1, "objectID": "46871254", "points": 1, "story_id": 46871254, "title": "Auto-Jira: AI that detects errors, diagnoses root causes, and files Jira tickets", "updated_at": "2026-02-03T14:23:37Z", "url": "https://medium.com/@tintinwinata/built-an-ai-that-auto-creates-jira-tickets-from-production-errors-and-won-1st-place-doing-it-79b4d83feb88"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "andriosr"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jira", "production"], "value": "Hello HN! I'm Andrios, from Runops.io - we're building a proxy to commands you run in the terminal that adds Git, code reviews in Slack, and removes sensitive data from results. It's like the Cloud Shells from GCP/AWS, but with more features and using your local zsh/bash terminal.<p>You run an AWS CLI command in the terminal and it goes to Runops instead of AWS. Runops adds the command to Git and gets peer reviews (when required) in Slack before sending it to AWS. After it runs, we deliver the results back in the terminal, but with all sensitive data masked. It works for AWS, Kubernetes, databases, and others.<p>I was leading the Infra team at a Fintech (pismo.io/en), and we wanted to give autonomy to all developers in <em>production</em>. But we couldn\u2019t give them direct access due to compliance requirements. The solution was to have a small number of people (my team) with &quot;full access&quot; to <em>production</em> systems. Engineers would ask us when they needed to run one-off scripts in <em>production</em>. Our goal was to deliver automations so that other teams wouldn't need to ask us to do things. We would build a way for them to do it with compliance, security, and reliability.<p>It didn't work. We were spending 80% of the time processing the queue of requests, and 20% building automations. The backlog was always increasing, and the team was burning out. Engineers were not happy as their requests took a long time to process and clients were angry at them.<p>But some nice automations came out of that. For instance: we needed to review ad-hoc prod database reads to avoid bad queries. So we built a Jenkins pipeline that ran SQL queries from Git after code review using Flyway. Any engineer could run queries in prod, leaving traces on who did it, reviews, when it happened, and why, for every query.<p>When talking to friends at similar companies, I saw the problem was even worse. Some of them weren't trying to automate, they already had dedicated people for running these scripts, i.e., an ops team. I knew there was a better way, so I set out to build it. I quit this job mid last year, with about 8 months' worth of savings to make this work before I'd need to find a job again. It was tough in the beginning, as I\u2019m an engineer and had to learn sales, marketing and product management on the job, but after getting the first few customers things started improving.<p>The goal for Runops is to let any engineer run anything in <em>production</em> as if they had full access, automating as much as possible of security and compliance. When human interaction is needed, we make it synchronous using Slack. Now, instead of having a single team as a bottleneck, you can have everyone do things in <em>production</em>. Centralizing teams with most of the access to AWS, Kubernetes, and databases is bad. It makes for slow Change Management processes using <em>Jira</em> or other tools with manual executions at the end. Runops let\u2019s you add quick reviews from experts (Infra, DBA, security, etc), and automates executions.<p>The primary interface is a CLI, where you run scripts that goes from SQL queries to kubectl exec and AWS CLI commands. We don't create new abstractions, you use the same commands and docs available, we just proxy them. A nice benefit is replacing VPNs and the 10 client tools/credentials you would need today. We also support templates for custom actions in a bunch of languages.<p>We built it using Github Actions for executing commands. We store configurations and credentials as Actions Secrets and they get injected when a command requires them. It's nice because we can run anything that goes in a Docker container in &lt;15 seconds. We have plans to improve it beyond Actions by creating a real-time proxy. That will enable a REPL-like experience.\nRunops doesn't have a web interface, this is on purpose, we don't want to be one more tool engineers have to learn. Most interactions happen with our CLI or Slack. We have a simple admin UI in Retool.<p>We do everything using Lisp. The CLI uses Clojurescript; the REST API uses Clojure. It's great to have the same language everywhere, and Lisp is also a fantastic advantage.<p>Today we have big Fintechs using Runops. They use it to let developers run commands inside Kubernetes pods, like Rails Runner and Elixir IEx, SQL queries, DynamoDB queries, and making internal API calls in private networks using cURL. One of the best parts of building this has been seeing developers doing more <em>production</em> work. Regulated companies that never considered giving this level of autonomy to all developers are changing their minds. It's great to see a tool impacting the culture, increasing trust.<p>We're really happy we get to show this to you all, thank you for reading about it! Please let us know your thoughts and questions."}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Launch HN: Runops (YC W21) \u2013 A better cloud shell for <em>production</em> apps"}}, "_tags": ["story", "author_andriosr", "story_26385434", "launch_hn"], "author": "andriosr", "children": [26386156, 26386190, 26386400, 26386598, 26386627, 26386950, 26387509, 26392287, 26396005], "created_at": "2021-03-08T13:26:18Z", "created_at_i": 1615209978, "num_comments": 23, "objectID": "26385434", "points": 97, "story_id": 26385434, "story_text": "Hello HN! I&#x27;m Andrios, from Runops.io - we&#x27;re building a proxy to commands you run in the terminal that adds Git, code reviews in Slack, and removes sensitive data from results. It&#x27;s like the Cloud Shells from GCP&#x2F;AWS, but with more features and using your local zsh&#x2F;bash terminal.<p>You run an AWS CLI command in the terminal and it goes to Runops instead of AWS. Runops adds the command to Git and gets peer reviews (when required) in Slack before sending it to AWS. After it runs, we deliver the results back in the terminal, but with all sensitive data masked. It works for AWS, Kubernetes, databases, and others.<p>I was leading the Infra team at a Fintech (pismo.io&#x2F;en), and we wanted to give autonomy to all developers in production. But we couldn\u2019t give them direct access due to compliance requirements. The solution was to have a small number of people (my team) with &quot;full access&quot; to production systems. Engineers would ask us when they needed to run one-off scripts in production. Our goal was to deliver automations so that other teams wouldn&#x27;t need to ask us to do things. We would build a way for them to do it with compliance, security, and reliability.<p>It didn&#x27;t work. We were spending 80% of the time processing the queue of requests, and 20% building automations. The backlog was always increasing, and the team was burning out. Engineers were not happy as their requests took a long time to process and clients were angry at them.<p>But some nice automations came out of that. For instance: we needed to review ad-hoc prod database reads to avoid bad queries. So we built a Jenkins pipeline that ran SQL queries from Git after code review using Flyway. Any engineer could run queries in prod, leaving traces on who did it, reviews, when it happened, and why, for every query.<p>When talking to friends at similar companies, I saw the problem was even worse. Some of them weren&#x27;t trying to automate, they already had dedicated people for running these scripts, i.e., an ops team. I knew there was a better way, so I set out to build it. I quit this job mid last year, with about 8 months&#x27; worth of savings to make this work before I&#x27;d need to find a job again. It was tough in the beginning, as I\u2019m an engineer and had to learn sales, marketing and product management on the job, but after getting the first few customers things started improving.<p>The goal for Runops is to let any engineer run anything in production as if they had full access, automating as much as possible of security and compliance. When human interaction is needed, we make it synchronous using Slack. Now, instead of having a single team as a bottleneck, you can have everyone do things in production. Centralizing teams with most of the access to AWS, Kubernetes, and databases is bad. It makes for slow Change Management processes using Jira or other tools with manual executions at the end. Runops let\u2019s you add quick reviews from experts (Infra, DBA, security, etc), and automates executions.<p>The primary interface is a CLI, where you run scripts that goes from SQL queries to kubectl exec and AWS CLI commands. We don&#x27;t create new abstractions, you use the same commands and docs available, we just proxy them. A nice benefit is replacing VPNs and the 10 client tools&#x2F;credentials you would need today. We also support templates for custom actions in a bunch of languages.<p>We built it using Github Actions for executing commands. We store configurations and credentials as Actions Secrets and they get injected when a command requires them. It&#x27;s nice because we can run anything that goes in a Docker container in &lt;15 seconds. We have plans to improve it beyond Actions by creating a real-time proxy. That will enable a REPL-like experience.\nRunops doesn&#x27;t have a web interface, this is on purpose, we don&#x27;t want to be one more tool engineers have to learn. Most interactions happen with our CLI or Slack. We have a simple admin UI in Retool.<p>We do everything using Lisp. The CLI uses Clojurescript; the REST API uses Clojure. It&#x27;s great to have the same language everywhere, and Lisp is also a fantastic advantage.<p>Today we have big Fintechs using Runops. They use it to let developers run commands inside Kubernetes pods, like Rails Runner and Elixir IEx, SQL queries, DynamoDB queries, and making internal API calls in private networks using cURL. One of the best parts of building this has been seeing developers doing more production work. Regulated companies that never considered giving this level of autonomy to all developers are changing their minds. It&#x27;s great to see a tool impacting the culture, increasing trust.<p>We&#x27;re really happy we get to show this to you all, thank you for reading about it! Please let us know your thoughts and questions.", "title": "Launch HN: Runops (YC W21) \u2013 A better cloud shell for production apps", "updated_at": "2024-09-20T08:07:46Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "jjdev8157"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jira", "production"], "value": "Hi HN,\nIn most codebases I\u2019ve worked on, temporary hacks (\u201cTODO: remove later\u201d, \u201cjust for this release\u201d) slowly become permanent. Nobody remembers why they exist, but they keep shipping to <em>production</em>.\nI built a small CLI called DebtBomb to make that explicit.\nInstead of free-form TODOs, you attach an expiry date to temporary code. When the date passes, CI fails until the code is removed or the expiry is intentionally extended.\nRecently I added integrations so expired debt bombs don\u2019t just fail CI \u2014 they become visible and owned:\nWhen a debt bomb expires, DebtBomb can automatically create a <em>Jira</em> ticket with file path, owner, reason, and code snippet.\nIt can also notify Slack, Discord, or Microsoft Teams.\nYou can configure \u201cexpiring soon\u201d warnings (e.g., 7 days before) so it\u2019s not just a surprise break.\nRepo: <a href=\"https://github.com/jobin-404/debtbomb\" rel=\"nofollow\">https://github.com/jobin-404/debtbomb</a>\nThis is still early and I\u2019m mainly trying to validate whether this actually improves how teams handle \u201ctemporary\u201d code compared to TODOs, linters, or just creating tickets manually.\nI\u2019d especially love feedback from people who\u2019ve dealt with tech debt in long-lived codebases or CI-heavy environments.\nThanks for reading."}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["jira"], "value": "Show HN: DebtBomb \u2013 Make TODOs expire and automatically create <em>Jira</em> tickets"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/jobin-404/debtbomb"}}, "_tags": ["story", "author_jjdev8157", "story_46603772", "show_hn"], "author": "jjdev8157", "children": [46604346, 46604423, 46604431, 46604474, 46604485, 46604486, 46604579, 46604775, 46604802, 46605072, 46608773], "created_at": "2026-01-13T16:59:29Z", "created_at_i": 1768323569, "num_comments": 15, "objectID": "46603772", "points": 16, "story_id": 46603772, "story_text": "Hi HN,\nIn most codebases I\u2019ve worked on, temporary hacks (\u201cTODO: remove later\u201d, \u201cjust for this release\u201d) slowly become permanent. Nobody remembers why they exist, but they keep shipping to production.\nI built a small CLI called DebtBomb to make that explicit.\nInstead of free-form TODOs, you attach an expiry date to temporary code. When the date passes, CI fails until the code is removed or the expiry is intentionally extended.\nRecently I added integrations so expired debt bombs don\u2019t just fail CI \u2014 they become visible and owned:\nWhen a debt bomb expires, DebtBomb can automatically create a Jira ticket with file path, owner, reason, and code snippet.\nIt can also notify Slack, Discord, or Microsoft Teams.\nYou can configure \u201cexpiring soon\u201d warnings (e.g., 7 days before) so it\u2019s not just a surprise break.\nRepo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;jobin-404&#x2F;debtbomb\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;jobin-404&#x2F;debtbomb</a>\nThis is still early and I\u2019m mainly trying to validate whether this actually improves how teams handle \u201ctemporary\u201d code compared to TODOs, linters, or just creating tickets manually.\nI\u2019d especially love feedback from people who\u2019ve dealt with tech debt in long-lived codebases or CI-heavy environments.\nThanks for reading.", "title": "Show HN: DebtBomb \u2013 Make TODOs expire and automatically create Jira tickets", "updated_at": "2026-01-15T18:13:43Z", "url": "https://github.com/jobin-404/debtbomb"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "buildinext"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jira", "production"], "value": "Hey HN! I've been building Quell, an AI QA testing agent designed to run tests directly triggered from issue trackers (<em>Jira</em>, Linear) or designs (Figma) or CI/CD platforms (Vercel, Netlify, GitHub), ensuring rapid and accurate acceptance testing without manual effort.<p>What problem does it solve?\nAs a product manager and founder myself, I constantly faced issues releasing a new feature only to discover critical bugs or that the build doesn't fully meet acceptance criteria. Bottlenecks in our QA and release process\u2014tickets and issues stuck in manual testing, slow deployments due to delayed verification, and missed acceptance criteria leading to bugs slipping into <em>production</em>. I built Quell to automate these tedious steps, freeing up teams to focus on actual feature development and faster iterations.<p>How is it different?<p>Integrates with existing dev workflows\u2014triggers tests via <em>Jira</em>/Linear issue status automatically testing Vercel, or Netlify or other URL deployment builds.<p>Tests against explicit acceptance criteria pulled directly from your issue tracker.<p>Current Capabilities (free to test):<p>Automatically trigger QA runs from Linear/<em>Jira</em> issue state transitions or Vercel/Netlify deploy previews.<p>Generate immediate test reports and tickets for issues spotted.<p>Quell is ready to test right now\u2014email only required to try out demo functionality directly:<p>Try out [Quellit.ai](<a href=\"http://quellit.ai/\" rel=\"nofollow\">http://quellit.ai/</a>) for free<p>I'm actively iterating based on user feedback\u2014would love to hear your thoughts, suggestions, or even criticisms on the idea, implementation, integrations, or anything else.<p>Thanks for checking it out!"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["jira"], "value": "Show HN: Quell \u2013 AI QA Agent Working Across Linear, Vercel, <em>Jira</em>, Netlify, Figma"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://www.quellit.ai/"}}, "_tags": ["story", "author_buildinext", "story_44083596", "show_hn"], "author": "buildinext", "children": [44187584, 44193749], "created_at": "2025-05-24T20:25:34Z", "created_at_i": 1748118334, "num_comments": 2, "objectID": "44083596", "points": 7, "story_id": 44083596, "story_text": "Hey HN! I&#x27;ve been building Quell, an AI QA testing agent designed to run tests directly triggered from issue trackers (Jira, Linear) or designs (Figma) or CI&#x2F;CD platforms (Vercel, Netlify, GitHub), ensuring rapid and accurate acceptance testing without manual effort.<p>What problem does it solve?\nAs a product manager and founder myself, I constantly faced issues releasing a new feature only to discover critical bugs or that the build doesn&#x27;t fully meet acceptance criteria. Bottlenecks in our QA and release process\u2014tickets and issues stuck in manual testing, slow deployments due to delayed verification, and missed acceptance criteria leading to bugs slipping into production. I built Quell to automate these tedious steps, freeing up teams to focus on actual feature development and faster iterations.<p>How is it different?<p>Integrates with existing dev workflows\u2014triggers tests via Jira&#x2F;Linear issue status automatically testing Vercel, or Netlify or other URL deployment builds.<p>Tests against explicit acceptance criteria pulled directly from your issue tracker.<p>Current Capabilities (free to test):<p>Automatically trigger QA runs from Linear&#x2F;Jira issue state transitions or Vercel&#x2F;Netlify deploy previews.<p>Generate immediate test reports and tickets for issues spotted.<p>Quell is ready to test right now\u2014email only required to try out demo functionality directly:<p>Try out [Quellit.ai](<a href=\"http:&#x2F;&#x2F;quellit.ai&#x2F;\" rel=\"nofollow\">http:&#x2F;&#x2F;quellit.ai&#x2F;</a>) for free<p>I&#x27;m actively iterating based on user feedback\u2014would love to hear your thoughts, suggestions, or even criticisms on the idea, implementation, integrations, or anything else.<p>Thanks for checking it out!", "title": "Show HN: Quell \u2013 AI QA Agent Working Across Linear, Vercel, Jira, Netlify, Figma", "updated_at": "2025-06-06T04:40:09Z", "url": "https://www.quellit.ai/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "MHenzi"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jira", "production"], "value": "Hi HN, I\u2019m Mark, VP of engineering and co-founder of Atono. This week, we officially launched Atono\u2019s GA\u2014an all-in-one platform to plan, build, run, and improve software.<p>Today\u2019s software development process often feels like an assembly line of disconnected tools\u2014never-ending inboxes, Slack threads, scattered issues, and complex apps that create more overhead than progress. The cognitive load is heavy, and each tool adds complexity. Meanwhile, every role\u2014PMs, devs, QA\u2014ends up working in silos with little visibility into each other\u2019s work.<p>Atono takes a different approach. It\u2019s built for cross-functional teams to work together, not just alongside each other. We prioritize a clean, thoughtful experience, with in-context tools directly tied to the work you're doing\u2014like toggling feature flags directly from the story you're working on or reporting bugs straight from your browser. And because software is never truly &quot;done&quot; once it\u2019s in <em>production</em>, Atono supports the full software lifecycle\u2014from planning and building to running and improving\u2014with built-in feature flags and usage tracking at the acceptance criteria level.<p>If you\u2019re a fast-moving, engineering-driven startup that needs just the essential features to build quickly and ship often, Atono is likely a slam dunk for you.\nWe\u2019ve been working on Atono for 14 months and are eager for feedback. We designed it with the goal of addressing the pain points of modern software development, taking lessons from tools like <em>Jira</em> but focusing on the needs of today\u2019s teams.\nIf this sounds like something you\u2019d find useful, give Atono a spin at <a href=\"https://atono.io\" rel=\"nofollow\">https://atono.io</a>."}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["jira"], "value": "Show HN: Atono \u2013 A clean, lean, and unstressed alternative to <em>Jira</em>"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://atono.io/"}}, "_tags": ["story", "author_MHenzi", "story_43485246", "show_hn"], "author": "MHenzi", "children": [43563862], "created_at": "2025-03-26T18:27:25Z", "created_at_i": 1743013645, "num_comments": 2, "objectID": "43485246", "points": 2, "story_id": 43485246, "story_text": "Hi HN, I\u2019m Mark, VP of engineering and co-founder of Atono. This week, we officially launched Atono\u2019s GA\u2014an all-in-one platform to plan, build, run, and improve software.<p>Today\u2019s software development process often feels like an assembly line of disconnected tools\u2014never-ending inboxes, Slack threads, scattered issues, and complex apps that create more overhead than progress. The cognitive load is heavy, and each tool adds complexity. Meanwhile, every role\u2014PMs, devs, QA\u2014ends up working in silos with little visibility into each other\u2019s work.<p>Atono takes a different approach. It\u2019s built for cross-functional teams to work together, not just alongside each other. We prioritize a clean, thoughtful experience, with in-context tools directly tied to the work you&#x27;re doing\u2014like toggling feature flags directly from the story you&#x27;re working on or reporting bugs straight from your browser. And because software is never truly &quot;done&quot; once it\u2019s in production, Atono supports the full software lifecycle\u2014from planning and building to running and improving\u2014with built-in feature flags and usage tracking at the acceptance criteria level.<p>If you\u2019re a fast-moving, engineering-driven startup that needs just the essential features to build quickly and ship often, Atono is likely a slam dunk for you.\nWe\u2019ve been working on Atono for 14 months and are eager for feedback. We designed it with the goal of addressing the pain points of modern software development, taking lessons from tools like Jira but focusing on the needs of today\u2019s teams.\nIf this sounds like something you\u2019d find useful, give Atono a spin at <a href=\"https:&#x2F;&#x2F;atono.io\" rel=\"nofollow\">https:&#x2F;&#x2F;atono.io</a>.", "title": "Show HN: Atono \u2013 A clean, lean, and unstressed alternative to Jira", "updated_at": "2025-04-03T22:56:33Z", "url": "https://atono.io/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "quickthrower"}, "story_text": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["jira"], "value": "In my current job and previous job there has been a huge emphasis on estimates for work and estimates vs. actual.<p>This is on the level of all tasks, even 2hr ones.<p>I find it causes stress as I am always looking at the clock and sometimes taking shortcuts so I don't feel the shame of going over or asking for more time.<p>It also means I don't bother thinking or exploring ideas to make things better as there isn't a <em>JIRA</em> ticket for that and i would have to get permission first. Probably they'd say no because backlog takes priority.<p>I've been taken to task for how long something has taken many times. I'm sick of it.<p>It was a big reason I quit my last job and similarly might quit this one.<p>These are in otherwise prima facie great jobs: good pay, good side perks like you'd imagine from Google.<p>Is this the trend towards holding a stopwatch up to he developers head?, have I been unlucky, am I being unrealistic to go back to the old days where your boss broadly trusts you?"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Ask HN: Does your job feel like a <em>production</em> line?"}}, "_tags": ["story", "author_quickthrower", "story_14725483", "ask_hn"], "author": "quickthrower", "children": [14725719], "created_at": "2017-07-08T14:18:54Z", "created_at_i": 1499523534, "num_comments": 1, "objectID": "14725483", "points": 2, "story_id": 14725483, "story_text": "In my current job and previous job there has been a huge emphasis on estimates for work and estimates vs. actual.<p>This is on the level of all tasks, even 2hr ones.<p>I find it causes stress as I am always looking at the clock and sometimes taking shortcuts so I don&#x27;t feel the shame of going over or asking for more time.<p>It also means I don&#x27;t bother thinking or exploring ideas to make things better as there isn&#x27;t a JIRA ticket for that and i would have to get permission first. Probably they&#x27;d say no because backlog takes priority.<p>I&#x27;ve been taken to task for how long something has taken many times. I&#x27;m sick of it.<p>It was a big reason I quit my last job and similarly might quit this one.<p>These are in otherwise prima facie great jobs: good pay, good side perks like you&#x27;d imagine from Google.<p>Is this the trend towards holding a stopwatch up to he developers head?, have I been unlucky, am I being unrealistic to go back to the old days where your boss broadly trusts you?", "title": "Ask HN: Does your job feel like a production line?", "updated_at": "2024-09-20T01:01:27Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "bashit"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jira", "production"], "value": "My company is still widely using CVCS (Central Version Control Systems) tools mostly SVN. We've just now been slowly integrating Git into our department.<p>Our SCM (Software Configuration Management) team audits our <em>production</em> ready software releases, verifies tickets are being reviewed/closed, ensuring instructions for recreating the release are clear and other tasks alike. Our company uses this tool called &quot;Agile&quot; that is largely responsible for maintaining the lifetime of a product we design along with its documentation, datasheets, bill of materials, and many other items including &quot;software&quot;.<p>Agile was explained to me as a database tool that (very loosely defined) works well with more hardware related products. Before wide adoption of DVCS (Distributed Version Control Systems) like Git and ticketing tools like <em>JIRA</em>, Agile and CVCS (Centralized Version Control Systems) tools like SVN have always been the way software and <em>production</em> ready releases were and are (in the case of my company) managed/controlled.<p>The point here is that our SCM has been the sole owner of how new tools for software control/management are to be used in coherence with our companies processes and industry standards. Tools like, Git/<em>JIRA</em>, serve the developer thus bringing a new era of how we control and manage software. So far the recent adoption of Git in my company (not so much <em>JIRA</em>) has received not the most favorable greeting. This largely because it's severing SCM more than the developer(s). Why should SCM own this and/or decide it's usage or better yet why can't the software team be in control?<p>Am I alone here? Is this a trend anyone else has seen? Should this impose change on our SCM team or only invite parts of it? If so how can a junior developer help in delivering this change when surrounded by senior level engineers. Has my padawan self missed something crucial in understanding here? I get it, this is the way industry life works but it shouldn't have to be.<p>To me Git is a powerful development tool allowing flexibility in a distributed environment (or a central one as well), improving a teams workflow thus their productivity, team collaboration &amp; cohesiveness, among several other attributes. Nothing against our SCM team but I feel if Git becomes more of a SCM tool it will significantly degrade it's true advantages and main intention as a DVCS (Distributed Version Control System) tool as well as drive away new talented developers.<p>What are your thoughts?"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Help! My company doesn't know how to use Git for <em>production</em> ready releases"}}, "_tags": ["story", "author_bashit", "story_18248086", "ask_hn"], "author": "bashit", "created_at": "2018-10-18T13:25:36Z", "created_at_i": 1539869136, "num_comments": 0, "objectID": "18248086", "points": 1, "story_id": 18248086, "story_text": "My company is still widely using CVCS (Central Version Control Systems) tools mostly SVN. We&#x27;ve just now been slowly integrating Git into our department.<p>Our SCM (Software Configuration Management) team audits our production ready software releases, verifies tickets are being reviewed&#x2F;closed, ensuring instructions for recreating the release are clear and other tasks alike. Our company uses this tool called &quot;Agile&quot; that is largely responsible for maintaining the lifetime of a product we design along with its documentation, datasheets, bill of materials, and many other items including &quot;software&quot;.<p>Agile was explained to me as a database tool that (very loosely defined) works well with more hardware related products. Before wide adoption of DVCS (Distributed Version Control Systems) like Git and ticketing tools like JIRA, Agile and CVCS (Centralized Version Control Systems) tools like SVN have always been the way software and production ready releases were and are (in the case of my company) managed&#x2F;controlled.<p>The point here is that our SCM has been the sole owner of how new tools for software control&#x2F;management are to be used in coherence with our companies processes and industry standards. Tools like, Git&#x2F;JIRA, serve the developer thus bringing a new era of how we control and manage software. So far the recent adoption of Git in my company (not so much JIRA) has received not the most favorable greeting. This largely because it&#x27;s severing SCM more than the developer(s). Why should SCM own this and&#x2F;or decide it&#x27;s usage or better yet why can&#x27;t the software team be in control?<p>Am I alone here? Is this a trend anyone else has seen? Should this impose change on our SCM team or only invite parts of it? If so how can a junior developer help in delivering this change when surrounded by senior level engineers. Has my padawan self missed something crucial in understanding here? I get it, this is the way industry life works but it shouldn&#x27;t have to be.<p>To me Git is a powerful development tool allowing flexibility in a distributed environment (or a central one as well), improving a teams workflow thus their productivity, team collaboration &amp; cohesiveness, among several other attributes. Nothing against our SCM team but I feel if Git becomes more of a SCM tool it will significantly degrade it&#x27;s true advantages and main intention as a DVCS (Distributed Version Control System) tool as well as drive away new talented developers.<p>What are your thoughts?", "title": "Help! My company doesn't know how to use Git for production ready releases", "updated_at": "2024-09-20T03:10:52Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "evmunro"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jira", "production"], "value": "Hey HN,<p>We\u2019re Everest, Andrei and Sabera, the founders behind Fuzzbuzz (<a href=\"https://fuzzbuzz.io\" rel=\"nofollow\">https://fuzzbuzz.io</a>) -  a fuzzing as a service platform that makes fuzzing your code as easy as writing a unit test, and pushing to GitHub.<p>Fuzzing is a type of software testing that generates &amp; runs millions of tests per day on your code, and is great at finding edge cases &amp; vulnerabilities that developers miss. It\u2019s been used to find tens of thousands of critical bugs in open-source software (<a href=\"https://bugs.chromium.org/p/oss-fuzz/issues/list\" rel=\"nofollow\">https://bugs.chromium.org/p/oss-fuzz/issues/list</a>), and is a great way to generate tests that cover a lot of code, without requiring your developers to think of every possibility. It achieves such great results by applying genetic algorithms to generate new tests from some initial examples, and using code coverage to track and report interesting test cases. Combining these two techniques with a bit of randomness, and running tests thousands of times every second has proven to be an incredibly effective automated bug finding technique.<p>I was first introduced to fuzzing a couple years ago while working on the Clusterfuzz team at Google, where I built Clusterfuzz Tools v1 (<a href=\"https://github.com/google/clusterfuzz-tools\" rel=\"nofollow\">https://github.com/google/clusterfuzz-tools</a>). I later built Maxfuzz (<a href=\"https://github.com/coinbase/maxfuzz\" rel=\"nofollow\">https://github.com/coinbase/maxfuzz</a>), a set of tools that makes it easier to fuzz code in Docker containers, while on the Coinbase security team.<p>As we learned more about fuzzing, we found ourselves wondering why very few teams outside of massive companies like Microsoft and Google were actively fuzzing their code - especially given the results (teams at Google that use fuzzing report that it finds 80% of their bugs, with the other 20% uncovered by normal tests, or in <em>production</em>).<p>It turns out that many teams don\u2019t want to invest the time and money needed to set up automated fuzzing infrastructure, and using fuzzing tools in an ad-hoc way on your own computer isn\u2019t nearly as effective as continuously fuzzing your code on multiple dedicated CPUs.<p>That\u2019s where Fuzzbuzz comes in! We\u2019ve built a platform that integrates with your existing GitHub workflow, and provide an open API for integrations with CI tools like Jenkins and TravisCI, so the latest version of your code is always being fuzzed. We manage the infrastructure, so you can fuzz your code on any number of CPUs with a single click. When bugs are found, we\u2019ll notify you through Slack and create <em>Jira</em> tickets or GitHub Issues for you. We also solve many of the issues that crop up when fuzzing, such as bug deduplication, and elimination of false positives.<p>Fuzzbuzz currently supports C, C++, Go and Python, with more languages like Java and Javascript on the way. Anyone can sign up for Fuzzbuzz and fuzz their code on 1 dedicated CPU, for free.<p>We\u2019ve noticed that the HN community has been increasingly interested in fuzzing, and we\u2019re really looking forward to hearing your feedback! The entire purpose of Fuzzbuzz is to make fuzzing as easy as possible, so all criticism is welcome."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: Fuzzbuzz (YC W19) \u2013 Fuzzing as a Service"}}, "_tags": ["story", "author_evmunro", "story_19265377", "launch_hn"], "author": "evmunro", "children": [19265618, 19265631, 19265666, 19265675, 19265711, 19265804, 19265809, 19265847, 19265886, 19265957, 19266109, 19266222, 19266313, 19266411, 19266607, 19266668, 19266680, 19266757, 19266772, 19266807, 19266871, 19266922, 19267046, 19267062, 19267221, 19267637, 19268595, 19269491, 19270704], "created_at": "2019-02-27T18:03:00Z", "created_at_i": 1551290580, "num_comments": 81, "objectID": "19265377", "points": 171, "story_id": 19265377, "story_text": "Hey HN,<p>We\u2019re Everest, Andrei and Sabera, the founders behind Fuzzbuzz (<a href=\"https:&#x2F;&#x2F;fuzzbuzz.io\" rel=\"nofollow\">https:&#x2F;&#x2F;fuzzbuzz.io</a>) -  a fuzzing as a service platform that makes fuzzing your code as easy as writing a unit test, and pushing to GitHub.<p>Fuzzing is a type of software testing that generates &amp; runs millions of tests per day on your code, and is great at finding edge cases &amp; vulnerabilities that developers miss. It\u2019s been used to find tens of thousands of critical bugs in open-source software (<a href=\"https:&#x2F;&#x2F;bugs.chromium.org&#x2F;p&#x2F;oss-fuzz&#x2F;issues&#x2F;list\" rel=\"nofollow\">https:&#x2F;&#x2F;bugs.chromium.org&#x2F;p&#x2F;oss-fuzz&#x2F;issues&#x2F;list</a>), and is a great way to generate tests that cover a lot of code, without requiring your developers to think of every possibility. It achieves such great results by applying genetic algorithms to generate new tests from some initial examples, and using code coverage to track and report interesting test cases. Combining these two techniques with a bit of randomness, and running tests thousands of times every second has proven to be an incredibly effective automated bug finding technique.<p>I was first introduced to fuzzing a couple years ago while working on the Clusterfuzz team at Google, where I built Clusterfuzz Tools v1 (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;clusterfuzz-tools\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;clusterfuzz-tools</a>). I later built Maxfuzz (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;coinbase&#x2F;maxfuzz\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;coinbase&#x2F;maxfuzz</a>), a set of tools that makes it easier to fuzz code in Docker containers, while on the Coinbase security team.<p>As we learned more about fuzzing, we found ourselves wondering why very few teams outside of massive companies like Microsoft and Google were actively fuzzing their code - especially given the results (teams at Google that use fuzzing report that it finds 80% of their bugs, with the other 20% uncovered by normal tests, or in production).<p>It turns out that many teams don\u2019t want to invest the time and money needed to set up automated fuzzing infrastructure, and using fuzzing tools in an ad-hoc way on your own computer isn\u2019t nearly as effective as continuously fuzzing your code on multiple dedicated CPUs.<p>That\u2019s where Fuzzbuzz comes in! We\u2019ve built a platform that integrates with your existing GitHub workflow, and provide an open API for integrations with CI tools like Jenkins and TravisCI, so the latest version of your code is always being fuzzed. We manage the infrastructure, so you can fuzz your code on any number of CPUs with a single click. When bugs are found, we\u2019ll notify you through Slack and create Jira tickets or GitHub Issues for you. We also solve many of the issues that crop up when fuzzing, such as bug deduplication, and elimination of false positives.<p>Fuzzbuzz currently supports C, C++, Go and Python, with more languages like Java and Javascript on the way. Anyone can sign up for Fuzzbuzz and fuzz their code on 1 dedicated CPU, for free.<p>We\u2019ve noticed that the HN community has been increasingly interested in fuzzing, and we\u2019re really looking forward to hearing your feedback! The entire purpose of Fuzzbuzz is to make fuzzing as easy as possible, so all criticism is welcome.", "title": "Launch HN: Fuzzbuzz (YC W19) \u2013 Fuzzing as a Service", "updated_at": "2025-12-26T11:22:38Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "wirehack"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jira", "production"], "value": "Hey HN! We are Klavis AI (<a href=\"https://www.klavis.ai/\">https://www.klavis.ai/</a>) and we're launching Strata, one open-source MCP server that helps AI agents use thousands of API tools without getting overwhelmed. Instead of showing all available tools at once, Strata reveals them step-by-step based on what the AI actually needs.<p>As a former Senior SWE on Google Gemini 's tool use team, I saw firsthand how AI would struggle with tools. If you've built AI agents, you've likely hit the same walls: (1) AI agents struggle to pick the right API from hundreds of options. (2) Tool descriptions and info consume massive token budgets. (3) Most servers cap at 40~50 tools to avoid these problems, limiting what you can build.<p>Instead of flooding the AI with everything upfront, Strata works like a human would. It guides the AI agents to discover relevant categories, then lists available actions in those categories. It relies on LLMs\u2019 reasoning to drill down progressively to find the exact tool needed. Here are some examples:<p><i>Github query: &quot;Find my stale pull requests in our main repo&quot;</i><p>Strata: AI model identifies GitHub \u2192 Shows categories (Repos, Issues, PRs, Actions) \u2192 AI selects PRs \u2192 Shows PR-specific actions -&gt; AI selects list_pull_requests \u2192 Shows  list_pull_requests details -&gt; Executes list_pull_requests with the right parameters.<p><i><em>Jira</em> query: &quot;Create a bug ticket in the 'MOBILE' project about the app crashing on startup.&quot;</i><p>Strata: AI identifies <em>Jira</em> \u2192 Shows categories (Projects, Issues, Sprints) \u2192 AI selects Issues \u2192 Shows actions (create_issue, get_issue) \u2192 AI selects create_issue \u2192 Shows create_issue details \u2192 Executes with correct parameters.<p><i>Slack query: &quot;Post a message in the #announcements channel that bonus will be paid out next Friday.&quot;</i><p>Strata: AI identifies Slack \u2192 Shows categories (Channels, Messages, Users) \u2192 AI selects Messages \u2192 Shows actions (send_message, schedule_message) \u2192 AI selects send_message \u2192 Shows send_message details \u2192 Executes with correct parameters.<p>This progressive approach unlocks a huge advantage: depth. While most integrations offer a handful of high-level tools, Strata can expose hundreds of granular features for a single app like GitHub, <em>Jira</em>, etc. Your AI agent can finally access the deep, specific features that real workflows require, without getting lost in a sea of options.<p>Under the hood, Strata manages authentication tokens and includes a built-in search tool for the agent to dig into documentation if it gets stuck.<p>On the MCPMark <a href=\"https://mcpmark.ai/leaderboard/mcp\" rel=\"nofollow\">https://mcpmark.ai/leaderboard/mcp</a>, Strata achieves +15.2% higher pass@1 rate vs the official GitHub server and +13.4% higher pass@1 rate vs the official Notion server. In human eval tests, it hits 83%+ accuracy on complex, real-world multi-app workflows.<p>Here is a quick demo to watch Strata navigate a complex workflow with multiple apps, automatically selecting the right tools at each step: <a href=\"https://www.youtube.com/watch?v=N00cY9Ov_fM\" rel=\"nofollow\">https://www.youtube.com/watch?v=N00cY9Ov_fM</a>.<p>You can connect to any external MCP Server into Strata, and we have an open source version for it: <a href=\"https://github.com/Klavis-AI/klavis\" rel=\"nofollow\">https://github.com/Klavis-AI/klavis</a>.<p>For team or <em>production</em> use with more features, visit our website: <a href=\"https://www.klavis.ai\">https://www.klavis.ai</a>. Add Strata to Cursor, VS Code or any MCP-compatible application with one click. You can also use our API to easily plug in Strata to your AI application.<p>We look forward to your comments. Thanks for reading!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: Strata (YC X25) \u2013 One MCP server for AI to handle thousands of tools"}}, "_tags": ["story", "author_wirehack", "story_45347914", "launch_hn"], "author": "wirehack", "children": [45348013, 45348437, 45348459, 45348542, 45348863, 45349291, 45349533, 45349664, 45349691, 45349733, 45349834, 45349914, 45350052, 45350175, 45350504, 45351056, 45351230, 45352047, 45352456, 45352930, 45353328, 45361825], "created_at": "2025-09-23T14:52:07Z", "created_at_i": 1758639127, "num_comments": 66, "objectID": "45347914", "points": 133, "story_id": 45347914, "story_text": "Hey HN! We are Klavis AI (<a href=\"https:&#x2F;&#x2F;www.klavis.ai&#x2F;\">https:&#x2F;&#x2F;www.klavis.ai&#x2F;</a>) and we&#x27;re launching Strata, one open-source MCP server that helps AI agents use thousands of API tools without getting overwhelmed. Instead of showing all available tools at once, Strata reveals them step-by-step based on what the AI actually needs.<p>As a former Senior SWE on Google Gemini &#x27;s tool use team, I saw firsthand how AI would struggle with tools. If you&#x27;ve built AI agents, you&#x27;ve likely hit the same walls: (1) AI agents struggle to pick the right API from hundreds of options. (2) Tool descriptions and info consume massive token budgets. (3) Most servers cap at 40~50 tools to avoid these problems, limiting what you can build.<p>Instead of flooding the AI with everything upfront, Strata works like a human would. It guides the AI agents to discover relevant categories, then lists available actions in those categories. It relies on LLMs\u2019 reasoning to drill down progressively to find the exact tool needed. Here are some examples:<p><i>Github query: &quot;Find my stale pull requests in our main repo&quot;</i><p>Strata: AI model identifies GitHub \u2192 Shows categories (Repos, Issues, PRs, Actions) \u2192 AI selects PRs \u2192 Shows PR-specific actions -&gt; AI selects list_pull_requests \u2192 Shows  list_pull_requests details -&gt; Executes list_pull_requests with the right parameters.<p><i>Jira query: &quot;Create a bug ticket in the &#x27;MOBILE&#x27; project about the app crashing on startup.&quot;</i><p>Strata: AI identifies Jira \u2192 Shows categories (Projects, Issues, Sprints) \u2192 AI selects Issues \u2192 Shows actions (create_issue, get_issue) \u2192 AI selects create_issue \u2192 Shows create_issue details \u2192 Executes with correct parameters.<p><i>Slack query: &quot;Post a message in the #announcements channel that bonus will be paid out next Friday.&quot;</i><p>Strata: AI identifies Slack \u2192 Shows categories (Channels, Messages, Users) \u2192 AI selects Messages \u2192 Shows actions (send_message, schedule_message) \u2192 AI selects send_message \u2192 Shows send_message details \u2192 Executes with correct parameters.<p>This progressive approach unlocks a huge advantage: depth. While most integrations offer a handful of high-level tools, Strata can expose hundreds of granular features for a single app like GitHub, Jira, etc. Your AI agent can finally access the deep, specific features that real workflows require, without getting lost in a sea of options.<p>Under the hood, Strata manages authentication tokens and includes a built-in search tool for the agent to dig into documentation if it gets stuck.<p>On the MCPMark <a href=\"https:&#x2F;&#x2F;mcpmark.ai&#x2F;leaderboard&#x2F;mcp\" rel=\"nofollow\">https:&#x2F;&#x2F;mcpmark.ai&#x2F;leaderboard&#x2F;mcp</a>, Strata achieves +15.2% higher pass@1 rate vs the official GitHub server and +13.4% higher pass@1 rate vs the official Notion server. In human eval tests, it hits 83%+ accuracy on complex, real-world multi-app workflows.<p>Here is a quick demo to watch Strata navigate a complex workflow with multiple apps, automatically selecting the right tools at each step: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=N00cY9Ov_fM\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=N00cY9Ov_fM</a>.<p>You can connect to any external MCP Server into Strata, and we have an open source version for it: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Klavis-AI&#x2F;klavis\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Klavis-AI&#x2F;klavis</a>.<p>For team or production use with more features, visit our website: <a href=\"https:&#x2F;&#x2F;www.klavis.ai\">https:&#x2F;&#x2F;www.klavis.ai</a>. Add Strata to Cursor, VS Code or any MCP-compatible application with one click. You can also use our API to easily plug in Strata to your AI application.<p>We look forward to your comments. Thanks for reading!", "title": "Launch HN: Strata (YC X25) \u2013 One MCP server for AI to handle thousands of tools", "updated_at": "2025-10-29T01:17:35Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "harshithmul"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jira", "production"], "value": "Hi HN, We\u2019re Harshith, Manoj, and Manik<p>Poozle (<a href=\"https://github.com/poozlehq/poozle\">https://github.com/poozlehq/poozle</a>) provides a single API that helps businesses achieve accurate LLM responses by providing real-time customer data from different SAAS tools (e.g Notion, Salesforce, <em>Jira</em>, Shopify, Google Ads etc).<p>Why we built Poozle: As we were talking to more AI companies who need to integrate with their customers\u2019 data we realised managing all SAAS tools data and keeping them up-to-date is a huge infra of ETL, Auth management, Webhooks and many more things before you take it to <em>production</em>.  It struck us \u2013 why not streamline this process and allow companies to prioritise their core product?<p>How it works: Poozle makes user authorization seamless using our drop-in component (Poozle Link) and handles both API Key and OAuth dance. Post-authentication developers can use our Unified model to fetch data to their LLMs (no need to sync data separately and then normalise at your end). Poozle keeps data updated in real time while giving you options to choose sync intervals. Even if the source doesn\u2019t support webhooks, we\u2019ve got you covered.<p>Currently, we support Unified API for 3 categories - Ticketing, Documentation and Email. You can watch a demo of Poozle (<a href=\"https://www.loom.com/share/30650e4d1fac41e3a7debc212b1c7c2d)l\" rel=\"nofollow noreferrer\">https://www.loom.com/share/30650e4d1fac41e3a7debc212b1c7c2d)...</a><p>We just got started a month ago and we\u2019re eager to get feedback and keep building. Let us know what you think in the comments : )"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Poozle \u2013 open-source Plaid for LLMs"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/poozlehq/poozle"}}, "_tags": ["story", "author_harshithmul", "story_37180017", "show_hn"], "author": "harshithmul", "children": [37180853, 37180909, 37181122, 37181363, 37181448, 37181968, 37182430, 37190113, 37190488, 37190767], "created_at": "2023-08-18T18:27:54Z", "created_at_i": 1692383274, "num_comments": 39, "objectID": "37180017", "points": 132, "story_id": 37180017, "story_text": "Hi HN, We\u2019re Harshith, Manoj, and Manik<p>Poozle (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;poozlehq&#x2F;poozle\">https:&#x2F;&#x2F;github.com&#x2F;poozlehq&#x2F;poozle</a>) provides a single API that helps businesses achieve accurate LLM responses by providing real-time customer data from different SAAS tools (e.g Notion, Salesforce, Jira, Shopify, Google Ads etc).<p>Why we built Poozle: As we were talking to more AI companies who need to integrate with their customers\u2019 data we realised managing all SAAS tools data and keeping them up-to-date is a huge infra of ETL, Auth management, Webhooks and many more things before you take it to production.  It struck us \u2013 why not streamline this process and allow companies to prioritise their core product?<p>How it works: Poozle makes user authorization seamless using our drop-in component (Poozle Link) and handles both API Key and OAuth dance. Post-authentication developers can use our Unified model to fetch data to their LLMs (no need to sync data separately and then normalise at your end). Poozle keeps data updated in real time while giving you options to choose sync intervals. Even if the source doesn\u2019t support webhooks, we\u2019ve got you covered.<p>Currently, we support Unified API for 3 categories - Ticketing, Documentation and Email. You can watch a demo of Poozle (<a href=\"https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;30650e4d1fac41e3a7debc212b1c7c2d)l\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;30650e4d1fac41e3a7debc212b1c7c2d)...</a><p>We just got started a month ago and we\u2019re eager to get feedback and keep building. Let us know what you think in the comments : )", "title": "Show HN: Poozle \u2013 open-source Plaid for LLMs", "updated_at": "2024-10-17T09:01:56Z", "url": "https://github.com/poozlehq/poozle"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "lovedev"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jira", "production"], "value": "Hey HN!<p>I'm Julian, co-founder of Haystack (<a href=\"https://usehaystack.io\" rel=\"nofollow\">https://usehaystack.io</a>). We\u2019re building one-click dashboards and alerts using Github data.<p>While managing teams from startups to more established companies like Cloudflare, my cofounder Kan and I were constantly trying to improve our team and process. But it was pretty tough to tell if our efforts were paying off. Even tougher to tell where we could improve.<p>We tried messing around with <em>JIRA</em> which gave us story points and tickets completed but it didn\u2019t help us dig deeper on where we could improve. We found a few tools that integrated with Github measuring # of commits, lines of code, and even comparing engineers using these metrics! - but we didn\u2019t like that approach.<p>We wanted to know (1) how quickly we deliver as a team (2) what bottlenecks tend to get in the way and (3) as we make adjustments, are they helping us improve?<p>We scoured the internet looking for every piece of research on the topic we could find, talked to &gt;500 engineering leaders working everywhere from startups to FAANG, and started to learn which metrics helped answer our questions and which ones just sucked. Once we had a clear picture of what that looked like, we built Haystack.<p>Haystack analyzes pull requests on the team level, giving you \u201cnorthstar\u201d metrics like cycle time, deployment frequency, change failure rate and 20+ more to help you improve delivery. Teams use Haystack to quickly find bottlenecks like code review, experiment with changes like smaller pull requests or automated tests, and see the result. Using this feedback loop, the top 70% of Haystack users have increased <em>production</em> deployments by 58% and achieved 30% faster cycle times on average.<p>We\u2019re lucky enough to work with some awesome teams at Microsoft, Robinhood, and The Economist. As we continue to build out our product, we\u2019d love to hear any of your experiences with engineering metrics, your thoughts about how to actually get them right, and of course your disaster stories :)"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: Haystack (YC W21) \u2013 Engineering analytics that don\u2019t suck"}}, "_tags": ["story", "author_lovedev", "story_26413311", "launch_hn"], "author": "lovedev", "children": [26413740, 26414047, 26414269, 26414477, 26414685, 26414989, 26415034, 26415122, 26415295, 26415564, 26416433, 26416503, 26417255, 26419239, 26421220, 26421346, 26421780], "created_at": "2021-03-10T16:54:00Z", "created_at_i": 1615395240, "num_comments": 39, "objectID": "26413311", "points": 104, "story_id": 26413311, "story_text": "Hey HN!<p>I&#x27;m Julian, co-founder of Haystack (<a href=\"https:&#x2F;&#x2F;usehaystack.io\" rel=\"nofollow\">https:&#x2F;&#x2F;usehaystack.io</a>). We\u2019re building one-click dashboards and alerts using Github data.<p>While managing teams from startups to more established companies like Cloudflare, my cofounder Kan and I were constantly trying to improve our team and process. But it was pretty tough to tell if our efforts were paying off. Even tougher to tell where we could improve.<p>We tried messing around with JIRA which gave us story points and tickets completed but it didn\u2019t help us dig deeper on where we could improve. We found a few tools that integrated with Github measuring # of commits, lines of code, and even comparing engineers using these metrics! - but we didn\u2019t like that approach.<p>We wanted to know (1) how quickly we deliver as a team (2) what bottlenecks tend to get in the way and (3) as we make adjustments, are they helping us improve?<p>We scoured the internet looking for every piece of research on the topic we could find, talked to &gt;500 engineering leaders working everywhere from startups to FAANG, and started to learn which metrics helped answer our questions and which ones just sucked. Once we had a clear picture of what that looked like, we built Haystack.<p>Haystack analyzes pull requests on the team level, giving you \u201cnorthstar\u201d metrics like cycle time, deployment frequency, change failure rate and 20+ more to help you improve delivery. Teams use Haystack to quickly find bottlenecks like code review, experiment with changes like smaller pull requests or automated tests, and see the result. Using this feedback loop, the top 70% of Haystack users have increased production deployments by 58% and achieved 30% faster cycle times on average.<p>We\u2019re lucky enough to work with some awesome teams at Microsoft, Robinhood, and The Economist. As we continue to build out our product, we\u2019d love to hear any of your experiences with engineering metrics, your thoughts about how to actually get them right, and of course your disaster stories :)", "title": "Launch HN: Haystack (YC W21) \u2013 Engineering analytics that don\u2019t suck", "updated_at": "2024-09-20T08:06:10Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "ivan_tsarynny"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jira", "production"], "value": "Hi HN! I'm Ivan, the co-founder of Feroot Security (YC W21) (<a href=\"https://www.feroot.com/\" rel=\"nofollow\">https://www.feroot.com/</a>). Feroot Inspector is a security scanner for the client-side javascript code of web apps made for app sec teams.<p>If you're not testing the security of the client-side code of your web app, there\u2019s a good chance you could be exposed to Magecart skimmers, malware and spyware loaded with third-party scripts - css, pixels, tags, trackers, and more. We use synthetic users (i.e. bots\u2014good ones!) to detect keyloggers, spyware, security misconfigurations, vulnerabilities, anomalies in the client-side code of web applications. Simulating activities that real users do, our scanner triggers all code activities first. And then it performs security testing and assessments of actual JavaScript code and everything else that is loaded into the browser when your users are using your web app. Pretty much what security scanners (like Qualys and Acunetix) are doing to test the application side code of web apps, but we do it for client-side code.<p>So why did we build Feroot? First, nobody knows what actually happens on the client-side of web apps. Client-side code is a mystery and nobody knows when keyloggers are stealing users\u2019 keystrokes or doing anything else sketchy. \nSecond, existing web app security testing tools don\u2019t perform data asset discovery. They don\u2019t tell you what web forms exist throughout the user journeys and what information is ingested by the web app through each and every web form. All that is missing. Third, client-side code of web apps is highly variable and dynamic. As web developers are moving logic to the client-side a lot more externally controlled JavaScript code is included into users\u2019 web browsers. Meaning, that every script, third-party and open source library can open a backdoor for hackers to exploit. \nWe saw a need for a simple self-serve solution that brings security, developers, marketing and compliance teams together to help them secure the client-side of web apps.<p>Feroot Inspector uses synthetic users and headless Chrome, which use algorithmic and heuristic approaches, to do activities that real users do -- type input into forms, submit forms to trigger potential keyloggers, skimmers, and all other  client-side script activities. It also monitors all incoming and outgoing network traffic from the browser and uses data traps to terminate outbound network requests, to avoid any impact during the scan.<p>Tech specs: 1) Support single-page/multiple-page web apps, and auto-discovery pm multi-page websites; 2) Resolves captchas, undetected by bot detection systems; 3) Tracks script changes, stores scripts content, detection of unauthorized scripts; 4) Audits page and frame security matrix, permission model for main frame of the page and all child-frames; 5) Detects data input and data ingestion points and report on data transfer, active data read (keystroke read), data access model; 6) Form-based authentication for scanning password-protected websites and custom scenario based authentication; 7) Detects data transfers from browser of user sessions to third-party hosts and domains; 8) Geo-decoding in real time of the destination country of data transfers; 8) Report export to: JSON (using API), CSV, Excel, and PDF; 9) Native Integrations: Slack, <em>Jira</em>, Datadog, PagerDuty, Splunk, JupiterOne, Sumo Logic, AWS Cloudwatch Events/logs, Opsgenie, ServiceNow, and webhooks; 10) Inspector performs non-intrusive, outside-in scanning of <em>production</em> live web apps.<p>We would love to hear your feedback about Feroot scanner, as well as answer questions you might have!<p>Thanks, Ivan &amp; Vitaliy"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: Feroot (YC W21) \u2013 security scanner for front-end JavaScript code"}}, "_tags": ["story", "author_ivan_tsarynny", "story_26024912", "launch_hn"], "author": "ivan_tsarynny", "children": [26024913, 26025272, 26025662, 26025753, 26028330, 26028428, 26028764, 26028905, 26029152, 26029533, 26031600, 26032128, 26032565, 26047505], "created_at": "2021-02-04T12:55:30Z", "created_at_i": 1612443330, "num_comments": 10, "objectID": "26024912", "points": 47, "story_id": 26024912, "story_text": "Hi HN! I&#x27;m Ivan, the co-founder of Feroot Security (YC W21) (<a href=\"https:&#x2F;&#x2F;www.feroot.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.feroot.com&#x2F;</a>). Feroot Inspector is a security scanner for the client-side javascript code of web apps made for app sec teams.<p>If you&#x27;re not testing the security of the client-side code of your web app, there\u2019s a good chance you could be exposed to Magecart skimmers, malware and spyware loaded with third-party scripts - css, pixels, tags, trackers, and more. We use synthetic users (i.e. bots\u2014good ones!) to detect keyloggers, spyware, security misconfigurations, vulnerabilities, anomalies in the client-side code of web applications. Simulating activities that real users do, our scanner triggers all code activities first. And then it performs security testing and assessments of actual JavaScript code and everything else that is loaded into the browser when your users are using your web app. Pretty much what security scanners (like Qualys and Acunetix) are doing to test the application side code of web apps, but we do it for client-side code.<p>So why did we build Feroot? First, nobody knows what actually happens on the client-side of web apps. Client-side code is a mystery and nobody knows when keyloggers are stealing users\u2019 keystrokes or doing anything else sketchy. \nSecond, existing web app security testing tools don\u2019t perform data asset discovery. They don\u2019t tell you what web forms exist throughout the user journeys and what information is ingested by the web app through each and every web form. All that is missing. Third, client-side code of web apps is highly variable and dynamic. As web developers are moving logic to the client-side a lot more externally controlled JavaScript code is included into users\u2019 web browsers. Meaning, that every script, third-party and open source library can open a backdoor for hackers to exploit. \nWe saw a need for a simple self-serve solution that brings security, developers, marketing and compliance teams together to help them secure the client-side of web apps.<p>Feroot Inspector uses synthetic users and headless Chrome, which use algorithmic and heuristic approaches, to do activities that real users do -- type input into forms, submit forms to trigger potential keyloggers, skimmers, and all other  client-side script activities. It also monitors all incoming and outgoing network traffic from the browser and uses data traps to terminate outbound network requests, to avoid any impact during the scan.<p>Tech specs: 1) Support single-page&#x2F;multiple-page web apps, and auto-discovery pm multi-page websites; 2) Resolves captchas, undetected by bot detection systems; 3) Tracks script changes, stores scripts content, detection of unauthorized scripts; 4) Audits page and frame security matrix, permission model for main frame of the page and all child-frames; 5) Detects data input and data ingestion points and report on data transfer, active data read (keystroke read), data access model; 6) Form-based authentication for scanning password-protected websites and custom scenario based authentication; 7) Detects data transfers from browser of user sessions to third-party hosts and domains; 8) Geo-decoding in real time of the destination country of data transfers; 8) Report export to: JSON (using API), CSV, Excel, and PDF; 9) Native Integrations: Slack, Jira, Datadog, PagerDuty, Splunk, JupiterOne, Sumo Logic, AWS Cloudwatch Events&#x2F;logs, Opsgenie, ServiceNow, and webhooks; 10) Inspector performs non-intrusive, outside-in scanning of production live web apps.<p>We would love to hear your feedback about Feroot scanner, as well as answer questions you might have!<p>Thanks, Ivan &amp; Vitaliy", "title": "Launch HN: Feroot (YC W21) \u2013 security scanner for front-end JavaScript code", "updated_at": "2024-09-20T07:49:54Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "person_to_blame"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jira", "production"], "value": "So a few days ago I added a \"Person to Blame\" field to our bug tracking system and this decision has attracted a lot of attention from outside of our organization.  I totally welcome the debate and love the passion from everyone.  Given the interest, I thought I'd share how the \"Person to Blame\" field works for our team.<p>We are a tight-knit dev team, part of an almost-3-year-old startup.  As a team, we spend a lot of time together and just like other startups, we probably spend more time with each other than with our families.  We only hire people who we respect and take pride in the team that we have built.  We are a shop that believes in peer code reviews, unit testing and open debate.  We also hold each other accountable when we do silly things.  For instance, if you break a continuous integration build you drop a $1 in the jar for our beer fund.   Oh, you also get a nice dose of tongue-in-cheek lashing from the team if you write a time bomb into our unit test suite.  All in all, we have fun together, we push each other to be great and we respect each other enough to be direct and honest.<p>About 6 months ago, we made a conscious effort to reshape our software development process in preparation for Continuous Deployment.  We promote an environment where developers are in charge of a story from start to finish.  This includes understanding the problem, thinking about how a story needs to be tested, implementing the solution, writing the necessary unit tests and functional tests, and ways to measure the effect of the story once in <em>production</em>.  As soon as a developer okays the story, it's included in the next release.  In short, we want to be a continuous deployment shop and we think that we have the right developers to do it.  (to be clear, we are still a few months away from the true continuous deployment process like the one installed at Etsy)<p>More than just tools and process, continuous deployment requires a different kind of mentality.  While the throw-my-stuff-over-the-fence mentality never existed on our team, we do need to introduce a higher level of responsibility and accountability from everyone on the team.  Since the shift about 6 months ago, we have seen an increase in the number of hot-fixes going out between deployments.  And that's okay, bugs happen. We anticipated the increase in <em>production</em> bugs when we moved away from having a dedicated QA team.  But, as we get closer to having a true continuous deployment system in place, we need to start treating <em>production</em> bugs as the exception rather than the rule.  Bugs are inevitable and are accounted for in the world of continuous deployment, but bugs should still be avoided if possible. So a few weeks back, I started talking about keeping metrics on <em>production</em> bugs: count per sprint, per developer, per team, etc.  I mean, you have to start tracking these things so that you can improve, right?  And to keep the accounting simple, I added a \"Person to Blame\" field to <em>Jira</em> a few days ago.  Could I have named the field something more politically correct, so that feelings don't get hurt? Sure.  But what's the fun in that?  The point was to bring awareness to the number of <em>production</em> bugs after each release so why not throw in a small dose of public shaming for good measure? And to be clear, the purpose of the field, and ultimately the purpose of the metric, is not to pinpoint the cause of the bug.  Shit happens and we have better things to do.  The ultimate purpose of the metric is a reminder for each developer to be better everyday.<p>Like I said in the beginning, I welcome the debate on the matter and appreciate the passion from everyone.<p>The \"Person to Blame\" Boss :)"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Why I added a \"Peson to Blame\" field to our bug tracking system"}}, "_tags": ["story", "author_person_to_blame", "story_4179298", "ask_hn"], "author": "person_to_blame", "children": [4179374, 4179390, 4179399, 4179430, 4179441, 4179446, 4179472, 4179674, 4179869, 4179887, 4179949, 4179995, 4180032, 4180099, 4180367, 4180372, 4180920, 4181116, 4182572, 4189988, 4191140], "created_at": "2012-06-29T21:51:58Z", "created_at_i": 1341006718, "num_comments": 25, "objectID": "4179298", "points": 19, "story_id": 4179298, "story_text": "So a few days ago I added a \"Person to Blame\" field to our bug tracking system and this decision has attracted a lot of attention from outside of our organization.  I totally welcome the debate and love the passion from everyone.  Given the interest, I thought I'd share how the \"Person to Blame\" field works for our team.<p>We are a tight-knit dev team, part of an almost-3-year-old startup.  As a team, we spend a lot of time together and just like other startups, we probably spend more time with each other than with our families.  We only hire people who we respect and take pride in the team that we have built.  We are a shop that believes in peer code reviews, unit testing and open debate.  We also hold each other accountable when we do silly things.  For instance, if you break a continuous integration build you drop a $1 in the jar for our beer fund.   Oh, you also get a nice dose of tongue-in-cheek lashing from the team if you write a time bomb into our unit test suite.  All in all, we have fun together, we push each other to be great and we respect each other enough to be direct and honest.<p>About 6 months ago, we made a conscious effort to reshape our software development process in preparation for Continuous Deployment.  We promote an environment where developers are in charge of a story from start to finish.  This includes understanding the problem, thinking about how a story needs to be tested, implementing the solution, writing the necessary unit tests and functional tests, and ways to measure the effect of the story once in production.  As soon as a developer okays the story, it's included in the next release.  In short, we want to be a continuous deployment shop and we think that we have the right developers to do it.  (to be clear, we are still a few months away from the true continuous deployment process like the one installed at Etsy)<p>More than just tools and process, continuous deployment requires a different kind of mentality.  While the throw-my-stuff-over-the-fence mentality never existed on our team, we do need to introduce a higher level of responsibility and accountability from everyone on the team.  Since the shift about 6 months ago, we have seen an increase in the number of hot-fixes going out between deployments.  And that's okay, bugs happen. We anticipated the increase in production bugs when we moved away from having a dedicated QA team.  But, as we get closer to having a true continuous deployment system in place, we need to start treating production bugs as the exception rather than the rule.  Bugs are inevitable and are accounted for in the world of continuous deployment, but bugs should still be avoided if possible. So a few weeks back, I started talking about keeping metrics on production bugs: count per sprint, per developer, per team, etc.  I mean, you have to start tracking these things so that you can improve, right?  And to keep the accounting simple, I added a \"Person to Blame\" field to Jira a few days ago.  Could I have named the field something more politically correct, so that feelings don't get hurt? Sure.  But what's the fun in that?  The point was to bring awareness to the number of production bugs after each release so why not throw in a small dose of public shaming for good measure? And to be clear, the purpose of the field, and ultimately the purpose of the metric, is not to pinpoint the cause of the bug.  Shit happens and we have better things to do.  The ultimate purpose of the metric is a reminder for each developer to be better everyday.<p>Like I said in the beginning, I welcome the debate on the matter and appreciate the passion from everyone.<p>The \"Person to Blame\" Boss :)", "title": "Why I added a \"Peson to Blame\" field to our bug tracking system", "updated_at": "2023-09-06T20:41:46Z"}], "hitsPerPage": 15, "nbHits": 48, "nbPages": 4, "page": 0, "params": "query=jira+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 8, "processingTimingsMS": {"_request": {"roundTrip": 26}, "afterFetch": {"format": {"highlighting": 2, "total": 2}}, "fetch": {"query": 4, "scanning": 2, "total": 7}, "total": 8}, "query": "jira production", "serverTimeMS": 11}}