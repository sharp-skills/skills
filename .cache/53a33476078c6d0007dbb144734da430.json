{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "jayl-e-e"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["ioredis", "production"], "value": "Hey everyone!<p>Over the past two years I threw myself back into full-time engineering with a simple goal: write code that <i>gives back</i> to the community. After a lot of late-night FOMO (\u201cAI will do it all for us, right?\u201d) and some painful <em>production</em> incidents, I finally turned my weekend project into an open-source library.<p>[ What is <i>Solidis</i>? ]<p>- <i>Super-light (&lt; 30 KB) RESP2/RESP3 client</i> with zero runtime deps and first-class ESM/CJS support.<p>- Fully <i>tree-shakable</i> \u2013 import only the commands you need.<p>- Written with SOLID principles &amp; full TypeScript typings for every command.<p>- Designed for <i>cold-start sensitive</i> serverless platforms (small bundle + tiny memory footprint).<p>[ Why I built it ]<p>1. <i>node-redis &amp; <em>ioredis</em> pain</i><p>- ESM is still an after-thought.<p>- Hidden deadlocks on RST, vague error surfaces.<p>- Everything gets bundled, even commands you\u2019ll never call.<p>2. I refuse to add a dependency I don\u2019t fully understand \u2013 I literally read candidates 10\u00d7 before `npm i`.<p>3. Serverless bills love to remind me that every KB and millisecond matters.<p>[ Key features ]<p>- Protocols: RESP2 and RESP3 (auto-negotiation)<p>- Bundle size: `&lt;30 KB` (core) / `&lt;105 KB` (full)<p>- Dependencies: <i>0</i><p>- Extensibility: Drop-in command plugins, custom transactions<p>- Reliability: Auto-reconnect, per-command timeouts, type-checked replies<p>[ Roadmap / Help wanted ]<p>- <i>Benchmarks</i> against `node-redis` &amp; `<em>ioredis</em>` (PRs welcome!)<p>- More first-class <i>Valkey</i> love<p>- <i>Fuzz-testing</i> the parser<p>- <i>Docs site</i> \u2013 the README came first; I\u2019d love help polishing full docs<p>This might be my last big OSS push for a while, so <i>stars, issues, and PRs mean the world</i>.<p>If Solidis saves you some cold-start time or just scratches a TypeScript itch, let me know!<p><i>Repo:</i> <a href=\"https://github.com/vcms-io/solidis\">https://github.com/vcms-io/solidis</a><p><i>License:</i> MIT<p>Thanks for reading, and happy hacking!<p><i>(Feel free to AMA in the comments \u2013 I\u2019m around.)</i>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Solidis \u2013 Tiny TS Redis client, no deps, for serverless"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/vcms-io/solidis"}}, "_tags": ["story", "author_jayl-e-e", "story_44009894", "show_hn"], "author": "jayl-e-e", "children": [44010128, 44011467], "created_at": "2025-05-16T21:20:15Z", "created_at_i": 1747430415, "num_comments": 8, "objectID": "44009894", "points": 71, "story_id": 44009894, "story_text": "Hey everyone!<p>Over the past two years I threw myself back into full-time engineering with a simple goal: write code that <i>gives back</i> to the community. After a lot of late-night FOMO (\u201cAI will do it all for us, right?\u201d) and some painful production incidents, I finally turned my weekend project into an open-source library.<p>[ What is <i>Solidis</i>? ]<p>- <i>Super-light (&lt; 30 KB) RESP2&#x2F;RESP3 client</i> with zero runtime deps and first-class ESM&#x2F;CJS support.<p>- Fully <i>tree-shakable</i> \u2013 import only the commands you need.<p>- Written with SOLID principles &amp; full TypeScript typings for every command.<p>- Designed for <i>cold-start sensitive</i> serverless platforms (small bundle + tiny memory footprint).<p>[ Why I built it ]<p>1. <i>node-redis &amp; ioredis pain</i><p>- ESM is still an after-thought.<p>- Hidden deadlocks on RST, vague error surfaces.<p>- Everything gets bundled, even commands you\u2019ll never call.<p>2. I refuse to add a dependency I don\u2019t fully understand \u2013 I literally read candidates 10\u00d7 before `npm i`.<p>3. Serverless bills love to remind me that every KB and millisecond matters.<p>[ Key features ]<p>- Protocols: RESP2 and RESP3 (auto-negotiation)<p>- Bundle size: `&lt;30 KB` (core) &#x2F; `&lt;105 KB` (full)<p>- Dependencies: <i>0</i><p>- Extensibility: Drop-in command plugins, custom transactions<p>- Reliability: Auto-reconnect, per-command timeouts, type-checked replies<p>[ Roadmap &#x2F; Help wanted ]<p>- <i>Benchmarks</i> against `node-redis` &amp; `ioredis` (PRs welcome!)<p>- More first-class <i>Valkey</i> love<p>- <i>Fuzz-testing</i> the parser<p>- <i>Docs site</i> \u2013 the README came first; I\u2019d love help polishing full docs<p>This might be my last big OSS push for a while, so <i>stars, issues, and PRs mean the world</i>.<p>If Solidis saves you some cold-start time or just scratches a TypeScript itch, let me know!<p><i>Repo:</i> <a href=\"https:&#x2F;&#x2F;github.com&#x2F;vcms-io&#x2F;solidis\">https:&#x2F;&#x2F;github.com&#x2F;vcms-io&#x2F;solidis</a><p><i>License:</i> MIT<p>Thanks for reading, and happy hacking!<p><i>(Feel free to AMA in the comments \u2013 I\u2019m around.)</i>", "title": "Show HN: Solidis \u2013 Tiny TS Redis client, no deps, for serverless", "updated_at": "2025-06-15T03:32:13Z", "url": "https://github.com/vcms-io/solidis"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "Attummm"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["ioredis", "production"], "value": "RedisDict is a Python dictionary with a Redis backend, designed for handling large datasets. It simplifies Redis operations especially for large-scale and distributed systems, and has been running in <em>production</em> since 2017, originally built in Python 2.<p>The library focuses on get and set operations in Redis, ensuring that each key-value pair operates independently, so changes to one entry do not affect others.<p>Optimized for performance with large datasets, RedisDict maintains high speed even at scale.<p>Data types are managed without using Pickle to avoid security risks associated with untrusted, serialized data.<p>Key features include namespacing, pipelining, expiration, and support for multiple data types. RedisDict provides a full dictionary interface and has extensive test coverage.<p>GitHub: <a href=\"https://github.com/Attumm/redis-dict\">https://github.com/Attumm/redis-dict</a><p>Documentation: <a href=\"https://attumm.github.io/redis-dict/\" rel=\"nofollow\">https://attumm.github.<em>io/redis</em>-dict/</a>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: RedisDict"}}, "_tags": ["story", "author_Attummm", "story_42051420", "show_hn"], "author": "Attummm", "children": [42051575], "created_at": "2024-11-05T13:46:53Z", "created_at_i": 1730814413, "num_comments": 2, "objectID": "42051420", "points": 3, "story_id": 42051420, "story_text": "RedisDict is a Python dictionary with a Redis backend, designed for handling large datasets. It simplifies Redis operations especially for large-scale and distributed systems, and has been running in production since 2017, originally built in Python 2.<p>The library focuses on get and set operations in Redis, ensuring that each key-value pair operates independently, so changes to one entry do not affect others.<p>Optimized for performance with large datasets, RedisDict maintains high speed even at scale.<p>Data types are managed without using Pickle to avoid security risks associated with untrusted, serialized data.<p>Key features include namespacing, pipelining, expiration, and support for multiple data types. RedisDict provides a full dictionary interface and has extensive test coverage.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Attumm&#x2F;redis-dict\">https:&#x2F;&#x2F;github.com&#x2F;Attumm&#x2F;redis-dict</a><p>Documentation: <a href=\"https:&#x2F;&#x2F;attumm.github.io&#x2F;redis-dict&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;attumm.github.io&#x2F;redis-dict&#x2F;</a>", "title": "Show HN: RedisDict", "updated_at": "2024-11-05T15:39:27Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "samrith"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["ioredis", "production"], "value": "Hi HN,<p>I\u2019m Samrith, creator of Hyperterse.<p>Today I\u2019m launching Hyperterse 2.0, a schema-first framework for building MCP servers directly on top of your existing <em>production</em> databases.<p>If you're building AI agents in <em>production</em>, you\u2019ve probably run into agents needing access to structured, reliable data but wiring your business logic to MCP tools is tedious. Most teams end up writing fragile glue code. Or worse, giving agents unsafe, overbroad access.<p>There isn\u2019t a clean, principled way to expose just the right data surface to agents.<p>Hyperterse lets you define a schema over your data and automatically exposes secure, typed MCP tools for AI agents.<p>Think of it as: Your business data \u2192 controlled, agent-ready interface.<p>Some key properties include a schema-first access layer, typed MCP tool generation, works with existing Postgres, MySQL, MongoDB, <em>Redis</em> databases, fine-grained exposure of queries, built for <em>production</em> agent workloads.<p>v2.0 focuses heavily on MCP with first-class MCP server support, cleaner schema ergonomics, better type safety, faster tool surfaces.<p>All of this, with only two tools - search &amp; execute - reducing token usage drastically.<p>Hyperterse is useful if you are building AI agents/copilots, adding LLM features to existing SaaS, trying to safely expose internal data to agents or are just tired of bespoke MCP glue layers.<p>I\u2019d love feedback, especially from folks running agents in <em>production</em>.<p>GitHub: <a href=\"https://github.com/hyperterse/hyperterse\" rel=\"nofollow\">https://github.com/hyperterse/hyperterse</a>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Declarative open-source framework for MCPs with search and execute"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://hyperterse.com"}}, "_tags": ["story", "author_samrith", "story_47142975", "show_hn"], "author": "samrith", "children": [47144269, 47149992], "created_at": "2026-02-24T21:01:28Z", "created_at_i": 1771966888, "num_comments": 4, "objectID": "47142975", "points": 11, "story_id": 47142975, "story_text": "Hi HN,<p>I\u2019m Samrith, creator of Hyperterse.<p>Today I\u2019m launching Hyperterse 2.0, a schema-first framework for building MCP servers directly on top of your existing production databases.<p>If you&#x27;re building AI agents in production, you\u2019ve probably run into agents needing access to structured, reliable data but wiring your business logic to MCP tools is tedious. Most teams end up writing fragile glue code. Or worse, giving agents unsafe, overbroad access.<p>There isn\u2019t a clean, principled way to expose just the right data surface to agents.<p>Hyperterse lets you define a schema over your data and automatically exposes secure, typed MCP tools for AI agents.<p>Think of it as: Your business data \u2192 controlled, agent-ready interface.<p>Some key properties include a schema-first access layer, typed MCP tool generation, works with existing Postgres, MySQL, MongoDB, Redis databases, fine-grained exposure of queries, built for production agent workloads.<p>v2.0 focuses heavily on MCP with first-class MCP server support, cleaner schema ergonomics, better type safety, faster tool surfaces.<p>All of this, with only two tools - search &amp; execute - reducing token usage drastically.<p>Hyperterse is useful if you are building AI agents&#x2F;copilots, adding LLM features to existing SaaS, trying to safely expose internal data to agents or are just tired of bespoke MCP glue layers.<p>I\u2019d love feedback, especially from folks running agents in production.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;hyperterse&#x2F;hyperterse\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;hyperterse&#x2F;hyperterse</a>", "title": "Show HN: Declarative open-source framework for MCPs with search and execute", "updated_at": "2026-02-27T10:02:08Z", "url": "https://hyperterse.com"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "supreeth_ravi"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["ioredis", "production"], "value": "I built MongoClaw because every AI enrichment pipeline I've seen hits the same concurrency bug nobody talks about.<p>Your agent reads a document at t0. Inference takes 2 seconds. At t1, another process updates that document. At t2, the agent writes back \u2014 silently overwriting live data with output generated from a stale snapshot. Clean 200 OK. No error.<p>That's not a prompt problem. It's a write-safety problem.<p>MongoClaw solves it by capturing version + content hash at dispatch time and issuing a conditional write that only succeeds if the source record still matches. Stale payload? Write suppressed, reason classified, execution record persisted.<p>It also handles:<p>* Idempotent replay <em>protection</em> across all write strategies\n* Loop detection via agent-origin metadata\n* In-band policy evaluation (enrich/block/tag) after inference and before mutation<p>Agents are declared in YAML. The runtime handles change stream ingestion, <em>Redis</em>-backed queuing, async execution, schema validation, and auditable writebacks.<p>It also works with external agent endpoints \u2014 normalising heterogeneous response formats into the same execution contract.<p>Would appreciate feedback on the write-safety mechanism specifically \u2014 curious if others have hit this problem differently."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: MongoClaw, A mutation runtime for MongoDB with write-time agent safety"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/supreeth-ravi/mongoclaw"}}, "_tags": ["story", "author_supreeth_ravi", "story_47171425", "show_hn"], "author": "supreeth_ravi", "created_at": "2026-02-26T20:12:33Z", "created_at_i": 1772136753, "num_comments": 0, "objectID": "47171425", "points": 3, "story_id": 47171425, "story_text": "I built MongoClaw because every AI enrichment pipeline I&#x27;ve seen hits the same concurrency bug nobody talks about.<p>Your agent reads a document at t0. Inference takes 2 seconds. At t1, another process updates that document. At t2, the agent writes back \u2014 silently overwriting live data with output generated from a stale snapshot. Clean 200 OK. No error.<p>That&#x27;s not a prompt problem. It&#x27;s a write-safety problem.<p>MongoClaw solves it by capturing version + content hash at dispatch time and issuing a conditional write that only succeeds if the source record still matches. Stale payload? Write suppressed, reason classified, execution record persisted.<p>It also handles:<p>* Idempotent replay protection across all write strategies\n* Loop detection via agent-origin metadata\n* In-band policy evaluation (enrich&#x2F;block&#x2F;tag) after inference and before mutation<p>Agents are declared in YAML. The runtime handles change stream ingestion, Redis-backed queuing, async execution, schema validation, and auditable writebacks.<p>It also works with external agent endpoints \u2014 normalising heterogeneous response formats into the same execution contract.<p>Would appreciate feedback on the write-safety mechanism specifically \u2014 curious if others have hit this problem differently.", "title": "Show HN: MongoClaw, A mutation runtime for MongoDB with write-time agent safety", "updated_at": "2026-02-26T20:34:21Z", "url": "https://github.com/supreeth-ravi/mongoclaw"}], "hitsPerPage": 15, "nbHits": 4, "nbPages": 1, "page": 0, "params": "query=ioredis+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 16, "processingTimingsMS": {"_request": {"roundTrip": 20}, "fetch": {"query": 13, "scanning": 1, "total": 15}, "total": 16}, "query": "ioredis production", "serverTimeMS": 18}}