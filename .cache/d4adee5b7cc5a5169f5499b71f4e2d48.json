{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "jbaudanza"}, "story_text": {"matchLevel": "none", "matchedWords": [], "value": ""}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["memcached", "production"], "value": "Show HN: Warming up a cold <em>memcached</em> cluster in <em>production</em> with Ruby."}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/jbaudanza/cache_migration"}}, "_tags": ["story", "author_jbaudanza", "story_6278808", "show_hn"], "author": "jbaudanza", "children": [6278816], "created_at": "2013-08-26T18:16:03Z", "created_at_i": 1377540963, "num_comments": 1, "objectID": "6278808", "points": 1, "story_id": 6278808, "story_text": "", "title": "Show HN: Warming up a cold memcached cluster in production with Ruby.", "updated_at": "2024-09-19T19:55:25Z", "url": "https://github.com/jbaudanza/cache_migration"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "jb007"}, "story_text": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "In order to build amazing apps for users, developers require multiple ways to store and query data. The cost and complexity of running multiple databases in <em>production</em> can be a distraction for engineers trying to build great apps. We believe that by providing developers with an API that supports multiple persistence and querying modes, we can offer the upsides of \npolyglot persistence without the pain of running multiple databases.<p>Your feedback on the architecture and also interests are welcomed.<p>website: http://www.amisalabs.com/"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["memcached"], "value": "Ask HN: PostgreSQL, Lucence and <em>Memcached</em> Integration"}, "url": {"matchLevel": "none", "matchedWords": [], "value": ""}}, "_tags": ["story", "author_jb007", "story_10067667", "ask_hn"], "author": "jb007", "created_at": "2015-08-16T01:57:29Z", "created_at_i": 1439690249, "num_comments": 0, "objectID": "10067667", "points": 6, "story_id": 10067667, "story_text": "In order to build amazing apps for users, developers require multiple ways to store and query data. The cost and complexity of running multiple databases in production can be a distraction for engineers trying to build great apps. We believe that by providing developers with an API that supports multiple persistence and querying modes, we can offer the upsides of \npolyglot persistence without the pain of running multiple databases.<p>Your feedback on the architecture and also interests are welcomed.<p>website: http:&#x2F;&#x2F;www.amisalabs.com&#x2F;", "title": "Ask HN: PostgreSQL, Lucence and Memcached Integration", "updated_at": "2023-09-06T23:23:38Z", "url": ""}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "LINKIWI"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["memcached", "production"], "value": "zcached is an in-memory key-value cache exposing a <em>memcached</em> ASCII protocol-compatible interface, built on pluggable cache engines like Ristretto and freecache [0].<p>It's not performance-competitive with <em>memcached</em>, especially at higher thread counts. That said, it achieves about 1.1M ops/s, but at significantly higher P99 and P999 latency (as measured by memtier). See [1] and [2] for benchmark results from my 7950x-based workstation.<p>Disclaimer: This is a hobby project created for fun while hacking over the holidays. zcached is not a commercial product and never will be. Don't use it in <em>production</em>; consider this a technology demo more than anything.<p>I don't expect the source code to build outside of my environment, but for those interested in playing with it, binary artifacts are available at [3]. Try `zcached --address tcp:localhost:11211`.<p>[0] <a href=\"https://github.com/dgraph-io/ristretto\">https://github.com/dgraph-io/ristretto</a>, <a href=\"https://github.com/coocood/freecache\">https://github.com/coocood/freecache</a><p>[1] <em>memcached</em>, 16 worker threads: <a href=\"https://pastebin.com/raw/WHmk08ZG\" rel=\"nofollow\">https://pastebin.com/raw/WHmk08ZG</a><p>[2] zcached: <a href=\"https://pastebin.com/raw/GjpwpMaD\" rel=\"nofollow\">https://pastebin.com/raw/GjpwpMaD</a><p>[3] <a href=\"https://artifacts.kevinlin.info/zcached/latest/release.tar.gz\" rel=\"nofollow\">https://artifacts.kevinlin.info/zcached/latest/release.tar.g...</a>"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["memcached"], "value": "Show HN: Zcached, in-memory key-value cache wire-compatible with <em>memcached</em>"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://source.static.kevinlin.info/zcached/files"}}, "_tags": ["story", "author_LINKIWI", "story_34163621", "show_hn"], "author": "LINKIWI", "created_at": "2022-12-28T17:48:51Z", "created_at_i": 1672249731, "num_comments": 0, "objectID": "34163621", "points": 5, "story_id": 34163621, "story_text": "zcached is an in-memory key-value cache exposing a memcached ASCII protocol-compatible interface, built on pluggable cache engines like Ristretto and freecache [0].<p>It&#x27;s not performance-competitive with memcached, especially at higher thread counts. That said, it achieves about 1.1M ops&#x2F;s, but at significantly higher P99 and P999 latency (as measured by memtier). See [1] and [2] for benchmark results from my 7950x-based workstation.<p>Disclaimer: This is a hobby project created for fun while hacking over the holidays. zcached is not a commercial product and never will be. Don&#x27;t use it in production; consider this a technology demo more than anything.<p>I don&#x27;t expect the source code to build outside of my environment, but for those interested in playing with it, binary artifacts are available at [3]. Try `zcached --address tcp:localhost:11211`.<p>[0] <a href=\"https:&#x2F;&#x2F;github.com&#x2F;dgraph-io&#x2F;ristretto\">https:&#x2F;&#x2F;github.com&#x2F;dgraph-io&#x2F;ristretto</a>, <a href=\"https:&#x2F;&#x2F;github.com&#x2F;coocood&#x2F;freecache\">https:&#x2F;&#x2F;github.com&#x2F;coocood&#x2F;freecache</a><p>[1] memcached, 16 worker threads: <a href=\"https:&#x2F;&#x2F;pastebin.com&#x2F;raw&#x2F;WHmk08ZG\" rel=\"nofollow\">https:&#x2F;&#x2F;pastebin.com&#x2F;raw&#x2F;WHmk08ZG</a><p>[2] zcached: <a href=\"https:&#x2F;&#x2F;pastebin.com&#x2F;raw&#x2F;GjpwpMaD\" rel=\"nofollow\">https:&#x2F;&#x2F;pastebin.com&#x2F;raw&#x2F;GjpwpMaD</a><p>[3] <a href=\"https:&#x2F;&#x2F;artifacts.kevinlin.info&#x2F;zcached&#x2F;latest&#x2F;release.tar.gz\" rel=\"nofollow\">https:&#x2F;&#x2F;artifacts.kevinlin.info&#x2F;zcached&#x2F;latest&#x2F;release.tar.g...</a>", "title": "Show HN: Zcached, in-memory key-value cache wire-compatible with memcached", "updated_at": "2024-09-20T12:53:27Z", "url": "https://source.static.kevinlin.info/zcached/files"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "dirtyhand"}, "story_text": {"matchLevel": "none", "matchedWords": [], "value": ""}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["memcached"], "value": "Rails 2.3, cache_fu and the <em>memcached</em> session_store"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "http://www.<em>production</em>-hacks.com/post/522050660/rails-2-3-and-cache-fu"}}, "_tags": ["story", "author_dirtyhand", "story_1266651"], "author": "dirtyhand", "created_at": "2010-04-15T01:19:32Z", "created_at_i": 1271294372, "num_comments": 0, "objectID": "1266651", "points": 2, "story_id": 1266651, "story_text": "", "title": "Rails 2.3, cache_fu and the memcached session_store", "updated_at": "2024-09-19T17:00:53Z", "url": "http://www.production-hacks.com/post/522050660/rails-2-3-and-cache-fu"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "dirtyhand"}, "story_text": {"matchLevel": "none", "matchedWords": [], "value": ""}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["memcached"], "value": "<em>Memcached</em> and Passenger connection sharing"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["memcached", "production"], "value": "http://www.<em>production</em>-hacks.com/2010/04/15/<em>memcached</em>-and-passenger-connection-sharing/"}}, "_tags": ["story", "author_dirtyhand", "story_1267671"], "author": "dirtyhand", "created_at": "2010-04-15T12:59:07Z", "created_at_i": 1271336347, "num_comments": 0, "objectID": "1267671", "points": 1, "story_id": 1267671, "story_text": "", "title": "Memcached and Passenger connection sharing", "updated_at": "2024-09-19T17:00:59Z", "url": "http://www.production-hacks.com/2010/04/15/memcached-and-passenger-connection-sharing/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "whattodochange"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["memcached", "production"], "value": "I have to find a strategy to fix this development team without managing them directly. Here is an overview:<p>- this code generates more than 20 million dollars a year of revenue<p>- it runs on PHP<p>- it has been developed for 12 years directly on <em>production</em> with no source control ( hello index-new_2021-test-john_v2.php )<p>- it doesn't use composer or any dependency management. It's all require_once.<p>- it doesn't use any framework<p>- the routing is managed exclusively as rewrites in NGInX ( the NGInX config is around 10,000 lines )<p>- no code has ever been deleted. Things are just added . I gather the reason for that is because it was developed on <em>production</em> directly and deleting things is too risky.<p>- the database structure is the same mess, no migrations, etc... When adding a column, because of the volume of data, they add a new table with a join.<p>- JS and CSS is the same. Multiple versions of jQuery fighting each other depending on which page you are or even on the same page.<p>- no MVC pattern of course, or whatever pattern. No templating library. It's PHP 2003 style.<p>- In many places I see controllers like files making curl requests to its own rest API (via domain name, not localhost) doing oauth authorizations, etc... Just to get the menu items or list of products...<p>- no caching ( but there is <em>memcached</em> but only used for sessions  ...)<p>- team is 3 people, quite junior. One backend, one front, one iOS/android. Resistance to change is huge.<p>- productivity is abysmal which is understandable. The mess is just too huge to be able to build anything.<p>This business unit has a pretty aggressive roadmap as management and HQ has no real understanding of these blockers. And post COVID, budget is really tight.<p>I know a full rewrite is necessary, but how to balance it?"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: Inherited the worst code and tech team I have ever seen. How to fix it?"}}, "_tags": ["story", "author_whattodochange", "story_32883596", "ask_hn"], "author": "whattodochange", "children": [32883654, 32883669, 32883673, 32883676, 32883677, 32883683, 32883692, 32883700, 32883705, 32883709, 32883724, 32883730, 32883731, 32883732, 32883744, 32883745, 32883748, 32883758, 32883768, 32883771, 32883783, 32883791, 32883793, 32883794, 32883798, 32883799, 32883800, 32883807, 32883808, 32883823, 32883830, 32883847, 32883852, 32883857, 32883869, 32883876, 32883877, 32883884, 32883894, 32883903, 32883908, 32883940, 32883959, 32883961, 32884010, 32884054, 32884063, 32884147, 32884148, 32884193, 32884305, 32884328, 32884334, 32884443, 32884507, 32884508, 32884534, 32884539, 32884542, 32884554, 32884567, 32884573, 32884602, 32884609, 32884620, 32884621, 32884643, 32884649, 32884667, 32884682, 32884692, 32884698, 32884707, 32884716, 32884737, 32884758, 32884772, 32884775, 32884789, 32884806, 32884852, 32884860, 32884887, 32884892, 32884910, 32884967, 32884978, 32884997, 32885005, 32885018, 32885026, 32885027, 32885057, 32885080, 32885090, 32885095, 32885125, 32885173, 32885179, 32885187, 32885206, 32885217, 32885221, 32885229, 32885237, 32885239, 32885277, 32885279, 32885335, 32885348, 32885389, 32885396, 32885424, 32885427, 32885439, 32885442, 32885465, 32885468, 32885505, 32885508, 32885533, 32885546, 32885557, 32885589, 32885600, 32885649, 32885684, 32885691, 32885698, 32885713, 32885722, 32885735, 32885749, 32885782, 32885806, 32885821, 32885828, 32885833, 32885835, 32885841, 32885881, 32885889, 32885915, 32885921, 32885929, 32885942, 32885954, 32885972, 32885982, 32886004, 32886013, 32886047, 32886049, 32886051, 32886056, 32886079, 32886115, 32886139, 32886148, 32886185, 32886188, 32886190, 32886197, 32886265, 32886270, 32886304, 32886311, 32886337, 32886349, 32886431, 32886447, 32886456, 32886486, 32886497, 32886514, 32886532, 32886540, 32886592, 32886604, 32886622, 32886692, 32886693, 32886701, 32886715, 32886728, 32886751, 32886752, 32886757, 32886834, 32886899, 32886943, 32886950, 32886951, 32886952, 32886959, 32886988, 32887083, 32887090, 32887108, 32887134, 32887136, 32887257, 32887297, 32887352, 32887397, 32887416, 32887436, 32887439, 32887440, 32887454, 32887475, 32887490, 32887504, 32887518, 32887556, 32887588, 32887592, 32887606, 32887799, 32887800, 32887845, 32887862, 32887872, 32887960, 32887975, 32888011, 32888015, 32888023, 32888031, 32888058, 32888084, 32888194, 32888260, 32888277, 32888314, 32888323, 32888353, 32888354, 32888390, 32888392, 32888419, 32888432, 32888433, 32888469, 32888481, 32888483, 32888553, 32888668, 32888692, 32888694, 32888709, 32888722, 32888823, 32888855, 32888891, 32888899, 32888900, 32888930, 32888931, 32888945, 32888972, 32888982, 32889027, 32889037, 32889131, 32889135, 32889212, 32889245, 32889346, 32889353, 32889419, 32889454, 32889709, 32889839, 32890209, 32890227, 32890374, 32890562, 32890592, 32890636, 32891322, 32891487, 32891522, 32891647, 32891718, 32891758, 32891809, 32892143, 32892163, 32892223, 32892635, 32892890, 32893330, 32893972, 32893994, 32894879, 32894961, 32895119, 32895238, 32896362, 32896439, 32896511, 32896879, 32897527, 32897584, 32898093, 32898442, 32899287, 32902412, 32902667, 32904667, 32906784, 32908537, 32910067, 32924969, 32935806, 32952853, 32953544, 32954768, 32963933, 32969797, 32977181], "created_at": "2022-09-18T01:51:13Z", "created_at_i": 1663465873, "num_comments": 676, "objectID": "32883596", "points": 557, "story_id": 32883596, "story_text": "I have to find a strategy to fix this development team without managing them directly. Here is an overview:<p>- this code generates more than 20 million dollars a year of revenue<p>- it runs on PHP<p>- it has been developed for 12 years directly on production with no source control ( hello index-new_2021-test-john_v2.php )<p>- it doesn&#x27;t use composer or any dependency management. It&#x27;s all require_once.<p>- it doesn&#x27;t use any framework<p>- the routing is managed exclusively as rewrites in NGInX ( the NGInX config is around 10,000 lines )<p>- no code has ever been deleted. Things are just added . I gather the reason for that is because it was developed on production directly and deleting things is too risky.<p>- the database structure is the same mess, no migrations, etc... When adding a column, because of the volume of data, they add a new table with a join.<p>- JS and CSS is the same. Multiple versions of jQuery fighting each other depending on which page you are or even on the same page.<p>- no MVC pattern of course, or whatever pattern. No templating library. It&#x27;s PHP 2003 style.<p>- In many places I see controllers like files making curl requests to its own rest API (via domain name, not localhost) doing oauth authorizations, etc... Just to get the menu items or list of products...<p>- no caching ( but there is memcached but only used for sessions  ...)<p>- team is 3 people, quite junior. One backend, one front, one iOS&#x2F;android. Resistance to change is huge.<p>- productivity is abysmal which is understandable. The mess is just too huge to be able to build anything.<p>This business unit has a pretty aggressive roadmap as management and HQ has no real understanding of these blockers. And post COVID, budget is really tight.<p>I know a full rewrite is necessary, but how to balance it?", "title": "Ask HN: Inherited the worst code and tech team I have ever seen. How to fix it?", "updated_at": "2026-02-25T23:11:19Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "johnwoods"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["memcached", "production"], "value": "It seems that several projects claim that they have built the &quot;world's fastest key/value store&quot; or sometimes the phrase used is even more outrageous. The following projects are in question:<p>- Redis: <a href=\"https://github.com/redis/redis\" rel=\"nofollow\">https://github.com/redis/redis</a><p>- KeyDB: <a href=\"https://github.com/snapchat/keydb\" rel=\"nofollow\">https://github.com/snapchat/keydb</a><p>- Dragonfly: <a href=\"https://github.com/dragonflydb/dragonfly\" rel=\"nofollow\">https://github.com/dragonflydb/dragonfly</a><p>- Skytable: <a href=\"https://github.com/skytable/skytable\" rel=\"nofollow\">https://github.com/skytable/skytable</a><p>And, these are my benchmark results (30 threads, 1 client per thread with GET/SET. See below for setup):<p>1. Redis: 112,100 / 99,892<p>2. KeyDB: 288,931 / 282,997<p>3. Dragonfly: 408,322 / 392,446<p>4. Skytable: 619,992 / 676,091<p># Notes<p>1. Redis:\nI'll start with Redis which I'd like to call the &quot;original&quot; key/value store (after <em>memcached</em>) because it is the oldest and most widely used of all. Being a long-time follower of Redis, I do know it's single-threaded (and uses io-threads since 6.0) and hence it achieves lesser throughput than the other stores listed above which are multi-threaded, at least to some extent. The best parts about Redis: it's the most feature complete of all the systems here, and is the oldest. (not saying old necessarily means better).<p>2. KeyDB:\nThe second is KeyDB. IIRC, I saw it in a blog post which said that it is a &quot;multithreaded fork of Redis that is 5X faster&quot;[1]. I really liked the idea because I was previously running several instances of Redis on the same node and proxying them like a &quot;single-node cluster.&quot; Why? To increase CPU utilization. A single KeyDB instance could replace the unwanted proxying funkiness, so I ditched Redis for KeyDB. Has been a fine experience so far, except for some occasional crashes.<p>3. Dragonfly:\nJust found it on HN and seems to be relatively new. Dragonfly claims that it is 25X faster (that I couldn't reproduce) than Redis[2] and has the slogan &quot;Probably, the fastest in-memory store in the universe!&quot;. Doesn't support all the Redis commands yet, but I find it interesting mainly because of performance. Also, it's good to know why it is faster because it clearly outlines the underlying architecture[2]. The other three stores don't say much about it. Will be following the project.<p>4. Skytable:\nFound it while looking for projects written in Rust. Claims to be &quot;insanely fast.&quot; Skytable's &quot;experimental benchmarks&quot; claim that it is something around 10X faster than Redis and some 2X-3X faster than KeyDB[3]. I hadn't heard of Skytable and it doesn't seem to be as widely used (unless I'm missing something?). I find it interesting because of the planned features[4] and performance. Only Skytable natively runs on Windows out of the four. Will be following the project.<p>5. My thoughts:\nRedis needs no introduction and is arguably super stable for use on <em>production</em> systems (using widely in our systems). KeyDB seems to be &quot;stable enough&quot; and it seems to be good for prod since Snapchat uses it already[5] (and so do we!). I found no Dragonfly v/s Skytable benchmarks.\nThe best part about Redis, KeyDB and Skytable is that they don't make any &quot;crazy assumptions&quot; about the system they run on. What do I mean?<p>Dragonfly expects you to have the latest hardware[6] and the latest kernel[7] on all your servers. I find this outrageous because not all servers run 5.10 and a majority of them are still using long-running branches on 4.x. Also, I don't expect them to have the latest processors, either. I'd argue if the other three stores started assuming the latest features, they'd be far faster than what they are today. Finally, both Dragonfly and Skytable are still early in their development so it may not be fair to compare their features against Redis and KeyDB who have been around for far longer. Also, all projects other than Skytable have companies behind them (unless I'm missing something).<p>Edit #1: I have run the benchmarks myself for each store. In the benchmark with Redis, KeyDB and Skytable (redis-benchmark, memtier and sky-bench): Redis and KeyDB benchmarks seem to be very consistent, Skytable is a little inconsistent at times. However, in the benchmark with Redis, KeyDB and Dragonfly (with memtier), I was NOT able to reproduce the 25X speed that Dragonfly claims. I ran all tests on two m5.4xlarge servers (one with the k/v store and one with the benchmark tool).<p>Edit #2: Added benchmark results<p>What are your thoughts? Have you tried benchmarking any of them locally or in the cloud?<p>References:<p>[1]: <a href=\"https://docs.keydb.dev/blog/2019/10/07/blog-post\" rel=\"nofollow\">https://docs.keydb.dev/blog/2019/10/07/blog-post</a><p>[2]: <a href=\"https://github.com/dragonflydb/dragonfly\" rel=\"nofollow\">https://github.com/dragonflydb/dragonfly</a><p>[3]: <a href=\"https://github.com/ohsayan/sky-benches\" rel=\"nofollow\">https://github.com/ohsayan/sky-benches</a><p>[4]: <a href=\"https://github.com/skytable/skytable/issues/203\" rel=\"nofollow\">https://github.com/skytable/skytable/issues/203</a><p>[5]: <a href=\"https://docs.keydb.dev/news/2022/05/12/keydb-joins-snap\" rel=\"nofollow\">https://docs.keydb.dev/news/2022/05/12/keydb-joins-snap</a><p>[6]: <a href=\"https://github.com/dragonflydb/dragonfly/issues/124\" rel=\"nofollow\">https://github.com/dragonflydb/dragonfly/issues/124</a><p>[7]: <a href=\"https://github.com/dragonflydb/dragonfly/issues/96\" rel=\"nofollow\">https://github.com/dragonflydb/dragonfly/issues/96</a>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Redis vs. KeyDB vs. Dragonfly vs. Skytable"}}, "_tags": ["story", "author_johnwoods", "story_31796311", "ask_hn"], "author": "johnwoods", "children": [31796381, 31796509, 31796510, 31796517, 31796527, 31796528, 31796728, 31796779, 31796990, 31797228, 31797300, 31797359, 31797517, 31799299, 31800617, 31802994, 31804116, 31804125, 31808102, 31851773, 31939667], "created_at": "2022-06-19T05:05:07Z", "created_at_i": 1655615107, "num_comments": 54, "objectID": "31796311", "points": 130, "story_id": 31796311, "story_text": "It seems that several projects claim that they have built the &quot;world&#x27;s fastest key&#x2F;value store&quot; or sometimes the phrase used is even more outrageous. The following projects are in question:<p>- Redis: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;redis&#x2F;redis\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;redis&#x2F;redis</a><p>- KeyDB: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;snapchat&#x2F;keydb\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;snapchat&#x2F;keydb</a><p>- Dragonfly: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;dragonflydb&#x2F;dragonfly\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;dragonflydb&#x2F;dragonfly</a><p>- Skytable: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;skytable&#x2F;skytable\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;skytable&#x2F;skytable</a><p>And, these are my benchmark results (30 threads, 1 client per thread with GET&#x2F;SET. See below for setup):<p>1. Redis: 112,100 &#x2F; 99,892<p>2. KeyDB: 288,931 &#x2F; 282,997<p>3. Dragonfly: 408,322 &#x2F; 392,446<p>4. Skytable: 619,992 &#x2F; 676,091<p># Notes<p>1. Redis:\nI&#x27;ll start with Redis which I&#x27;d like to call the &quot;original&quot; key&#x2F;value store (after memcached) because it is the oldest and most widely used of all. Being a long-time follower of Redis, I do know it&#x27;s single-threaded (and uses io-threads since 6.0) and hence it achieves lesser throughput than the other stores listed above which are multi-threaded, at least to some extent. The best parts about Redis: it&#x27;s the most feature complete of all the systems here, and is the oldest. (not saying old necessarily means better).<p>2. KeyDB:\nThe second is KeyDB. IIRC, I saw it in a blog post which said that it is a &quot;multithreaded fork of Redis that is 5X faster&quot;[1]. I really liked the idea because I was previously running several instances of Redis on the same node and proxying them like a &quot;single-node cluster.&quot; Why? To increase CPU utilization. A single KeyDB instance could replace the unwanted proxying funkiness, so I ditched Redis for KeyDB. Has been a fine experience so far, except for some occasional crashes.<p>3. Dragonfly:\nJust found it on HN and seems to be relatively new. Dragonfly claims that it is 25X faster (that I couldn&#x27;t reproduce) than Redis[2] and has the slogan &quot;Probably, the fastest in-memory store in the universe!&quot;. Doesn&#x27;t support all the Redis commands yet, but I find it interesting mainly because of performance. Also, it&#x27;s good to know why it is faster because it clearly outlines the underlying architecture[2]. The other three stores don&#x27;t say much about it. Will be following the project.<p>4. Skytable:\nFound it while looking for projects written in Rust. Claims to be &quot;insanely fast.&quot; Skytable&#x27;s &quot;experimental benchmarks&quot; claim that it is something around 10X faster than Redis and some 2X-3X faster than KeyDB[3]. I hadn&#x27;t heard of Skytable and it doesn&#x27;t seem to be as widely used (unless I&#x27;m missing something?). I find it interesting because of the planned features[4] and performance. Only Skytable natively runs on Windows out of the four. Will be following the project.<p>5. My thoughts:\nRedis needs no introduction and is arguably super stable for use on production systems (using widely in our systems). KeyDB seems to be &quot;stable enough&quot; and it seems to be good for prod since Snapchat uses it already[5] (and so do we!). I found no Dragonfly v&#x2F;s Skytable benchmarks.\nThe best part about Redis, KeyDB and Skytable is that they don&#x27;t make any &quot;crazy assumptions&quot; about the system they run on. What do I mean?<p>Dragonfly expects you to have the latest hardware[6] and the latest kernel[7] on all your servers. I find this outrageous because not all servers run 5.10 and a majority of them are still using long-running branches on 4.x. Also, I don&#x27;t expect them to have the latest processors, either. I&#x27;d argue if the other three stores started assuming the latest features, they&#x27;d be far faster than what they are today. Finally, both Dragonfly and Skytable are still early in their development so it may not be fair to compare their features against Redis and KeyDB who have been around for far longer. Also, all projects other than Skytable have companies behind them (unless I&#x27;m missing something).<p>Edit #1: I have run the benchmarks myself for each store. In the benchmark with Redis, KeyDB and Skytable (redis-benchmark, memtier and sky-bench): Redis and KeyDB benchmarks seem to be very consistent, Skytable is a little inconsistent at times. However, in the benchmark with Redis, KeyDB and Dragonfly (with memtier), I was NOT able to reproduce the 25X speed that Dragonfly claims. I ran all tests on two m5.4xlarge servers (one with the k&#x2F;v store and one with the benchmark tool).<p>Edit #2: Added benchmark results<p>What are your thoughts? Have you tried benchmarking any of them locally or in the cloud?<p>References:<p>[1]: <a href=\"https:&#x2F;&#x2F;docs.keydb.dev&#x2F;blog&#x2F;2019&#x2F;10&#x2F;07&#x2F;blog-post\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.keydb.dev&#x2F;blog&#x2F;2019&#x2F;10&#x2F;07&#x2F;blog-post</a><p>[2]: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;dragonflydb&#x2F;dragonfly\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;dragonflydb&#x2F;dragonfly</a><p>[3]: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ohsayan&#x2F;sky-benches\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ohsayan&#x2F;sky-benches</a><p>[4]: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;skytable&#x2F;skytable&#x2F;issues&#x2F;203\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;skytable&#x2F;skytable&#x2F;issues&#x2F;203</a><p>[5]: <a href=\"https:&#x2F;&#x2F;docs.keydb.dev&#x2F;news&#x2F;2022&#x2F;05&#x2F;12&#x2F;keydb-joins-snap\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.keydb.dev&#x2F;news&#x2F;2022&#x2F;05&#x2F;12&#x2F;keydb-joins-snap</a><p>[6]: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;dragonflydb&#x2F;dragonfly&#x2F;issues&#x2F;124\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;dragonflydb&#x2F;dragonfly&#x2F;issues&#x2F;124</a><p>[7]: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;dragonflydb&#x2F;dragonfly&#x2F;issues&#x2F;96\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;dragonflydb&#x2F;dragonfly&#x2F;issues&#x2F;96</a>", "title": "Redis vs. KeyDB vs. Dragonfly vs. Skytable", "updated_at": "2026-01-06T02:13:54Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "ZoFreX"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["memcached", "production"], "value": "I'm a \"generalist\" with shallow knowledge in a wide number of areas, and I think that might be a bad strategy. It seems most people are looking for hackers that are really, really good at just a few things. What's your opinion? Is it better to specialise?<p>The other half of the problem is what to specialise in. I have no idea, and I love so many different things it's hard to deliberately give up on most of them to focus. Right now I feel very directionless and could really use some advice from people a bit further on in their development than me (I left university a year ago). To give you an idea of my knowledge and capabilities, the things I've done (or helped with) include:<p>Basic game physics engine (C++) \u2020<p>Inverse kinematics solver (C++) \u2020<p>Cross-platform dynamic music engine (C++, OpenAL) \u2020<p>High performance bittorrent tracker (Java - and way faster than XBTT, the main competition)<p>Raytracer (Java) \u2020<p>Typing tutor (Java) \u2020<p>Bittorrent web front-end with forums etc (PHP, <em>memcached</em>, Sphinx - one installation of this code has 120000 users with a single MySQL server)<p>I've also made a lot of websites (this is my day job), and I consider my skills to be most developed in this area - but again, I'm a generalist, I do a little front-end, a little back-end, a little server administration.<p>\u2020 denotes a student project, so these aren't \"<em>production</em>-ready\" (with the exception of the typing tutor, which has been downloaded 10,000 times and so potentially has some life in it)<p>I'm confident that I have a lot of raw talent, and could make some great things - I just have no idea how to get there from here. Thank you for reading my ramblings, I can't tell you how much I appreciate all the advice and guidance this community gives and I look forward to reading any advice you may have for me (and others in similar situations to mine)."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: Should I specialise?"}, "url": {"matchLevel": "none", "matchedWords": [], "value": ""}}, "_tags": ["story", "author_ZoFreX", "story_2474055", "ask_hn"], "author": "ZoFreX", "children": [2474075, 2474210, 2474259, 2474561, 2476324], "created_at": "2011-04-22T14:01:25Z", "created_at_i": 1303480885, "num_comments": 6, "objectID": "2474055", "points": 12, "story_id": 2474055, "story_text": "I'm a \"generalist\" with shallow knowledge in a wide number of areas, and I think that might be a bad strategy. It seems most people are looking for hackers that are really, really good at just a few things. What's your opinion? Is it better to specialise?<p>The other half of the problem is what to specialise in. I have no idea, and I love so many different things it's hard to deliberately give up on most of them to focus. Right now I feel very directionless and could really use some advice from people a bit further on in their development than me (I left university a year ago). To give you an idea of my knowledge and capabilities, the things I've done (or helped with) include:<p>Basic game physics engine (C++) \u2020<p>Inverse kinematics solver (C++) \u2020<p>Cross-platform dynamic music engine (C++, OpenAL) \u2020<p>High performance bittorrent tracker (Java - and way faster than XBTT, the main competition)<p>Raytracer (Java) \u2020<p>Typing tutor (Java) \u2020<p>Bittorrent web front-end with forums etc (PHP, memcached, Sphinx - one installation of this code has 120000 users with a single MySQL server)<p>I've also made a lot of websites (this is my day job), and I consider my skills to be most developed in this area - but again, I'm a generalist, I do a little front-end, a little back-end, a little server administration.<p>\u2020 denotes a student project, so these aren't \"production-ready\" (with the exception of the typing tutor, which has been downloaded 10,000 times and so potentially has some life in it)<p>I'm confident that I have a lot of raw talent, and could make some great things - I just have no idea how to get there from here. Thank you for reading my ramblings, I can't tell you how much I appreciate all the advice and guidance this community gives and I look forward to reading any advice you may have for me (and others in similar situations to mine).", "title": "Ask HN: Should I specialise?", "updated_at": "2024-09-19T17:43:17Z", "url": ""}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "vibhanshugarg"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["memcached", "production"], "value": "Hi HN,<p>I\u2019ve been working on a small project called MemCloud \u2014 a distributed, in-memory data store written in Rust.\nIt lets multiple machines on a LAN pool their RAM and act like a shared, ephemeral storage cloud.<p>Why I built it<p>I often have multiple devices around me (Mac + Linux laptop + home server) that sit mostly idle.\nI wanted these machines to behave like one big RAM cache for local development, ML experiments, and data processing \u2014 without installing heavy systems or configuring clusters.<p>So I built a lightweight daemon that:<p>auto-discovers peers via mDNS<p>exposes a simple local RPC API<p>pools memory across devices<p>supports raw block storage and a Redis-style key-value interface<p>works offline on macOS and Linux<p>has a CLI + Rust SDK + JS/TypeScript SDK<p>What it does<p>Store a block on any peer and load it from another in &lt;10ms over LAN<p>Offload large streams (logs, datasets) without spiking local RAM<p>Build small distributed workflows without running Redis/<em>Memcached</em> clusters<p>Experiment with P2P memory systems in a simple way<p>Repo<p><a href=\"https://github.com/vibhanshu2001/memcloud\" rel=\"nofollow\">https://github.com/vibhanshu2001/memcloud</a><p>Architecture (short version)<p>Each device runs a small Rust daemon (&quot;memnode&quot;):<p>mDNS \u2192 discovers peers<p>Peer Manager \u2192 handles connections<p>Block Manager \u2192 stores/loads blocks in local RAM<p>RPC API \u2192 CLI/SDK communication<p>Optional KV store \u2192 set(key, value) / get(key)<p>SDKs talk only to the local daemon, which routes requests to the correct peer.<p>Benchmarks (on M1 Mac)<p>SET: ~25k ops/sec (1KB payloads)<p>GET: ~16k ops/sec\n(Not optimized \u2014 curious what others get on their machines.)<p>Looking for feedback on:<p>architecture &amp; safety<p>networking design<p>memory model &amp; eviction strategies<p>real-world use cases<p>potential pitfalls I might not be aware of<p>This is still early-stage/alpha and definitely not <em>production</em>-ready, but I\u2019d love to hear your thoughts or suggestions.<p>Happy to answer questions!<p><a href=\"https://memcloud.vercel.app/\" rel=\"nofollow\">https://memcloud.vercel.app/</a><p>\u2014 Vibhanshu"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: MemCloud \u2013 Pool unused RAM across LAN devices (Rust, zero-config)"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/vibhanshu2001/memcloud"}}, "_tags": ["story", "author_vibhanshugarg", "story_46184507", "show_hn"], "author": "vibhanshugarg", "created_at": "2025-12-07T19:47:48Z", "created_at_i": 1765136868, "num_comments": 0, "objectID": "46184507", "points": 2, "story_id": 46184507, "story_text": "Hi HN,<p>I\u2019ve been working on a small project called MemCloud \u2014 a distributed, in-memory data store written in Rust.\nIt lets multiple machines on a LAN pool their RAM and act like a shared, ephemeral storage cloud.<p>Why I built it<p>I often have multiple devices around me (Mac + Linux laptop + home server) that sit mostly idle.\nI wanted these machines to behave like one big RAM cache for local development, ML experiments, and data processing \u2014 without installing heavy systems or configuring clusters.<p>So I built a lightweight daemon that:<p>auto-discovers peers via mDNS<p>exposes a simple local RPC API<p>pools memory across devices<p>supports raw block storage and a Redis-style key-value interface<p>works offline on macOS and Linux<p>has a CLI + Rust SDK + JS&#x2F;TypeScript SDK<p>What it does<p>Store a block on any peer and load it from another in &lt;10ms over LAN<p>Offload large streams (logs, datasets) without spiking local RAM<p>Build small distributed workflows without running Redis&#x2F;Memcached clusters<p>Experiment with P2P memory systems in a simple way<p>Repo<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;vibhanshu2001&#x2F;memcloud\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;vibhanshu2001&#x2F;memcloud</a><p>Architecture (short version)<p>Each device runs a small Rust daemon (&quot;memnode&quot;):<p>mDNS \u2192 discovers peers<p>Peer Manager \u2192 handles connections<p>Block Manager \u2192 stores&#x2F;loads blocks in local RAM<p>RPC API \u2192 CLI&#x2F;SDK communication<p>Optional KV store \u2192 set(key, value) &#x2F; get(key)<p>SDKs talk only to the local daemon, which routes requests to the correct peer.<p>Benchmarks (on M1 Mac)<p>SET: ~25k ops&#x2F;sec (1KB payloads)<p>GET: ~16k ops&#x2F;sec\n(Not optimized \u2014 curious what others get on their machines.)<p>Looking for feedback on:<p>architecture &amp; safety<p>networking design<p>memory model &amp; eviction strategies<p>real-world use cases<p>potential pitfalls I might not be aware of<p>This is still early-stage&#x2F;alpha and definitely not production-ready, but I\u2019d love to hear your thoughts or suggestions.<p>Happy to answer questions!<p><a href=\"https:&#x2F;&#x2F;memcloud.vercel.app&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;memcloud.vercel.app&#x2F;</a><p>\u2014 Vibhanshu", "title": "Show HN: MemCloud \u2013 Pool unused RAM across LAN devices (Rust, zero-config)", "updated_at": "2025-12-08T05:11:17Z", "url": "https://github.com/vibhanshu2001/memcloud"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "workmonster"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["memcached", "production"], "value": "Looking for some advice on High Availability Wordpress and AWS.\nWe were on Digital Ocean but had outgrown what we had and so decided it was time to build a real hosting platform.<p>However, we have built out an AWS stack but is really slow compared to Digital Ocean. Page loads on AWS are 2seconds &gt; 12 seconds - random. Where DO was stable around 2.9seconds.<p>AWS Current stack<p>TeraForm for AWS and Ansible Scripts for box setup (looking at RunDeck for Ansible running)<p>CloudFlare CDN &gt; Amazon AWS (Large RDS (mySQL) + Micro EC2 Ubuntu 16.04 + PHP + NGNX + Redis cache + EFS<p>Controller Server for Ansible and looking at RunDeck to control it.<p>Auto Scaling<p>NewRelic and PapertailsApp for Monitoring.<p>BitBucket for core plugins, themes, base WP etc<p>Finding EFS is really slow :( . We have done the trick with 256gb file to go up to the next speed level but did not seem to make a difference.<p>Now trying .....<p>CloudFlare &gt; AWS (Large RDS (mySQL) + XLarge EC2 Ubuntu 16.04 + PHP + Varnish in front of NGNX + <em>Memcached</em> (AWS ElastiCache) + EFS / S3 which looks to be a better solution so far - but feeling like we are just plugging stuff together without really having past experience so looking for someone who has been through this before.<p>Some blogs/posts reading that never put PHP on EFS and always use scripts to copy to EBS first. While Amazon best practice for high-availability Wordpress says EFS is fine - clearly not the case!<p>We also have Ansible scripts in place to move Wordpress sites between development &gt; Staging &gt; <em>production</em> instances. Before it used to take hours to move a site, with the scripts now takes around 10-20mins and seems to work.<p>Thanks"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: Advice on High-Availability Wordpress and Amazon AWS"}}, "_tags": ["story", "author_workmonster", "story_17599256", "ask_hn"], "author": "workmonster", "children": [17600842], "created_at": "2018-07-24T09:05:01Z", "created_at_i": 1532423101, "num_comments": 1, "objectID": "17599256", "points": 1, "story_id": 17599256, "story_text": "Looking for some advice on High Availability Wordpress and AWS.\nWe were on Digital Ocean but had outgrown what we had and so decided it was time to build a real hosting platform.<p>However, we have built out an AWS stack but is really slow compared to Digital Ocean. Page loads on AWS are 2seconds &gt; 12 seconds - random. Where DO was stable around 2.9seconds.<p>AWS Current stack<p>TeraForm for AWS and Ansible Scripts for box setup (looking at RunDeck for Ansible running)<p>CloudFlare CDN &gt; Amazon AWS (Large RDS (mySQL) + Micro EC2 Ubuntu 16.04 + PHP + NGNX + Redis cache + EFS<p>Controller Server for Ansible and looking at RunDeck to control it.<p>Auto Scaling<p>NewRelic and PapertailsApp for Monitoring.<p>BitBucket for core plugins, themes, base WP etc<p>Finding EFS is really slow :( . We have done the trick with 256gb file to go up to the next speed level but did not seem to make a difference.<p>Now trying .....<p>CloudFlare &gt; AWS (Large RDS (mySQL) + XLarge EC2 Ubuntu 16.04 + PHP + Varnish in front of NGNX + Memcached (AWS ElastiCache) + EFS &#x2F; S3 which looks to be a better solution so far - but feeling like we are just plugging stuff together without really having past experience so looking for someone who has been through this before.<p>Some blogs&#x2F;posts reading that never put PHP on EFS and always use scripts to copy to EBS first. While Amazon best practice for high-availability Wordpress says EFS is fine - clearly not the case!<p>We also have Ansible scripts in place to move Wordpress sites between development &gt; Staging &gt; production instances. Before it used to take hours to move a site, with the scripts now takes around 10-20mins and seems to work.<p>Thanks", "title": "Ask HN: Advice on High-Availability Wordpress and Amazon AWS", "updated_at": "2024-09-20T02:51:37Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "yassi_dev"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["memcached", "production"], "value": "I built a small open-source tool called dj-cache-panel after realizing Django gives you almost no visibility into what's inside your cache backends.<p>It provides a unified Django admin interface to inspect, search, view, and delete cache keys across multiple backend types (Redis, <em>Memcached</em>, LocMem, Database cache, etc.). It auto-detects backends, works without models, requires zero configuration for most setups, and integrates cleanly with the admin.<p>What it offers:<p>- Search keys (exact or pattern-based)<p>- Delete keys, flush keys<p>- Backend-aware panels (Redis, <em>Memcached</em>, LocMem, DB cache)<p>- Multi-backend support out of the box<p>-Zero models, zero migrations, lightweight install<p>Repo: <a href=\"https://github.com/yassi/dj-cache-panel\" rel=\"nofollow\">https://github.com/yassi/dj-cache-panel</a><p>Docs: <a href=\"https://yassi.github.io/dj-cache-panel/\" rel=\"nofollow\">https://yassi.github.io/dj-cache-panel/</a><p>pypi: <a href=\"https://pypi.org/project/dj-cache-panel/\" rel=\"nofollow\">https://pypi.org/project/dj-cache-panel/</a><p>Would love feedback, especially from anyone running multi-cache or <em>production</em> Redis setups.<p>This is a natural extension to my previous work on dj-redis-panel, feel free to check that out as well."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Dj-Cache-Panel \u2013 Inspect and Debug Django Cache Back Ends"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/yassi/dj-cache-panel"}}, "_tags": ["story", "author_yassi_dev", "story_46266375", "show_hn"], "author": "yassi_dev", "created_at": "2025-12-14T20:11:41Z", "created_at_i": 1765743101, "num_comments": 0, "objectID": "46266375", "points": 1, "story_id": 46266375, "story_text": "I built a small open-source tool called dj-cache-panel after realizing Django gives you almost no visibility into what&#x27;s inside your cache backends.<p>It provides a unified Django admin interface to inspect, search, view, and delete cache keys across multiple backend types (Redis, Memcached, LocMem, Database cache, etc.). It auto-detects backends, works without models, requires zero configuration for most setups, and integrates cleanly with the admin.<p>What it offers:<p>- Search keys (exact or pattern-based)<p>- Delete keys, flush keys<p>- Backend-aware panels (Redis, Memcached, LocMem, DB cache)<p>- Multi-backend support out of the box<p>-Zero models, zero migrations, lightweight install<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;yassi&#x2F;dj-cache-panel\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;yassi&#x2F;dj-cache-panel</a><p>Docs: <a href=\"https:&#x2F;&#x2F;yassi.github.io&#x2F;dj-cache-panel&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;yassi.github.io&#x2F;dj-cache-panel&#x2F;</a><p>pypi: <a href=\"https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;dj-cache-panel&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;dj-cache-panel&#x2F;</a><p>Would love feedback, especially from anyone running multi-cache or production Redis setups.<p>This is a natural extension to my previous work on dj-redis-panel, feel free to check that out as well.", "title": "Show HN: Dj-Cache-Panel \u2013 Inspect and Debug Django Cache Back Ends", "updated_at": "2025-12-14T20:14:59Z", "url": "https://github.com/yassi/dj-cache-panel"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "viridIT"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["memcached", "production"], "value": "We are proud to announce that vSMTP, an MTA server written in rust is now ready for <em>production</em> !\nvSMTP is an open source MTA that is fast, safe and easy to configure. It comes with complex email filtering rules using a custom scripting language.<p>It supports basic MTA features like DKIM, DMARC, SPF, etc. And is shipped with a plugin system to extend the server, enabling interfaces with third party software like <em>memcache</em>, mysql, etc.<p>Feel free to follow the project on our github page and join our discord server !"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "VSMTP 2.1 is out and ready for <em>production</em>"}}, "_tags": ["story", "author_viridIT", "story_34610485", "ask_hn"], "author": "viridIT", "children": [34615736], "created_at": "2023-02-01T14:01:17Z", "created_at_i": 1675260077, "num_comments": 1, "objectID": "34610485", "points": 3, "story_id": 34610485, "story_text": "We are proud to announce that vSMTP, an MTA server written in rust is now ready for production !\nvSMTP is an open source MTA that is fast, safe and easy to configure. It comes with complex email filtering rules using a custom scripting language.<p>It supports basic MTA features like DKIM, DMARC, SPF, etc. And is shipped with a plugin system to extend the server, enabling interfaces with third party software like memcache, mysql, etc.<p>Feel free to follow the project on our github page and join our discord server !", "title": "VSMTP 2.1 is out and ready for production", "updated_at": "2024-09-20T13:10:54Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "prasenjit_pro"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["memcached", "production"], "value": "Background<p>Proxies API is a rotating proxies API that developers use to fetch hard to scrape data at scale and consistently. We auto-rotate millions of proxy servers, and also handle auto retries, rotate user agent strings, handle cookies, CAPTCHAs behind the scenes.<p>The Constraints<p>The service has to scale to millions of URL fetches a day without lagging on speed and should work out of a single API like this.<p>curl \u201chttp://api.proxiesapi.com/?key=API_KEY&amp;url=https://example.com&quot;<p>The Architecture<p>The architecture looks somewhat like this.<p>A more in-depth look at this architecture is provided in this article.<p>Load balancing &amp; Serving<p>The whole infrastructure is on Amazon EC2. The load balancer plays a significant role in calling the right service based on just the variables passed and the API KEY that holds some secret information like what pool of servers are assigned for them etc.<p>Our plans have higher concurrency as customers pay more, so we need to pass them to more reliable, dedicated servers as they have higher concurrency needs.<p>Luckily amazon elastic load balancer can make this using rules you can set, which look at the URL patterns and direct them to different pools of servers intelligently.<p>Without this exact combination of facilities, we would not have been able to create it all using a single API call without compromising speed and performance somewhere.<p>We use Apache if there is a need for HTTP servers. Many of these are super optimized to be able to crawl data concurrently using multiple cores. We will soon write an article on how we can get the most amount of crawling ability out of Apache instances.<p>Proxy Components<p>For CGI, we use a combination of Python and even PHP where required.<p><em>Memcache</em> is used to monitor and throttle concurrencies gracefully, so some rouge code by one of our clients doesn\u2019t bring down the entire setup.<p>As I described earlier, most of this throttling happens in the way we route out requests from the load balancer.<p>We use the Node Js/Puppeteer library extensively as an interface to connect to Browserless docker instances located on multiple servers. Browserless is optimized to run as many ready-to-go instances of Chromium as possible, so there is no lag in loading any of them for our clients.<p>Database<p>We use good old MySQL in a Master/Slave configuration to hold user info, cache info, millions of proxy info, quality metrics for each, etc.<p>Maintenance tools<p>We have a pool pruner that\u2019s written in Python running as a Cronjob. Uses Scrapy and Scrapyd extensively in making calls, monitoring, benchmarking, and pruning proxies from our database.<p>We use the Beanstalk library for Queues. We use Datadog for monitoring and PagerDuty for alerts.<p>The author is the founder of Proxies API, a proxy rotation API service.<p>This article originally appeared here:https://www.proxiesapi.com/blog/The-Stack-Behind-A-<em>Production</em>-Level-Rotating-Proxy-Service.php"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "The Stack Behind a <em>Production</em> Level Rotating Proxy Service"}}, "_tags": ["story", "author_prasenjit_pro", "story_33187751", "ask_hn"], "author": "prasenjit_pro", "children": [33187915, 33189247], "created_at": "2022-10-13T05:59:07Z", "created_at_i": 1665640747, "num_comments": 2, "objectID": "33187751", "points": 2, "story_id": 33187751, "story_text": "Background<p>Proxies API is a rotating proxies API that developers use to fetch hard to scrape data at scale and consistently. We auto-rotate millions of proxy servers, and also handle auto retries, rotate user agent strings, handle cookies, CAPTCHAs behind the scenes.<p>The Constraints<p>The service has to scale to millions of URL fetches a day without lagging on speed and should work out of a single API like this.<p>curl \u201chttp:&#x2F;&#x2F;api.proxiesapi.com&#x2F;?key=API_KEY&amp;url=https:&#x2F;&#x2F;example.com&quot;<p>The Architecture<p>The architecture looks somewhat like this.<p>A more in-depth look at this architecture is provided in this article.<p>Load balancing &amp; Serving<p>The whole infrastructure is on Amazon EC2. The load balancer plays a significant role in calling the right service based on just the variables passed and the API KEY that holds some secret information like what pool of servers are assigned for them etc.<p>Our plans have higher concurrency as customers pay more, so we need to pass them to more reliable, dedicated servers as they have higher concurrency needs.<p>Luckily amazon elastic load balancer can make this using rules you can set, which look at the URL patterns and direct them to different pools of servers intelligently.<p>Without this exact combination of facilities, we would not have been able to create it all using a single API call without compromising speed and performance somewhere.<p>We use Apache if there is a need for HTTP servers. Many of these are super optimized to be able to crawl data concurrently using multiple cores. We will soon write an article on how we can get the most amount of crawling ability out of Apache instances.<p>Proxy Components<p>For CGI, we use a combination of Python and even PHP where required.<p>Memcache is used to monitor and throttle concurrencies gracefully, so some rouge code by one of our clients doesn\u2019t bring down the entire setup.<p>As I described earlier, most of this throttling happens in the way we route out requests from the load balancer.<p>We use the Node Js&#x2F;Puppeteer library extensively as an interface to connect to Browserless docker instances located on multiple servers. Browserless is optimized to run as many ready-to-go instances of Chromium as possible, so there is no lag in loading any of them for our clients.<p>Database<p>We use good old MySQL in a Master&#x2F;Slave configuration to hold user info, cache info, millions of proxy info, quality metrics for each, etc.<p>Maintenance tools<p>We have a pool pruner that\u2019s written in Python running as a Cronjob. Uses Scrapy and Scrapyd extensively in making calls, monitoring, benchmarking, and pruning proxies from our database.<p>We use the Beanstalk library for Queues. We use Datadog for monitoring and PagerDuty for alerts.<p>The author is the founder of Proxies API, a proxy rotation API service.<p>This article originally appeared here:https:&#x2F;&#x2F;www.proxiesapi.com&#x2F;blog&#x2F;The-Stack-Behind-A-Production-Level-Rotating-Proxy-Service.php", "title": "The Stack Behind a Production Level Rotating Proxy Service", "updated_at": "2024-09-20T12:18:04Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "albertogh"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["memcached", "production"], "value": "I had this domain for some time and I never got around to make a project for it. This last weekend I finally managed to find a few hours to work on it and I've just finished putting the code into <em>production</em>.<p>The site lets you choose some pictures from your Facebook photos and then it will let other users vote on them, as long as they know your URL. This way you can find your best picture.<p>Some random facts the HN crowd will appreciate:<p>- Technologies: Tornado, mongodb and <em>memcache</em>, served with nginx<p>- The site took around 5 hours to design and write (including time spent in Photoshop and shopping around for stock photos)<p>- 1055 lines of code, including Python and Javascript<p>http://onepic.me"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Weekend project - onepic.me"}, "url": {"matchLevel": "none", "matchedWords": [], "value": ""}}, "_tags": ["story", "author_albertogh", "story_2803525", "show_hn"], "author": "albertogh", "children": [2803533, 2803654, 2811853], "created_at": "2011-07-25T17:16:34Z", "created_at_i": 1311614194, "num_comments": 5, "objectID": "2803525", "points": 7, "story_id": 2803525, "story_text": "I had this domain for some time and I never got around to make a project for it. This last weekend I finally managed to find a few hours to work on it and I've just finished putting the code into production.<p>The site lets you choose some pictures from your Facebook photos and then it will let other users vote on them, as long as they know your URL. This way you can find your best picture.<p>Some random facts the HN crowd will appreciate:<p>- Technologies: Tornado, mongodb and memcache, served with nginx<p>- The site took around 5 hours to design and write (including time spent in Photoshop and shopping around for stock photos)<p>- 1055 lines of code, including Python and Javascript<p>http://onepic.me", "title": "Show HN: Weekend project - onepic.me", "updated_at": "2024-09-19T17:49:23Z", "url": ""}], "hitsPerPage": 15, "nbHits": 14, "nbPages": 1, "page": 0, "params": "query=memcached+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 10, "processingTimingsMS": {"_request": {"roundTrip": 20}, "afterFetch": {"format": {"highlighting": 1, "total": 1}}, "fetch": {"query": 7, "scanning": 1, "total": 9}, "total": 10}, "query": "memcached production", "serverTimeMS": 12}}