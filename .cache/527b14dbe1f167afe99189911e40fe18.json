{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "wittydeveloper"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["aws", "sqs", "production"], "value": "Hi HN! We are Charly and Bryan, founders of Defer (<a href=\"https://www.defer.run/\">https://www.defer.run/</a>). Defer is a zero-infrastructure background jobs platform for Node.js developers. As a managed platform that brings modern development standards to background jobs (ex: multi-env support, zero-API design), we enable Node.js developers to build products faster and scale without effort and infrastructure knowledge.<p>Background jobs, while being used in all web applications (processing webhooks, interacting with 3rd party APIs, or powering core features), did not benefit from the developer experience improvements that arose in all other layers of the Node.js API stack: quick and reliable databases with Supabase or easy Serverless deployment with Vercel.<p>Today, even for simple use cases, working with background jobs in Node.js necessarily requires some infrastructure knowledge\u2014either by deploying and scaling an open source solution (ex: BullMQ) or using an IaaS such as <em>AWS SQS</em> with Lambdas, which comes with complexity and limited features (no support for dead letter queues, dynamic concurrency, or throttling).<p>At a large scale, you will need to solve how to handle rolling restarts, how to auto-scale your workers, how to safely deploy without interrupting long-running jobs, how to safely encrypt jobs\u2019 data, and how to version them. Once deployed, your background job\u2019s code lives in a separate part of your codebase, with its own mental model (queues and workers). Finally, most solutions provide technical dashboards which are not always helpful in debugging <em>production</em> issues, so you end up having to build custom dashboards.<p>Most companies we talked to try to handle those different aspects, building custom similar solutions and using developers\u2019 time that could have been used on user-facing features.<p>Bryan and I are technical founders with 10+ years of experience working at start-ups of all stages (e.g. Algolia, home of HN Search!), from tech lead to CTO roles. Like many developers, we got asked many times to work on background job stacks and invest time into tailoring and scaling them for product needs.<p>I even dedicated most of my time at Algolia to building a custom background jobs pipeline to power the Algolia Shopify integration: ingesting partial webhooks from Shopify, enriching them given customers configuration, in FIFO order per shop, with the Shopify rate limited API, for thousands of shops and the equivalents of 3 millions of jobs per day. Given the complex and unique product requirements of the Algolia Shopify Ingestion Pipeline, the only solution (at the time and context) was to build a custom background jobs stack combining Redis and Kubernetes.<p>When consulting with some startups, we witnessed some developers choosing to keep some slow API routes calling 3rd party APIs synchronously instead of investing time in setting up background jobs. When looking back to the recent increase of productive zero infrastructure solutions in the Node.js ecosystem, we were surprised that the experience with background jobs remained unchanged. We decided to build Defer, so working with background jobs, CRONs, and workflows would match the current standard of Node.js developer experience.<p>Inspired by Next.js, Remix, and Netlify design, background jobs in Defer become background functions that live in your application\u2019s code, with direct access to all configuration options: retry, concurrency, and more (<a href=\"https://docs.defer.run/features/retries-concurrency/\">https://docs.defer.run/features/retries-concurrency/</a>) , and no specific mental model to learn. Your background functions get continuously deployed from GitHub with support for branch-based environments, allowing you to test new background jobs in no time, before safely moving to <em>production</em>.<p>Defer works for all kinds of Node.js projects, not only serverless ones. It does not require you to learn any new architectures or adapt your system design\u2014you just turn your code into background functions using coding patterns you already know, ex: map-reduce, or recursion. \nDefer brings features such as configurable retries (advanced backoff options), throttling, and concurrency at the background job level, which other solutions either require you to implement yourself or are simply not available. Finally, the Defer Dashboard is the only background jobs Dashboard to allow developers to quickly find executions based on business/product metadata, ex: \u201cShow all executions for `user_id=123`) to quickly debug product issues.<p>Defer\u2019s infrastructure, written in Go, is composed of 3 main components: a Build pipeline, a Scheduler, and a Runner. The Build pipeline enables us to build any Node.js project without requiring any configuration file (<a href=\"https://docs.defer.run/platform/builds/\">https://docs.defer.run/platform/builds/</a>). The Scheduler relies on Postgres for persistent storage of your jobs (no risk of losing some)\u2014all jobs\u2019 data is encrypted\u2014and on Redis, as an atomic counter to handle features such as concurrency and throttling (<a href=\"https://docs.defer.run/platform/executions/\">https://docs.defer.run/platform/executions/</a>). Our infrastructure runs on AWS EC2 - leveraging auto-scaling groups, using the containerd API directly from Go.<p>We run a progressive deployment approach to enable uninterrupted long-running jobs (some of our customers\u2019 jobs run for more than 5h) while releasing updates multiple times a day.\nOnce your application is up and running, the Defer dashboard gives you all the essential information to operate background jobs: activity histograms, performances, and Slack alerting upon failures. The executions list comes with rich filters, allowing you to quickly find all the executions linked to a specific customer or other business metadata.<p>In short, we ensure that you get all the essential features, with the best developer experience, and with a fully managed infrastructure and observability tools so you can focus on building your product.<p>All of this would be meaningless without a free plan for small and side projects and usage-based pricing, so that\u2019s what we offer: <a href=\"https://www.defer.run/pricing\">https://www.defer.run/pricing</a>. If you want to give Defer a try, you can get started with a simple GitHub login, without any credit card information required, and our docs are at <a href=\"https://docs.defer.run\">https://docs.defer.run</a>.<p>We would love to get to read about your experience with doing background jobs in Node.js and feedback on what we\u2019ve built. We look forward to your comments!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: Defer (YC W23) \u2013 Zero-infrastructure background jobs for Node.js"}}, "_tags": ["story", "author_wittydeveloper", "story_35096366", "launch_hn"], "author": "wittydeveloper", "children": [35096646, 35096731, 35096886, 35096954, 35096959, 35097077, 35097099, 35097402, 35097535, 35098275, 35098305, 35098361, 35098423, 35098557, 35098565, 35098719, 35098883, 35099085, 35099170, 35099345, 35099662, 35099755, 35099762, 35100148, 35100323, 35100358, 35100904, 35100981, 35101468, 35102310, 35103784, 35103985, 35104591, 35104896, 35106645, 35106927, 35107080, 35107948, 35108417, 35265216], "created_at": "2023-03-10T16:16:28Z", "created_at_i": 1678464988, "num_comments": 111, "objectID": "35096366", "points": 202, "story_id": 35096366, "story_text": "Hi HN! We are Charly and Bryan, founders of Defer (<a href=\"https:&#x2F;&#x2F;www.defer.run&#x2F;\">https:&#x2F;&#x2F;www.defer.run&#x2F;</a>). Defer is a zero-infrastructure background jobs platform for Node.js developers. As a managed platform that brings modern development standards to background jobs (ex: multi-env support, zero-API design), we enable Node.js developers to build products faster and scale without effort and infrastructure knowledge.<p>Background jobs, while being used in all web applications (processing webhooks, interacting with 3rd party APIs, or powering core features), did not benefit from the developer experience improvements that arose in all other layers of the Node.js API stack: quick and reliable databases with Supabase or easy Serverless deployment with Vercel.<p>Today, even for simple use cases, working with background jobs in Node.js necessarily requires some infrastructure knowledge\u2014either by deploying and scaling an open source solution (ex: BullMQ) or using an IaaS such as AWS SQS with Lambdas, which comes with complexity and limited features (no support for dead letter queues, dynamic concurrency, or throttling).<p>At a large scale, you will need to solve how to handle rolling restarts, how to auto-scale your workers, how to safely deploy without interrupting long-running jobs, how to safely encrypt jobs\u2019 data, and how to version them. Once deployed, your background job\u2019s code lives in a separate part of your codebase, with its own mental model (queues and workers). Finally, most solutions provide technical dashboards which are not always helpful in debugging production issues, so you end up having to build custom dashboards.<p>Most companies we talked to try to handle those different aspects, building custom similar solutions and using developers\u2019 time that could have been used on user-facing features.<p>Bryan and I are technical founders with 10+ years of experience working at start-ups of all stages (e.g. Algolia, home of HN Search!), from tech lead to CTO roles. Like many developers, we got asked many times to work on background job stacks and invest time into tailoring and scaling them for product needs.<p>I even dedicated most of my time at Algolia to building a custom background jobs pipeline to power the Algolia Shopify integration: ingesting partial webhooks from Shopify, enriching them given customers configuration, in FIFO order per shop, with the Shopify rate limited API, for thousands of shops and the equivalents of 3 millions of jobs per day. Given the complex and unique product requirements of the Algolia Shopify Ingestion Pipeline, the only solution (at the time and context) was to build a custom background jobs stack combining Redis and Kubernetes.<p>When consulting with some startups, we witnessed some developers choosing to keep some slow API routes calling 3rd party APIs synchronously instead of investing time in setting up background jobs. When looking back to the recent increase of productive zero infrastructure solutions in the Node.js ecosystem, we were surprised that the experience with background jobs remained unchanged. We decided to build Defer, so working with background jobs, CRONs, and workflows would match the current standard of Node.js developer experience.<p>Inspired by Next.js, Remix, and Netlify design, background jobs in Defer become background functions that live in your application\u2019s code, with direct access to all configuration options: retry, concurrency, and more (<a href=\"https:&#x2F;&#x2F;docs.defer.run&#x2F;features&#x2F;retries-concurrency&#x2F;\">https:&#x2F;&#x2F;docs.defer.run&#x2F;features&#x2F;retries-concurrency&#x2F;</a>) , and no specific mental model to learn. Your background functions get continuously deployed from GitHub with support for branch-based environments, allowing you to test new background jobs in no time, before safely moving to production.<p>Defer works for all kinds of Node.js projects, not only serverless ones. It does not require you to learn any new architectures or adapt your system design\u2014you just turn your code into background functions using coding patterns you already know, ex: map-reduce, or recursion. \nDefer brings features such as configurable retries (advanced backoff options), throttling, and concurrency at the background job level, which other solutions either require you to implement yourself or are simply not available. Finally, the Defer Dashboard is the only background jobs Dashboard to allow developers to quickly find executions based on business&#x2F;product metadata, ex: \u201cShow all executions for `user_id=123`) to quickly debug product issues.<p>Defer\u2019s infrastructure, written in Go, is composed of 3 main components: a Build pipeline, a Scheduler, and a Runner. The Build pipeline enables us to build any Node.js project without requiring any configuration file (<a href=\"https:&#x2F;&#x2F;docs.defer.run&#x2F;platform&#x2F;builds&#x2F;\">https:&#x2F;&#x2F;docs.defer.run&#x2F;platform&#x2F;builds&#x2F;</a>). The Scheduler relies on Postgres for persistent storage of your jobs (no risk of losing some)\u2014all jobs\u2019 data is encrypted\u2014and on Redis, as an atomic counter to handle features such as concurrency and throttling (<a href=\"https:&#x2F;&#x2F;docs.defer.run&#x2F;platform&#x2F;executions&#x2F;\">https:&#x2F;&#x2F;docs.defer.run&#x2F;platform&#x2F;executions&#x2F;</a>). Our infrastructure runs on AWS EC2 - leveraging auto-scaling groups, using the containerd API directly from Go.<p>We run a progressive deployment approach to enable uninterrupted long-running jobs (some of our customers\u2019 jobs run for more than 5h) while releasing updates multiple times a day.\nOnce your application is up and running, the Defer dashboard gives you all the essential information to operate background jobs: activity histograms, performances, and Slack alerting upon failures. The executions list comes with rich filters, allowing you to quickly find all the executions linked to a specific customer or other business metadata.<p>In short, we ensure that you get all the essential features, with the best developer experience, and with a fully managed infrastructure and observability tools so you can focus on building your product.<p>All of this would be meaningless without a free plan for small and side projects and usage-based pricing, so that\u2019s what we offer: <a href=\"https:&#x2F;&#x2F;www.defer.run&#x2F;pricing\">https:&#x2F;&#x2F;www.defer.run&#x2F;pricing</a>. If you want to give Defer a try, you can get started with a simple GitHub login, without any credit card information required, and our docs are at <a href=\"https:&#x2F;&#x2F;docs.defer.run\">https:&#x2F;&#x2F;docs.defer.run</a>.<p>We would love to get to read about your experience with doing background jobs in Node.js and feedback on what we\u2019ve built. We look forward to your comments!", "title": "Launch HN: Defer (YC W23) \u2013 Zero-infrastructure background jobs for Node.js", "updated_at": "2024-09-20T13:31:31Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "DjGilcrease"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["aws", "sqs", "production"], "value": "The Problem\nEnterprise Go apps typically use multiple message queues: RabbitMQ for reliability, Kafka for streaming, SQS for cloud, NATS for microservices, Redis for caching. Each has different APIs, error handling, and testing strategies.<p>Result: Teams spend months learning 6+ SDKs instead of building features. Migration = complete rewrites.<p>The Solution\nmqutils provides one unified API for 6 major message queue systems. Same code, different URL:<p>// Switch systems by changing URL only\nconsumer, err := mqutils.NewConsumer(&quot;amqp://localhost:5672/orders&quot;)\nconsumer, err := mqutils.NewConsumer(&quot;kafka://localhost:9092/orders&quot;) \nconsumer, err := mqutils.NewConsumer(&quot;sqs://us-east-1/orders&quot;)<p>// Same handler code works everywhere\nconsumer.RegisterHandler(&quot;process&quot;, func(msg types.Message) error {\n    return processOrder(msg.Body())\n})\nWhy It's Different\nNot just another wrapper. <em>Production</em>-grade features built-in:<p>Health monitoring across all 6 systems\nBatch processing with configurable timeouts\nGraceful shutdown with proper cleanup\nContext propagation for distributed tracing\nThread-safe operations with race condition prevention\nPerformance: 100K+ msg/sec, &lt;10ms P99 latency, 99.9% uptime in <em>production</em>.<p>Supported Systems\nAMQP/RabbitMQ (amqp://)\nApache Kafka (kafka://)\nNATS Core/JetStream (nats://, jetstream://)\n<em>AWS SQS</em> (sqs://)\nGCP Pub/Sub (pubsub://)\nRedis Pub/Sub &amp; Streams (redis://, redisstream://)"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Mqutils \u2013 Universal Go message queue library"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://mqutils.dev/"}}, "_tags": ["story", "author_DjGilcrease", "story_44350790", "show_hn"], "author": "DjGilcrease", "created_at": "2025-06-22T22:22:32Z", "created_at_i": 1750630952, "num_comments": 0, "objectID": "44350790", "points": 6, "story_id": 44350790, "story_text": "The Problem\nEnterprise Go apps typically use multiple message queues: RabbitMQ for reliability, Kafka for streaming, SQS for cloud, NATS for microservices, Redis for caching. Each has different APIs, error handling, and testing strategies.<p>Result: Teams spend months learning 6+ SDKs instead of building features. Migration = complete rewrites.<p>The Solution\nmqutils provides one unified API for 6 major message queue systems. Same code, different URL:<p>&#x2F;&#x2F; Switch systems by changing URL only\nconsumer, err := mqutils.NewConsumer(&quot;amqp:&#x2F;&#x2F;localhost:5672&#x2F;orders&quot;)\nconsumer, err := mqutils.NewConsumer(&quot;kafka:&#x2F;&#x2F;localhost:9092&#x2F;orders&quot;) \nconsumer, err := mqutils.NewConsumer(&quot;sqs:&#x2F;&#x2F;us-east-1&#x2F;orders&quot;)<p>&#x2F;&#x2F; Same handler code works everywhere\nconsumer.RegisterHandler(&quot;process&quot;, func(msg types.Message) error {\n    return processOrder(msg.Body())\n})\nWhy It&#x27;s Different\nNot just another wrapper. Production-grade features built-in:<p>Health monitoring across all 6 systems\nBatch processing with configurable timeouts\nGraceful shutdown with proper cleanup\nContext propagation for distributed tracing\nThread-safe operations with race condition prevention\nPerformance: 100K+ msg&#x2F;sec, &lt;10ms P99 latency, 99.9% uptime in production.<p>Supported Systems\nAMQP&#x2F;RabbitMQ (amqp:&#x2F;&#x2F;)\nApache Kafka (kafka:&#x2F;&#x2F;)\nNATS Core&#x2F;JetStream (nats:&#x2F;&#x2F;, jetstream:&#x2F;&#x2F;)\nAWS SQS (sqs:&#x2F;&#x2F;)\nGCP Pub&#x2F;Sub (pubsub:&#x2F;&#x2F;)\nRedis Pub&#x2F;Sub &amp; Streams (redis:&#x2F;&#x2F;, redisstream:&#x2F;&#x2F;)", "title": "Show HN: Mqutils \u2013 Universal Go message queue library", "updated_at": "2025-06-23T08:30:16Z", "url": "https://mqutils.dev/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "csummers"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["aws", "sqs", "production"], "value": "Hi, I'm Curtis, the founder of Hot Dev, a new backend workflow platform.<p>Intro Blog Post: <a href=\"https://hot.dev/blog/introducing-hot-dev\" rel=\"nofollow\">https://hot.dev/blog/introducing-hot-dev</a><p>Building modern backend systems often means wrestling with complex orchestration, scattered logging, poor observability, opaque AI integrations, and difficult developer/devops experiences. Hot Dev is designed to solve these problems!<p>---<p>Why am I building Hot Dev?<p>As a backend developer for 25+ years, at almost every company, the backend team ends up cobbling together background utility servers and workers to process items off of queues, handle events coming into the system, run scheduled jobs and other on-demand asynchronous processes. This is more true in recent years because companies are integrating AI services into every part of their systems and workflows.<p>The team is tasked with choosing and building up each of these services from cloud providers (AWS, Google, etc) and integrating them into applications and backend services. These tasks create a lot of development work (i.e., time and money!) spent on managing and monitoring the infrastructure instead of thinking about your problem domain and your business.<p>Hot Dev provides a managed platform for defining and monitoring workflows at the problem-domain level--allowing you to focus on your business needs.<p>In the same way that Vercel runs your web app for you without you having to think about AWS EC2 servers or Kubernetes, Hot Dev runs your backend workflows for you without you having to think about <em>AWS SQS</em>, Kafka, or ECS.<p>Additionally, as a software developer, I care deeply about the Developer Experience and the DevOps Experience. Hot Dev is designed for a simple, streamlined developer experience...where local development matches <em>production</em>, and deploys are a single command: `hot deploy`<p>Download Hot Dev today for your Mac, Linux, or Window machine at <a href=\"https://hot.dev\" rel=\"nofollow\">https://hot.dev</a><p>---<p>FAQ: (anticipating some HN crowd questions!)<p>Q: A new language.  Are you crazy?<p>A: Yes, and maybe!  But, I felt like bolting on the level of traceability to existing languages created lots of boilerplate code...obscuring the problem domain.  It's definitely a trade-off, but one that I was willing to take.  Hot is a simple, functional, expression-based language with immutable data and optional/gradual types. The language is inspired by Clojure with nods to Rust and Typescript.  I think most developers will find it easy to learn and use. The Hot language vm and the platform itself is written in Rust.<p>Q: How do you compare to temporal, inngest, trigger.dev?\nA: \nHot Dev supports many similar features for scheduled jobs, cancellations, failing, retries, and event-driven architecture.  The primary differences are the use of the Hot Language to defined your workflows and Hot functions wrapping other API services--either your own backend APIs or other external API services.<p>And, as mentioned at the end of the intro blog post, I'll be adding two significant features to the platform soon: \n1) Hot Box Container Execution--the ability to run an OCI container image as a Hot function\n2) MCP (Model Context Protocol) support -- turn any Hot function into an MCP Tool.<p>Q: Is this Open Source?\nA: Not yet, but this is the plan.  I'm holding the reigns a little tight for now with the new language, but I expect the Hot language implementation to be open source within the year.  If it helps...I'm also the author of HugSQL (<a href=\"https://hugsql.org\" rel=\"nofollow\">https://hugsql.org</a>).<p>---<p>If you can't tell from the video, I'm having so much fun with this! Follow Hot Dev on X <a href=\"https://x.com/hotdotdev\" rel=\"nofollow\">https://x.com/hotdotdev</a> for updates!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Hot Dev \u2013 a new backend workflow language and platform"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://hot.dev"}}, "_tags": ["story", "author_csummers", "story_46797907", "show_hn"], "author": "csummers", "created_at": "2026-01-28T16:51:45Z", "created_at_i": 1769619105, "num_comments": 0, "objectID": "46797907", "points": 1, "story_id": 46797907, "story_text": "Hi, I&#x27;m Curtis, the founder of Hot Dev, a new backend workflow platform.<p>Intro Blog Post: <a href=\"https:&#x2F;&#x2F;hot.dev&#x2F;blog&#x2F;introducing-hot-dev\" rel=\"nofollow\">https:&#x2F;&#x2F;hot.dev&#x2F;blog&#x2F;introducing-hot-dev</a><p>Building modern backend systems often means wrestling with complex orchestration, scattered logging, poor observability, opaque AI integrations, and difficult developer&#x2F;devops experiences. Hot Dev is designed to solve these problems!<p>---<p>Why am I building Hot Dev?<p>As a backend developer for 25+ years, at almost every company, the backend team ends up cobbling together background utility servers and workers to process items off of queues, handle events coming into the system, run scheduled jobs and other on-demand asynchronous processes. This is more true in recent years because companies are integrating AI services into every part of their systems and workflows.<p>The team is tasked with choosing and building up each of these services from cloud providers (AWS, Google, etc) and integrating them into applications and backend services. These tasks create a lot of development work (i.e., time and money!) spent on managing and monitoring the infrastructure instead of thinking about your problem domain and your business.<p>Hot Dev provides a managed platform for defining and monitoring workflows at the problem-domain level--allowing you to focus on your business needs.<p>In the same way that Vercel runs your web app for you without you having to think about AWS EC2 servers or Kubernetes, Hot Dev runs your backend workflows for you without you having to think about AWS SQS, Kafka, or ECS.<p>Additionally, as a software developer, I care deeply about the Developer Experience and the DevOps Experience. Hot Dev is designed for a simple, streamlined developer experience...where local development matches production, and deploys are a single command: `hot deploy`<p>Download Hot Dev today for your Mac, Linux, or Window machine at <a href=\"https:&#x2F;&#x2F;hot.dev\" rel=\"nofollow\">https:&#x2F;&#x2F;hot.dev</a><p>---<p>FAQ: (anticipating some HN crowd questions!)<p>Q: A new language.  Are you crazy?<p>A: Yes, and maybe!  But, I felt like bolting on the level of traceability to existing languages created lots of boilerplate code...obscuring the problem domain.  It&#x27;s definitely a trade-off, but one that I was willing to take.  Hot is a simple, functional, expression-based language with immutable data and optional&#x2F;gradual types. The language is inspired by Clojure with nods to Rust and Typescript.  I think most developers will find it easy to learn and use. The Hot language vm and the platform itself is written in Rust.<p>Q: How do you compare to temporal, inngest, trigger.dev?\nA: \nHot Dev supports many similar features for scheduled jobs, cancellations, failing, retries, and event-driven architecture.  The primary differences are the use of the Hot Language to defined your workflows and Hot functions wrapping other API services--either your own backend APIs or other external API services.<p>And, as mentioned at the end of the intro blog post, I&#x27;ll be adding two significant features to the platform soon: \n1) Hot Box Container Execution--the ability to run an OCI container image as a Hot function\n2) MCP (Model Context Protocol) support -- turn any Hot function into an MCP Tool.<p>Q: Is this Open Source?\nA: Not yet, but this is the plan.  I&#x27;m holding the reigns a little tight for now with the new language, but I expect the Hot language implementation to be open source within the year.  If it helps...I&#x27;m also the author of HugSQL (<a href=\"https:&#x2F;&#x2F;hugsql.org\" rel=\"nofollow\">https:&#x2F;&#x2F;hugsql.org</a>).<p>---<p>If you can&#x27;t tell from the video, I&#x27;m having so much fun with this! Follow Hot Dev on X <a href=\"https:&#x2F;&#x2F;x.com&#x2F;hotdotdev\" rel=\"nofollow\">https:&#x2F;&#x2F;x.com&#x2F;hotdotdev</a> for updates!", "title": "Show HN: Hot Dev \u2013 a new backend workflow language and platform", "updated_at": "2026-01-28T16:57:02Z", "url": "https://hot.dev"}], "hitsPerPage": 15, "nbHits": 3, "nbPages": 1, "page": 0, "params": "query=aws-sqs+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 8, "processingTimingsMS": {"_request": {"roundTrip": 20}, "afterFetch": {"format": {"highlighting": 1, "total": 1}}, "fetch": {"query": 6, "total": 7}, "total": 8}, "query": "aws-sqs production", "serverTimeMS": 9}}