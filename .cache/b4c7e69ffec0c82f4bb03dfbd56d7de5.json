{"d": [{"url": "https://api.github.com/repos/run-llama/llama_index/releases/287829122", "assets_url": "https://api.github.com/repos/run-llama/llama_index/releases/287829122/assets", "upload_url": "https://uploads.github.com/repos/run-llama/llama_index/releases/287829122/assets{?name,label}", "html_url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.15", "id": 287829122, "author": {"login": "github-actions[bot]", "id": 41898282, "node_id": "MDM6Qm90NDE4OTgyODI=", "avatar_url": "https://avatars.githubusercontent.com/in/15368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/github-actions%5Bbot%5D", "html_url": "https://github.com/apps/github-actions", "followers_url": "https://api.github.com/users/github-actions%5Bbot%5D/followers", "following_url": "https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/github-actions%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/github-actions%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/github-actions%5Bbot%5D/repos", "events_url": "https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/github-actions%5Bbot%5D/received_events", "type": "Bot", "user_view_type": "public", "site_admin": false}, "node_id": "RE_kwDOIWuq584RJ-yC", "tag_name": "v0.14.15", "target_commitish": "main", "name": "v0.14.15", "draft": false, "immutable": false, "prerelease": false, "created_at": "2026-02-18T19:04:35Z", "updated_at": "2026-02-18T19:06:42Z", "published_at": "2026-02-18T19:06:42Z", "assets": [{"url": "https://api.github.com/repos/run-llama/llama_index/releases/assets/358093886", "id": 358093886, "node_id": "RA_kwDOIWuq584VWBQ-", "name": "llama_index-0.14.15.tar.gz", "label": "", "uploader": {"login": "github-actions[bot]", "id": 41898282, "node_id": "MDM6Qm90NDE4OTgyODI=", "avatar_url": "https://avatars.githubusercontent.com/in/15368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/github-actions%5Bbot%5D", "html_url": "https://github.com/apps/github-actions", "followers_url": "https://api.github.com/users/github-actions%5Bbot%5D/followers", "following_url": "https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/github-actions%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/github-actions%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/github-actions%5Bbot%5D/repos", "events_url": "https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/github-actions%5Bbot%5D/received_events", "type": "Bot", "user_view_type": "public", "site_admin": false}, "content_type": "application/x-gtar", "state": "uploaded", "size": 8472, "digest": "sha256:079f65e72af87c72dd8b516aa2dd520b52eb2128722d66ecce1e5148cee357c0", "download_count": 8, "created_at": "2026-02-18T19:06:41Z", "updated_at": "2026-02-18T19:06:41Z", "browser_download_url": "https://github.com/run-llama/llama_index/releases/download/v0.14.15/llama_index-0.14.15.tar.gz"}], "tarball_url": "https://api.github.com/repos/run-llama/llama_index/tarball/v0.14.15", "zipball_url": "https://api.github.com/repos/run-llama/llama_index/zipball/v0.14.15", "body": "# Release Notes\n\n## [2026-02-18]\n\n### llama-index-agent-agentmesh [0.1.0]\n\n- [Integration] AgentMesh: Trust Layer for LlamaIndex Agents ([#20644](https://github.com/run-llama/llama_index/pull/20644))\n\n### llama-index-core [0.14.15]\n\n- Support basic operations for multimodal types ([#20640](https://github.com/run-llama/llama_index/pull/20640))\n- Feat recursive llm type support ([#20642](https://github.com/run-llama/llama_index/pull/20642))\n- fix: remove redundant metadata_seperator field from TextNode ([#20649](https://github.com/run-llama/llama_index/pull/20649))\n- fix(tests): update mock prompt type in mock_prompts.py ([#20661](https://github.com/run-llama/llama_index/pull/20661))\n- Feat multimodal template var formatting ([#20682](https://github.com/run-llama/llama_index/pull/20682))\n- Feat multimodal prompt templates ([#20683](https://github.com/run-llama/llama_index/pull/20683))\n- Feat multimodal chat prompt helper ([#20684](https://github.com/run-llama/llama_index/pull/20684))\n- Add retry and error handling to BaseExtractor ([#20693](https://github.com/run-llama/llama_index/pull/20693))\n- ensure at least one message/content block is returned by the old memory ([#20729](https://github.com/run-llama/llama_index/pull/20729))\n\n### llama-index-embeddings-ibm [0.6.0.post1]\n\n- chore: Remove persistent_connection parameter support, update ([#20714](https://github.com/run-llama/llama_index/pull/20714))\n- docs: Update IBM docs ([#20718](https://github.com/run-llama/llama_index/pull/20718))\n\n### llama-index-llms-anthropic [0.10.9]\n\n- Sonnet 4-6 addition ([#20723](https://github.com/run-llama/llama_index/pull/20723))\n\n### llama-index-llms-bedrock-converse [0.12.10]\n\n- fix(bedrock-converse): ensure thinking_delta is populated in all chat modes ([#20664](https://github.com/run-llama/llama_index/pull/20664))\n- feat(bedrock-converse): Add support for Claude Sonnet 4.6 ([#20726](https://github.com/run-llama/llama_index/pull/20726))\n\n### llama-index-llms-ibm [0.7.0.post1]\n\n- chore: Remove persistent_connection parameter support, update ([#20714](https://github.com/run-llama/llama_index/pull/20714))\n- docs: Update IBM docs ([#20718](https://github.com/run-llama/llama_index/pull/20718))\n\n### llama-index-llms-mistralai [0.10.0]\n\n- Rrubini/mistral azure sdk ([#20668](https://github.com/run-llama/llama_index/pull/20668))\n\n### llama-index-llms-oci-data-science [1.0.0]\n\n- Add support for new OCI DataScience endpoint /predictWithStream for streaming use case ([#20545](https://github.com/run-llama/llama_index/pull/20545))\n\n### llama-index-observability-otel [0.3.0]\n\n- improve otel data serialization by flattening dicts ([#20719](https://github.com/run-llama/llama_index/pull/20719))\n- feat: support custom span processor; refactor: use llama-index-instrumentation instead of llama-index-core ([#20732](https://github.com/run-llama/llama_index/pull/20732))\n\n### llama-index-program-evaporate [0.5.2]\n\n- Sandbox LLM-generated code execution in EvaporateExtractor ([#20676](https://github.com/run-llama/llama_index/pull/20676))\n\n### llama-index-readers-bitbucket [0.4.2]\n\n- fix: replace mutable default argument in load_all_file_paths ([#20698](https://github.com/run-llama/llama_index/pull/20698))\n\n### llama-index-readers-github [0.10.0]\n\n- feat: Enhance GitHubRepoReader with selective file fetching and deduplication (Issue #20471) ([#20550](https://github.com/run-llama/llama_index/pull/20550))\n\n### llama-index-readers-layoutir [0.1.1]\n\n- feat: Add LayoutIR reader integration ([#20708](https://github.com/run-llama/llama_index/pull/20708))\n- fix(layoutir): hotfix for output_dir crash and Block extraction (#20708 follow-up) ([#20715](https://github.com/run-llama/llama_index/pull/20715))\n- fix(layoutir): restrict requires-python to >=3.12 to match layoutir dependency ([#20733](https://github.com/run-llama/llama_index/pull/20733))\n\n### llama-index-readers-microsoft-sharepoint [0.8.0]\n\n- Add pagination support for Microsoft Graph API calls in SharePoint reader ([#20704](https://github.com/run-llama/llama_index/pull/20704))\n\n### llama-index-readers-whatsapp [0.4.2]\n\n- fix: Update WhatsAppChatLoader to retrieve DataFrame in pandas format ([#20722](https://github.com/run-llama/llama_index/pull/20722))\n\n### llama-index-tools-mcp [0.4.7]\n\n- feat: propagate partial_params to get_tools_from_mcp utils ([#20669](https://github.com/run-llama/llama_index/pull/20669))\n\n### llama-index-vector-stores-faiss [0.5.3]\n\n- Replace eval() with json.loads in FaissMapVectorStore persistence ([#20675](https://github.com/run-llama/llama_index/pull/20675))\n\n### llama-index-vector-stores-milvus [1.0.0]\n\n- Fix: remove ORM Collection mix-usage with MilvusClient in Milvus vector store ([#20687](https://github.com/run-llama/llama_index/pull/20687))\n\n"}, {"url": "https://api.github.com/repos/run-llama/llama_index/releases/285038911", "assets_url": "https://api.github.com/repos/run-llama/llama_index/releases/285038911/assets", "upload_url": "https://uploads.github.com/repos/run-llama/llama_index/releases/285038911/assets{?name,label}", "html_url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.14", "id": 285038911, "author": {"login": "github-actions[bot]", "id": 41898282, "node_id": "MDM6Qm90NDE4OTgyODI=", "avatar_url": "https://avatars.githubusercontent.com/in/15368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/github-actions%5Bbot%5D", "html_url": "https://github.com/apps/github-actions", "followers_url": "https://api.github.com/users/github-actions%5Bbot%5D/followers", "following_url": "https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/github-actions%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/github-actions%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/github-actions%5Bbot%5D/repos", "events_url": "https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/github-actions%5Bbot%5D/received_events", "type": "Bot", "user_view_type": "public", "site_admin": false}, "node_id": "RE_kwDOIWuq584Q_Vk_", "tag_name": "v0.14.14", "target_commitish": "main", "name": "v0.14.14", "draft": false, "immutable": false, "prerelease": false, "created_at": "2026-02-10T23:06:47Z", "updated_at": "2026-02-10T23:08:46Z", "published_at": "2026-02-10T23:08:46Z", "assets": [{"url": "https://api.github.com/repos/run-llama/llama_index/releases/assets/353865567", "id": 353865567, "node_id": "RA_kwDOIWuq584VF49f", "name": "llama_index-0.14.14.tar.gz", "label": "", "uploader": {"login": "github-actions[bot]", "id": 41898282, "node_id": "MDM6Qm90NDE4OTgyODI=", "avatar_url": "https://avatars.githubusercontent.com/in/15368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/github-actions%5Bbot%5D", "html_url": "https://github.com/apps/github-actions", "followers_url": "https://api.github.com/users/github-actions%5Bbot%5D/followers", "following_url": "https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/github-actions%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/github-actions%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/github-actions%5Bbot%5D/repos", "events_url": "https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/github-actions%5Bbot%5D/received_events", "type": "Bot", "user_view_type": "public", "site_admin": false}, "content_type": "application/x-gtar", "state": "uploaded", "size": 8508, "digest": "sha256:cb3524adade2d5171caf67bac5ce1c5c080be312497956f31b597a79a9dee225", "download_count": 8, "created_at": "2026-02-10T23:08:45Z", "updated_at": "2026-02-10T23:08:46Z", "browser_download_url": "https://github.com/run-llama/llama_index/releases/download/v0.14.14/llama_index-0.14.14.tar.gz"}], "tarball_url": "https://api.github.com/repos/run-llama/llama_index/tarball/v0.14.14", "zipball_url": "https://api.github.com/repos/run-llama/llama_index/zipball/v0.14.14", "body": "# Release Notes\n\n## [2026-02-10]\n\n### llama-index-callbacks-wandb [0.4.2]\n\n- Fix potential crashes and improve security defaults in core components ([#20610](https://github.com/run-llama/llama_index/pull/20610))\n\n### llama-index-core [0.14.14]\n\n- fix: catch pydantic ValidationError in VectorStoreQueryOutputParser ([#20450](https://github.com/run-llama/llama_index/pull/20450))\n- fix: distinguish empty string from None in MediaResource.hash ([#20451](https://github.com/run-llama/llama_index/pull/20451))\n- Langchain1.x support ([#20472](https://github.com/run-llama/llama_index/pull/20472))\n- Fix DeprecationWarning: 'asyncio.iscoroutinefunction' is deprecated ([#20517](https://github.com/run-llama/llama_index/pull/20517))\n- fix(core): fallback to bundled nltk cache if env var missing ([#20528](https://github.com/run-llama/llama_index/pull/20528))\n- feat(callbacks): add TokenBudgetHandler for cost governance ([#20546](https://github.com/run-llama/llama_index/pull/20546))\n- fix(core):handled a edge case in truncate_text function ([#20551](https://github.com/run-llama/llama_index/pull/20551))\n- fix(core):fix in types Thread passing None when target is None instead of copy_context().run ([#20553](https://github.com/run-llama/llama_index/pull/20553))\n- chore: bump llama-index lockfile, and minor test tweaks ([#20556](https://github.com/run-llama/llama_index/pull/20556))\n- Compatibility for workflows context changes ([#20557](https://github.com/run-llama/llama_index/pull/20557))\n- test(core): fix cache dir path test for Windows compatibility ([#20566](https://github.com/run-llama/llama_index/pull/20566))\n- fix(tests): enforce utf-8 encoding in json reader tests for windows compatibility ([#20576](https://github.com/run-llama/llama_index/pull/20576))\n- Fix BM25Retriever mapping in upgrade tool / \u4fee\u590d\u5347\u7ea7\u5de5\u5177\u4e2d\u7684 BM25Retriever \u6620\u5c04 ([#20582](https://github.com/run-llama/llama_index/pull/20582))\n- fix(agent): handle empty LLM responses with retry logic and add test cases ([#20596](https://github.com/run-llama/llama_index/pull/20596))\n- fix: add show_progress parameter to run_transformations to prevent unexpected keyword argument error ([#20608](https://github.com/run-llama/llama_index/pull/20608))\n- Fix potential crashes and improve security defaults in core components ([#20610](https://github.com/run-llama/llama_index/pull/20610))\n- Add core 3.14 tests ([#20619](https://github.com/run-llama/llama_index/pull/20619))\n\n### llama-index-embeddings-cohere [0.7.0]\n\n- fix(embeddings-cohere): add retry logic with tenacity ([#20592](https://github.com/run-llama/llama_index/pull/20592))\n\n### llama-index-embeddings-google-genai [0.3.2]\n\n- Add client headers to Gemini API requests ([#20519](https://github.com/run-llama/llama_index/pull/20519))\n\n### llama-index-embeddings-siliconflow [0.3.2]\n\n- Fix DeprecationWarning: 'asyncio.iscoroutinefunction' is deprecated ([#20517](https://github.com/run-llama/llama_index/pull/20517))\n\n### llama-index-embeddings-upstage [0.5.1]\n\n- chore(deps): bump the uv group across 4 directories with 4 updates ([#20531](https://github.com/run-llama/llama_index/pull/20531))\n\n### llama-index-graph-stores-falkordb [0.4.2]\n\n- fix(falkordb): Fix MENTIONS relationship creation with triplet_source_id ([#20650](https://github.com/run-llama/llama_index/pull/20650))\n\n### llama-index-llms-anthropic [0.10.8]\n\n- chore: Update cacheable Anthropic models ([#20581](https://github.com/run-llama/llama_index/pull/20581))\n- chore: add support for opus 4.6 ([#20635](https://github.com/run-llama/llama_index/pull/20635))\n\n### llama-index-llms-bedrock-converse [0.12.8]\n\n- fix bedrock converse empty tool config issue ([#20571](https://github.com/run-llama/llama_index/pull/20571))\n- fix(llms-bedrock-converse): improve bedrock converse retry handling ([#20590](https://github.com/run-llama/llama_index/pull/20590))\n- feat(bedrock-converse): Add support for Claude Opus 4.6 ([#20637](https://github.com/run-llama/llama_index/pull/20637))\n- Add support for adaptive thinking in Bedrock ([#20659](https://github.com/run-llama/llama_index/pull/20659))\n- chore(deps): bump the pip group across 2 directories with 7 updates ([#20662](https://github.com/run-llama/llama_index/pull/20662))\n\n### llama-index-llms-cohere [0.7.1]\n\n- Feat: add custom base_url support to Cohere LLM ([#20534](https://github.com/run-llama/llama_index/pull/20534))\n- fix(llms-cohere): handle additional error types in retry logic ([#20591](https://github.com/run-llama/llama_index/pull/20591))\n\n### llama-index-llms-dashscope [0.5.2]\n\n- fix(dashscope): remove empty tool_calls from assistant messages ([#20535](https://github.com/run-llama/llama_index/pull/20535))\n\n### llama-index-llms-google-genai [0.8.7]\n\n- Add client headers to Gemini API requests ([#20519](https://github.com/run-llama/llama_index/pull/20519))\n- fix(decorator):adds logic to llm_retry_decorator for async methods. ([#20588](https://github.com/run-llama/llama_index/pull/20588))\n- Fix/google genai cleanup ([#20607](https://github.com/run-llama/llama_index/pull/20607))\n- fix(google-genai): skip model meta fetch when not needed ([#20639](https://github.com/run-llama/llama_index/pull/20639))\n\n### llama-index-llms-huggingface-api [0.6.2]\n\n- Update sensible default provider for huggingface inference api ([#20589](https://github.com/run-llama/llama_index/pull/20589))\n\n### llama-index-llms-langchain [0.7.1]\n\n- Langchain1.x support ([#20472](https://github.com/run-llama/llama_index/pull/20472))\n\n### llama-index-llms-openai [0.6.18]\n\n- OpenAI response fix ([#20538](https://github.com/run-llama/llama_index/pull/20538))\n- feat: Add support for gpt-5.2-chat model ([#20549](https://github.com/run-llama/llama_index/pull/20549))\n- fix(openai): make image_url detail optional in message dict ([#20609](https://github.com/run-llama/llama_index/pull/20609))\n- Add new reasoning types ([#20612](https://github.com/run-llama/llama_index/pull/20612))\n- fix(openai): exclude unsupported params for all reasoning models ([#20627](https://github.com/run-llama/llama_index/pull/20627))\n\n### llama-index-llms-openai-like [0.6.0]\n\n- make transformers an optional dependency for openai-like ([#20580](https://github.com/run-llama/llama_index/pull/20580))\n\n### llama-index-llms-openrouter [0.4.4]\n\n- make transformers an optional dependency for openai-like ([#20580](https://github.com/run-llama/llama_index/pull/20580))\n\n### llama-index-llms-siliconflow [0.4.3]\n\n- Fix DeprecationWarning: 'asyncio.iscoroutinefunction' is deprecated ([#20517](https://github.com/run-llama/llama_index/pull/20517))\n\n### llama-index-llms-upstage [0.7.0]\n\n- add new upstage model(solar-pro3) ([#20544](https://github.com/run-llama/llama_index/pull/20544))\n\n### llama-index-llms-vllm [0.6.2]\n\n- feat: add openai-like server mode for VllmServer ([#20537](https://github.com/run-llama/llama_index/pull/20537))\n\n### llama-index-memory-bedrock-agentcore [0.1.2]\n\n- Add event and memory record deletion methods in bedrock-agentcorememory ([#20428](https://github.com/run-llama/llama_index/pull/20428))\n- chore(deps): update llama-index-core dependency lock to include 0.14.x ([#20483](https://github.com/run-llama/llama_index/pull/20483))\n\n### llama-index-memory-mem0 [1.0.0]\n\n- fix: mem0 integration cleanup + refactor ([#20532](https://github.com/run-llama/llama_index/pull/20532))\n\n### llama-index-node-parser-chonkie [0.1.1]\n\n- feat: add chonkie integration ([#20622](https://github.com/run-llama/llama_index/pull/20622))\n- update readme ([#20656](https://github.com/run-llama/llama_index/pull/20656))\n\n### llama-index-node-parser-docling [0.4.2]\n\n- fix: catch pydantic ValidationError in VectorStoreQueryOutputParser ([#20450](https://github.com/run-llama/llama_index/pull/20450))\n\n### llama-index-packs-code-hierarchy [0.6.1]\n\n- chore(deps): bump the uv group across 12 directories with 14 updates ([#20578](https://github.com/run-llama/llama_index/pull/20578))\n\n### llama-index-packs-gmail-openai-agent [0.4.1]\n\n- chore(deps): bump the uv group across 12 directories with 14 updates ([#20578](https://github.com/run-llama/llama_index/pull/20578))\n\n### llama-index-packs-multidoc-autoretrieval [0.4.1]\n\n- chore(deps): bump the uv group across 12 directories with 14 updates ([#20578](https://github.com/run-llama/llama_index/pull/20578))\n\n### llama-index-packs-panel-chatbot [0.4.1]\n\n- chore(deps): bump the uv group across 12 directories with 14 updates ([#20578](https://github.com/run-llama/llama_index/pull/20578))\n\n### llama-index-packs-recursive-retriever [0.7.1]\n\n- chore(deps): bump the uv group across 12 directories with 14 updates ([#20578](https://github.com/run-llama/llama_index/pull/20578))\n- chore(deps): bump the pip group across 2 directories with 7 updates ([#20662](https://github.com/run-llama/llama_index/pull/20662))\n\n### llama-index-packs-resume-screener [0.9.3]\n\n- chore(deps): bump the uv group across 12 directories with 14 updates ([#20578](https://github.com/run-llama/llama_index/pull/20578))\n\n### llama-index-packs-retry-engine-weaviate [0.5.1]\n\n- chore(deps): bump the uv group across 12 directories with 14 updates ([#20578](https://github.com/run-llama/llama_index/pull/20578))\n\n### llama-index-packs-streamlit-chatbot [0.5.2]\n\n- chore(deps): bump the uv group across 12 directories with 14 updates ([#20578](https://github.com/run-llama/llama_index/pull/20578))\n\n### llama-index-packs-sub-question-weaviate [0.4.1]\n\n- chore(deps): bump the uv group across 12 directories with 14 updates ([#20578](https://github.com/run-llama/llama_index/pull/20578))\n\n### llama-index-packs-timescale-vector-autoretrieval [0.4.1]\n\n- chore(deps): bump the uv group across 12 directories with 14 updates ([#20578](https://github.com/run-llama/llama_index/pull/20578))\n\n### llama-index-postprocessor-cohere-rerank [0.6.0]\n\n- fix(cohere-rerank): add retry logic and tenacity dependency to cohere rerank ([#20593](https://github.com/run-llama/llama_index/pull/20593))\n\n### llama-index-postprocessor-nvidia-rerank [0.5.4]\n\n- fix(nvidia-rerank): fix initialization logic for on-prem auth ([#20560](https://github.com/run-llama/llama_index/pull/20560))\n- fix(nvidia-rerank): correct private attribute reference ([#20570](https://github.com/run-llama/llama_index/pull/20570))\n- fix(nvidia-rerank): Fix POST request url for locally hosted NIM rerankers ([#20579](https://github.com/run-llama/llama_index/pull/20579))\n\n### llama-index-postprocessor-tei-rerank [0.4.2]\n\n- fix(tei-rerank): use index field from API response for correct score \u2026 ([#20599](https://github.com/run-llama/llama_index/pull/20599))\n- test(tei-rerank): add test coverage for rerank retry coverage ([#20600](https://github.com/run-llama/llama_index/pull/20600))\n\n### llama-index-protocols-ag-ui [0.2.4]\n\n- fix: avoid ValueError in ag-ui message conversion for multi-block ChatMessages ([#20648](https://github.com/run-llama/llama_index/pull/20648))\n\n### llama-index-readers-datasets [0.1.0]\n\n- chore(deps): bump the uv group across 4 directories with 4 updates ([#20531](https://github.com/run-llama/llama_index/pull/20531))\n\n### llama-index-readers-microsoft-sharepoint [0.7.0]\n\n- Sharepoint page support events ([#20572](https://github.com/run-llama/llama_index/pull/20572))\n\n### llama-index-readers-obsidian [0.6.1]\n\n- Langchain1.x support ([#20472](https://github.com/run-llama/llama_index/pull/20472))\n\n### llama-index-readers-service-now [0.2.2]\n\n- chore(deps): bump the pip group across 2 directories with 7 updates ([#20662](https://github.com/run-llama/llama_index/pull/20662))\n\n### llama-index-tools-mcp [0.4.6]\n\n- feat: implement partial_params support to McpToolSpec ([#20554](https://github.com/run-llama/llama_index/pull/20554))\n\n### llama-index-tools-mcp-discovery [0.1.0]\n\n- Add llama-index-tools-mcp-discovery integration ([#20502](https://github.com/run-llama/llama_index/pull/20502))\n\n### llama-index-tools-moss [0.1.0]\n\n- feat(tools): add Moss search engine integration ([#20615](https://github.com/run-llama/llama_index/pull/20615))\n\n### llama-index-tools-seltz [0.1.0]\n\n- feat(tools): add Seltz web knowledge tool integration ([#20626](https://github.com/run-llama/llama_index/pull/20626))\n\n### llama-index-tools-typecast [0.1.0]\n\n- Migrate Typecast tool to V2 API for voices endpoints ([#20548](https://github.com/run-llama/llama_index/pull/20548))\n\n### llama-index-tools-wolfram-alpha [0.5.0]\n\n- feat(wolfram-alpha): switch to LLM API with bearer auth ([#20586](https://github.com/run-llama/llama_index/pull/20586))\n\n### llama-index-vector-stores-clickhouse [0.6.2]\n\n- fix(clickhouse): Add drop_existing_table parameter to prevent data loss ([#20651](https://github.com/run-llama/llama_index/pull/20651))\n\n### llama-index-vector-stores-milvus [0.9.6]\n\n- chore(deps): bump the uv group across 4 directories with 4 updates ([#20531](https://github.com/run-llama/llama_index/pull/20531))\n\n### llama-index-vector-stores-mongodb [0.9.1]\n\n- Update MongoDB vector store tests to use newer model ([#20515](https://github.com/run-llama/llama_index/pull/20515))\n\n### llama-index-vector-stores-oceanbase [0.4.0]\n\n- feat(oceanbase): add sparse/fulltext/hybrid search ([#20524](https://github.com/run-llama/llama_index/pull/20524))\n\n### llama-index-vector-stores-opensearch [1.0.0]\n\n- Changed OpenSearch engine default from deprecated `nmslib` to `faiss` ([#20507](https://github.com/run-llama/llama_index/pull/20507))\n- chore(deps): bump the uv group across 4 directories with 4 updates ([#20531](https://github.com/run-llama/llama_index/pull/20531))\n\n### llama-index-vector-stores-postgres [0.7.3]\n\n- fix(postgres): disable bitmap scan for vector queries ([#20514](https://github.com/run-llama/llama_index/pull/20514))\n\n### llama-index-vector-stores-yugabytedb [0.5.4]\n\n- Add YugabyteDB as a Vector Store ([#20559](https://github.com/run-llama/llama_index/pull/20559))\n- chore(deps): bump the pip group across 2 directories with 7 updates ([#20662](https://github.com/run-llama/llama_index/pull/20662))\n\n### llama-index-voice-agents-gemini-live [0.2.2]\n\n- Add client headers to Gemini API requests ([#20519](https://github.com/run-llama/llama_index/pull/20519))\n\n"}, {"url": "https://api.github.com/repos/run-llama/llama_index/releases/278780918", "assets_url": "https://api.github.com/repos/run-llama/llama_index/releases/278780918/assets", "upload_url": "https://uploads.github.com/repos/run-llama/llama_index/releases/278780918/assets{?name,label}", "html_url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.13", "id": 278780918, "author": {"login": "github-actions[bot]", "id": 41898282, "node_id": "MDM6Qm90NDE4OTgyODI=", "avatar_url": "https://avatars.githubusercontent.com/in/15368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/github-actions%5Bbot%5D", "html_url": "https://github.com/apps/github-actions", "followers_url": "https://api.github.com/users/github-actions%5Bbot%5D/followers", "following_url": "https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/github-actions%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/github-actions%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/github-actions%5Bbot%5D/repos", "events_url": "https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/github-actions%5Bbot%5D/received_events", "type": "Bot", "user_view_type": "public", "site_admin": false}, "node_id": "RE_kwDOIWuq584Qndv2", "tag_name": "v0.14.13", "target_commitish": "main", "name": "v0.14.13", "draft": false, "immutable": false, "prerelease": false, "created_at": "2026-01-21T20:43:07Z", "updated_at": "2026-01-21T20:44:52Z", "published_at": "2026-01-21T20:44:52Z", "assets": [{"url": "https://api.github.com/repos/run-llama/llama_index/releases/assets/343941540", "id": 343941540, "node_id": "RA_kwDOIWuq584UgCGk", "name": "llama_index-0.14.13.tar.gz", "label": "", "uploader": {"login": "github-actions[bot]", "id": 41898282, "node_id": "MDM6Qm90NDE4OTgyODI=", "avatar_url": "https://avatars.githubusercontent.com/in/15368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/github-actions%5Bbot%5D", "html_url": "https://github.com/apps/github-actions", "followers_url": "https://api.github.com/users/github-actions%5Bbot%5D/followers", "following_url": "https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/github-actions%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/github-actions%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/github-actions%5Bbot%5D/repos", "events_url": "https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/github-actions%5Bbot%5D/received_events", "type": "Bot", "user_view_type": "public", "site_admin": false}, "content_type": "application/x-gtar", "state": "uploaded", "size": 8461, "digest": "sha256:6392822f8ad0e747da2f0adbfcd170bc91fafdff4341cd50da809feae5ca828a", "download_count": 21, "created_at": "2026-01-21T20:44:51Z", "updated_at": "2026-01-21T20:44:51Z", "browser_download_url": "https://github.com/run-llama/llama_index/releases/download/v0.14.13/llama_index-0.14.13.tar.gz"}], "tarball_url": "https://api.github.com/repos/run-llama/llama_index/tarball/v0.14.13", "zipball_url": "https://api.github.com/repos/run-llama/llama_index/zipball/v0.14.13", "body": "# Release Notes\n\n## [2026-01-21]\n\n### llama-index-core [0.14.13]\n\n- feat: add early_stopping_method parameter to agent workflows ([#20389](https://github.com/run-llama/llama_index/pull/20389))\n- feat: Add token-based code splitting support to CodeSplitter ([#20438](https://github.com/run-llama/llama_index/pull/20438))\n- Add RayIngestionPipeline integration for distributed data ingestion ([#20443](https://github.com/run-llama/llama_index/pull/20443))\n- Added the multi-modal version of the Condensed Conversation & Context\u2026 ([#20446](https://github.com/run-llama/llama_index/pull/20446))\n- Replace ChatMemoryBuffer with Memory ([#20458](https://github.com/run-llama/llama_index/pull/20458))\n- fix(bug):Raise value error on when input is empty list in mean_agg instead of returning float ([#20466](https://github.com/run-llama/llama_index/pull/20466))\n- fix: The classmethod of ReActChatFormatter should use cls instead of the class name ([#20475](https://github.com/run-llama/llama_index/pull/20475))\n- feat: add configurable empty response message to synthesizers ([#20503](https://github.com/run-llama/llama_index/pull/20503))\n\n### llama-index-embeddings-bedrock [0.7.3]\n\n- Enable use of ARNs for Bedrock Embedding Models ([#20435](https://github.com/run-llama/llama_index/pull/20435))\n\n### llama-index-embeddings-ollama [0.8.6]\n\n- Improved Ollama batch embedding ([#20447](https://github.com/run-llama/llama_index/pull/20447))\n\n### llama-index-embeddings-voyageai [0.5.3]\n\n- Adding voyage-4 models ([#20497](https://github.com/run-llama/llama_index/pull/20497))\n\n### llama-index-ingestion-ray [0.1.0]\n\n- Add RayIngestionPipeline integration for distributed data ingestion ([#20443](https://github.com/run-llama/llama_index/pull/20443))\n\n### llama-index-llms-anthropic [0.10.6]\n\n- feat: enhance structured predict methods for anthropic ([#20440](https://github.com/run-llama/llama_index/pull/20440))\n- fix: preserve input_tokens in Anthropic stream_chat responses ([#20512](https://github.com/run-llama/llama_index/pull/20512))\n\n### llama-index-llms-apertis [0.1.0]\n\n- Add Apertis LLM integration with example notebook ([#20436](https://github.com/run-llama/llama_index/pull/20436))\n\n### llama-index-llms-bedrock-converse [0.12.4]\n\n- chore(bedrock-converse): Remove extraneous thinking_delta kwarg from ChatMessage ([#20455](https://github.com/run-llama/llama_index/pull/20455))\n\n### llama-index-llms-gemini [0.6.2]\n\n- chore: deprecate llama-index-llms-gemini ([#20511](https://github.com/run-llama/llama_index/pull/20511))\n\n### llama-index-llms-openai [0.6.13]\n\n- Sanitize OpenAI structured output JSON schema name for generic Pydantic models ([#20452](https://github.com/run-llama/llama_index/pull/20452))\n- chore: vbump openai ([#20482](https://github.com/run-llama/llama_index/pull/20482))\n\n### llama-index-llms-openrouter [0.4.3]\n\n- Feature/openrouter provider routing support ([#20431](https://github.com/run-llama/llama_index/pull/20431))\n\n### llama-index-packs-recursive-retriever [0.7.1]\n\n- security: remove exposed OpenAI API keys from notebook outputs ([#20474](https://github.com/run-llama/llama_index/pull/20474))\n\n### llama-index-packs-sentence-window-retriever [0.5.1]\n\n- security: remove exposed OpenAI API keys from notebook outputs ([#20474](https://github.com/run-llama/llama_index/pull/20474))\n\n### llama-index-readers-datasets [0.1.0]\n\n- Add HuggingFace datasets reader integration ([#20468](https://github.com/run-llama/llama_index/pull/20468))\n\n### llama-index-readers-patentsview [1.0.0]\n\n- Patentsview reader api changes ([#20481](https://github.com/run-llama/llama_index/pull/20481))\n\n### llama-index-retrievers-you [1.0.0]\n\n- Revamp YouRetriever integration ([#20493](https://github.com/run-llama/llama_index/pull/20493))\n\n### llama-index-tools-parallel-web-systems [0.1.0]\n\n- feat: added Parallel Web System tools ([#20442](https://github.com/run-llama/llama_index/pull/20442))\n\n### llama-index-vector-stores-alibabacloud-mysql [0.1.0]\n\n- Feature/alibaba mysql vector integration ([#20396](https://github.com/run-llama/llama_index/pull/20396))\n\n### llama-index-vector-stores-milvus [0.9.6]\n\n- Feat milvus partition names ([#20445](https://github.com/run-llama/llama_index/pull/20445))\n- improve(llama-index-vector-stores-milvus): Changed the partition parameter to `milvus_partition_name` in add/delete. ([#20460](https://github.com/run-llama/llama_index/pull/20460))\n\n### llama-index-vector-stores-mongodb [0.9.1]\n\n- INTPYTHON-863 Fix mongodb async integration ([#20444](https://github.com/run-llama/llama_index/pull/20444))\n\n### llama-index-vector-stores-neo4jvector [0.5.2]\n\n- Handle missing metadata for neo4j vector store ([#20491](https://github.com/run-llama/llama_index/pull/20491))\n\n### llama-index-vector-stores-opensearch [0.6.3]\n\n- fix (opensearch): add close and aclose methods to vector client ([#20463](https://github.com/run-llama/llama_index/pull/20463))\n\n### llama-index-vector-stores-qdrant [0.9.1]\n\n- Qdrant search params ([#20476](https://github.com/run-llama/llama_index/pull/20476))\n\n### llama-index-vector-stores-vertexaivectorsearch [0.3.4]\n\n- feat(vertexaivectorsearch): add hybrid search support ([#20487](https://github.com/run-llama/llama_index/pull/20487))\n\n### llama-index-vector-stores-volcenginemysql [0.2.0]\n\n- feat: Volcengine MySQL vector store integration ([#20404](https://github.com/run-llama/llama_index/pull/20404))\n\n"}, {"url": "https://api.github.com/repos/run-llama/llama_index/releases/273313070", "assets_url": "https://api.github.com/repos/run-llama/llama_index/releases/273313070/assets", "upload_url": "https://uploads.github.com/repos/run-llama/llama_index/releases/273313070/assets{?name,label}", "html_url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.12", "id": 273313070, "author": {"login": "github-actions[bot]", "id": 41898282, "node_id": "MDM6Qm90NDE4OTgyODI=", "avatar_url": "https://avatars.githubusercontent.com/in/15368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/github-actions%5Bbot%5D", "html_url": "https://github.com/apps/github-actions", "followers_url": "https://api.github.com/users/github-actions%5Bbot%5D/followers", "following_url": "https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/github-actions%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/github-actions%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/github-actions%5Bbot%5D/repos", "events_url": "https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/github-actions%5Bbot%5D/received_events", "type": "Bot", "user_view_type": "public", "site_admin": false}, "node_id": "RE_kwDOIWuq584QSm0u", "tag_name": "v0.14.12", "target_commitish": "main", "name": "v0.14.12", "draft": false, "immutable": false, "prerelease": false, "created_at": "2025-12-30T01:05:27Z", "updated_at": "2025-12-30T01:07:03Z", "published_at": "2025-12-30T01:07:03Z", "assets": [{"url": "https://api.github.com/repos/run-llama/llama_index/releases/assets/334286374", "id": 334286374, "node_id": "RA_kwDOIWuq584T7M4m", "name": "llama_index-0.14.12.tar.gz", "label": "", "uploader": {"login": "github-actions[bot]", "id": 41898282, "node_id": "MDM6Qm90NDE4OTgyODI=", "avatar_url": "https://avatars.githubusercontent.com/in/15368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/github-actions%5Bbot%5D", "html_url": "https://github.com/apps/github-actions", "followers_url": "https://api.github.com/users/github-actions%5Bbot%5D/followers", "following_url": "https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/github-actions%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/github-actions%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/github-actions%5Bbot%5D/repos", "events_url": "https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/github-actions%5Bbot%5D/received_events", "type": "Bot", "user_view_type": "public", "site_admin": false}, "content_type": "application/x-gtar", "state": "uploaded", "size": 8461, "digest": "sha256:ec3cdc79116a3de62def00b5a2c55ea09013acb3ebc79acee1d9fe7903766385", "download_count": 20, "created_at": "2025-12-30T01:07:02Z", "updated_at": "2025-12-30T01:07:03Z", "browser_download_url": "https://github.com/run-llama/llama_index/releases/download/v0.14.12/llama_index-0.14.12.tar.gz"}], "tarball_url": "https://api.github.com/repos/run-llama/llama_index/tarball/v0.14.12", "zipball_url": "https://api.github.com/repos/run-llama/llama_index/zipball/v0.14.12", "body": "# Release Notes\n\n## [2025-12-30]\n\n### llama-index-callbacks-agentops [0.4.1]\n\n- Feat/async tool spec support ([#20338](https://github.com/run-llama/llama_index/pull/20338))\n\n### llama-index-core [0.14.12]\n\n- Feat/async tool spec support ([#20338](https://github.com/run-llama/llama_index/pull/20338))\n- Improve `MockFunctionCallingLLM` ([#20356](https://github.com/run-llama/llama_index/pull/20356))\n- fix(openai): sanitize generic Pydantic model schema names ([#20371](https://github.com/run-llama/llama_index/pull/20371))\n- Element node parser ([#20399](https://github.com/run-llama/llama_index/pull/20399))\n- improve llama dev logging ([#20411](https://github.com/run-llama/llama_index/pull/20411))\n- test(node_parser): add unit tests for Java CodeSplitter ([#20423](https://github.com/run-llama/llama_index/pull/20423))\n- fix: crash in log_vector_store_query_result when result.ids is None ([#20427](https://github.com/run-llama/llama_index/pull/20427))\n\n### llama-index-embeddings-litellm [0.4.1]\n\n- Add docstring to LiteLLM embedding class ([#20336](https://github.com/run-llama/llama_index/pull/20336))\n\n### llama-index-embeddings-ollama [0.8.5]\n\n- feat(llama-index-embeddings-ollama): Add keep_alive parameter ([#20395](https://github.com/run-llama/llama_index/pull/20395))\n- docs: improve Ollama embeddings README with comprehensive documentation ([#20414](https://github.com/run-llama/llama_index/pull/20414))\n\n### llama-index-embeddings-voyageai [0.5.2]\n\n- Voyage multimodal 35 ([#20398](https://github.com/run-llama/llama_index/pull/20398))\n\n### llama-index-graph-stores-nebula [0.5.1]\n\n- feat(nebula): add MENTIONS edge to property graph store ([#20401](https://github.com/run-llama/llama_index/pull/20401))\n\n### llama-index-llms-aibadgr [0.1.0]\n\n- feat(llama-index-llms-aibadgr): Add AI Badgr OpenAI\u2011compatible LLM integration ([#20365](https://github.com/run-llama/llama_index/pull/20365))\n\n### llama-index-llms-anthropic [0.10.4]\n\n- add back haiku-3 support ([#20408](https://github.com/run-llama/llama_index/pull/20408))\n\n### llama-index-llms-bedrock-converse [0.12.3]\n\n- fix: bedrock converse thinking block issue ([#20355](https://github.com/run-llama/llama_index/pull/20355))\n\n### llama-index-llms-google-genai [0.8.3]\n\n- Switch use_file_api to Flexible file_mode; Improve File Upload Handling & Bump google-genai to v1.52.0 ([#20347](https://github.com/run-llama/llama_index/pull/20347))\n- Fix missing role from Google-GenAI ([#20357](https://github.com/run-llama/llama_index/pull/20357))\n- Add signature index fix ([#20362](https://github.com/run-llama/llama_index/pull/20362))\n- Add positional thought signature for thoughts ([#20418](https://github.com/run-llama/llama_index/pull/20418))\n\n### llama-index-llms-ollama [0.9.1]\n\n- feature: pydantic no longer complains if you pass 'low', 'medium', 'h\u2026 ([#20394](https://github.com/run-llama/llama_index/pull/20394))\n\n### llama-index-llms-openai [0.6.12]\n\n- fix: Handle tools=None in OpenAIResponses.\\_get_model_kwargs ([#20358](https://github.com/run-llama/llama_index/pull/20358))\n- feat: add support for gpt-5.2 and 5.2 pro ([#20361](https://github.com/run-llama/llama_index/pull/20361))\n\n### llama-index-readers-confluence [0.6.1]\n\n- fix(confluence): support Python 3.14 ([#20370](https://github.com/run-llama/llama_index/pull/20370))\n\n### llama-index-readers-file [0.5.6]\n\n- Loosen constraint on `pandas` version ([#20387](https://github.com/run-llama/llama_index/pull/20387))\n\n### llama-index-readers-service-now [0.2.2]\n\n- chore(deps): bump urllib3 from 2.5.0 to 2.6.0 in /llama-index-integrations/readers/llama-index-readers-service-now in the pip group across 1 directory ([#20341](https://github.com/run-llama/llama_index/pull/20341))\n\n### llama-index-tools-mcp [0.4.5]\n\n- fix: pass timeout parameters to transport clients in BasicMCPClient ([#20340](https://github.com/run-llama/llama_index/pull/20340))\n- feature: Permit to pass a custom httpx.AsyncClient when creating a BasicMcpClient ([#20368](https://github.com/run-llama/llama_index/pull/20368))\n\n### llama-index-tools-typecast [0.1.0]\n\n- feat: add Typecast tool integration with text to speech features ([#20343](https://github.com/run-llama/llama_index/pull/20343))\n\n### llama-index-vector-stores-azurepostgresql [0.2.0]\n\n- Feat/async tool spec support ([#20338](https://github.com/run-llama/llama_index/pull/20338))\n\n### llama-index-vector-stores-chroma [0.5.5]\n\n- Fix chroma nested metadata filters ([#20424](https://github.com/run-llama/llama_index/pull/20424))\n- fix(chroma): support multimodal results ([#20426](https://github.com/run-llama/llama_index/pull/20426))\n\n### llama-index-vector-stores-couchbase [0.6.0]\n\n- Update FTS & GSI reference docs for Couchbase vector-store ([#20346](https://github.com/run-llama/llama_index/pull/20346))\n\n### llama-index-vector-stores-faiss [0.5.2]\n\n- fix(faiss): pass numpy array instead of int to add_with_ids ([#20384](https://github.com/run-llama/llama_index/pull/20384))\n\n### llama-index-vector-stores-lancedb [0.4.4]\n\n- Feat/async tool spec support ([#20338](https://github.com/run-llama/llama_index/pull/20338))\n- fix(vector_stores/lancedb): add missing '<' filter operator ([#20364](https://github.com/run-llama/llama_index/pull/20364))\n- fix(lancedb): fix metadata filtering logic and list value SQL generation ([#20374](https://github.com/run-llama/llama_index/pull/20374))\n\n### llama-index-vector-stores-mongodb [0.9.0]\n\n- Update mongo vector store to initialize without list permissions ([#20354](https://github.com/run-llama/llama_index/pull/20354))\n- add mongodb delete index ([#20429](https://github.com/run-llama/llama_index/pull/20429))\n- async mongodb atlas support ([#20430](https://github.com/run-llama/llama_index/pull/20430))\n\n### llama-index-vector-stores-redis [0.6.2]\n\n- Redis metadata filter fix ([#20359](https://github.com/run-llama/llama_index/pull/20359))\n\n### llama-index-vector-stores-vertexaivectorsearch [0.3.3]\n\n- feat(vertex-vector-search): Add Google Vertex AI Vector Search v2.0 support ([#20351](https://github.com/run-llama/llama_index/pull/20351))\n\n"}, {"url": "https://api.github.com/repos/run-llama/llama_index/releases/267562449", "assets_url": "https://api.github.com/repos/run-llama/llama_index/releases/267562449/assets", "upload_url": "https://uploads.github.com/repos/run-llama/llama_index/releases/267562449/assets{?name,label}", "html_url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.10", "id": 267562449, "author": {"login": "github-actions[bot]", "id": 41898282, "node_id": "MDM6Qm90NDE4OTgyODI=", "avatar_url": "https://avatars.githubusercontent.com/in/15368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/github-actions%5Bbot%5D", "html_url": "https://github.com/apps/github-actions", "followers_url": "https://api.github.com/users/github-actions%5Bbot%5D/followers", "following_url": "https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/github-actions%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/github-actions%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/github-actions%5Bbot%5D/repos", "events_url": "https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/github-actions%5Bbot%5D/received_events", "type": "Bot", "user_view_type": "public", "site_admin": false}, "node_id": "RE_kwDOIWuq584P8q3R", "tag_name": "v0.14.10", "target_commitish": "main", "name": "v0.14.10", "draft": false, "immutable": false, "prerelease": false, "created_at": "2025-12-04T19:43:39Z", "updated_at": "2025-12-04T19:46:03Z", "published_at": "2025-12-04T19:46:03Z", "assets": [{"url": "https://api.github.com/repos/run-llama/llama_index/releases/assets/324441165", "id": 324441165, "node_id": "RA_kwDOIWuq584TVpRN", "name": "llama_index-0.14.10.tar.gz", "label": "", "uploader": {"login": "github-actions[bot]", "id": 41898282, "node_id": "MDM6Qm90NDE4OTgyODI=", "avatar_url": "https://avatars.githubusercontent.com/in/15368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/github-actions%5Bbot%5D", "html_url": "https://github.com/apps/github-actions", "followers_url": "https://api.github.com/users/github-actions%5Bbot%5D/followers", "following_url": "https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/github-actions%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/github-actions%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/github-actions%5Bbot%5D/repos", "events_url": "https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/github-actions%5Bbot%5D/received_events", "type": "Bot", "user_view_type": "public", "site_admin": false}, "content_type": "application/x-gtar", "state": "uploaded", "size": 8461, "digest": "sha256:49f539e4c68ddf77bb2a10f80f49bd950de3a91fe0e3ecd3b2d55a6fbc05c31e", "download_count": 24, "created_at": "2025-12-04T19:46:02Z", "updated_at": "2025-12-04T19:46:02Z", "browser_download_url": "https://github.com/run-llama/llama_index/releases/download/v0.14.10/llama_index-0.14.10.tar.gz"}], "tarball_url": "https://api.github.com/repos/run-llama/llama_index/tarball/v0.14.10", "zipball_url": "https://api.github.com/repos/run-llama/llama_index/zipball/v0.14.10", "body": "# Release Notes\n\n## [2025-12-04]\n\n### llama-index-core [0.14.10]\n\n- feat: add mock function calling llm ([#20331](https://github.com/run-llama/llama_index/pull/20331))\n\n### llama-index-llms-qianfan [0.4.1]\n\n- test: fix typo 'reponse' to 'response' in variable names ([#20329](https://github.com/run-llama/llama_index/pull/20329))\n\n### llama-index-tools-airweave [0.1.0]\n\n- feat: add Airweave tool integration with advanced search features ([#20111](https://github.com/run-llama/llama_index/pull/20111))\n\n### llama-index-utils-qianfan [0.4.1]\n\n- test: fix typo 'reponse' to 'response' in variable names ([#20329](https://github.com/run-llama/llama_index/pull/20329))\n\n"}]}