{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "r_thambapillai"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["okta", "production"], "value": "Hi Hacker News! We\u2019re Ravin and Jack, the founders of Credal.ai (<a href=\"https://www.credal.ai/\">https://www.credal.ai/</a>). We provide a Chat UI and APIs that enforce PII redaction, audit logging, and data access controls for companies that want to use LLMs with their corporate data from Google Docs, Slack, or Confluence. There\u2019s a demo video here: <a href=\"https://www.loom.com/share/2b5409fd64464dc9b5b6277f2be4e90f?sid=7a728d97-58ac-4355-9c87-75eaf12b0775\" rel=\"nofollow noreferrer\">https://www.loom.com/share/2b5409fd64464dc9b5b6277f2be4e90f?...</a>.<p>One big thing enterprises and businesses are worried about with LLMs is \u201cwhat\u2019s happening to my data\u201d? The way we see it, there are three big security and privacy barriers companies need to solve:<p>1. Controlling what data goes to whom: the basic stuff is just putting controls in place around customer and employee PII, but it can get trickier when you also want to be putting controls in place around business secrets, so companies can ensure the Coca Cola recipe doesn\u2019t accidentally leave the company.<p>2. Visibility: Enterprise IT wants to know exactly what data was shared by whom, when, at what time, and what the model responded with (not to mention how much the request cost!). Each provider gives you a piece of the puzzle in their dashboard, but getting all this visibility per request from either of the main providers currently requires writing code yourself.<p>3. Access Controls: Enterprises have lots of documents that for whatever reason cannot be shared internally to everyone. So how do I make sure employees can use AI with this stuff, without compromising the sensitivity of the data?<p>Typically this pain is something that is felt most acutely by Enterprise IT, but also of course by the developers and business people who get told not to build the great stuff they can envision.\nWe think it\u2019s critical to solve these issues since the more visibility and control we can give Enterprise IT about how data is used, the more we can actually build on top of these APIs and start applying some of the awesome capabilities of the foundation models across every business problem.<p>You can easily grab data from sources like Google Docs via their APIs, but for <em>production</em> use cases, you have to respect the permissions on each Google Doc, Confluence Page, Slack channel etc. This gets tricky when these systems combine some permissions defined totally inside their product, with permissions that are inherited from the company\u2019s SSO provider (often <em>Okta</em> or Azure AD). Respecting all these permissions becomes both hard and vital as the number of employees and tools accessing the data grows.<p>The current state of the art is to use a vector database like Pinecone, Milvus, or Chroma, integrate your internal data with those systems, and then when a user asks a question, dynamically figure out which bits are relevant to the user\u2019s question and send those to the AI as part of the prompt. We handle all this automatically for you (using Milvus for now, which we host ourselves), including the point and click connectors for your data (Google Docs/Sheets, Slack, Confluence with many more coming soon). You can use that data through our UI already and we\u2019re in the process of adding this search functionality to the API as well.<p>There\u2019s other schlep work that devs would rather not worry about: building out request level audit logs, staying on top of the rapidly changing API formats from these providers, implementing failover for when these heavily overburdened APIs go down etc,  We think  individual devs should not have to do these themselves, but the foundation model providers are unlikely to provide consistent, customer centric approaches for them. The PII detection piece in some ways is the easiest - there are a lot of good open source models for doing this, and companies using Azure OpenAI and AWS Bedrock seem less concerned with it anyway. We expect that the emphasis companies place on the redactions we provide may actually go down over time, while the emphasis on unified, consistent audit logging and data access controls will increase.<p>Right now we have three plans: a free tier (which is admittedly very limited but intended to give you a feel for the product), the business plan which starts at $500pm which gets you access to the data integration as well as the most powerful models like GPT 4 32k, Anthropic 100k etc, and an enterprise plan which starts at $5000pm, which is a scaled up version of the business tier and lets you go on-prem (more details on each plan are on the website). You can try the free tier self-serve, but we haven\u2019t yet built out fully self service onboarding for the paid plans so for now it is a \u201cbook a meeting\u201d button, apologies! (But it only takes 5 minutes and if you want it, we can fully onboard you in the meeting itself).<p>When Jack and I started Credal, we actually set out to solve a different problem: an \u2018AI Chief of Staff\u2019 that could read your documents and task trackers, and guide your strategic decision making. We knew that data security was going to be a critical problem for enterprises. Jack and I were both deep in the Enterprise Data Security + AI space before Credal, so we naturally took a security first approach to building out our AI Chief of Staff. But in reality, when we started showing the product to customers, we learned pretty fast that the \u2018Chief of Staff\u2019 features were at best nice to have, and the security features were what they were actually excited by. So we stripped the product back to basics, and built out the thing our customers actually needed. Since then we\u2019ve signed a bunch of customers and thousands of users, which has been really exciting.<p>Now that our product is concretely helping a bunch of people at work, is SOC 2 T1 Compliant, and is ready for anyone to just walk up and use, we\u2019re super excited to share it with the Hacker News community, which Jack and I have been avid readers of for a decade now. It\u2019s still a very early product (the private beta opened in March), but we can\u2019t wait to get your feedback and see how we can make it even better!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: Credal.ai (YC W23) \u2013 Data Safety for Enterprise AI"}}, "_tags": ["story", "author_r_thambapillai", "story_36326525", "launch_hn"], "author": "r_thambapillai", "children": [36326917, 36326962, 36327564, 36327940, 36328429, 36328819, 36330020, 36330371, 36333611, 36357825], "created_at": "2023-06-14T14:26:55Z", "created_at_i": 1686752815, "num_comments": 24, "objectID": "36326525", "points": 114, "story_id": 36326525, "story_text": "Hi Hacker News! We\u2019re Ravin and Jack, the founders of Credal.ai (<a href=\"https:&#x2F;&#x2F;www.credal.ai&#x2F;\">https:&#x2F;&#x2F;www.credal.ai&#x2F;</a>). We provide a Chat UI and APIs that enforce PII redaction, audit logging, and data access controls for companies that want to use LLMs with their corporate data from Google Docs, Slack, or Confluence. There\u2019s a demo video here: <a href=\"https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;2b5409fd64464dc9b5b6277f2be4e90f?sid=7a728d97-58ac-4355-9c87-75eaf12b0775\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;2b5409fd64464dc9b5b6277f2be4e90f?...</a>.<p>One big thing enterprises and businesses are worried about with LLMs is \u201cwhat\u2019s happening to my data\u201d? The way we see it, there are three big security and privacy barriers companies need to solve:<p>1. Controlling what data goes to whom: the basic stuff is just putting controls in place around customer and employee PII, but it can get trickier when you also want to be putting controls in place around business secrets, so companies can ensure the Coca Cola recipe doesn\u2019t accidentally leave the company.<p>2. Visibility: Enterprise IT wants to know exactly what data was shared by whom, when, at what time, and what the model responded with (not to mention how much the request cost!). Each provider gives you a piece of the puzzle in their dashboard, but getting all this visibility per request from either of the main providers currently requires writing code yourself.<p>3. Access Controls: Enterprises have lots of documents that for whatever reason cannot be shared internally to everyone. So how do I make sure employees can use AI with this stuff, without compromising the sensitivity of the data?<p>Typically this pain is something that is felt most acutely by Enterprise IT, but also of course by the developers and business people who get told not to build the great stuff they can envision.\nWe think it\u2019s critical to solve these issues since the more visibility and control we can give Enterprise IT about how data is used, the more we can actually build on top of these APIs and start applying some of the awesome capabilities of the foundation models across every business problem.<p>You can easily grab data from sources like Google Docs via their APIs, but for production use cases, you have to respect the permissions on each Google Doc, Confluence Page, Slack channel etc. This gets tricky when these systems combine some permissions defined totally inside their product, with permissions that are inherited from the company\u2019s SSO provider (often Okta or Azure AD). Respecting all these permissions becomes both hard and vital as the number of employees and tools accessing the data grows.<p>The current state of the art is to use a vector database like Pinecone, Milvus, or Chroma, integrate your internal data with those systems, and then when a user asks a question, dynamically figure out which bits are relevant to the user\u2019s question and send those to the AI as part of the prompt. We handle all this automatically for you (using Milvus for now, which we host ourselves), including the point and click connectors for your data (Google Docs&#x2F;Sheets, Slack, Confluence with many more coming soon). You can use that data through our UI already and we\u2019re in the process of adding this search functionality to the API as well.<p>There\u2019s other schlep work that devs would rather not worry about: building out request level audit logs, staying on top of the rapidly changing API formats from these providers, implementing failover for when these heavily overburdened APIs go down etc,  We think  individual devs should not have to do these themselves, but the foundation model providers are unlikely to provide consistent, customer centric approaches for them. The PII detection piece in some ways is the easiest - there are a lot of good open source models for doing this, and companies using Azure OpenAI and AWS Bedrock seem less concerned with it anyway. We expect that the emphasis companies place on the redactions we provide may actually go down over time, while the emphasis on unified, consistent audit logging and data access controls will increase.<p>Right now we have three plans: a free tier (which is admittedly very limited but intended to give you a feel for the product), the business plan which starts at $500pm which gets you access to the data integration as well as the most powerful models like GPT 4 32k, Anthropic 100k etc, and an enterprise plan which starts at $5000pm, which is a scaled up version of the business tier and lets you go on-prem (more details on each plan are on the website). You can try the free tier self-serve, but we haven\u2019t yet built out fully self service onboarding for the paid plans so for now it is a \u201cbook a meeting\u201d button, apologies! (But it only takes 5 minutes and if you want it, we can fully onboard you in the meeting itself).<p>When Jack and I started Credal, we actually set out to solve a different problem: an \u2018AI Chief of Staff\u2019 that could read your documents and task trackers, and guide your strategic decision making. We knew that data security was going to be a critical problem for enterprises. Jack and I were both deep in the Enterprise Data Security + AI space before Credal, so we naturally took a security first approach to building out our AI Chief of Staff. But in reality, when we started showing the product to customers, we learned pretty fast that the \u2018Chief of Staff\u2019 features were at best nice to have, and the security features were what they were actually excited by. So we stripped the product back to basics, and built out the thing our customers actually needed. Since then we\u2019ve signed a bunch of customers and thousands of users, which has been really exciting.<p>Now that our product is concretely helping a bunch of people at work, is SOC 2 T1 Compliant, and is ready for anyone to just walk up and use, we\u2019re super excited to share it with the Hacker News community, which Jack and I have been avid readers of for a decade now. It\u2019s still a very early product (the private beta opened in March), but we can\u2019t wait to get your feedback and see how we can make it even better!", "title": "Launch HN: Credal.ai (YC W23) \u2013 Data Safety for Enterprise AI", "updated_at": "2024-09-20T14:21:48Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "robszumski"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["okta", "production"], "value": "Hi HN, we\u2019re Rob, Russell and Eugene from EdgeBit (<a href=\"https://edgebit.io\">https://edgebit.io</a>). EdgeBit is a tool to secure your software supply chain that focuses on code that is actually running. This simplifies vulnerability management as it cuts through the noise of vulnerabilities you\u2019re not actually exposed to. EdgeBit secures your software all the way from a pull request to build and <em>production</em>. It\u2019s like inbox zero for CVEs. Here\u2019s a demo video: <a href=\"https://www.youtube.com/watch?v=4lC6qkfN4Uo\">https://www.youtube.com/watch?v=4lC6qkfN4Uo</a>.<p>Nothing is more frustrating than investigating a vulnerability to find that it's not exploitable at all. Russell ran security engineering at <em>Okta</em> and knows first hand it\u2019s a constantly moving target of dependencies, frameworks and deployment platforms. Automation is key, but security teams aren\u2019t experts in each app, so \u201copen a ticket for any vulnerability found\u201d is a typical workflow. This is a noisy and frustrating firehose for engineering teams, and tickets don\u2019t contain the context needed for a speedy investigation.<p>EdgeBit ranks threats to keep the patch SLA promised to your customers, helps engineers fix the riskiest items first and assigns dormant items to a lower tier. We automatically inventory your software dependencies, ensure they are trusted, and monitor vulnerabilities, securing your software supply chain. For security teams, we help you meet new compliance requirements about the libraries and packages in your products. For engineers, we make vulnerability investigation/patching streamlined, so you can get back to writing code.<p>We use eBPF-based observation of your running software to keep the threat list as short as possible. For example, if your code has a history of exec-ing imagemagick we\u2019ll include it, but if it\u2019s dormant we can lower the priority of those vulnerabilities. When adding a new dependency, EdgeBit\u2019s runtime knowledge helps our GitHub bot suggest versions already in use by other teams in your company, as a nudge towards consistency.<p>To use EdgeBit, each build execution sends a software bill of materials (SBOM) to EdgeBit. We\u2019re big fans of the open source Syft project, which we use to generate SBOMs. After a build is deployed, we use eBPF to identify packages and files in use, and compare it to the SBOM and vulnerability databases. If there\u2019s a new CVE, EdgeBit passes along context to the engineers tasked to fix it. If a package reports a CVE, but we observe it\u2019s dormant (i.e. you\u2019re not running that particular library), the CVE should be fixed but not be at the top of the list.<p>Looking beyond compliance, real attacks are happening via software dependencies. Since the Colonial Pipeline attack, Federal compliance requirements and Biden\u2019s cybersecurity directive [1] now cover tracking and understanding your supply chain. For a single library, it\u2019s tricky to securely download, integrate, sign and verify it\u2026and very hard for 100s of dependencies across many apps. Where did the dependency come from? What builds is it in? Where is it deployed? EdgeBit provides a single view across OS packages, standalone binaries and containers to understand the full attack surface.<p>Monitoring tools don't tie back to the source build nor do they verify the integrity of your workload, so they leave a lot of gruntwork undone. Also, most scanning tools are noisy by design and we're headed to a world where SBOMs are going to be used as a checklist to add even more useless toil to the firehouse, so new tooling is sorely needed. EdgeBit looks at your OS, workloads, and containers continuously. It's not enough to just scan containers in a registry or validate them upon cluster admission and then never look again.<p>Check us out by using <a href=\"https://signup.edgebit.io\">https://signup.edgebit.io</a> to build a real-time SBOM from a live server and then trace your workloads to close the loop. Signup to claim an org name, no payment required. Developers can hook up automation for 10 workloads for free. Past that, we charge per server with unlimited workloads and build volume. I think you\u2019ll be surprised by the ratio of active to dormant dependencies\u2014we\u2019re seeing about 20-40% are actually active.<p>Our near-term roadmap includes tighter integration with sigstore, pulling SBOMs out of containers automatically, and a smarter Kubernetes admission controller. Today we track file accesses and correlate it to package managers like Deb, RPM, PyPi. Soon we'll add more language specific hooks to better support compiled languages. Further out, we will also allow you to block execution of dormant dependencies and enforce file integrity to ensure the bits that are executing match the SBOM. And we're also exploring how an app can communicate its trust profile to other apps, like a secret store.<p>We\u2019d love to talk to you about the future of this space, how you\u2019re scaling vulnerability response and feedback on what we\u2019ve built so far. We look forward to your comments!<p>[1]: <a href=\"https://www.whitehouse.gov/briefing-room/presidential-actions/2021/05/12/executive-order-on-improving-the-nations-cybersecurity/\" rel=\"nofollow\">https://www.whitehouse.gov/briefing-room/presidential-action...</a>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: EdgeBit (YC W23) \u2013 live software vulnerability analysis"}}, "_tags": ["story", "author_robszumski", "story_34981946", "launch_hn"], "author": "robszumski", "children": [34982090, 34982106, 34982669, 34983019, 34983049, 34983082, 34983224, 34983292, 34983627, 34984658, 34986898, 34988532, 34988688, 34989454, 34995657, 34995951, 34996005], "created_at": "2023-03-01T13:08:05Z", "created_at_i": 1677676085, "num_comments": 29, "objectID": "34981946", "points": 80, "story_id": 34981946, "story_text": "Hi HN, we\u2019re Rob, Russell and Eugene from EdgeBit (<a href=\"https:&#x2F;&#x2F;edgebit.io\">https:&#x2F;&#x2F;edgebit.io</a>). EdgeBit is a tool to secure your software supply chain that focuses on code that is actually running. This simplifies vulnerability management as it cuts through the noise of vulnerabilities you\u2019re not actually exposed to. EdgeBit secures your software all the way from a pull request to build and production. It\u2019s like inbox zero for CVEs. Here\u2019s a demo video: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=4lC6qkfN4Uo\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=4lC6qkfN4Uo</a>.<p>Nothing is more frustrating than investigating a vulnerability to find that it&#x27;s not exploitable at all. Russell ran security engineering at Okta and knows first hand it\u2019s a constantly moving target of dependencies, frameworks and deployment platforms. Automation is key, but security teams aren\u2019t experts in each app, so \u201copen a ticket for any vulnerability found\u201d is a typical workflow. This is a noisy and frustrating firehose for engineering teams, and tickets don\u2019t contain the context needed for a speedy investigation.<p>EdgeBit ranks threats to keep the patch SLA promised to your customers, helps engineers fix the riskiest items first and assigns dormant items to a lower tier. We automatically inventory your software dependencies, ensure they are trusted, and monitor vulnerabilities, securing your software supply chain. For security teams, we help you meet new compliance requirements about the libraries and packages in your products. For engineers, we make vulnerability investigation&#x2F;patching streamlined, so you can get back to writing code.<p>We use eBPF-based observation of your running software to keep the threat list as short as possible. For example, if your code has a history of exec-ing imagemagick we\u2019ll include it, but if it\u2019s dormant we can lower the priority of those vulnerabilities. When adding a new dependency, EdgeBit\u2019s runtime knowledge helps our GitHub bot suggest versions already in use by other teams in your company, as a nudge towards consistency.<p>To use EdgeBit, each build execution sends a software bill of materials (SBOM) to EdgeBit. We\u2019re big fans of the open source Syft project, which we use to generate SBOMs. After a build is deployed, we use eBPF to identify packages and files in use, and compare it to the SBOM and vulnerability databases. If there\u2019s a new CVE, EdgeBit passes along context to the engineers tasked to fix it. If a package reports a CVE, but we observe it\u2019s dormant (i.e. you\u2019re not running that particular library), the CVE should be fixed but not be at the top of the list.<p>Looking beyond compliance, real attacks are happening via software dependencies. Since the Colonial Pipeline attack, Federal compliance requirements and Biden\u2019s cybersecurity directive [1] now cover tracking and understanding your supply chain. For a single library, it\u2019s tricky to securely download, integrate, sign and verify it\u2026and very hard for 100s of dependencies across many apps. Where did the dependency come from? What builds is it in? Where is it deployed? EdgeBit provides a single view across OS packages, standalone binaries and containers to understand the full attack surface.<p>Monitoring tools don&#x27;t tie back to the source build nor do they verify the integrity of your workload, so they leave a lot of gruntwork undone. Also, most scanning tools are noisy by design and we&#x27;re headed to a world where SBOMs are going to be used as a checklist to add even more useless toil to the firehouse, so new tooling is sorely needed. EdgeBit looks at your OS, workloads, and containers continuously. It&#x27;s not enough to just scan containers in a registry or validate them upon cluster admission and then never look again.<p>Check us out by using <a href=\"https:&#x2F;&#x2F;signup.edgebit.io\">https:&#x2F;&#x2F;signup.edgebit.io</a> to build a real-time SBOM from a live server and then trace your workloads to close the loop. Signup to claim an org name, no payment required. Developers can hook up automation for 10 workloads for free. Past that, we charge per server with unlimited workloads and build volume. I think you\u2019ll be surprised by the ratio of active to dormant dependencies\u2014we\u2019re seeing about 20-40% are actually active.<p>Our near-term roadmap includes tighter integration with sigstore, pulling SBOMs out of containers automatically, and a smarter Kubernetes admission controller. Today we track file accesses and correlate it to package managers like Deb, RPM, PyPi. Soon we&#x27;ll add more language specific hooks to better support compiled languages. Further out, we will also allow you to block execution of dormant dependencies and enforce file integrity to ensure the bits that are executing match the SBOM. And we&#x27;re also exploring how an app can communicate its trust profile to other apps, like a secret store.<p>We\u2019d love to talk to you about the future of this space, how you\u2019re scaling vulnerability response and feedback on what we\u2019ve built so far. We look forward to your comments!<p>[1]: <a href=\"https:&#x2F;&#x2F;www.whitehouse.gov&#x2F;briefing-room&#x2F;presidential-actions&#x2F;2021&#x2F;05&#x2F;12&#x2F;executive-order-on-improving-the-nations-cybersecurity&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.whitehouse.gov&#x2F;briefing-room&#x2F;presidential-action...</a>", "title": "Launch HN: EdgeBit (YC W23) \u2013 live software vulnerability analysis", "updated_at": "2024-09-20T13:30:38Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "abuggia"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["okta", "production"], "value": "Hello HN,<p>My cofounder (jon918) and I started Sym three years ago because we were frustrated with how hard it was to manage access to cloud infrastructure. We wanted to build a tool for JIT access that was <i>actually</i> designed for developers. We were wary of tools that tried to accommodate both devs and IT but ended up with usability compromises for both.<p>First, we figured no one wants another web app to log into so we let administrators define access workflows in Terraform and let developers request and gain access via Slack. That seemed to pay off: being code-based was a big plus for our early customers since it let them manage the logic in version control and test in CI/CD.<p>Second, we knew that updating permissions/roles/access was a major source of toil and risk in the world of cloud infrastructure. Have you ever tried to avoid annoying, persistent access requests by setting policies that are a bit more permissive than you\u2019d like? We felt that fully automated just-in-time access + approvals could really help here. But we also knew that a simple approval tool could end up leading to request fatigue - kind of defeating the purpose. So we built an SDK to let you define checks in code (e.g. pagerduty.on_call, <em>okta</em>.is_user_in_group,  github.get_repo_collaborators) in order to dynamically route requests or fast-track access when appropriate. This seems to be paying off: users are creating Slack-based approvals in front of different types of risky actions like <em>production</em> access, sensitive queries and triggering Lambdas.<p>We\u2019d love your feedback on our approach so far. Does this make sense to you? Is this a tool you'd use? What would you want to see out of it?<p>To learn more, check out the video that Nick (nmeans (Sym VPEng)) made [1]. You can also check out our docs [2] or set up your own flow [3].<p>thanks!<p>-adam<p>[1] <a href=\"https://vimeo.com/815222490/c717c18c42\" rel=\"nofollow\">https://vimeo.com/815222490/c717c18c42</a><p>[2] <a href=\"https://docs.symops.com\" rel=\"nofollow\">https://docs.symops.com</a><p>[3] <a href=\"https://symops.com/signup\" rel=\"nofollow\">https://symops.com/signup</a>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Sym, define just-in-time access workflows in code"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://symops.com/"}}, "_tags": ["story", "author_abuggia", "story_35468981", "show_hn"], "author": "abuggia", "children": [35469244, 35472211, 35473304, 35473499, 35475860, 35476830], "created_at": "2023-04-06T14:45:20Z", "created_at_i": 1680792320, "num_comments": 11, "objectID": "35468981", "points": 50, "story_id": 35468981, "story_text": "Hello HN,<p>My cofounder (jon918) and I started Sym three years ago because we were frustrated with how hard it was to manage access to cloud infrastructure. We wanted to build a tool for JIT access that was <i>actually</i> designed for developers. We were wary of tools that tried to accommodate both devs and IT but ended up with usability compromises for both.<p>First, we figured no one wants another web app to log into so we let administrators define access workflows in Terraform and let developers request and gain access via Slack. That seemed to pay off: being code-based was a big plus for our early customers since it let them manage the logic in version control and test in CI&#x2F;CD.<p>Second, we knew that updating permissions&#x2F;roles&#x2F;access was a major source of toil and risk in the world of cloud infrastructure. Have you ever tried to avoid annoying, persistent access requests by setting policies that are a bit more permissive than you\u2019d like? We felt that fully automated just-in-time access + approvals could really help here. But we also knew that a simple approval tool could end up leading to request fatigue - kind of defeating the purpose. So we built an SDK to let you define checks in code (e.g. pagerduty.on_call, okta.is_user_in_group,  github.get_repo_collaborators) in order to dynamically route requests or fast-track access when appropriate. This seems to be paying off: users are creating Slack-based approvals in front of different types of risky actions like production access, sensitive queries and triggering Lambdas.<p>We\u2019d love your feedback on our approach so far. Does this make sense to you? Is this a tool you&#x27;d use? What would you want to see out of it?<p>To learn more, check out the video that Nick (nmeans (Sym VPEng)) made [1]. You can also check out our docs [2] or set up your own flow [3].<p>thanks!<p>-adam<p>[1] <a href=\"https:&#x2F;&#x2F;vimeo.com&#x2F;815222490&#x2F;c717c18c42\" rel=\"nofollow\">https:&#x2F;&#x2F;vimeo.com&#x2F;815222490&#x2F;c717c18c42</a><p>[2] <a href=\"https:&#x2F;&#x2F;docs.symops.com\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.symops.com</a><p>[3] <a href=\"https:&#x2F;&#x2F;symops.com&#x2F;signup\" rel=\"nofollow\">https:&#x2F;&#x2F;symops.com&#x2F;signup</a>", "title": "Show HN: Sym, define just-in-time access workflows in code", "updated_at": "2024-09-20T13:50:41Z", "url": "https://symops.com/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "basilisk01"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["okta", "production"], "value": "Summation is an open source database/API gateway that lets you get the data you need, without having to wait for your backend team to write APIs for you.<p>You can:\n- query your SQL databases directly from web/mobile apps without risk of SQL injection\n- make API requests to third-party APIs (stripe, twillio, etc.) directly from web/mobile apps without exposing your credentials<p>Benefits:\n- you get the full power of SQL, which most developers already know (instead of having to learn graphQL)\n- supports all major SQL databases/warehouses, and any JSON REST API\n- Client libraries exist for Javascript, iOS, and Android<p>How it works:\n- the gateway authenticates your users via JWT tokens you pass it (supports Firebase/Auth0/<em>Okta</em>/Cognito)\n- only specific queries/API requests that have been approved can be executed in <em>production</em>\n- any parameters you pass in get bound to the query/API request (so you can filter queries to the logged-in user's JWT user ID, etc.)\n- credentials are encrypted in PostgreSQL (open source version) or your company's cloud secrets manager (cloud version, currently in alpha)\n- you can chain together multiple queries/API requests, with parameters securely passed from one to the other server-side<p>https://github.com/summation-app/docker<p>looking forward to your questions &amp; feedback, thanks!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Secure SQL queries from web/mobile clients"}}, "_tags": ["story", "author_basilisk01", "story_26344277", "show_hn"], "author": "basilisk01", "created_at": "2021-03-04T16:17:11Z", "created_at_i": 1614874631, "num_comments": 0, "objectID": "26344277", "points": 2, "story_id": 26344277, "story_text": "Summation is an open source database&#x2F;API gateway that lets you get the data you need, without having to wait for your backend team to write APIs for you.<p>You can:\n- query your SQL databases directly from web&#x2F;mobile apps without risk of SQL injection\n- make API requests to third-party APIs (stripe, twillio, etc.) directly from web&#x2F;mobile apps without exposing your credentials<p>Benefits:\n- you get the full power of SQL, which most developers already know (instead of having to learn graphQL)\n- supports all major SQL databases&#x2F;warehouses, and any JSON REST API\n- Client libraries exist for Javascript, iOS, and Android<p>How it works:\n- the gateway authenticates your users via JWT tokens you pass it (supports Firebase&#x2F;Auth0&#x2F;Okta&#x2F;Cognito)\n- only specific queries&#x2F;API requests that have been approved can be executed in production\n- any parameters you pass in get bound to the query&#x2F;API request (so you can filter queries to the logged-in user&#x27;s JWT user ID, etc.)\n- credentials are encrypted in PostgreSQL (open source version) or your company&#x27;s cloud secrets manager (cloud version, currently in alpha)\n- you can chain together multiple queries&#x2F;API requests, with parameters securely passed from one to the other server-side<p>https:&#x2F;&#x2F;github.com&#x2F;summation-app&#x2F;docker<p>looking forward to your questions &amp; feedback, thanks!", "title": "Show HN: Secure SQL queries from web/mobile clients", "updated_at": "2024-09-20T08:03:40Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "vale710"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["okta", "production"], "value": "<em>Production</em> controllers, <em>OTA</em> software updates and the impact of IoT"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "https://www.devicechronicle.com/<em>production</em>-controllers/"}}, "_tags": ["story", "author_vale710", "story_27116532"], "author": "vale710", "created_at": "2021-05-11T11:00:16Z", "created_at_i": 1620730816, "num_comments": 0, "objectID": "27116532", "points": 1, "story_id": 27116532, "title": "Production controllers, OTA software updates and the impact of IoT", "updated_at": "2024-09-20T08:30:50Z", "url": "https://www.devicechronicle.com/production-controllers/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "ralphmender"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["okta"], "value": "Mender \u2013 An open-source <em>OTA</em> software updater for embedded Linux devices"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "https://www.mender.io/blog/announcing-the-<em>production</em>-ready-mender-release-1-0"}}, "_tags": ["story", "author_ralphmender", "story_13741625"], "author": "ralphmender", "children": [13742156, 13742346, 13742380, 13743462, 13743962, 13744011, 13744340, 13744559], "created_at": "2017-02-27T03:21:07Z", "created_at_i": 1488165667, "num_comments": 45, "objectID": "13741625", "points": 132, "story_id": 13741625, "title": "Mender \u2013 An open-source OTA software updater for embedded Linux devices", "updated_at": "2024-09-20T00:25:57Z", "url": "https://www.mender.io/blog/announcing-the-production-ready-mender-release-1-0"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "oaknutspiano"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["okta", "production"], "value": "A few month ago my roommates and I started building Rubbrband(https://rubbrband.com). It's a platform that helps you monitor and modify your users' Redux states, LocalStorage, and browser cache all from your browser.<p>Why did we start working on this?<p>We want to make the data layer on the client-side less siloed from developers. This is obviously hard because each client's device is remote and is typically part of one-way communication.<p>Essentially we're building the set of tools that we each wanted as developers building web apps that go into <em>production</em>. One of the main issues we found is that most frontend bugs we've found came from some sort of a data state issue, which got extremely frustrating when the code went into <em>production</em> since you'd have to talk to the customer, get on a call, etc... We wanted a simple way to monitor the user's app, contextualize it in the grander scheme of the data models and application structure, and ideally push out an <em>OTA</em> update that would patch bugs.<p>What's included<p>- A simple React library to monitor Redux, and LocalStorage states<p>- Monitoring user's LocalStorage and Redux states in a clean dashboard, tied together with User data<p>- Client-side and Server-side API for serverless caching, with support for GoLang and Node.js<p>I'd love to get feedback on what you think<p>Mainly I'm interested in these questions:<p>- Does this solve a pain point that you face as a Frontend developer?<p>- What features would you want to see built out?<p>Thanks a ton!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "A Data Platform for React"}}, "_tags": ["story", "author_oaknutspiano", "story_32182766", "ask_hn"], "author": "oaknutspiano", "created_at": "2022-07-21T18:14:54Z", "created_at_i": 1658427294, "num_comments": 0, "objectID": "32182766", "points": 3, "story_id": 32182766, "story_text": "A few month ago my roommates and I started building Rubbrband(https:&#x2F;&#x2F;rubbrband.com). It&#x27;s a platform that helps you monitor and modify your users&#x27; Redux states, LocalStorage, and browser cache all from your browser.<p>Why did we start working on this?<p>We want to make the data layer on the client-side less siloed from developers. This is obviously hard because each client&#x27;s device is remote and is typically part of one-way communication.<p>Essentially we&#x27;re building the set of tools that we each wanted as developers building web apps that go into production. One of the main issues we found is that most frontend bugs we&#x27;ve found came from some sort of a data state issue, which got extremely frustrating when the code went into production since you&#x27;d have to talk to the customer, get on a call, etc... We wanted a simple way to monitor the user&#x27;s app, contextualize it in the grander scheme of the data models and application structure, and ideally push out an OTA update that would patch bugs.<p>What&#x27;s included<p>- A simple React library to monitor Redux, and LocalStorage states<p>- Monitoring user&#x27;s LocalStorage and Redux states in a clean dashboard, tied together with User data<p>- Client-side and Server-side API for serverless caching, with support for GoLang and Node.js<p>I&#x27;d love to get feedback on what you think<p>Mainly I&#x27;m interested in these questions:<p>- Does this solve a pain point that you face as a Frontend developer?<p>- What features would you want to see built out?<p>Thanks a ton!", "title": "A Data Platform for React", "updated_at": "2024-09-20T11:41:54Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "ayeeye1careers"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["okta", "production"], "value": "Hi,<p>We\u2019re a start-up company based in London and building building a privacy-first, offline-first edge AI platform that runs on real devices (camera boards, HDMI sticks, edge nodes).<p>We need a Senior Embedded Linux / Device OS Engineer to own the device OS end-to-end (bootloader \u2192 kernel \u2192 userspace), including Yocto/Buildroot, secure boot &amp; device identity at OS level, <em>OTA</em> with rollback/recovery, and driver integration (V4L2/USB/HDMI/GPIO/I2C/SPI). This is not a research role. This is about shipping reliable hardware into the real world. Please see more details of the role as follows:<p>Location: Remote / Hybrid (UK / EU preferred)<p>Type: Full-time<p>Responsibilities<p>\u00b7         Linux bring-up on custom hardware (bootloader \u2192 kernel \u2192 userspace)<p>\u00b7         Yocto or Buildroot build systems<p>\u00b7         Device provisioning, secure boot, identity at OS level<p>\u00b7         <em>OTA</em> updates with rollback and recovery<p>\u00b7         Driver integration (V4L2, USB, HDMI, GPIO, I2C, SPI)<p>\u00b7         Power, thermal, watchdog, storage integrity<p>\u00b7         Debugging at the metal (serial, JTAG, logic analyser)<p>Required Experience<p>\u00b7         5+ years embedded Linux<p>\u00b7         Shipped <em>production</em> devices<p>\u00b7         Comfortable with poor documentation and hardware quirks<p>\u00b7         Strong C / shell / low-level Linux skills<p>We are committed to remote/hybrid(UK/EU preferred), and we offer a competitive salary and a senior role that allows you to get the full picture of the project as well. That said, would you be open to a short intro call to see if there\u2019s a good fit? If yes, please feel free to contact ayeeye.career@gmail.com<p>Thanks!<p>Look forward to hearing from you."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Senior Embedded Linux / Device OS Engineer"}}, "_tags": ["story", "author_ayeeye1careers", "story_47067799", "ask_hn"], "author": "ayeeye1careers", "children": [47068877], "created_at": "2026-02-18T23:23:54Z", "created_at_i": 1771457034, "num_comments": 1, "objectID": "47067799", "points": 1, "story_id": 47067799, "story_text": "Hi,<p>We\u2019re a start-up company based in London and building building a privacy-first, offline-first edge AI platform that runs on real devices (camera boards, HDMI sticks, edge nodes).<p>We need a Senior Embedded Linux &#x2F; Device OS Engineer to own the device OS end-to-end (bootloader \u2192 kernel \u2192 userspace), including Yocto&#x2F;Buildroot, secure boot &amp; device identity at OS level, OTA with rollback&#x2F;recovery, and driver integration (V4L2&#x2F;USB&#x2F;HDMI&#x2F;GPIO&#x2F;I2C&#x2F;SPI). This is not a research role. This is about shipping reliable hardware into the real world. Please see more details of the role as follows:<p>Location: Remote &#x2F; Hybrid (UK &#x2F; EU preferred)<p>Type: Full-time<p>Responsibilities<p>\u00b7         Linux bring-up on custom hardware (bootloader \u2192 kernel \u2192 userspace)<p>\u00b7         Yocto or Buildroot build systems<p>\u00b7         Device provisioning, secure boot, identity at OS level<p>\u00b7         OTA updates with rollback and recovery<p>\u00b7         Driver integration (V4L2, USB, HDMI, GPIO, I2C, SPI)<p>\u00b7         Power, thermal, watchdog, storage integrity<p>\u00b7         Debugging at the metal (serial, JTAG, logic analyser)<p>Required Experience<p>\u00b7         5+ years embedded Linux<p>\u00b7         Shipped production devices<p>\u00b7         Comfortable with poor documentation and hardware quirks<p>\u00b7         Strong C &#x2F; shell &#x2F; low-level Linux skills<p>We are committed to remote&#x2F;hybrid(UK&#x2F;EU preferred), and we offer a competitive salary and a senior role that allows you to get the full picture of the project as well. That said, would you be open to a short intro call to see if there\u2019s a good fit? If yes, please feel free to contact ayeeye.career@gmail.com<p>Thanks!<p>Look forward to hearing from you.", "title": "Senior Embedded Linux / Device OS Engineer", "updated_at": "2026-02-19T01:44:08Z"}], "hitsPerPage": 15, "nbHits": 8, "nbPages": 1, "page": 0, "params": "query=okta+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 13, "processingTimingsMS": {"_request": {"roundTrip": 25}, "afterFetch": {"format": {"highlighting": 1, "total": 1}}, "fetch": {"query": 9, "scanning": 2, "total": 12}, "total": 13}, "query": "okta production", "serverTimeMS": 16}}