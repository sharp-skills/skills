{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "copperegg"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["aws", "dynamodb", "production"], "value": "Overview of recent Amazon <em>AWS DynamoDB</em> analysis for <em>production</em> use at CopperEgg - details out use cases for & against, performance, operational considerations, what's missing, and what's cool."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "DynamoDB - the Good, the Bad, and the AWSome"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "http://copperegg.com/dynamodb-the-good-the-bad-and-the-awsome/"}}, "_tags": ["story", "author_copperegg", "story_4674275"], "author": "copperegg", "created_at": "2012-10-19T16:44:42Z", "created_at_i": 1350665082, "num_comments": 0, "objectID": "4674275", "points": 2, "story_id": 4674275, "story_text": "Overview of recent Amazon AWS DynamoDB analysis for production use at CopperEgg - details out use cases for &#38; against, performance, operational considerations, what's missing, and what's cool.", "title": "DynamoDB - the Good, the Bad, and the AWSome", "updated_at": "2024-09-19T18:58:37Z", "url": "http://copperegg.com/dynamodb-the-good-the-bad-and-the-awsome/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "Jet_Xu"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["aws", "dynamodb", "production"], "value": "I recently discovered what I consider a serious design flaw in <em>AWS DynamoDB</em> Triggers that I believe deserves more attention from the community.<p>Here's the issue: DynamoDB Triggers can only point to the `$LATEST` version of a Lambda function. Yes, you read that right - there's no built-in way to target a specific version or alias through the console. This means any changes to your Lambda function's `$LATEST` version immediately affect your <em>production</em> triggers, whether you intended to or not.<p>Consider this scenario:\n1. You have a critical DynamoDB table with a Lambda trigger handling important business logic\n2. A developer pushes changes to the Lambda's `$LATEST` version for testing\n3. Surprise! Those changes are now processing your <em>production</em> data<p>The workarounds are all suboptimal:\n- Create triggers through CloudFormation/CDK (requires delete and recreate)\n- Maintain separate tables for different environments\n- Add environment checks in your Lambda code\n- Use the Lambda console to configure triggers (unintuitive and error-prone)<p>This design choice seems to violate several fundamental principles:\n- Separation of concerns\n- Safe deployment practices\n- The principle of least surprise\n- AWS's own best practices for <em>production</em> workloads<p>What's particularly puzzling is that other AWS services (API Gateway, EventBridge, etc.) handle versioning and aliases perfectly well. Why is DynamoDB different?<p>Some questions for the community:\n1. Has anyone else encountered <em>production</em> issues because of this?\n2. What workarounds have you found effective?\n3. Is there a technical limitation I'm missing that explains this design choice?\n4. Should we push AWS to change this behavior?<p>For now, my team has implemented a multi-layer safety net:\n```python\ndef lambda_handler(event, context):\n    if not is_<em>production</em>_alias():\n        log_and_alert(&quot;Non-<em>production</em> version processing <em>production</em> data!&quot;)\n        return<p><pre><code>    if not validate_deployment_state():\n        return\n        \n    # Actual business logic here</code></pre>\n```<p>But this feels like we're working around a problem that shouldn't exist in the first place.<p>Curious to hear others' experiences and thoughts on this. Have you encountered similar &quot;gotchas&quot; in AWS services that seem to go against cloud deployment best practices?"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["aws", "dynamodb", "production"], "value": "Ask HN: <em>AWS DynamoDB</em> Triggers \u2013 A Time Bomb in Your <em>Production</em> Environment?"}}, "_tags": ["story", "author_Jet_Xu", "story_42529361", "ask_hn"], "author": "Jet_Xu", "children": [42529388, 42532209, 42535765], "created_at": "2024-12-28T07:53:29Z", "created_at_i": 1735372409, "num_comments": 3, "objectID": "42529361", "points": 3, "story_id": 42529361, "story_text": "I recently discovered what I consider a serious design flaw in AWS DynamoDB Triggers that I believe deserves more attention from the community.<p>Here&#x27;s the issue: DynamoDB Triggers can only point to the `$LATEST` version of a Lambda function. Yes, you read that right - there&#x27;s no built-in way to target a specific version or alias through the console. This means any changes to your Lambda function&#x27;s `$LATEST` version immediately affect your production triggers, whether you intended to or not.<p>Consider this scenario:\n1. You have a critical DynamoDB table with a Lambda trigger handling important business logic\n2. A developer pushes changes to the Lambda&#x27;s `$LATEST` version for testing\n3. Surprise! Those changes are now processing your production data<p>The workarounds are all suboptimal:\n- Create triggers through CloudFormation&#x2F;CDK (requires delete and recreate)\n- Maintain separate tables for different environments\n- Add environment checks in your Lambda code\n- Use the Lambda console to configure triggers (unintuitive and error-prone)<p>This design choice seems to violate several fundamental principles:\n- Separation of concerns\n- Safe deployment practices\n- The principle of least surprise\n- AWS&#x27;s own best practices for production workloads<p>What&#x27;s particularly puzzling is that other AWS services (API Gateway, EventBridge, etc.) handle versioning and aliases perfectly well. Why is DynamoDB different?<p>Some questions for the community:\n1. Has anyone else encountered production issues because of this?\n2. What workarounds have you found effective?\n3. Is there a technical limitation I&#x27;m missing that explains this design choice?\n4. Should we push AWS to change this behavior?<p>For now, my team has implemented a multi-layer safety net:\n```python\ndef lambda_handler(event, context):\n    if not is_production_alias():\n        log_and_alert(&quot;Non-production version processing production data!&quot;)\n        return<p><pre><code>    if not validate_deployment_state():\n        return\n        \n    # Actual business logic here</code></pre>\n```<p>But this feels like we&#x27;re working around a problem that shouldn&#x27;t exist in the first place.<p>Curious to hear others&#x27; experiences and thoughts on this. Have you encountered similar &quot;gotchas&quot; in AWS services that seem to go against cloud deployment best practices?", "title": "Ask HN: AWS DynamoDB Triggers \u2013 A Time Bomb in Your Production Environment?", "updated_at": "2024-12-30T00:06:41Z"}], "hitsPerPage": 15, "nbHits": 2, "nbPages": 1, "page": 0, "params": "query=aws-dynamodb+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 17, "processingTimingsMS": {"_request": {"roundTrip": 18}, "fetch": {"query": 11, "scanning": 5, "total": 17}, "total": 17}, "query": "aws-dynamodb production", "serverTimeMS": 18}}