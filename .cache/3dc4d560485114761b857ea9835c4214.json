{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "thomas-martin"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jaeger", "production"], "value": "I've been running <em>Jaeger</em> in <em>production</em> for a while and thinking of spinning it off as a hosted service. Would anyone be interested in trying it out when I have it deployed ?"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["jaeger"], "value": "Ask HN: Interest in Uber <em>Jaeger</em> tracing as a service?"}}, "_tags": ["story", "author_thomas-martin", "story_15123810", "ask_hn"], "author": "thomas-martin", "created_at": "2017-08-29T12:29:04Z", "created_at_i": 1504009744, "num_comments": 0, "objectID": "15123810", "points": 2, "story_id": 15123810, "story_text": "I&#x27;ve been running Jaeger in production for a while and thinking of spinning it off as a hosted service. Would anyone be interested in trying it out when I have it deployed ?", "title": "Ask HN: Interest in Uber Jaeger tracing as a service?", "updated_at": "2024-09-20T01:16:47Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "xinweihe"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jaeger", "production"], "value": "Hey Xinwei and Zecheng here, we are the authors of TraceRoot (<a href=\"https://github.com/traceroot-ai/traceroot\">https://github.com/traceroot-ai/traceroot</a>).<p>TraceRoot (<a href=\"https://traceroot.ai\">https://traceroot.ai</a>) is an open-source debugging platform that helps engineers fix <em>production</em> issues faster by combining structured traces, logs, source code contexts and discussions in Github PRs, issues and Slack channels, etc. with AI Agents.<p>At the heart are our lightweight Python (<a href=\"https://github.com/traceroot-ai/traceroot-sdk\">https://github.com/traceroot-ai/traceroot-sdk</a>) and TypeScript (<a href=\"https://github.com/traceroot-ai/traceroot-sdk-ts\">https://github.com/traceroot-ai/traceroot-sdk-ts</a>) SDKs - they can hook into your app using OpenTelemetry and captures logs and traces. These are either sent to a local <em>Jaeger</em> (<a href=\"https://www.jaegertracing.io/\" rel=\"nofollow\">https://www.jaegertracing.io/</a>) + SQLite backend or to our cloud backend, where we correlate them into a single view. From there, our custom agent takes over.<p>The agent builds a heterogeneous execution tree that merges spans, logs, and GitHub context into one internal structure. This allows it to model the control and data flow of a request across services. It then uses LLMs to reason over this tree - pruning irrelevant branches, surfacing anomalous spans, and identifying likely root causes. You can ask questions like \u201cwhat caused this timeout?\u201d or \u201csummarize the errors in these 3 spans\u201d, and it can trace the failure back to a specific commit, summarize the chain of events, or even propose a fix via a draft PR.<p>We also built a debugging UI that ties everything together - you explore traces visually, pick spans of interest, and get AI-assisted insights with full context: logs, timings, metadata, and surrounding code. Unlike most tools, TraceRoot stores long-term debugging history and builds structured context for each company - something we haven\u2019t seen many others do in this space.<p>What\u2019s live today:<p>- Python and TypeScript SDKs for structured logs and traces.<p>- AI summaries, GitHub issue generation, and PR creation.<p>- Debugging UI that ties everything together<p>TraceRoot is MIT licensed and easy to self-host (via Docker). We support both local mode (<em>Jaeger</em> + SQLite) and cloud mode. Inspired by OSS projects like PostHog and Supabase - core is free, enterprise features like agent mode multi-tenant and slack integration are paid.<p>If you find it interesting, you can see a demo video here: <a href=\"https://www.youtube.com/watch?v=nb-D3LM0sJM\" rel=\"nofollow\">https://www.youtube.com/watch?v=nb-D3LM0sJM</a><p>We\u2019d love you to try TraceRoot (<a href=\"https://traceroot.ai\">https://traceroot.ai</a>) and share any feedback. If you're interested, our code is available here: <a href=\"https://github.com/traceroot-ai/traceroot\">https://github.com/traceroot-ai/traceroot</a>. If we don\u2019t have something, let us know and we\u2019d be happy to build it for you. We look forward to your comments!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: TraceRoot \u2013 Open-source agentic debugging for distributed services"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/traceroot-ai/traceroot"}}, "_tags": ["story", "author_xinweihe", "story_44759406", "show_hn"], "author": "xinweihe", "children": [44759749, 44759902, 44761725, 44762246, 44764939, 44766340, 44772821, 44774723, 44778245], "created_at": "2025-08-01T16:58:51Z", "created_at_i": 1754067531, "num_comments": 22, "objectID": "44759406", "points": 40, "story_id": 44759406, "story_text": "Hey Xinwei and Zecheng here, we are the authors of TraceRoot (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;traceroot-ai&#x2F;traceroot\">https:&#x2F;&#x2F;github.com&#x2F;traceroot-ai&#x2F;traceroot</a>).<p>TraceRoot (<a href=\"https:&#x2F;&#x2F;traceroot.ai\">https:&#x2F;&#x2F;traceroot.ai</a>) is an open-source debugging platform that helps engineers fix production issues faster by combining structured traces, logs, source code contexts and discussions in Github PRs, issues and Slack channels, etc. with AI Agents.<p>At the heart are our lightweight Python (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;traceroot-ai&#x2F;traceroot-sdk\">https:&#x2F;&#x2F;github.com&#x2F;traceroot-ai&#x2F;traceroot-sdk</a>) and TypeScript (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;traceroot-ai&#x2F;traceroot-sdk-ts\">https:&#x2F;&#x2F;github.com&#x2F;traceroot-ai&#x2F;traceroot-sdk-ts</a>) SDKs - they can hook into your app using OpenTelemetry and captures logs and traces. These are either sent to a local Jaeger (<a href=\"https:&#x2F;&#x2F;www.jaegertracing.io&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.jaegertracing.io&#x2F;</a>) + SQLite backend or to our cloud backend, where we correlate them into a single view. From there, our custom agent takes over.<p>The agent builds a heterogeneous execution tree that merges spans, logs, and GitHub context into one internal structure. This allows it to model the control and data flow of a request across services. It then uses LLMs to reason over this tree - pruning irrelevant branches, surfacing anomalous spans, and identifying likely root causes. You can ask questions like \u201cwhat caused this timeout?\u201d or \u201csummarize the errors in these 3 spans\u201d, and it can trace the failure back to a specific commit, summarize the chain of events, or even propose a fix via a draft PR.<p>We also built a debugging UI that ties everything together - you explore traces visually, pick spans of interest, and get AI-assisted insights with full context: logs, timings, metadata, and surrounding code. Unlike most tools, TraceRoot stores long-term debugging history and builds structured context for each company - something we haven\u2019t seen many others do in this space.<p>What\u2019s live today:<p>- Python and TypeScript SDKs for structured logs and traces.<p>- AI summaries, GitHub issue generation, and PR creation.<p>- Debugging UI that ties everything together<p>TraceRoot is MIT licensed and easy to self-host (via Docker). We support both local mode (Jaeger + SQLite) and cloud mode. Inspired by OSS projects like PostHog and Supabase - core is free, enterprise features like agent mode multi-tenant and slack integration are paid.<p>If you find it interesting, you can see a demo video here: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=nb-D3LM0sJM\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=nb-D3LM0sJM</a><p>We\u2019d love you to try TraceRoot (<a href=\"https:&#x2F;&#x2F;traceroot.ai\">https:&#x2F;&#x2F;traceroot.ai</a>) and share any feedback. If you&#x27;re interested, our code is available here: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;traceroot-ai&#x2F;traceroot\">https:&#x2F;&#x2F;github.com&#x2F;traceroot-ai&#x2F;traceroot</a>. If we don\u2019t have something, let us know and we\u2019d be happy to build it for you. We look forward to your comments!", "title": "Show HN: TraceRoot \u2013 Open-source agentic debugging for distributed services", "updated_at": "2025-09-08T07:18:47Z", "url": "https://github.com/traceroot-ai/traceroot"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "GalKlm"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jaeger", "production"], "value": "Hey HN, Gal, Nir and Doron here.<p>Over the past 2 years, we've helped teams debug everything from prompt issues to <em>production</em> outages.<p>We kept running into the same problem: Jumping between our IDEs and our observability dashboards.  So, we built an open-source MCP server that connects any OpenTelemetry backend (Grafana, <em>Jaeger</em>, Datadog, Dynatrace, Traceloop) to our dev environment using an MCP.<p>While there are many MCP servers built for specific providers (like Datadog\u2019s - <a href=\"https://docs.datadoghq.com/bits_ai/mcp_server\" rel=\"nofollow\">https://docs.datadoghq.com/bits_ai/mcp_server</a>), they\u2019re closed source (so we can\u2019t easily extend them), and they\u2019re locked to a single platform, so organizations that leverage multiple platforms, where data is scattered in between them, can\u2019t really use them.<p>We\u2019re adding support for more providers every day - feel free to contribute your own.<p>We would love your feedback and opinions - feel free to connect it to Claude or ChatGPT and try to investigate your own <em>production</em> data. What do you think about the set of tools that we currently expose? Do you think we should expose more or others?<p>Github: <a href=\"https://github.com/traceloop/opentelemetry-mcp-server\" rel=\"nofollow\">https://github.com/traceloop/opentelemetry-mcp-server</a>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: MCP Server for OpenTelemetry"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/traceloop/opentelemetry-mcp-server"}}, "_tags": ["story", "author_GalKlm", "story_45967204", "show_hn"], "author": "GalKlm", "children": [45967537], "created_at": "2025-11-18T15:09:15Z", "created_at_i": 1763478555, "num_comments": 2, "objectID": "45967204", "points": 13, "story_id": 45967204, "story_text": "Hey HN, Gal, Nir and Doron here.<p>Over the past 2 years, we&#x27;ve helped teams debug everything from prompt issues to production outages.<p>We kept running into the same problem: Jumping between our IDEs and our observability dashboards.  So, we built an open-source MCP server that connects any OpenTelemetry backend (Grafana, Jaeger, Datadog, Dynatrace, Traceloop) to our dev environment using an MCP.<p>While there are many MCP servers built for specific providers (like Datadog\u2019s - <a href=\"https:&#x2F;&#x2F;docs.datadoghq.com&#x2F;bits_ai&#x2F;mcp_server\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.datadoghq.com&#x2F;bits_ai&#x2F;mcp_server</a>), they\u2019re closed source (so we can\u2019t easily extend them), and they\u2019re locked to a single platform, so organizations that leverage multiple platforms, where data is scattered in between them, can\u2019t really use them.<p>We\u2019re adding support for more providers every day - feel free to contribute your own.<p>We would love your feedback and opinions - feel free to connect it to Claude or ChatGPT and try to investigate your own production data. What do you think about the set of tools that we currently expose? Do you think we should expose more or others?<p>Github: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;traceloop&#x2F;opentelemetry-mcp-server\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;traceloop&#x2F;opentelemetry-mcp-server</a>", "title": "Show HN: MCP Server for OpenTelemetry", "updated_at": "2025-11-18T17:19:22Z", "url": "https://github.com/traceloop/opentelemetry-mcp-server"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "kirankgollu"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jaeger", "production"], "value": "Hey HN -<p>Kiran and Vijay here.<p>We built Oodle after seeing teams forced to choose between low cost, great experience, zero ops, and no lock-in. Even with premium tools, debugging still meant switching between Grafana for metrics, OpenSearch for logs, and <em>Jaeger</em> or Tempo for traces - copying timestamps, losing context, and burning time during incidents.<p>So we decided to rethink observability from first principles - in both architecture and experience.<p>Architecturally, we borrowed ideas from Snowflake: separated storage and compute so each can scale independently. All telemetry - metrics, logs, and traces - is stored on S3 in a custom columnar format, while serverless compute scales on demand. The result is 3\u20135\u00d7 lower cost, massive scale, and zero operational overhead, with full compatibility for Grafana dashboards, PromQL, and OpenSearch queries.<p>On the experience side, Oodle unifies everything you already use. It works with your existing Grafana and OpenSearch setup, but when an alert fires, Oodle automatically correlates metrics, logs, and traces in one view - showing the latency spike, the related logs, and the exact service that caused it.<p>It\u2019s already in <em>production</em> across SaaS, fintech, and healthcare companies processing 10 TB+ logs/day and 50 M+ time-series/day.<p>We\u2019ve both spent years building large-scale data systems. Vijay worked on Rubrik\u2019s petabyte-scale file system on object storage, and I helped build AWS S3 and DynamoDB before leading Rubrik\u2019s cloud platform. Oodle applies the same design principles to observability.<p>You can try a live OpenTelemetry demo in &lt; 5 minutes (no signup needed): \n<a href=\"https://play.oodle.ai/settings?isUnifiedExperienceTourModalOpen=true\" rel=\"nofollow\">https://play.oodle.ai/settings?isUnifiedExperienceTourModalO...</a><p>or watch a short product walkthrough here: \n<a href=\"https://www.youtube.com/watch?v=wdYWDG3dRkU\" rel=\"nofollow\">https://www.youtube.com/watch?v=wdYWDG3dRkU</a><p>Would love feedback - what\u2019s your biggest observability pain today: cost, debuggability, or lock-in?"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Oodle \u2013 Unified Debugging with OpenSearch and Grafana"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://blog.oodle.ai/meet-oodle-unified-and-ai-native-observability/"}}, "_tags": ["story", "author_kirankgollu", "story_45812312", "show_hn"], "author": "kirankgollu", "children": [45816488], "created_at": "2025-11-04T15:49:08Z", "created_at_i": 1762271348, "num_comments": 3, "objectID": "45812312", "points": 11, "story_id": 45812312, "story_text": "Hey HN -<p>Kiran and Vijay here.<p>We built Oodle after seeing teams forced to choose between low cost, great experience, zero ops, and no lock-in. Even with premium tools, debugging still meant switching between Grafana for metrics, OpenSearch for logs, and Jaeger or Tempo for traces - copying timestamps, losing context, and burning time during incidents.<p>So we decided to rethink observability from first principles - in both architecture and experience.<p>Architecturally, we borrowed ideas from Snowflake: separated storage and compute so each can scale independently. All telemetry - metrics, logs, and traces - is stored on S3 in a custom columnar format, while serverless compute scales on demand. The result is 3\u20135\u00d7 lower cost, massive scale, and zero operational overhead, with full compatibility for Grafana dashboards, PromQL, and OpenSearch queries.<p>On the experience side, Oodle unifies everything you already use. It works with your existing Grafana and OpenSearch setup, but when an alert fires, Oodle automatically correlates metrics, logs, and traces in one view - showing the latency spike, the related logs, and the exact service that caused it.<p>It\u2019s already in production across SaaS, fintech, and healthcare companies processing 10 TB+ logs&#x2F;day and 50 M+ time-series&#x2F;day.<p>We\u2019ve both spent years building large-scale data systems. Vijay worked on Rubrik\u2019s petabyte-scale file system on object storage, and I helped build AWS S3 and DynamoDB before leading Rubrik\u2019s cloud platform. Oodle applies the same design principles to observability.<p>You can try a live OpenTelemetry demo in &lt; 5 minutes (no signup needed): \n<a href=\"https:&#x2F;&#x2F;play.oodle.ai&#x2F;settings?isUnifiedExperienceTourModalOpen=true\" rel=\"nofollow\">https:&#x2F;&#x2F;play.oodle.ai&#x2F;settings?isUnifiedExperienceTourModalO...</a><p>or watch a short product walkthrough here: \n<a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=wdYWDG3dRkU\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=wdYWDG3dRkU</a><p>Would love feedback - what\u2019s your biggest observability pain today: cost, debuggability, or lock-in?", "title": "Show HN: Oodle \u2013 Unified Debugging with OpenSearch and Grafana", "updated_at": "2025-11-05T02:42:45Z", "url": "https://blog.oodle.ai/meet-oodle-unified-and-ai-native-observability/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "RogerAlsing"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["jaeger", "production"], "value": "TraceLens is a new user interface and data collector for OpenTelemetry-based systems.<p>Although there are existing tools like <em>Jaeger</em> and Zipkin that offer some visualization capabilities, I wanted a solution that could provide a deeper level of insight.<p>TraceLens is not designed for <em>production</em> environments, but as a debugging tool to help developers better understand the intricacies of their systems.<p>Key features are detailed component diagrams. and sequence diagrams."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: TraceLens Visualizing Distributed Systems"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://tracelens.io/"}}, "_tags": ["story", "author_RogerAlsing", "story_40899724", "show_hn"], "author": "RogerAlsing", "created_at": "2024-07-07T19:11:22Z", "created_at_i": 1720379482, "num_comments": 0, "objectID": "40899724", "points": 6, "story_id": 40899724, "story_text": "TraceLens is a new user interface and data collector for OpenTelemetry-based systems.<p>Although there are existing tools like Jaeger and Zipkin that offer some visualization capabilities, I wanted a solution that could provide a deeper level of insight.<p>TraceLens is not designed for production environments, but as a debugging tool to help developers better understand the intricacies of their systems.<p>Key features are detailed component diagrams. and sequence diagrams.", "title": "Show HN: TraceLens Visualizing Distributed Systems", "updated_at": "2024-09-20T17:28:18Z", "url": "https://tracelens.io/"}], "hitsPerPage": 15, "nbHits": 5, "nbPages": 1, "page": 0, "params": "query=jaeger+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 10, "processingTimingsMS": {"_request": {"roundTrip": 13}, "fetch": {"query": 6, "scanning": 2, "total": 9}, "total": 10}, "query": "jaeger production", "serverTimeMS": 11}}