{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "viksit"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["algolia", "production"], "value": "Who's using Clojure in <em>production</em> today and what are you using it for? I'm curious about the state of the ecosystem and its adoption today.<p>There are a lot of old threads (on HN[1] or Quora[2]) that ask this - but none of them seem to reflect latest on who's using Clojure in <em>production</em> in late 2014. The recent State of Clojure data [3] doesn't capture this either.<p>[1] https://hn.<em>algolia</em>.com/#!/story/forever/0/whos%20using%20clojure<p>[2] https://www.quora.com/Whos-using-Clojure-in-<em>production</em><p>[3] https://cognitect.wufoo.com/reports/state-of-clojure-2014-results/"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Ask HN: Who's using Clojure in <em>production</em>?"}}, "_tags": ["story", "author_viksit", "story_8549823", "ask_hn"], "author": "viksit", "children": [8549878, 8550953, 8550959, 8550965, 8551001, 8551041, 8551086, 8551242, 8551536, 8551870, 8552639, 8554345, 8554415, 8554418, 8554774, 8554871, 8554906, 8555095, 8555165, 8555172, 8555438, 8555450, 8555459, 8555484, 8555576, 8556250, 8556302, 8557185, 8557317, 8558021, 8558566, 8559221, 8559543, 8559555, 8560261, 8561747, 8562285, 8562286, 8566474, 8568801, 8571712], "created_at": "2014-11-03T08:10:18Z", "created_at_i": 1415002218, "num_comments": 54, "objectID": "8549823", "points": 79, "story_id": 8549823, "story_text": "Who&#x27;s using Clojure in production today and what are you using it for? I&#x27;m curious about the state of the ecosystem and its adoption today.<p>There are a lot of old threads (on HN[1] or Quora[2]) that ask this - but none of them seem to reflect latest on who&#x27;s using Clojure in production in late 2014. The recent State of Clojure data [3] doesn&#x27;t capture this either.<p>[1] https:&#x2F;&#x2F;hn.algolia.com&#x2F;#!&#x2F;story&#x2F;forever&#x2F;0&#x2F;whos%20using%20clojure<p>[2] https:&#x2F;&#x2F;www.quora.com&#x2F;Whos-using-Clojure-in-production<p>[3] https:&#x2F;&#x2F;cognitect.wufoo.com&#x2F;reports&#x2F;state-of-clojure-2014-results&#x2F;", "title": "Ask HN: Who's using Clojure in production?", "updated_at": "2025-06-26T21:36:47Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "aprdm"}, "story_text": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["algolia"], "value": "We are evaluating a scheduler to use for our services and we came across Nomad (http://nomadproject.io)<p>This article (https://medium.com/@copyconstruct/schedulers-kubernetes-and-nomad-b0f2e14a896) which a co-worker sent has a very good reasoning / introduction to why this particular company uses Nomad and it does seem to match our requirements.<p>Plus we already use Consul and Nomad plugs really well with Consul.<p>Are there more stories about people using (or not using and why) Nomad? Haven't found much in hacker news through <em>Algolia</em> search<p>Cheers"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Ask HN: Do you use Nomad in <em>production</em>?"}}, "_tags": ["story", "author_aprdm", "story_15866768", "ask_hn"], "author": "aprdm", "created_at": "2017-12-07T01:18:23Z", "created_at_i": 1512609503, "num_comments": 0, "objectID": "15866768", "points": 4, "story_id": 15866768, "story_text": "We are evaluating a scheduler to use for our services and we came across Nomad (http:&#x2F;&#x2F;nomadproject.io)<p>This article (https:&#x2F;&#x2F;medium.com&#x2F;@copyconstruct&#x2F;schedulers-kubernetes-and-nomad-b0f2e14a896) which a co-worker sent has a very good reasoning &#x2F; introduction to why this particular company uses Nomad and it does seem to match our requirements.<p>Plus we already use Consul and Nomad plugs really well with Consul.<p>Are there more stories about people using (or not using and why) Nomad? Haven&#x27;t found much in hacker news through Algolia search<p>Cheers", "title": "Ask HN: Do you use Nomad in production?", "updated_at": "2024-09-20T01:44:05Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "vvoyer"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "<em>Production</em>-tested best practices for Kubernetes"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["algolia"], "value": "https://blog.<em>algolia</em>.com/8-<em>algolia</em>-tested-best-practices-kubernetes/"}}, "_tags": ["story", "author_vvoyer", "story_20174972"], "author": "vvoyer", "created_at": "2019-06-13T14:07:00Z", "created_at_i": 1560434820, "num_comments": 0, "objectID": "20174972", "points": 2, "story_id": 20174972, "title": "Production-tested best practices for Kubernetes", "updated_at": "2024-09-20T04:28:01Z", "url": "https://blog.algolia.com/8-algolia-tested-best-practices-kubernetes/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "wittydeveloper"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["algolia", "production"], "value": "Hi HN! We are Charly and Bryan, founders of Defer (<a href=\"https://www.defer.run/\">https://www.defer.run/</a>). Defer is a zero-infrastructure background jobs platform for Node.js developers. As a managed platform that brings modern development standards to background jobs (ex: multi-env support, zero-API design), we enable Node.js developers to build products faster and scale without effort and infrastructure knowledge.<p>Background jobs, while being used in all web applications (processing webhooks, interacting with 3rd party APIs, or powering core features), did not benefit from the developer experience improvements that arose in all other layers of the Node.js API stack: quick and reliable databases with Supabase or easy Serverless deployment with Vercel.<p>Today, even for simple use cases, working with background jobs in Node.js necessarily requires some infrastructure knowledge\u2014either by deploying and scaling an open source solution (ex: BullMQ) or using an IaaS such as AWS SQS with Lambdas, which comes with complexity and limited features (no support for dead letter queues, dynamic concurrency, or throttling).<p>At a large scale, you will need to solve how to handle rolling restarts, how to auto-scale your workers, how to safely deploy without interrupting long-running jobs, how to safely encrypt jobs\u2019 data, and how to version them. Once deployed, your background job\u2019s code lives in a separate part of your codebase, with its own mental model (queues and workers). Finally, most solutions provide technical dashboards which are not always helpful in debugging <em>production</em> issues, so you end up having to build custom dashboards.<p>Most companies we talked to try to handle those different aspects, building custom similar solutions and using developers\u2019 time that could have been used on user-facing features.<p>Bryan and I are technical founders with 10+ years of experience working at start-ups of all stages (e.g. <em>Algolia</em>, home of HN Search!), from tech lead to CTO roles. Like many developers, we got asked many times to work on background job stacks and invest time into tailoring and scaling them for product needs.<p>I even dedicated most of my time at <em>Algolia</em> to building a custom background jobs pipeline to power the <em>Algolia</em> Shopify integration: ingesting partial webhooks from Shopify, enriching them given customers configuration, in FIFO order per shop, with the Shopify rate limited API, for thousands of shops and the equivalents of 3 millions of jobs per day. Given the complex and unique product requirements of the <em>Algolia</em> Shopify Ingestion Pipeline, the only solution (at the time and context) was to build a custom background jobs stack combining Redis and Kubernetes.<p>When consulting with some startups, we witnessed some developers choosing to keep some slow API routes calling 3rd party APIs synchronously instead of investing time in setting up background jobs. When looking back to the recent increase of productive zero infrastructure solutions in the Node.js ecosystem, we were surprised that the experience with background jobs remained unchanged. We decided to build Defer, so working with background jobs, CRONs, and workflows would match the current standard of Node.js developer experience.<p>Inspired by Next.js, Remix, and Netlify design, background jobs in Defer become background functions that live in your application\u2019s code, with direct access to all configuration options: retry, concurrency, and more (<a href=\"https://docs.defer.run/features/retries-concurrency/\">https://docs.defer.run/features/retries-concurrency/</a>) , and no specific mental model to learn. Your background functions get continuously deployed from GitHub with support for branch-based environments, allowing you to test new background jobs in no time, before safely moving to <em>production</em>.<p>Defer works for all kinds of Node.js projects, not only serverless ones. It does not require you to learn any new architectures or adapt your system design\u2014you just turn your code into background functions using coding patterns you already know, ex: map-reduce, or recursion. \nDefer brings features such as configurable retries (advanced backoff options), throttling, and concurrency at the background job level, which other solutions either require you to implement yourself or are simply not available. Finally, the Defer Dashboard is the only background jobs Dashboard to allow developers to quickly find executions based on business/product metadata, ex: \u201cShow all executions for `user_id=123`) to quickly debug product issues.<p>Defer\u2019s infrastructure, written in Go, is composed of 3 main components: a Build pipeline, a Scheduler, and a Runner. The Build pipeline enables us to build any Node.js project without requiring any configuration file (<a href=\"https://docs.defer.run/platform/builds/\">https://docs.defer.run/platform/builds/</a>). The Scheduler relies on Postgres for persistent storage of your jobs (no risk of losing some)\u2014all jobs\u2019 data is encrypted\u2014and on Redis, as an atomic counter to handle features such as concurrency and throttling (<a href=\"https://docs.defer.run/platform/executions/\">https://docs.defer.run/platform/executions/</a>). Our infrastructure runs on AWS EC2 - leveraging auto-scaling groups, using the containerd API directly from Go.<p>We run a progressive deployment approach to enable uninterrupted long-running jobs (some of our customers\u2019 jobs run for more than 5h) while releasing updates multiple times a day.\nOnce your application is up and running, the Defer dashboard gives you all the essential information to operate background jobs: activity histograms, performances, and Slack alerting upon failures. The executions list comes with rich filters, allowing you to quickly find all the executions linked to a specific customer or other business metadata.<p>In short, we ensure that you get all the essential features, with the best developer experience, and with a fully managed infrastructure and observability tools so you can focus on building your product.<p>All of this would be meaningless without a free plan for small and side projects and usage-based pricing, so that\u2019s what we offer: <a href=\"https://www.defer.run/pricing\">https://www.defer.run/pricing</a>. If you want to give Defer a try, you can get started with a simple GitHub login, without any credit card information required, and our docs are at <a href=\"https://docs.defer.run\">https://docs.defer.run</a>.<p>We would love to get to read about your experience with doing background jobs in Node.js and feedback on what we\u2019ve built. We look forward to your comments!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: Defer (YC W23) \u2013 Zero-infrastructure background jobs for Node.js"}}, "_tags": ["story", "author_wittydeveloper", "story_35096366", "launch_hn"], "author": "wittydeveloper", "children": [35096646, 35096731, 35096886, 35096954, 35096959, 35097077, 35097099, 35097402, 35097535, 35098275, 35098305, 35098361, 35098423, 35098557, 35098565, 35098719, 35098883, 35099085, 35099170, 35099345, 35099662, 35099755, 35099762, 35100148, 35100323, 35100358, 35100904, 35100981, 35101468, 35102310, 35103784, 35103985, 35104591, 35104896, 35106645, 35106927, 35107080, 35107948, 35108417, 35265216], "created_at": "2023-03-10T16:16:28Z", "created_at_i": 1678464988, "num_comments": 111, "objectID": "35096366", "points": 202, "story_id": 35096366, "story_text": "Hi HN! We are Charly and Bryan, founders of Defer (<a href=\"https:&#x2F;&#x2F;www.defer.run&#x2F;\">https:&#x2F;&#x2F;www.defer.run&#x2F;</a>). Defer is a zero-infrastructure background jobs platform for Node.js developers. As a managed platform that brings modern development standards to background jobs (ex: multi-env support, zero-API design), we enable Node.js developers to build products faster and scale without effort and infrastructure knowledge.<p>Background jobs, while being used in all web applications (processing webhooks, interacting with 3rd party APIs, or powering core features), did not benefit from the developer experience improvements that arose in all other layers of the Node.js API stack: quick and reliable databases with Supabase or easy Serverless deployment with Vercel.<p>Today, even for simple use cases, working with background jobs in Node.js necessarily requires some infrastructure knowledge\u2014either by deploying and scaling an open source solution (ex: BullMQ) or using an IaaS such as AWS SQS with Lambdas, which comes with complexity and limited features (no support for dead letter queues, dynamic concurrency, or throttling).<p>At a large scale, you will need to solve how to handle rolling restarts, how to auto-scale your workers, how to safely deploy without interrupting long-running jobs, how to safely encrypt jobs\u2019 data, and how to version them. Once deployed, your background job\u2019s code lives in a separate part of your codebase, with its own mental model (queues and workers). Finally, most solutions provide technical dashboards which are not always helpful in debugging production issues, so you end up having to build custom dashboards.<p>Most companies we talked to try to handle those different aspects, building custom similar solutions and using developers\u2019 time that could have been used on user-facing features.<p>Bryan and I are technical founders with 10+ years of experience working at start-ups of all stages (e.g. Algolia, home of HN Search!), from tech lead to CTO roles. Like many developers, we got asked many times to work on background job stacks and invest time into tailoring and scaling them for product needs.<p>I even dedicated most of my time at Algolia to building a custom background jobs pipeline to power the Algolia Shopify integration: ingesting partial webhooks from Shopify, enriching them given customers configuration, in FIFO order per shop, with the Shopify rate limited API, for thousands of shops and the equivalents of 3 millions of jobs per day. Given the complex and unique product requirements of the Algolia Shopify Ingestion Pipeline, the only solution (at the time and context) was to build a custom background jobs stack combining Redis and Kubernetes.<p>When consulting with some startups, we witnessed some developers choosing to keep some slow API routes calling 3rd party APIs synchronously instead of investing time in setting up background jobs. When looking back to the recent increase of productive zero infrastructure solutions in the Node.js ecosystem, we were surprised that the experience with background jobs remained unchanged. We decided to build Defer, so working with background jobs, CRONs, and workflows would match the current standard of Node.js developer experience.<p>Inspired by Next.js, Remix, and Netlify design, background jobs in Defer become background functions that live in your application\u2019s code, with direct access to all configuration options: retry, concurrency, and more (<a href=\"https:&#x2F;&#x2F;docs.defer.run&#x2F;features&#x2F;retries-concurrency&#x2F;\">https:&#x2F;&#x2F;docs.defer.run&#x2F;features&#x2F;retries-concurrency&#x2F;</a>) , and no specific mental model to learn. Your background functions get continuously deployed from GitHub with support for branch-based environments, allowing you to test new background jobs in no time, before safely moving to production.<p>Defer works for all kinds of Node.js projects, not only serverless ones. It does not require you to learn any new architectures or adapt your system design\u2014you just turn your code into background functions using coding patterns you already know, ex: map-reduce, or recursion. \nDefer brings features such as configurable retries (advanced backoff options), throttling, and concurrency at the background job level, which other solutions either require you to implement yourself or are simply not available. Finally, the Defer Dashboard is the only background jobs Dashboard to allow developers to quickly find executions based on business&#x2F;product metadata, ex: \u201cShow all executions for `user_id=123`) to quickly debug product issues.<p>Defer\u2019s infrastructure, written in Go, is composed of 3 main components: a Build pipeline, a Scheduler, and a Runner. The Build pipeline enables us to build any Node.js project without requiring any configuration file (<a href=\"https:&#x2F;&#x2F;docs.defer.run&#x2F;platform&#x2F;builds&#x2F;\">https:&#x2F;&#x2F;docs.defer.run&#x2F;platform&#x2F;builds&#x2F;</a>). The Scheduler relies on Postgres for persistent storage of your jobs (no risk of losing some)\u2014all jobs\u2019 data is encrypted\u2014and on Redis, as an atomic counter to handle features such as concurrency and throttling (<a href=\"https:&#x2F;&#x2F;docs.defer.run&#x2F;platform&#x2F;executions&#x2F;\">https:&#x2F;&#x2F;docs.defer.run&#x2F;platform&#x2F;executions&#x2F;</a>). Our infrastructure runs on AWS EC2 - leveraging auto-scaling groups, using the containerd API directly from Go.<p>We run a progressive deployment approach to enable uninterrupted long-running jobs (some of our customers\u2019 jobs run for more than 5h) while releasing updates multiple times a day.\nOnce your application is up and running, the Defer dashboard gives you all the essential information to operate background jobs: activity histograms, performances, and Slack alerting upon failures. The executions list comes with rich filters, allowing you to quickly find all the executions linked to a specific customer or other business metadata.<p>In short, we ensure that you get all the essential features, with the best developer experience, and with a fully managed infrastructure and observability tools so you can focus on building your product.<p>All of this would be meaningless without a free plan for small and side projects and usage-based pricing, so that\u2019s what we offer: <a href=\"https:&#x2F;&#x2F;www.defer.run&#x2F;pricing\">https:&#x2F;&#x2F;www.defer.run&#x2F;pricing</a>. If you want to give Defer a try, you can get started with a simple GitHub login, without any credit card information required, and our docs are at <a href=\"https:&#x2F;&#x2F;docs.defer.run\">https:&#x2F;&#x2F;docs.defer.run</a>.<p>We would love to get to read about your experience with doing background jobs in Node.js and feedback on what we\u2019ve built. We look forward to your comments!", "title": "Launch HN: Defer (YC W23) \u2013 Zero-infrastructure background jobs for Node.js", "updated_at": "2024-09-20T13:31:31Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "austinjp"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["algolia", "production"], "value": "The HN conversations around unikernels suggest that they're not ready for <em>production</em> yet [0] but feel free to set that record straight.<p>In the meantime, a handful of organisations/individuals seem to be working on becoming &quot;Docker for unikernels&quot;. That's probably an unfair description, but they're aiming to produce tools for building and managing unikernels: Unikraft [1], NanoVMs/Nanos [2], Unik [3]. Other orgs are producing unikernel-based OSs and VMs [4].<p>What is your toolset for building and managing unikernels? What have you learned?<p>Bonus question: is Unik dead? [5]<p>[0] <a href=\"https://hn.algolia.com/?dateRange=all&amp;page=0&amp;prefix=true&amp;query=unikernel&amp;sort=byPopularity&amp;type=story\" rel=\"nofollow\">https://hn.<em>algolia</em>.com/?dateRange=all&amp;page=0&amp;prefix=true&amp;que...</a><p>[1] <a href=\"https://unikraft.org/\" rel=\"nofollow\">https://unikraft.org/</a><p>[2] <a href=\"https://github.com/nanovms/nanos\" rel=\"nofollow\">https://github.com/nanovms/nanos</a><p>[3] <a href=\"https://github.com/solo-io/unik/\" rel=\"nofollow\">https://github.com/solo-io/unik/</a><p>[4] <a href=\"http://unikernel.org/projects/\" rel=\"nofollow\">http://unikernel.org/projects/</a><p>[5] <a href=\"https://github.com/solo-io/unik/issues/172\" rel=\"nofollow\">https://github.com/solo-io/unik/issues/172</a>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: How are you using unikernels?"}}, "_tags": ["story", "author_austinjp", "story_27301210", "ask_hn"], "author": "austinjp", "children": [27321059, 27321224, 27321491, 27321564, 27321640, 27321751, 27322366, 27325826], "created_at": "2021-05-27T10:27:49Z", "created_at_i": 1622111269, "num_comments": 34, "objectID": "27301210", "points": 120, "story_id": 27301210, "story_text": "The HN conversations around unikernels suggest that they&#x27;re not ready for production yet [0] but feel free to set that record straight.<p>In the meantime, a handful of organisations&#x2F;individuals seem to be working on becoming &quot;Docker for unikernels&quot;. That&#x27;s probably an unfair description, but they&#x27;re aiming to produce tools for building and managing unikernels: Unikraft [1], NanoVMs&#x2F;Nanos [2], Unik [3]. Other orgs are producing unikernel-based OSs and VMs [4].<p>What is your toolset for building and managing unikernels? What have you learned?<p>Bonus question: is Unik dead? [5]<p>[0] <a href=\"https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&amp;page=0&amp;prefix=true&amp;query=unikernel&amp;sort=byPopularity&amp;type=story\" rel=\"nofollow\">https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&amp;page=0&amp;prefix=true&amp;que...</a><p>[1] <a href=\"https:&#x2F;&#x2F;unikraft.org&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;unikraft.org&#x2F;</a><p>[2] <a href=\"https:&#x2F;&#x2F;github.com&#x2F;nanovms&#x2F;nanos\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;nanovms&#x2F;nanos</a><p>[3] <a href=\"https:&#x2F;&#x2F;github.com&#x2F;solo-io&#x2F;unik&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;solo-io&#x2F;unik&#x2F;</a><p>[4] <a href=\"http:&#x2F;&#x2F;unikernel.org&#x2F;projects&#x2F;\" rel=\"nofollow\">http:&#x2F;&#x2F;unikernel.org&#x2F;projects&#x2F;</a><p>[5] <a href=\"https:&#x2F;&#x2F;github.com&#x2F;solo-io&#x2F;unik&#x2F;issues&#x2F;172\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;solo-io&#x2F;unik&#x2F;issues&#x2F;172</a>", "title": "Ask HN: How are you using unikernels?", "updated_at": "2024-09-20T08:38:18Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "udkl"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["algolia", "production"], "value": "Who's using Clojure in <em>production</em> today and what are you using it for? I'm curious about the state of the ecosystem and its adoption today.\nThere are a lot of old threads (on HN[1] or Quora[2]) that ask this - but none of them seem to reflect latest on who's using Clojure in <em>production</em> in 2017.<p>[1] https://hn.<em>algolia</em>.com/#!/story/forever/0/whos%20using%20clojure<p>[2] https://www.quora.com/Whos-using-Clojure-in-<em>production</em><p>Ask HN post from 2014 : https://news.ycombinator.com/item?id=8549823"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: Who's using Clojure, and to do what?"}}, "_tags": ["story", "author_udkl", "story_14302762", "ask_hn"], "author": "udkl", "children": [14303211, 14303276, 14303278, 14303282, 14303346, 14303396, 14303421, 14303449, 14303558, 14303563, 14303742, 14303787, 14303815, 14303901, 14304278, 14304344, 14304367, 14304377, 14304672, 14304717, 14304781, 14305142, 14305179, 14305470, 14305660, 14305722, 14305840, 14305948, 14306292, 14306420, 14306495, 14306850, 14307644, 14308467, 14309254, 14309642, 14311075, 14313437, 14327091, 14328909, 14331892, 14383911, 14394108], "created_at": "2017-05-09T18:42:02Z", "created_at_i": 1494355322, "num_comments": 49, "objectID": "14302762", "points": 109, "story_id": 14302762, "story_text": "Who&#x27;s using Clojure in production today and what are you using it for? I&#x27;m curious about the state of the ecosystem and its adoption today.\nThere are a lot of old threads (on HN[1] or Quora[2]) that ask this - but none of them seem to reflect latest on who&#x27;s using Clojure in production in 2017.<p>[1] https:&#x2F;&#x2F;hn.algolia.com&#x2F;#!&#x2F;story&#x2F;forever&#x2F;0&#x2F;whos%20using%20clojure<p>[2] https:&#x2F;&#x2F;www.quora.com&#x2F;Whos-using-Clojure-in-production<p>Ask HN post from 2014 : https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=8549823", "title": "Ask HN: Who's using Clojure, and to do what?", "updated_at": "2024-09-20T00:43:30Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "_zfsy"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["algolia", "production"], "value": "Trading cards are awesome, but paying $30 for some cardboard isn\u2019t. I\u2019ve upscaled 60,000 cards from the entire catalog of Yugioh, Magic, Pokemon, &amp; a newer game, <a href=\"https://elestrals.com\" rel=\"nofollow\">https://elestrals.com</a>. I've made it easy to build a decklist, download it, and then print at home. Modern inkjet printers got really good when nobody was looking. While it\u2019s clear they\u2019re not real cards, the upscaling makes them look great for casual play (these are not tournament legal). It\u2019s totally free, give it a try!<p>Supplies: [url-redacted]\nPrinter Settings: [url-redacted]\nInstructions: [url-redacted]<p>Overview: I built [name-redacted] because I had some scripts to do this lying around, and wanted to explore the new Rails 8 magic. Kamal 2 (kamal-deploy.org/) is a game changer, SQLite in <em>production</em> is fine, and the database backed solid family of gems work like a charm.<p>Compute: I am renting a box on <a href=\"https://hetzner.com\" rel=\"nofollow\">https://hetzner.com</a> located in VA for $15/mo. This box has 8 gigs of ram and 2 vCPU's. This is such a deal compared to compute prices on <a href=\"https://render.com\" rel=\"nofollow\">https://render.com</a>.<p>Kamal 2: This thing is amazing. Kamal gives me everything I could want (easy console access, easy shell access, a way to manage secrets, a way to see my logs, and letsencrypt support for DNS), all without a PaaS tax. The best part is the accessories feature: <a href=\"https://kamal-deploy.org/docs/commands/accessory/\" rel=\"nofollow\">https://kamal-deploy.org/docs/commands/accessory/</a>. I am running my main app with two accessories: Meilisearch(<a href=\"https://meilisearch.com\" rel=\"nofollow\">https://meilisearch.com</a>) and OpenObserve (<a href=\"https://openobserve.ai\" rel=\"nofollow\">https://openobserve.ai</a>). Instead of paying <em>Algolia</em> to host search infrastructure and sentry to host monitoring infrastructure, I\u2019m hosting my own OSS without any fanfare.<p>Upscaling: To upscale the trading cards (a mandatory part of this build, scans are never high enough DPI). I am using this (<a href=\"https://replicate.com/nightmareai/real-esrgan\" rel=\"nofollow\">https://replicate.com/nightmareai/real-esrgan</a>) model. For upscaling every card, I've used under a hundred bucks of compute. This model was picked on a whim, but worked well enough that I didn\u2019t compare other models.<p>SQLite: I used SQLite combined with Litestream (litestream.io) for my database. While I considered Postgres, I hesitated due to uncertainties around handling backups on self-hosted infrastructure. This was my first time using SQLite in <em>production</em>, and it was functional but with some minor annoyances. Here\u2019s what I encountered: 1. No Default UUID Primary Key Type I had to set primary keys as strings and assign IDs manually from the application record. It\u2019s an annoying workaround but manageable. 2. No Native Array Columns Because SQLite doesn\u2019t support array columns, I had to use its native JSON column type, which just felt icky. If I were working with something like embeddings, this would be especially annoying, because you couldn\u2019t enforce all the records to have the same number of dimensions. 3. Cryptic Errors At one point, a migration failed silently, leaving a cryptic error in schema.rb. The issue was resolved by rolling back the migration and redoing it, but it was once again, annoying. 4. Litestream Defaults Litestream deletes snapshots after 24 hours by default, which is far too short. When I tried to recover some data, I found it had already been deleted. Adjusting these defaults fixed the problem.<p>Solid Queue/Cache/Cable: The solid family of gems are all backed by the database and were a pleasure to work with. Goal was to prevent needing to reach for redis, so you have one less thing to worry about. You end up with a little more latency, which is a totally reasonable tradeoff.<p>Conclusions: We are moving into a post platform as a service world. Instead of buying a bespoke render.com or heroku, you just buy commodity compute and use Kamal to manage. It's like, pretty much all there, excited to see how this space matures."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Free TCG Proxy Manager for Magic, Yugioh, and Pokemon"}}, "_tags": ["story", "author__zfsy", "story_42635049", "show_hn"], "author": "_zfsy", "children": [42636982, 42636999, 42637222, 42637266, 42637387, 42637630, 42638399, 42638901, 42639495, 42639830, 42655624, 42660872], "created_at": "2025-01-08T15:11:41Z", "created_at_i": 1736349101, "num_comments": 49, "objectID": "42635049", "points": 69, "story_id": 42635049, "story_text": "Trading cards are awesome, but paying $30 for some cardboard isn\u2019t. I\u2019ve upscaled 60,000 cards from the entire catalog of Yugioh, Magic, Pokemon, &amp; a newer game, <a href=\"https:&#x2F;&#x2F;elestrals.com\" rel=\"nofollow\">https:&#x2F;&#x2F;elestrals.com</a>. I&#x27;ve made it easy to build a decklist, download it, and then print at home. Modern inkjet printers got really good when nobody was looking. While it\u2019s clear they\u2019re not real cards, the upscaling makes them look great for casual play (these are not tournament legal). It\u2019s totally free, give it a try!<p>Supplies: [url-redacted]\nPrinter Settings: [url-redacted]\nInstructions: [url-redacted]<p>Overview: I built [name-redacted] because I had some scripts to do this lying around, and wanted to explore the new Rails 8 magic. Kamal 2 (kamal-deploy.org&#x2F;) is a game changer, SQLite in production is fine, and the database backed solid family of gems work like a charm.<p>Compute: I am renting a box on <a href=\"https:&#x2F;&#x2F;hetzner.com\" rel=\"nofollow\">https:&#x2F;&#x2F;hetzner.com</a> located in VA for $15&#x2F;mo. This box has 8 gigs of ram and 2 vCPU&#x27;s. This is such a deal compared to compute prices on <a href=\"https:&#x2F;&#x2F;render.com\" rel=\"nofollow\">https:&#x2F;&#x2F;render.com</a>.<p>Kamal 2: This thing is amazing. Kamal gives me everything I could want (easy console access, easy shell access, a way to manage secrets, a way to see my logs, and letsencrypt support for DNS), all without a PaaS tax. The best part is the accessories feature: <a href=\"https:&#x2F;&#x2F;kamal-deploy.org&#x2F;docs&#x2F;commands&#x2F;accessory&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;kamal-deploy.org&#x2F;docs&#x2F;commands&#x2F;accessory&#x2F;</a>. I am running my main app with two accessories: Meilisearch(<a href=\"https:&#x2F;&#x2F;meilisearch.com\" rel=\"nofollow\">https:&#x2F;&#x2F;meilisearch.com</a>) and OpenObserve (<a href=\"https:&#x2F;&#x2F;openobserve.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;openobserve.ai</a>). Instead of paying Algolia to host search infrastructure and sentry to host monitoring infrastructure, I\u2019m hosting my own OSS without any fanfare.<p>Upscaling: To upscale the trading cards (a mandatory part of this build, scans are never high enough DPI). I am using this (<a href=\"https:&#x2F;&#x2F;replicate.com&#x2F;nightmareai&#x2F;real-esrgan\" rel=\"nofollow\">https:&#x2F;&#x2F;replicate.com&#x2F;nightmareai&#x2F;real-esrgan</a>) model. For upscaling every card, I&#x27;ve used under a hundred bucks of compute. This model was picked on a whim, but worked well enough that I didn\u2019t compare other models.<p>SQLite: I used SQLite combined with Litestream (litestream.io) for my database. While I considered Postgres, I hesitated due to uncertainties around handling backups on self-hosted infrastructure. This was my first time using SQLite in production, and it was functional but with some minor annoyances. Here\u2019s what I encountered: 1. No Default UUID Primary Key Type I had to set primary keys as strings and assign IDs manually from the application record. It\u2019s an annoying workaround but manageable. 2. No Native Array Columns Because SQLite doesn\u2019t support array columns, I had to use its native JSON column type, which just felt icky. If I were working with something like embeddings, this would be especially annoying, because you couldn\u2019t enforce all the records to have the same number of dimensions. 3. Cryptic Errors At one point, a migration failed silently, leaving a cryptic error in schema.rb. The issue was resolved by rolling back the migration and redoing it, but it was once again, annoying. 4. Litestream Defaults Litestream deletes snapshots after 24 hours by default, which is far too short. When I tried to recover some data, I found it had already been deleted. Adjusting these defaults fixed the problem.<p>Solid Queue&#x2F;Cache&#x2F;Cable: The solid family of gems are all backed by the database and were a pleasure to work with. Goal was to prevent needing to reach for redis, so you have one less thing to worry about. You end up with a little more latency, which is a totally reasonable tradeoff.<p>Conclusions: We are moving into a post platform as a service world. Instead of buying a bespoke render.com or heroku, you just buy commodity compute and use Kamal to manage. It&#x27;s like, pretty much all there, excited to see how this space matures.", "title": "Show HN: Free TCG Proxy Manager for Magic, Yugioh, and Pokemon", "updated_at": "2026-02-03T03:11:06Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "h1fra"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["algolia", "production"], "value": "Hey HN, I'm Samuel, founder of Specfy.<p>Very excited to be launching Specfy, an open source platform to improve the way we talk about infrastructure and technology inside our organizations (<a href=\"https://github.com/specfy/specfy\">https://github.com/specfy/specfy</a>).<p>During my time at <em>Algolia</em> --and previous--, I often felt the communication around <em>production</em>, tech choices and infrastructure was messy at best. Trying to understand how various components came together across teams or sifting through documentation scattered everywhere left me thinking there had to be a better way. Almost nobody, from engineering to C-level, could entirely list what was currently in <em>production</em>, how it was built and, sometimes, why it was built. So, I decided to create something to address it.<p>Specfy is what came out of that frustration. It's a platform that ingest all your GitHub repositories and extracts metadata, to create a continuously updated infrastructure graph and tech stack documentation.<p>It's open source: <a href=\"https://github.com/specfy/specfy\">https://github.com/specfy/specfy</a> + <a href=\"https://github.com/specfy/stack-analyser\">https://github.com/specfy/stack-analyser</a><p>You can try it here: <a href=\"https://app.specfy.io/\" rel=\"nofollow noreferrer\">https://app.specfy.io/</a><p>Short demo: <a href=\"https://www.youtube.com/watch?v=0DuMBEB0PLY\">https://www.youtube.com/watch?v=0DuMBEB0PLY</a><p>It\u2019s an open beta and as a solo founder I had to make hard choices regarding what features would land on <em>production</em> right now, but I would love feedback from the Hacker News community. I\u2019m sure this problematic will resonate to some of you.<p>Feel free to reach out to me samuel@specfy.io or contributes to the repositories."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Specfy \u2013 Stack Intelligence Platform"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/specfy/specfy"}}, "_tags": ["story", "author_h1fra", "story_37390318", "show_hn"], "author": "h1fra", "created_at": "2023-09-05T11:30:04Z", "created_at_i": 1693913404, "num_comments": 0, "objectID": "37390318", "points": 24, "story_id": 37390318, "story_text": "Hey HN, I&#x27;m Samuel, founder of Specfy.<p>Very excited to be launching Specfy, an open source platform to improve the way we talk about infrastructure and technology inside our organizations (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;specfy&#x2F;specfy\">https:&#x2F;&#x2F;github.com&#x2F;specfy&#x2F;specfy</a>).<p>During my time at Algolia --and previous--, I often felt the communication around production, tech choices and infrastructure was messy at best. Trying to understand how various components came together across teams or sifting through documentation scattered everywhere left me thinking there had to be a better way. Almost nobody, from engineering to C-level, could entirely list what was currently in production, how it was built and, sometimes, why it was built. So, I decided to create something to address it.<p>Specfy is what came out of that frustration. It&#x27;s a platform that ingest all your GitHub repositories and extracts metadata, to create a continuously updated infrastructure graph and tech stack documentation.<p>It&#x27;s open source: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;specfy&#x2F;specfy\">https:&#x2F;&#x2F;github.com&#x2F;specfy&#x2F;specfy</a> + <a href=\"https:&#x2F;&#x2F;github.com&#x2F;specfy&#x2F;stack-analyser\">https:&#x2F;&#x2F;github.com&#x2F;specfy&#x2F;stack-analyser</a><p>You can try it here: <a href=\"https:&#x2F;&#x2F;app.specfy.io&#x2F;\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;app.specfy.io&#x2F;</a><p>Short demo: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=0DuMBEB0PLY\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=0DuMBEB0PLY</a><p>It\u2019s an open beta and as a solo founder I had to make hard choices regarding what features would land on production right now, but I would love feedback from the Hacker News community. I\u2019m sure this problematic will resonate to some of you.<p>Feel free to reach out to me samuel@specfy.io or contributes to the repositories.", "title": "Show HN: Specfy \u2013 Stack Intelligence Platform", "updated_at": "2024-09-20T15:05:57Z", "url": "https://github.com/specfy/specfy"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "wintonzheng"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["algolia", "production"], "value": "Hello HN. I\u2019m Shu, here with my best friend Suchintan. We\u2019re the creators of Wyvern (<a href=\"https://github.com/Wyvern-AI/wyvern\">https://github.com/Wyvern-AI/wyvern</a>), a real-time machine learning framework to help marketplaces adopt ML earlier in their life.<p>Wyvern is an end-to-end platform to help marketplaces build and scale custom machine learning pipelines, with the goal of enabling data scientists to own the full machine learning stack. It offers a bundle of:\n1. Feature store to store and serve features\n2. Model service to serve ML models \n3. Feature + Model observability platform \n4. Orchestration framework for ML Pipelines<p>While being mindful of the following constraints:\n1. Pipeline evaluation in &lt; 200ms to optimize user experience [1]\n2. Minimizing train / test skew for model training<p>Suchintan built the ML Platform at Faire and Gopuff to improve their Search and Discovery experience. At both places, the platform became an engine that empowered the data team to independently deliver new models to <em>production</em>, generating over $100M of impact.<p>Small marketplaces usually buy solutions like <em>Algolia</em> and AWS Personalize for Search and Discovery. Once a marketplace grows to a certain size (usually &gt;$100M GMV), they hit limitations around how many custom (\u201dlong-tail\u201d) insights they can incorporate into these solutions.<p>Long-tail insights may come in the form of \u201cfeatures\u201d that help move model accuracy, or changes in model objectives that help optimize for underlying business objectives:\n- B2B Marketplaces like Faire are able to segment users based on what they\u2019re selling through on their storefront by asking them to categorize themselves on sign-up, and feed that into machine learning models to cold-start personalization for new users.\n- Margin-sensitive companies like Gopuff are able to build a function to predict the expected revenue of a product being shown to the user, and ordered the results accordingly. This was composed by several ML models coming together trying to predict the probability the user would purchase a product if we showed it to them, and the expected margin of that transaction. Cart-state as a signal is also very helpful when ranking complementary products for users, ie specific types of chips would be favored if you had some coke in your cart, versus sprite<p>We\u2019ve talked to a bunch of other marketplaces and we\u2019ve learned they have their own long-tail insights that may improve the user experience within their own models:\n- Recipe marketplaces like Cookpad may associate each recipe with a flavour profile, and leverage that data to map recipe flavors to predicted user profiles (ie weight Savoury recipes higher for users that enjoy Savoury food)\n- Device reselling marketplaces like Valyuu may use the brand of the users\u2019 device they\u2019re viewing the website on to predict which type of product they were most likely to purchase (iPhone users buying another iPhone)<p>The question we asked ourselves is: How much engineering involvement is actually required here, and how much can we generalize? We built Wyvern to abstract ML engineering work mentioned above away from data scientists. As a result, they can just focus on defining the request/response of the API, the model, the features for the model, the business logic, and finally training the models with the feedback data generated by the ML pipeline.<p>We would love your opinions and hot-takes. Please follow our Quickstart (<a href=\"https://github.com/Wyvern-AI/wyvern#quickstart\">https://github.com/Wyvern-AI/wyvern#quickstart</a>) to give it a try.<p>[1] <a href=\"https://iarapakis.github.io/papers/TOIS17.pdf\" rel=\"nofollow noreferrer\">https://iarapakis.github.io/papers/TOIS17.pdf</a>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Wyvern \u2013 Real-time machine learning platform for marketplaces"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/Wyvern-AI/wyvern"}}, "_tags": ["story", "author_wintonzheng", "story_37501070", "show_hn"], "author": "wintonzheng", "created_at": "2023-09-13T20:06:47Z", "created_at_i": 1694635607, "num_comments": 0, "objectID": "37501070", "points": 15, "story_id": 37501070, "story_text": "Hello HN. I\u2019m Shu, here with my best friend Suchintan. We\u2019re the creators of Wyvern (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;Wyvern-AI&#x2F;wyvern\">https:&#x2F;&#x2F;github.com&#x2F;Wyvern-AI&#x2F;wyvern</a>), a real-time machine learning framework to help marketplaces adopt ML earlier in their life.<p>Wyvern is an end-to-end platform to help marketplaces build and scale custom machine learning pipelines, with the goal of enabling data scientists to own the full machine learning stack. It offers a bundle of:\n1. Feature store to store and serve features\n2. Model service to serve ML models \n3. Feature + Model observability platform \n4. Orchestration framework for ML Pipelines<p>While being mindful of the following constraints:\n1. Pipeline evaluation in &lt; 200ms to optimize user experience [1]\n2. Minimizing train &#x2F; test skew for model training<p>Suchintan built the ML Platform at Faire and Gopuff to improve their Search and Discovery experience. At both places, the platform became an engine that empowered the data team to independently deliver new models to production, generating over $100M of impact.<p>Small marketplaces usually buy solutions like Algolia and AWS Personalize for Search and Discovery. Once a marketplace grows to a certain size (usually &gt;$100M GMV), they hit limitations around how many custom (\u201dlong-tail\u201d) insights they can incorporate into these solutions.<p>Long-tail insights may come in the form of \u201cfeatures\u201d that help move model accuracy, or changes in model objectives that help optimize for underlying business objectives:\n- B2B Marketplaces like Faire are able to segment users based on what they\u2019re selling through on their storefront by asking them to categorize themselves on sign-up, and feed that into machine learning models to cold-start personalization for new users.\n- Margin-sensitive companies like Gopuff are able to build a function to predict the expected revenue of a product being shown to the user, and ordered the results accordingly. This was composed by several ML models coming together trying to predict the probability the user would purchase a product if we showed it to them, and the expected margin of that transaction. Cart-state as a signal is also very helpful when ranking complementary products for users, ie specific types of chips would be favored if you had some coke in your cart, versus sprite<p>We\u2019ve talked to a bunch of other marketplaces and we\u2019ve learned they have their own long-tail insights that may improve the user experience within their own models:\n- Recipe marketplaces like Cookpad may associate each recipe with a flavour profile, and leverage that data to map recipe flavors to predicted user profiles (ie weight Savoury recipes higher for users that enjoy Savoury food)\n- Device reselling marketplaces like Valyuu may use the brand of the users\u2019 device they\u2019re viewing the website on to predict which type of product they were most likely to purchase (iPhone users buying another iPhone)<p>The question we asked ourselves is: How much engineering involvement is actually required here, and how much can we generalize? We built Wyvern to abstract ML engineering work mentioned above away from data scientists. As a result, they can just focus on defining the request&#x2F;response of the API, the model, the features for the model, the business logic, and finally training the models with the feedback data generated by the ML pipeline.<p>We would love your opinions and hot-takes. Please follow our Quickstart (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;Wyvern-AI&#x2F;wyvern#quickstart\">https:&#x2F;&#x2F;github.com&#x2F;Wyvern-AI&#x2F;wyvern#quickstart</a>) to give it a try.<p>[1] <a href=\"https:&#x2F;&#x2F;iarapakis.github.io&#x2F;papers&#x2F;TOIS17.pdf\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;iarapakis.github.io&#x2F;papers&#x2F;TOIS17.pdf</a>", "title": "Show HN: Wyvern \u2013 Real-time machine learning platform for marketplaces", "updated_at": "2024-09-20T15:06:20Z", "url": "https://github.com/Wyvern-AI/wyvern"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "srcreigh"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["algolia", "production"], "value": "Please share tips or experiences related to vitamins/supplements<p>Vitamin A is pretty scarce in many diets, yet a 2010 paper shows that sufficient vitamin A produces 30% increase in ATP <em>production</em>. [0] ATP facilitates energy transfer between cells [5]<p>Lots of sources including wikipedia vitamin A page [6] don't seem to recognize the role of Vitamin A in energy transfer between cells. [2] [4] Wikipedia page for ATP does not mention the link with Vitamin A either. [7]<p>There are reports of Vitamin A supplements producing psychological productivity energy boost akin to caffeine. [1]<p>One cup of boiled carrots is sufficient daily intake of vitamin A. [2] Boiling the carrots increases vitamin A absorption due to breaking down the cellulose in carrots. [2]<p>Other sources include cooked tuna, cooked squash or pumpkin, cooked sweet potato, cooked spinach/kale/collard/chard/bok choy, or beef/fish liver. [3] If you aren't eating a good amount of these foods every day you are likely deficient.<p>VitaminA Vitamin-A (<em>algolia</em> has trouble with &quot;Vitamin A&quot; searches)<p>[0]: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2812036/<p>[1]: https://www.reddit.com/r/Supplements/comments/cxm1pg/vitamin_a_increase_in_energy/<p>[2]: https://www.livestrong.com/article/542992-does-boiling-carrots-destroy-the-nutrients/<p>[3]: https://www.myfooddata.com/articles/food-sources-of-vitamin-A.php<p>[4]: https://www.mayoclinic.org/drugs-supplements-vitamin-a/art-20365945<p>[5]: https://en.wikipedia.org/wiki/Adenosine_triphosphate<p>[6]: https://en.wikipedia.org/wiki/Vitamin_A<p>[7]: https://en.wikipedia.org/wiki/Adenosine_triphosphate"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Tell HN: Vitamin A Linked to Energy Levels"}}, "_tags": ["story", "author_srcreigh", "story_31329054", "ask_hn"], "author": "srcreigh", "children": [31329234, 31329326, 31329505, 31329705, 31332568], "created_at": "2022-05-10T16:31:19Z", "created_at_i": 1652200279, "num_comments": 20, "objectID": "31329054", "points": 12, "story_id": 31329054, "story_text": "Please share tips or experiences related to vitamins&#x2F;supplements<p>Vitamin A is pretty scarce in many diets, yet a 2010 paper shows that sufficient vitamin A produces 30% increase in ATP production. [0] ATP facilitates energy transfer between cells [5]<p>Lots of sources including wikipedia vitamin A page [6] don&#x27;t seem to recognize the role of Vitamin A in energy transfer between cells. [2] [4] Wikipedia page for ATP does not mention the link with Vitamin A either. [7]<p>There are reports of Vitamin A supplements producing psychological productivity energy boost akin to caffeine. [1]<p>One cup of boiled carrots is sufficient daily intake of vitamin A. [2] Boiling the carrots increases vitamin A absorption due to breaking down the cellulose in carrots. [2]<p>Other sources include cooked tuna, cooked squash or pumpkin, cooked sweet potato, cooked spinach&#x2F;kale&#x2F;collard&#x2F;chard&#x2F;bok choy, or beef&#x2F;fish liver. [3] If you aren&#x27;t eating a good amount of these foods every day you are likely deficient.<p>VitaminA Vitamin-A (algolia has trouble with &quot;Vitamin A&quot; searches)<p>[0]: https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC2812036&#x2F;<p>[1]: https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;Supplements&#x2F;comments&#x2F;cxm1pg&#x2F;vitamin_a_increase_in_energy&#x2F;<p>[2]: https:&#x2F;&#x2F;www.livestrong.com&#x2F;article&#x2F;542992-does-boiling-carrots-destroy-the-nutrients&#x2F;<p>[3]: https:&#x2F;&#x2F;www.myfooddata.com&#x2F;articles&#x2F;food-sources-of-vitamin-A.php<p>[4]: https:&#x2F;&#x2F;www.mayoclinic.org&#x2F;drugs-supplements-vitamin-a&#x2F;art-20365945<p>[5]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Adenosine_triphosphate<p>[6]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Vitamin_A<p>[7]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Adenosine_triphosphate", "title": "Tell HN: Vitamin A Linked to Energy Levels", "updated_at": "2024-09-20T11:05:28Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "vinishbhaskar"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["algolia", "production"], "value": "CozyCommerce is a powerful, <em>production</em>-ready Next.js eCommerce boilerplate with a built-in CMS\u2014perfect for developers, indie hackers, and startups who want full control over their store.<p>Built with Next.js 15+, Tailwind CSS, PostgreSQL, and Prisma, it includes over 100 customizable UI components, 20+ ready-to-use pages, a flexible CMS, secure authentication (NextAuth.js), Stripe integration, and AI-powered <em>Algolia</em> search. Everything\u2019s self-hosted with one-click deployment to Vercel, Netlify, or Railway.<p>Whether you\u2019re launching an MVP or a full-scale store, CozyCommerce lets you build fast, scale confidently, and own every part of your stack\u2014no lock-ins, no limitations.<p>Check it out here: https://cozycommerce.dev/"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "CozyCommerce - Next.js eCommerce Boilerplate with CMS"}}, "_tags": ["story", "author_vinishbhaskar", "story_44312997", "ask_hn"], "author": "vinishbhaskar", "children": [44313010], "created_at": "2025-06-18T20:23:24Z", "created_at_i": 1750278204, "num_comments": 0, "objectID": "44312997", "points": 1, "story_id": 44312997, "story_text": "CozyCommerce is a powerful, production-ready Next.js eCommerce boilerplate with a built-in CMS\u2014perfect for developers, indie hackers, and startups who want full control over their store.<p>Built with Next.js 15+, Tailwind CSS, PostgreSQL, and Prisma, it includes over 100 customizable UI components, 20+ ready-to-use pages, a flexible CMS, secure authentication (NextAuth.js), Stripe integration, and AI-powered Algolia search. Everything\u2019s self-hosted with one-click deployment to Vercel, Netlify, or Railway.<p>Whether you\u2019re launching an MVP or a full-scale store, CozyCommerce lets you build fast, scale confidently, and own every part of your stack\u2014no lock-ins, no limitations.<p>Check it out here: https:&#x2F;&#x2F;cozycommerce.dev&#x2F;", "title": "CozyCommerce - Next.js eCommerce Boilerplate with CMS", "updated_at": "2025-06-18T21:06:58Z"}], "hitsPerPage": 15, "nbHits": 11, "nbPages": 1, "page": 0, "params": "query=algolia+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 12, "processingTimingsMS": {"_request": {"roundTrip": 22}, "afterFetch": {"format": {"highlighting": 1, "total": 1}}, "fetch": {"query": 9, "scanning": 2, "total": 12}, "total": 12}, "query": "algolia production", "serverTimeMS": 14}}