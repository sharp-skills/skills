{"d": "<h1 align=\"center\">\n    <span>Open-Assistant</span>\n  <img width=\"auto\" height=\"50px\" src=\"https://github.com/LAION-AI/Open-Assistant/blob/main/assets/logo_crop.png\"/>\n</h1>\n\n<blockquote>\n<p>:memo: <strong>NOTE</strong>: OpenAssistant is completed, and the project is now finished. Thank you to everyone who contributed! Check out our <a href=\"https://projects.laion.ai/Open-Assistant/blog/2023/10/25/open-assistant-is-completed\">blog post</a> for more information. The final published oasst2 dataset can be found on HuggingFace at <a href=\"https://huggingface.co/datasets/OpenAssistant/oasst2\">OpenAssistant/oasst2</a></p>\n</blockquote>\n\n<div align=\"center\">\n\n<a href=\"https://github.com/LAION-AI/Open-Assistant/stargazers\">![GitHub Repo stars](https://img.shields.io/github/stars/LAION-AI/Open-Assistant?style=social)</a>\n<a href=\"https://laion-ai.github.io/Open-Assistant/\">![Docs](https://img.shields.io/badge/docs-laion--ai.github.io%2FOpen--Assistant%2F-green)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/actions/workflows/build-frontend.yaml\">![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/LAION-AI/Open-Assistant/build-frontend.yaml?label=build-frontend)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/actions/workflows/build-postgres.yaml\">![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/LAION-AI/Open-Assistant/build-postgres.yaml?label=build-postgres)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/actions/workflows/pre-commit.yaml\">![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/LAION-AI/Open-Assistant/pre-commit.yaml?label=pre-commit)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/actions/workflows/test-api-contract.yaml\">![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/LAION-AI/Open-Assistant/test-api-contract.yaml?label=tests-api)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/actions/workflows/test-e2e.yaml\">![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/LAION-AI/Open-Assistant/test-e2e.yaml?label=tests-web)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/actions/workflows/deploy-docs-site.yaml\">![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/LAION-AI/Open-Assistant/deploy-docs-site.yaml?label=deploy-docs)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/actions/workflows/production-deploy.yaml\">![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/LAION-AI/Open-Assistant/production-deploy.yaml?label=deploy-production)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/actions/workflows/release.yaml\">![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/LAION-AI/Open-Assistant/release.yaml?label=deploy-release)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/releases\">![GitHub release (latest by date)](https://img.shields.io/github/v/release/LAION-AI/Open-Assistant)</a>\n<a href=\"https://github-com.translate.goog/LAION-AI/Open-Assistant/blob/main/README.md?_x_tr_sl=auto&_x_tr_tl=en&_x_tr_hl=en&_x_tr_pto=wapp\">![Translate](https://img.shields.io/badge/Translate-blue)</a>\n\n</div>\n\n# Table of Contents\n\n- [What is Open Assistant?](#what-is-open-assistant)\n- [Useful Links](#useful-links)\n- [How To Try It Out](#how-to-try-it-out)\n- [The Vision](#the-vision)\n- [The Plan](#the-plan)\n- [How You Can Help](#how-you-can-help)\n\n---\n\n## What is Open Assistant?\n\n<p align=\"center\">\nOpen Assistant is a project meant to give everyone access to a great chat based\nlarge language model.\n</p>\n\nWe believe that by doing this we will create a revolution in innovation in\nlanguage. In the same way that stable-diffusion helped the world make art and\nimages in new ways we hope Open Assistant can help improve the world by\nimproving language itself.\n\n# Useful Links\n\n- [Data Collection](https://open-assistant.io)\n\n- [Chat](https://open-assistant.io/chat)\n\n- [Project Documentation](https://projects.laion.ai/Open-Assistant/)\n\n## How To Try It Out\n\n### Chatting with the AI\n\nThe chat frontend is now live [here](https://open-assistant.io/chat). Log in and\nstart chatting! Please try to react with a thumbs up or down for the assistant's\nresponses when chatting.\n\n### Contributing to Data Collection\n\nThe data collection frontend is now live [here](https://open-assistant.io/). Log\nin and start taking on tasks! We want to collect a high volume of quality data.\nBy submitting, ranking, and labelling model prompts and responses you will be\ndirectly helping to improve the capabilities of Open Assistant.\n\n### Running the Development Setup Locally (without chat)\n\n**You do not need to run the project locally unless you are contributing to the\ndevelopment process. The website link above will take you to the public website\nwhere you can use the data collection app and the chat.**\n\nIf you would like to run the data collection app locally for development, you\ncan set up an entire stack needed to run **Open-Assistant**, including the\nwebsite, backend, and associated dependent services, with Docker.\n\nTo start the demo, run this in the root directory of the repository (check\n[this FAQ](https://projects.laion.ai/Open-Assistant/docs/faq#docker-compose-instead-of-docker-compose)\nif you have problems):\n\n```sh\ndocker compose --profile ci up --build --attach-dependencies\n```\n\n> **Note:** when running on MacOS with an M1 chip you have to use:\n> `DB_PLATFORM=linux/x86_64 docker compose ...`\n\nThen, navigate to `http://localhost:3000` (It may take some time to boot up) and\ninteract with the website.\n\n> **Note:** If an issue occurs with the build, please head to the\n> [FAQ](https://projects.laion.ai/Open-Assistant/docs/faq) and check out the\n> entries about Docker.\n\n> **Note:** When logging in via email, navigate to `http://localhost:1080` to\n> get the magic email login link.\n\n> **Note:** If you would like to run this in a standardized development\n> environment (a\n> [\"devcontainer\"](https://code.visualstudio.com/docs/devcontainers/containers))\n> using\n> [vscode locally](https://code.visualstudio.com/docs/devcontainers/create-dev-container#_create-a-devcontainerjson-file)\n> or in a web browser using\n> [GitHub Codespaces](https://github.com/features/codespaces), you can use the\n> provided [`.devcontainer`](.devcontainer/) folder.\n\n### Running the Development Setup Locally for Chat\n\n**You do not need to run the project locally unless you are contributing to the\ndevelopment process. The website link above will take you to the public website\nwhere you can use the data collection app and the chat.**\n\n**Also note that the local setup is only for development and is not meant to be\nused as a local chatbot, unless you know what you are doing.**\n\nIf you _do_ know what you are doing, then see the `inference` folder for getting\nthe inference system up and running, or have a look at `--profile inference` in\naddition to `--profile ci` in the above command.\n\n## The Vision\n\nWe are not going to stop at replicating ChatGPT. We want to build the assistant\nof the future, able to not only write email and cover letters, but do meaningful\nwork, use APIs, dynamically research information, and much more, with the\nability to be personalized and extended by anyone. And we want to do this in a\nway that is open and accessible, which means we must not only build a great\nassistant, but also make it small and efficient enough to run on consumer\nhardware.\n\n## The Plan\n\n##### We want to get to an initial MVP as fast as possible, by following the 3-steps outlined in the [InstructGPT paper](https://arxiv.org/abs/2203.02155)\n\n1. Collect high-quality human generated Instruction-Fulfillment samples\n   (prompt + response), goal >50k. We design a crowdsourced process to collect\n   and reviewed prompts. We do not want to train on\n   flooding/toxic/spam/junk/personal information data. We will have a\n   leaderboard to motivate the community that shows progress and the most active\n   users. Swag will be given to the top-contributors.\n2. For each of the collected prompts we will sample multiple completions.\n   Completions of one prompt will then be shown randomly to users to rank them\n   from best to worst. Again this should happen crowd-sourced, e.g. we need to\n   deal with unreliable potentially malicious users. At least multiple votes by\n   independent users have to be collected to measure the overall agreement. The\n   gathered ranking-data will be used to train a reward model.\n3. Now follows the RLHF training phase based on the prompts and the reward\n   model.\n\nWe can then take the resulting model and continue with completion sampling step\n2 for a next iteration.\n\n### Slide Decks\n\n[Vision & Roadmap](https://docs.google.com/presentation/d/1n7IrAOVOqwdYgiYrXc8Sj0He8krn5MVZO_iLkCjTtu0/edit?usp=sharing)\n\n[Important Data Structures](https://docs.google.com/presentation/d/1iaX_nxasVWlvPiSNs0cllR9L_1neZq0RJxd6MFEalUY/edit?usp=sharing)\n\n## How You Can Help\n\nAll open source projects begin with people like you. Open source is the belief\nthat if we collaborate we can together gift our knowledge and technology to the\nworld for the benefit of humanity.\n\nCheck out our [contributing guide](CONTRIBUTING.md) to get started.\n"}