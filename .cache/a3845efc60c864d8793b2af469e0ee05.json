{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "presiozo"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["terraform", "production"], "value": "Scaffold a <em>production</em>-ready <em>Terraform</em> project on Azure"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["terraform", "production"], "value": "https://medium.com/@nicomeisenzahl/scaffold-a-<em>production</em>-ready-<em>terraform</em>-project-on-azure-3064cf5d3744"}}, "_tags": ["story", "author_presiozo", "story_22767413"], "author": "presiozo", "created_at": "2020-04-03T08:59:13Z", "created_at_i": 1585904353, "num_comments": 0, "objectID": "22767413", "points": 2, "story_id": 22767413, "title": "Scaffold a production-ready Terraform project on Azure", "updated_at": "2024-09-20T05:55:31Z", "url": "https://medium.com/@nicomeisenzahl/scaffold-a-production-ready-terraform-project-on-azure-3064cf5d3744"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "fatihkocnet"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["terraform", "production"], "value": "<em>Production</em> Ready <em>Terraform</em> with Testing, Validation and CI/CD"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["terraform", "production"], "value": "https://fatihkoc.net/posts/<em>production</em>-ready-<em>terraform</em>/"}}, "_tags": ["story", "author_fatihkocnet", "story_46146061"], "author": "fatihkocnet", "created_at": "2025-12-04T10:41:40Z", "created_at_i": 1764844900, "num_comments": 0, "objectID": "46146061", "points": 1, "story_id": 46146061, "title": "Production Ready Terraform with Testing, Validation and CI/CD", "updated_at": "2025-12-04T10:46:34Z", "url": "https://fatihkoc.net/posts/production-ready-terraform/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "tchiotludo"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["terraform", "production"], "value": "Hey HN, I'm really proud to share with you my new open source project: Kestra <a href=\"https://github.com/kestra-io/kestra\" rel=\"nofollow\">https://github.com/kestra-io/kestra</a><p>I created a few years ago a successful open source AKHQ project: <a href=\"https://github.com/tchiotludo/akhq\" rel=\"nofollow\">https://github.com/tchiotludo/akhq</a> (renamed from KafkaHQ) which has been adopted by big companies like Best Buy, Pipedrive, BMW, Decathlon and many more. 2300 stars, 120 contributors, 10M docker downloads, much more than I expected.<p>Now let's talk about Kestra, an infinitely scalable orchestration and scheduling platform for creating, running, scheduling and monitoring millions of complex pipelines.<p>I started the project 30 months ago and I'm even more proud of this project that required a lot of investment and time to build the future of data pipelines (I hope). The result is now ready to be presented and I hope to get some feedback from you, HN community.<p>To have a fully scalable solution, we choose Kafka as our database (of course, I love Kafka if you didn't know) as well as ElasticSearch, Micronaut, ... and can be deployed on Kubernetes, VM or on premise.<p>You may think there are many alternatives in this area, but we decided to take a different road by using a descriptive approach (low code) to build your pipelines allowing to edit directly from the web interface and deploy to <em>production</em> with <em>terraform</em> directly. We paid a lot of attention to the scalability and performance part which allows us to have already a big <em>production</em> at a big French retailer: Leroy Merlin<p>Since Kestra core is plugin based, many are available from the core team, but you can create one easily.<p>More information: \n- on the official website: <a href=\"https://kestra.io/\" rel=\"nofollow\">https://kestra.io/</a>\n- on the medium post: <a href=\"https://medium.com/@kestra-io/introducing-kestra-infinitely-scalable-open-source-orchestration-and-scheduling-platform-8e4d47193616\" rel=\"nofollow\">https://medium.com/@kestra-io/introducing-kestra-infinitely-...</a>\n- check out the project: <a href=\"https://github.com/kestra-io/kestra\" rel=\"nofollow\">https://github.com/kestra-io/kestra</a><p>Your comments are more than welcome, thank you!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Kestra - Open-Source Airflow Alternative"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/kestra-io/kestra"}}, "_tags": ["story", "author_tchiotludo", "story_30790047", "show_hn"], "author": "tchiotludo", "children": [30790057, 30790108, 30790563, 30790736, 30790875, 30791202, 30791271, 30791304, 30792331, 30792681, 30792878, 30794631, 30795935, 30812241], "created_at": "2022-03-24T14:14:33Z", "created_at_i": 1648131273, "num_comments": 69, "objectID": "30790047", "points": 142, "story_id": 30790047, "story_text": "Hey HN, I&#x27;m really proud to share with you my new open source project: Kestra <a href=\"https:&#x2F;&#x2F;github.com&#x2F;kestra-io&#x2F;kestra\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;kestra-io&#x2F;kestra</a><p>I created a few years ago a successful open source AKHQ project: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;tchiotludo&#x2F;akhq\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;tchiotludo&#x2F;akhq</a> (renamed from KafkaHQ) which has been adopted by big companies like Best Buy, Pipedrive, BMW, Decathlon and many more. 2300 stars, 120 contributors, 10M docker downloads, much more than I expected.<p>Now let&#x27;s talk about Kestra, an infinitely scalable orchestration and scheduling platform for creating, running, scheduling and monitoring millions of complex pipelines.<p>I started the project 30 months ago and I&#x27;m even more proud of this project that required a lot of investment and time to build the future of data pipelines (I hope). The result is now ready to be presented and I hope to get some feedback from you, HN community.<p>To have a fully scalable solution, we choose Kafka as our database (of course, I love Kafka if you didn&#x27;t know) as well as ElasticSearch, Micronaut, ... and can be deployed on Kubernetes, VM or on premise.<p>You may think there are many alternatives in this area, but we decided to take a different road by using a descriptive approach (low code) to build your pipelines allowing to edit directly from the web interface and deploy to production with terraform directly. We paid a lot of attention to the scalability and performance part which allows us to have already a big production at a big French retailer: Leroy Merlin<p>Since Kestra core is plugin based, many are available from the core team, but you can create one easily.<p>More information: \n- on the official website: <a href=\"https:&#x2F;&#x2F;kestra.io&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;kestra.io&#x2F;</a>\n- on the medium post: <a href=\"https:&#x2F;&#x2F;medium.com&#x2F;@kestra-io&#x2F;introducing-kestra-infinitely-scalable-open-source-orchestration-and-scheduling-platform-8e4d47193616\" rel=\"nofollow\">https:&#x2F;&#x2F;medium.com&#x2F;@kestra-io&#x2F;introducing-kestra-infinitely-...</a>\n- check out the project: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;kestra-io&#x2F;kestra\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;kestra-io&#x2F;kestra</a><p>Your comments are more than welcome, thank you!", "title": "Show HN: Kestra - Open-Source Airflow Alternative", "updated_at": "2025-11-15T04:33:37Z", "url": "https://github.com/kestra-io/kestra"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "fabioluciano"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["terraform", "production"], "value": "PowerKit is an open-source, modular status bar framework for tmux. It provides 32+ built-in plugins for displaying system information, development context, security status, and media information\u2014all with intelligent caching and a semantic color system.<p>WHY I BUILT THIS<p>I was frustrated with the fragmented tmux status bar ecosystem. Most solutions required cobbling together multiple plugins, each with different configuration styles, no caching, and inconsistent theming. I wanted:<p>1. One framework with consistent configuration across all plugins\n2. Smart caching to avoid hammering system calls every status refresh\n3. Semantic colors that work across different themes\n4. Conditional display - plugins that hide when not relevant (e.g., VPN only shows when connected)<p>TECHNICAL HIGHLIGHTS<p>Intelligent Caching: Every plugin has configurable TTL caching. Results are stored in ~/.cache/tmux-powerkit/ with timestamps. Default TTLs are tuned per-plugin based on data volatility\u2014camera/microphone checks every 1s for privacy, while package updates cache for 1 hour.<p>Semantic Colors: Instead of hardcoding hex values, plugins use semantic names like 'warning' and 'error'. The active theme resolves these at runtime. Switch themes without reconfiguring plugins.<p>Threshold-Based Colors: Many plugins support multi-tier thresholds. CPU can turn yellow at 70%, red at 90%.<p>Conditional Display: Plugins intelligently hide when not relevant:\n- git: only shows in git repositories\n- vpn: only shows when connected  \n- network: only shows above configurable traffic threshold\n- camera: only shows when camera is active\n- kubernetes: can show only when cluster is reachable<p>PLUGINS (32+)<p>System Monitoring: cpu, gpu (NVIDIA/AMD/Intel), memory, disk, loadavg, temperature, fan, uptime, brightness<p>Network: network (bandwidth), wifi (with signal strength), vpn (WireGuard, OpenVPN, Tailscale, etc.), external_ip, ping, ssh, bluetooth, weather<p>Development Tools:\n- git: branch with modified repo detection\n- kubernetes: context/namespace with interactive fzf selectors\n- cloud: AWS/GCP/Azure context with <em>production</em> warnings\n- <em>terraform</em>: workspace with <em>production</em> highlighting, OpenTofu support<p>Security: smartkey - hardware security key detection (YubiKey, SoloKeys, Nitrokey) with &quot;waiting for touch&quot; indicator<p>Media &amp; Audio: audiodevices (with device switching popup), microphone (with mute toggle), nowplaying (Spotify, Apple Music, MPRIS), volume, camera (privacy indicator)<p>Package Managers: packages - unified updates for brew, yay, apt, dnf, pacman<p>Time: datetime, timezones (multiple zones with aliases like nyc, tokyo, london)<p>INTERACTIVE KEYBINDINGS<p>prefix + ? : Browse all PowerKit options\nprefix + K : Kubernetes context selector\nprefix + N : Kubernetes namespace selector  \nprefix + W : <em>Terraform</em> workspace selector\nprefix + J/O : Audio input/output device selector\nprefix + m : Microphone mute toggle\nprefix + Q : Clear all caches<p>EXTERNAL PLUGIN INTEGRATION<p>Wrap any external tmux plugin with PowerKit's styling using the external() function. Supports custom icons, colors, and cache TTL.<p>INSTALLATION<p><pre><code>  set -g @plugin 'fabioluciano/tmux-powerkit'\n  set -g @powerkit_theme 'tokyo-night'\n  set -g @powerkit_plugins 'datetime,cpu,memory,git,battery'\n</code></pre>\nPLATFORM SUPPORT<p>Linux: Full support\nmacOS: Full support (some plugins use different backends)\nBSD: Partial support\nWSL: Works with Linux-compatible plugins<p>STACK<p>Pure shell (bash/zsh compatible). No compiled dependencies. Uses standard Unix tools (df, ps, /proc/*, etc.) with fallbacks per platform.<p>Themes included: Tokyo Night, Kiribyte. More welcome via PR.<p>Feedback and contributions welcome. What plugins would be useful for your workflow?"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: PowerKit for Tmux \u2013 32 Plugins"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/fabioluciano/tmux-powerkit"}}, "_tags": ["story", "author_fabioluciano", "story_46240824", "show_hn"], "author": "fabioluciano", "created_at": "2025-12-12T04:18:18Z", "created_at_i": 1765513098, "num_comments": 0, "objectID": "46240824", "points": 3, "story_id": 46240824, "story_text": "PowerKit is an open-source, modular status bar framework for tmux. It provides 32+ built-in plugins for displaying system information, development context, security status, and media information\u2014all with intelligent caching and a semantic color system.<p>WHY I BUILT THIS<p>I was frustrated with the fragmented tmux status bar ecosystem. Most solutions required cobbling together multiple plugins, each with different configuration styles, no caching, and inconsistent theming. I wanted:<p>1. One framework with consistent configuration across all plugins\n2. Smart caching to avoid hammering system calls every status refresh\n3. Semantic colors that work across different themes\n4. Conditional display - plugins that hide when not relevant (e.g., VPN only shows when connected)<p>TECHNICAL HIGHLIGHTS<p>Intelligent Caching: Every plugin has configurable TTL caching. Results are stored in ~&#x2F;.cache&#x2F;tmux-powerkit&#x2F; with timestamps. Default TTLs are tuned per-plugin based on data volatility\u2014camera&#x2F;microphone checks every 1s for privacy, while package updates cache for 1 hour.<p>Semantic Colors: Instead of hardcoding hex values, plugins use semantic names like &#x27;warning&#x27; and &#x27;error&#x27;. The active theme resolves these at runtime. Switch themes without reconfiguring plugins.<p>Threshold-Based Colors: Many plugins support multi-tier thresholds. CPU can turn yellow at 70%, red at 90%.<p>Conditional Display: Plugins intelligently hide when not relevant:\n- git: only shows in git repositories\n- vpn: only shows when connected  \n- network: only shows above configurable traffic threshold\n- camera: only shows when camera is active\n- kubernetes: can show only when cluster is reachable<p>PLUGINS (32+)<p>System Monitoring: cpu, gpu (NVIDIA&#x2F;AMD&#x2F;Intel), memory, disk, loadavg, temperature, fan, uptime, brightness<p>Network: network (bandwidth), wifi (with signal strength), vpn (WireGuard, OpenVPN, Tailscale, etc.), external_ip, ping, ssh, bluetooth, weather<p>Development Tools:\n- git: branch with modified repo detection\n- kubernetes: context&#x2F;namespace with interactive fzf selectors\n- cloud: AWS&#x2F;GCP&#x2F;Azure context with production warnings\n- terraform: workspace with production highlighting, OpenTofu support<p>Security: smartkey - hardware security key detection (YubiKey, SoloKeys, Nitrokey) with &quot;waiting for touch&quot; indicator<p>Media &amp; Audio: audiodevices (with device switching popup), microphone (with mute toggle), nowplaying (Spotify, Apple Music, MPRIS), volume, camera (privacy indicator)<p>Package Managers: packages - unified updates for brew, yay, apt, dnf, pacman<p>Time: datetime, timezones (multiple zones with aliases like nyc, tokyo, london)<p>INTERACTIVE KEYBINDINGS<p>prefix + ? : Browse all PowerKit options\nprefix + K : Kubernetes context selector\nprefix + N : Kubernetes namespace selector  \nprefix + W : Terraform workspace selector\nprefix + J&#x2F;O : Audio input&#x2F;output device selector\nprefix + m : Microphone mute toggle\nprefix + Q : Clear all caches<p>EXTERNAL PLUGIN INTEGRATION<p>Wrap any external tmux plugin with PowerKit&#x27;s styling using the external() function. Supports custom icons, colors, and cache TTL.<p>INSTALLATION<p><pre><code>  set -g @plugin &#x27;fabioluciano&#x2F;tmux-powerkit&#x27;\n  set -g @powerkit_theme &#x27;tokyo-night&#x27;\n  set -g @powerkit_plugins &#x27;datetime,cpu,memory,git,battery&#x27;\n</code></pre>\nPLATFORM SUPPORT<p>Linux: Full support\nmacOS: Full support (some plugins use different backends)\nBSD: Partial support\nWSL: Works with Linux-compatible plugins<p>STACK<p>Pure shell (bash&#x2F;zsh compatible). No compiled dependencies. Uses standard Unix tools (df, ps, &#x2F;proc&#x2F;*, etc.) with fallbacks per platform.<p>Themes included: Tokyo Night, Kiribyte. More welcome via PR.<p>Feedback and contributions welcome. What plugins would be useful for your workflow?", "title": "Show HN: PowerKit for Tmux \u2013 32 Plugins", "updated_at": "2025-12-24T21:04:11Z", "url": "https://github.com/fabioluciano/tmux-powerkit"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "meadhikari"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["terraform", "production"], "value": "Hi all,<p>First a little background about me, I am a software engineer by education and currently am leading a team of 20 passionate engineers mainly focused on cloud consulting in AWS.<p>Blockchain has always been a fascinating subject for me and I believe it will be just as impactful this decade as the internet was in the last.<p>To get in-depth knowledge of blockchain, I explored Hyperledger Fabric and got to the point where I can create a supply chain hello world application of my own.<p>My question is how can I capitalize on knowing the fact that blockchain is going to be huge? I have the technical resource arsenal, that too from a third world country which can create almost anything at really low cost. What sort of development should a team like me be focused on? One of my friends suggested developing <em>terraform</em> scripts to automate <em>production</em> level hyperledger fabric. What could other things me? Maybe interactive tutorials? What do you guys think?"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: How to capitalize on the fact that blockchain is going to be big?"}}, "_tags": ["story", "author_meadhikari", "story_21954849", "ask_hn"], "author": "meadhikari", "children": [21956078, 21956403, 21963588], "created_at": "2020-01-04T13:45:25Z", "created_at_i": 1578145525, "num_comments": 3, "objectID": "21954849", "points": 1, "story_id": 21954849, "story_text": "Hi all,<p>First a little background about me, I am a software engineer by education and currently am leading a team of 20 passionate engineers mainly focused on cloud consulting in AWS.<p>Blockchain has always been a fascinating subject for me and I believe it will be just as impactful this decade as the internet was in the last.<p>To get in-depth knowledge of blockchain, I explored Hyperledger Fabric and got to the point where I can create a supply chain hello world application of my own.<p>My question is how can I capitalize on knowing the fact that blockchain is going to be huge? I have the technical resource arsenal, that too from a third world country which can create almost anything at really low cost. What sort of development should a team like me be focused on? One of my friends suggested developing terraform scripts to automate production level hyperledger fabric. What could other things me? Maybe interactive tutorials? What do you guys think?", "title": "Ask HN: How to capitalize on the fact that blockchain is going to be big?", "updated_at": "2024-09-20T05:31:48Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "mochtar"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["terraform", "production"], "value": "<em>Production</em> ready AWS ECS with <em>terraform</em>"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["terraform"], "value": "https://github.com/arminc/<em>terraform</em>-ecs"}}, "_tags": ["story", "author_mochtar", "story_14412473"], "author": "mochtar", "children": [14415127], "created_at": "2017-05-24T18:53:18Z", "created_at_i": 1495651998, "num_comments": 1, "objectID": "14412473", "points": 3, "story_id": 14412473, "title": "Production ready AWS ECS with terraform", "updated_at": "2024-09-20T00:49:10Z", "url": "https://github.com/arminc/terraform-ecs"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "fasten"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["terraform", "production"], "value": "Hello Hacker News! We're Roxane, Julien, Pierre, Mawen and Stephane from Anyshift.io. We are building a GitHub app (and platform) that detects <em>Terraform</em> complex dependencies (hardcoded values, intricated-modules, shadow IT\u2026), flags potential breakages, and provides a <em>Terraform</em> \u2018Superplan\u2019 for your changes. \nTo do that we create and maintain a digital twin of your infrastructure using Neo4j.<p>- 2 min demo : <a href=\"https://app.guideflow.com/player/dkd2en3t9r\" rel=\"nofollow\">https://app.guideflow.com/player/dkd2en3t9r</a>\n- try it now: <a href=\"https://app.anyshift.io/\" rel=\"nofollow\">https://app.anyshift.io/</a> (5min setup).<p>We experienced how dealing with IaC/<em>Terraform</em> is complex and opaque. <em>Terraform</em> \u2018plans\u2019 are hard to navigate and intertwined dependencies are error prone: one simple change in a security group, firewall rules, subnet CIDR range... can lead to a cascading effect of breaking changes.<p>I\u2019ve dealt in <em>production</em> with those issues since <em>Terraform</em>\u2019s early days. In 2016, I wrote a book about Infrastructure-as-code and created driftctl based on those experiences (open source tool to manage drifts which was acquired by Snyk).<p>Our team is building Anyshift because we believe this problem of complex dependencies is unresolved and is going to explode with AI-generated code (more legacy, weaker sense of ownership). Unlike existing tools (<em>Terraform</em> Cloud/Stacks, Terragrunt, etc...), Anyshift uses a graph-based approach that references the real environment to uncover hidden, interlinked changes.<p>For instance, changing a subnet can force an ENI to switch IP addresses, triggering an EC2 reconfiguration and breaking DNS referenced records. Our GitHub app identifies these hidden issues, while our platform uncovers unmanaged \u201cshadow IT\u201d and lets you search any cloud resource to find exactly where it\u2019s defined in your <em>Terraform</em> code.<p>To do so, one of our key challenges was to achieve a frictionless setup, so we created an event-driven reconciliation system that unifies AWS resources, <em>Terraform</em> states, and code in a Neo4j graph database. This \u201ctime machine\u201d of your infra updates automatically, and for each PR, we query it (via Cypher) to see what might break.<p>Thanks to that, the onboarding is super fast (5 min): \n1. Install the Github app\n2. Grant AWS read only access to the app<p>The choice of a graph database was a way for us to avoid scale limitations compared to relational databases. We already have a handful of enterprise customers running it in prod and can query hundreds of thousands of relationships with linear search times. We'd love you to try our free plan to see it in action<p>We're excited to share this with you, thanks for reading! Let us know your thoughts or questions here or in our future Slack discussions.\nRoxane, Julien, Pierre, Mawen and Stephane!"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["terraform"], "value": "Show HN: Anyshift.io \u2013 <em>Terraform</em> \"Superplan\""}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://app.anyshift.io/"}}, "_tags": ["story", "author_fasten", "story_42712522", "show_hn"], "author": "fasten", "children": [42712697, 42712773, 42712821, 42712848, 42712970, 42712971, 42713038, 42713039, 42713050, 42713210, 42713229, 42713378, 42713563, 42713565, 42713954, 42714247, 42714419, 42714541, 42714544, 42715961, 42716703, 42722834, 42723019, 42726549, 42738587, 42797865], "created_at": "2025-01-15T16:00:49Z", "created_at_i": 1736956849, "num_comments": 42, "objectID": "42712522", "points": 35, "story_id": 42712522, "story_text": "Hello Hacker News! We&#x27;re Roxane, Julien, Pierre, Mawen and Stephane from Anyshift.io. We are building a GitHub app (and platform) that detects Terraform complex dependencies (hardcoded values, intricated-modules, shadow IT\u2026), flags potential breakages, and provides a Terraform \u2018Superplan\u2019 for your changes. \nTo do that we create and maintain a digital twin of your infrastructure using Neo4j.<p>- 2 min demo : <a href=\"https:&#x2F;&#x2F;app.guideflow.com&#x2F;player&#x2F;dkd2en3t9r\" rel=\"nofollow\">https:&#x2F;&#x2F;app.guideflow.com&#x2F;player&#x2F;dkd2en3t9r</a>\n- try it now: <a href=\"https:&#x2F;&#x2F;app.anyshift.io&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;app.anyshift.io&#x2F;</a> (5min setup).<p>We experienced how dealing with IaC&#x2F;Terraform is complex and opaque. Terraform \u2018plans\u2019 are hard to navigate and intertwined dependencies are error prone: one simple change in a security group, firewall rules, subnet CIDR range... can lead to a cascading effect of breaking changes.<p>I\u2019ve dealt in production with those issues since Terraform\u2019s early days. In 2016, I wrote a book about Infrastructure-as-code and created driftctl based on those experiences (open source tool to manage drifts which was acquired by Snyk).<p>Our team is building Anyshift because we believe this problem of complex dependencies is unresolved and is going to explode with AI-generated code (more legacy, weaker sense of ownership). Unlike existing tools (Terraform Cloud&#x2F;Stacks, Terragrunt, etc...), Anyshift uses a graph-based approach that references the real environment to uncover hidden, interlinked changes.<p>For instance, changing a subnet can force an ENI to switch IP addresses, triggering an EC2 reconfiguration and breaking DNS referenced records. Our GitHub app identifies these hidden issues, while our platform uncovers unmanaged \u201cshadow IT\u201d and lets you search any cloud resource to find exactly where it\u2019s defined in your Terraform code.<p>To do so, one of our key challenges was to achieve a frictionless setup, so we created an event-driven reconciliation system that unifies AWS resources, Terraform states, and code in a Neo4j graph database. This \u201ctime machine\u201d of your infra updates automatically, and for each PR, we query it (via Cypher) to see what might break.<p>Thanks to that, the onboarding is super fast (5 min): \n1. Install the Github app\n2. Grant AWS read only access to the app<p>The choice of a graph database was a way for us to avoid scale limitations compared to relational databases. We already have a handful of enterprise customers running it in prod and can query hundreds of thousands of relationships with linear search times. We&#x27;d love you to try our free plan to see it in action<p>We&#x27;re excited to share this with you, thanks for reading! Let us know your thoughts or questions here or in our future Slack discussions.\nRoxane, Julien, Pierre, Mawen and Stephane!", "title": "Show HN: Anyshift.io \u2013 Terraform \"Superplan\"", "updated_at": "2025-02-14T07:45:15Z", "url": "https://app.anyshift.io/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "bleonard"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["terraform", "production"], "value": "Hi HN friends!<p>We can hardly believe it\u2019s been almost four years since our original HN launch (<a href=\"https://news.ycombinator.com/item?id=25917403\">https://news.ycombinator.com/item?id=25917403</a>). What started as a small project has grown way beyond what we imagined, with over 170,000 deployments and 7,000 companies using Airbyte daily.<p>When we started Airbyte, our mission was simple (though not easy): to solve data movement once and for all. Today feels like a big step toward that goal with the release of Airbyte 1.0 (<a href=\"https://airbyte.com/v1\">https://airbyte.com/v1</a>). Reaching this milestone wasn\u2019t a solo effort. It\u2019s taken an incredible amount of work from the whole community and the feedback we\u2019ve received from many of you along the way. We had three goals to reach 1.0:\n- Broad deployments to cover all major use cases, supported by over 1,200 community contributions.\n- Reliability and performance improvements (this has been a huge focus for the past year).\n- Making sure Airbyte fits with your existing <em>production</em> workflow \u2013 from Python scripts to <em>Terraform</em>, API, and UI interfaces.<p>It\u2019s been quite the journey, and we\u2019re excited to say we\u2019ve hit those marks!<p>But there\u2019s actually more to Airbyte 1.0!\n- An AI Assistant to help you build connectors in minutes. Just give it the API docs, and you\u2019re good to go. We\u2019ve also added support for GraphQL APIs to our Connector Builder.\n- The Connector Marketplace: You can now easily contribute connectors or make changes directly from the no-code/low-code builder. Every connector in the marketplace is editable, and we\u2019ve added usage and confidence scores to help gauge reliability.\n- Airbyte Self-Managed Enterprise generally available: it comes with everything you get from the open-source version, plus enterprise-level features like premium support with SLA, SSO, RBAC, multiple workspaces, advanced observability, and enterprise connectors for Netsuite, Workday, Oracle, and more.\n- Airbyte can now power your RAG / GenAI workflows without limitations, through its support of unstructured data sources, vector databases, and new mapping capabilities. It also converts structured and unstructured data into documents for chunking, along with embedding support for Cohere and OpenAI.<p>There\u2019s a lot more coming, and we\u2019d love to hear your thoughts!\nIf you\u2019re curious, check out our launch keynote (<a href=\"https://airbyte.com/v1\">https://airbyte.com/v1</a>) and let us know what you think \u2013 are there features we could improve? Areas we should explore next? We\u2019re all ears.<p>Thanks for being part of this journey!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Airbyte 1.0, Marketplace, AI Assist, GenAI Support and Enterprise GA"}}, "_tags": ["story", "author_bleonard", "story_41637452", "show_hn"], "author": "bleonard", "children": [41637523, 41637561, 41637587, 41638033, 41638037, 41638192, 41638260, 41638641, 41638967, 41639173, 41639487, 41642945, 41643669], "created_at": "2024-09-24T15:17:21Z", "created_at_i": 1727191041, "num_comments": 14, "objectID": "41637452", "points": 58, "story_id": 41637452, "story_text": "Hi HN friends!<p>We can hardly believe it\u2019s been almost four years since our original HN launch (<a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=25917403\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=25917403</a>). What started as a small project has grown way beyond what we imagined, with over 170,000 deployments and 7,000 companies using Airbyte daily.<p>When we started Airbyte, our mission was simple (though not easy): to solve data movement once and for all. Today feels like a big step toward that goal with the release of Airbyte 1.0 (<a href=\"https:&#x2F;&#x2F;airbyte.com&#x2F;v1\">https:&#x2F;&#x2F;airbyte.com&#x2F;v1</a>). Reaching this milestone wasn\u2019t a solo effort. It\u2019s taken an incredible amount of work from the whole community and the feedback we\u2019ve received from many of you along the way. We had three goals to reach 1.0:\n- Broad deployments to cover all major use cases, supported by over 1,200 community contributions.\n- Reliability and performance improvements (this has been a huge focus for the past year).\n- Making sure Airbyte fits with your existing production workflow \u2013 from Python scripts to Terraform, API, and UI interfaces.<p>It\u2019s been quite the journey, and we\u2019re excited to say we\u2019ve hit those marks!<p>But there\u2019s actually more to Airbyte 1.0!\n- An AI Assistant to help you build connectors in minutes. Just give it the API docs, and you\u2019re good to go. We\u2019ve also added support for GraphQL APIs to our Connector Builder.\n- The Connector Marketplace: You can now easily contribute connectors or make changes directly from the no-code&#x2F;low-code builder. Every connector in the marketplace is editable, and we\u2019ve added usage and confidence scores to help gauge reliability.\n- Airbyte Self-Managed Enterprise generally available: it comes with everything you get from the open-source version, plus enterprise-level features like premium support with SLA, SSO, RBAC, multiple workspaces, advanced observability, and enterprise connectors for Netsuite, Workday, Oracle, and more.\n- Airbyte can now power your RAG &#x2F; GenAI workflows without limitations, through its support of unstructured data sources, vector databases, and new mapping capabilities. It also converts structured and unstructured data into documents for chunking, along with embedding support for Cohere and OpenAI.<p>There\u2019s a lot more coming, and we\u2019d love to hear your thoughts!\nIf you\u2019re curious, check out our launch keynote (<a href=\"https:&#x2F;&#x2F;airbyte.com&#x2F;v1\">https:&#x2F;&#x2F;airbyte.com&#x2F;v1</a>) and let us know what you think \u2013 are there features we could improve? Areas we should explore next? We\u2019re all ears.<p>Thanks for being part of this journey!", "title": "Show HN: Airbyte 1.0, Marketplace, AI Assist, GenAI Support and Enterprise GA", "updated_at": "2025-10-29T17:28:24Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "lekiwi"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["terraform", "production"], "value": "Linksie is a way for you to put a paywall on any link.<p>I took a different approach for Linksie. I made a conscious choice to &quot;over-engineer&quot; it, not for complexity's sake, but to build a stable, scalable foundation and to aggressively upskill in areas where I was weak.<p>For me, over-engineering was a conscious choice to shift from the typical startup mindset of &quot;ship features at all costs&quot; to &quot;with a little extra time, could I build something that scales more elegantly and remains stable for longer?&quot; It was about thinking like a founding CTO: if I had to hire engineers tomorrow, what is the foundation I'd want in place for them?<p>It ended up as a monorepo containing containerized services and shared packages.<p>Application Services:\nFrontend: Next.js (Pages Router)\nBackend: HonoJS API\nKey Libraries: BetterAuth, Tailwind CSS, Headless UI, Tanstack Query/Form, Stripe<p>Worker Services:\nA dedicated container for node-pg-migrate database migrations.\nA job queue worker for asynchronous tasks (e.g., our referral system).<p>Shared Packages:\nInternal libraries for shared types and database clients (PostgreSQL, Redis) to ensure consistency between the API and workers.\nThe entire stack is containerized with Docker and spins up locally with a single docker-compose up command. The codebase is currently around 30k lines of code.<p>The SDLC: Automation from Day One<p>I wanted a professional software development lifecycle from the start.\nCI/CD: On merge to main, a GitHub Actions pipeline runs tests, builds all container images, pushes them to Google Artifact Registry, and deploys everything to a dedicated staging environment. This includes running database migrations automatically.\n<em>Production</em>: After verification on staging, a manual approval in the GitHub UI triggers the exact same pipeline targeted at the <em>production</em> environment.<p>The Infrastructure: 90% <em>Terraform</em><p>I chose GCP over AWS primarily for Cloud Run's developer experience and auto-scaling. The entire infrastructure is provisioned with <em>Terraform</em>.<p>Compute: Cloud Run for all services and jobs (with min/max instances set).\nData: Cloud SQL (Postgres) and Memorystore (Redis).\nNetworking: VPC, Cloud Load Balancer, Cloud DNS.\nSecrets &amp; Artifacts: Secrets Manager and Artifact Registry.\nExternal: Cloudflare for public DNS and R2 for storage.<p>The &quot;Why&quot;: Justifying the Upfront Investment<p>I know the common wisdom is to use Vercel, Supabase, etc., and get to market faster and cheaper. I chose this path for two main reasons:<p>1. I Despise Vendor Lock-in: PaaS providers like Vercel are fantastic, but they are for-profit entities that can and will change their pricing and priorities. We've all seen the horror stories of unexpected six-figure bills. We write modular code to avoid lock-in; I believe the same principle should apply to infrastructure. Owning the stack gives me control and predictable costs.<p>2. A Deliberate Opportunity for Growth: As a full-stack engineer, my DevOps and IaC knowledge was purely conceptual. This project forced me to learn <em>Terraform</em>, container networking, VPCs, and cloud architecture hands-on. The argument to &quot;just hire someone later&quot; is a weak one if you don't know how to evaluate their work. This experience filled a massive gap in my skillset. Even if the SaaS fails, the knowledge gained has been invaluable. I went from zero to proficient with <em>Terraform</em> in about a week, largely thanks to AI-assisted learning.<p>Retrospective &amp; What I'd Do Differently<p>Would I do it the exact same way again? No. The current infrastructure has hefty costs for a pre-revenue project. My next iteration would be more pragmatic: Drop the managed Redis cache, use a cheaper DB option, eliminate the dedicated staging environment<p>Open to thoughts, suggestions, improvements!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Overengineering Linksie \u2013 a link paywall generator"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://linksie.co"}}, "_tags": ["story", "author_lekiwi", "story_44339519", "show_hn"], "author": "lekiwi", "created_at": "2025-06-21T18:12:09Z", "created_at_i": 1750529529, "num_comments": 0, "objectID": "44339519", "points": 3, "story_id": 44339519, "story_text": "Linksie is a way for you to put a paywall on any link.<p>I took a different approach for Linksie. I made a conscious choice to &quot;over-engineer&quot; it, not for complexity&#x27;s sake, but to build a stable, scalable foundation and to aggressively upskill in areas where I was weak.<p>For me, over-engineering was a conscious choice to shift from the typical startup mindset of &quot;ship features at all costs&quot; to &quot;with a little extra time, could I build something that scales more elegantly and remains stable for longer?&quot; It was about thinking like a founding CTO: if I had to hire engineers tomorrow, what is the foundation I&#x27;d want in place for them?<p>It ended up as a monorepo containing containerized services and shared packages.<p>Application Services:\nFrontend: Next.js (Pages Router)\nBackend: HonoJS API\nKey Libraries: BetterAuth, Tailwind CSS, Headless UI, Tanstack Query&#x2F;Form, Stripe<p>Worker Services:\nA dedicated container for node-pg-migrate database migrations.\nA job queue worker for asynchronous tasks (e.g., our referral system).<p>Shared Packages:\nInternal libraries for shared types and database clients (PostgreSQL, Redis) to ensure consistency between the API and workers.\nThe entire stack is containerized with Docker and spins up locally with a single docker-compose up command. The codebase is currently around 30k lines of code.<p>The SDLC: Automation from Day One<p>I wanted a professional software development lifecycle from the start.\nCI&#x2F;CD: On merge to main, a GitHub Actions pipeline runs tests, builds all container images, pushes them to Google Artifact Registry, and deploys everything to a dedicated staging environment. This includes running database migrations automatically.\nProduction: After verification on staging, a manual approval in the GitHub UI triggers the exact same pipeline targeted at the production environment.<p>The Infrastructure: 90% Terraform<p>I chose GCP over AWS primarily for Cloud Run&#x27;s developer experience and auto-scaling. The entire infrastructure is provisioned with Terraform.<p>Compute: Cloud Run for all services and jobs (with min&#x2F;max instances set).\nData: Cloud SQL (Postgres) and Memorystore (Redis).\nNetworking: VPC, Cloud Load Balancer, Cloud DNS.\nSecrets &amp; Artifacts: Secrets Manager and Artifact Registry.\nExternal: Cloudflare for public DNS and R2 for storage.<p>The &quot;Why&quot;: Justifying the Upfront Investment<p>I know the common wisdom is to use Vercel, Supabase, etc., and get to market faster and cheaper. I chose this path for two main reasons:<p>1. I Despise Vendor Lock-in: PaaS providers like Vercel are fantastic, but they are for-profit entities that can and will change their pricing and priorities. We&#x27;ve all seen the horror stories of unexpected six-figure bills. We write modular code to avoid lock-in; I believe the same principle should apply to infrastructure. Owning the stack gives me control and predictable costs.<p>2. A Deliberate Opportunity for Growth: As a full-stack engineer, my DevOps and IaC knowledge was purely conceptual. This project forced me to learn Terraform, container networking, VPCs, and cloud architecture hands-on. The argument to &quot;just hire someone later&quot; is a weak one if you don&#x27;t know how to evaluate their work. This experience filled a massive gap in my skillset. Even if the SaaS fails, the knowledge gained has been invaluable. I went from zero to proficient with Terraform in about a week, largely thanks to AI-assisted learning.<p>Retrospective &amp; What I&#x27;d Do Differently<p>Would I do it the exact same way again? No. The current infrastructure has hefty costs for a pre-revenue project. My next iteration would be more pragmatic: Drop the managed Redis cache, use a cheaper DB option, eliminate the dedicated staging environment<p>Open to thoughts, suggestions, improvements!", "title": "Show HN: Overengineering Linksie \u2013 a link paywall generator", "updated_at": "2025-06-25T11:21:02Z", "url": "https://linksie.co"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "lucas_vieira"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["terraform", "production"], "value": "Hi HN, we're Lucas and Lucas, the authors of Layerform (https://github.com/ergomake/layerform). Layerform is an open-source tool for setting up development environments using plain .tf files. We allow each engineer to create their own &quot;staging&quot; environment and reuse infrastructure.<p>Whenever engineers run layerform spawn, we use plain .tf files to give them their own &quot;staging&quot; environment that looks just like <em>production</em>.<p>Many teams have a single (or too few) staging environments, which developers have to queue to use. This is particularly a problem when a system is large, because then engineers can't run it on their machines and cannot easily test their changes in a <em>production</em>-like environment. Often they end up with a cluttered Slack channel in which engineers wait for their turn to use staging. Sometimes, they don't even have that clunky channel and end up merging broken code or shipping bugs to <em>production</em>. Lucas and I decided to solve this because we previously suffered with shared staging environments.<p>Layerform gives each developer their own <em>production</em>-like environment.This eliminates the bottleneck, increasing the number of deploys engineers make. Additionally, it reduces the amount of bugs and rework because developers have a <em>production</em>-like environment to develop and test against. They can just run &quot;layerform spawn&quot; and get their own staging.<p>We wrap the MPL-licensed <em>Terraform</em> and allow engineers to encapsulate each part of their infrastructure into layers. They can then create multiple instances of a particular layer to create a development environment.The benefit of using layers instead of raw <em>Terraform</em> modules is that they're much easier to write and reuse, meaning multiple development environments can run on top of the same infrastructure.<p>Layerform's environments are quick and cheap to spin up because they share core pieces of infrastructure. Additionally, Layerform can automatically tag components in each layer, making it easier for FinOps teams to manage costs and do chargebacks.<p>For example: with Layerform, a product developer can spin up their own lambdas and pods for staging while still using a shared Kubernetes cluster and Kafka instance. That way, development environments are quicker to spin up and cheaper to maintain. Each developer's layer also gets a tag, meaning FinOps teams know how much each team's environments cost.<p>For the sake of transparency, the way we intend to make money is by providing a managed service with governance, management, and cost-control features, including turning off environments automatically on inactivity or after business hours. The Layerform CLI itself will remain free and open (GPL).<p>You can download the Layerform CLI right now and use it for free. Currently, all the state, permissions, and layer definitions stay in your cloud, under your control.<p>After the whole license change thing, I think it's also worth mentioning we'll be building on top of the community's fork and will consider adding support for Pulumi too.<p>We'd love your feedback on our solution to eliminate \u201cthe staging bottleneck&quot;. What do you think?"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["terraform"], "value": "Show HN: Layerform \u2013 Open-source development environments using <em>Terraform</em> files"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/ergomake/layerform"}}, "_tags": ["story", "author_lucas_vieira", "story_37134293", "show_hn"], "author": "lucas_vieira", "children": [37136453, 37136724, 37138265, 37138719, 37138990, 37140080, 37141627, 37142007, 37142926, 37144595], "created_at": "2023-08-15T14:15:51Z", "created_at_i": 1692108951, "num_comments": 23, "objectID": "37134293", "points": 124, "story_id": 37134293, "story_text": "Hi HN, we&#x27;re Lucas and Lucas, the authors of Layerform (https:&#x2F;&#x2F;github.com&#x2F;ergomake&#x2F;layerform). Layerform is an open-source tool for setting up development environments using plain .tf files. We allow each engineer to create their own &quot;staging&quot; environment and reuse infrastructure.<p>Whenever engineers run layerform spawn, we use plain .tf files to give them their own &quot;staging&quot; environment that looks just like production.<p>Many teams have a single (or too few) staging environments, which developers have to queue to use. This is particularly a problem when a system is large, because then engineers can&#x27;t run it on their machines and cannot easily test their changes in a production-like environment. Often they end up with a cluttered Slack channel in which engineers wait for their turn to use staging. Sometimes, they don&#x27;t even have that clunky channel and end up merging broken code or shipping bugs to production. Lucas and I decided to solve this because we previously suffered with shared staging environments.<p>Layerform gives each developer their own production-like environment.This eliminates the bottleneck, increasing the number of deploys engineers make. Additionally, it reduces the amount of bugs and rework because developers have a production-like environment to develop and test against. They can just run &quot;layerform spawn&quot; and get their own staging.<p>We wrap the MPL-licensed Terraform and allow engineers to encapsulate each part of their infrastructure into layers. They can then create multiple instances of a particular layer to create a development environment.The benefit of using layers instead of raw Terraform modules is that they&#x27;re much easier to write and reuse, meaning multiple development environments can run on top of the same infrastructure.<p>Layerform&#x27;s environments are quick and cheap to spin up because they share core pieces of infrastructure. Additionally, Layerform can automatically tag components in each layer, making it easier for FinOps teams to manage costs and do chargebacks.<p>For example: with Layerform, a product developer can spin up their own lambdas and pods for staging while still using a shared Kubernetes cluster and Kafka instance. That way, development environments are quicker to spin up and cheaper to maintain. Each developer&#x27;s layer also gets a tag, meaning FinOps teams know how much each team&#x27;s environments cost.<p>For the sake of transparency, the way we intend to make money is by providing a managed service with governance, management, and cost-control features, including turning off environments automatically on inactivity or after business hours. The Layerform CLI itself will remain free and open (GPL).<p>You can download the Layerform CLI right now and use it for free. Currently, all the state, permissions, and layer definitions stay in your cloud, under your control.<p>After the whole license change thing, I think it&#x27;s also worth mentioning we&#x27;ll be building on top of the community&#x27;s fork and will consider adding support for Pulumi too.<p>We&#x27;d love your feedback on our solution to eliminate \u201cthe staging bottleneck&quot;. What do you think?", "title": "Show HN: Layerform \u2013 Open-source development environments using Terraform files", "updated_at": "2024-09-20T14:48:49Z", "url": "https://github.com/ergomake/layerform"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "SweetSoftPillow"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Deploy <em>Production</em>-Ready Kubernetes on Hetzner Cloud"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["terraform"], "value": "https://github.com/hcloud-k8s/<em>terraform</em>-hcloud-kubernetes"}}, "_tags": ["story", "author_SweetSoftPillow", "story_44916908"], "author": "SweetSoftPillow", "children": [44925106], "created_at": "2025-08-15T20:23:09Z", "created_at_i": 1755289389, "num_comments": 1, "objectID": "44916908", "points": 18, "story_id": 44916908, "title": "Deploy Production-Ready Kubernetes on Hetzner Cloud", "updated_at": "2026-02-01T20:31:45Z", "url": "https://github.com/hcloud-k8s/terraform-hcloud-kubernetes"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "albertlie"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["terraform", "production"], "value": "Hi all,<p>I'm starting a project in my company for upgrading our deployment infrastructure across cloud providers. Our current system is mainly using ansible for both provisioning and configuration management.<p>I'm trying to see <em>Terraform</em> as well for this option. And I wonder anyone has experience on migrating from ansible to <em>Terraform</em> or using both of them? And maybe can share the benefit and drawback of both of them when using them in <em>production</em>?"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["terraform"], "value": "Ask HN: Ansible vs. <em>Terraform</em>"}}, "_tags": ["story", "author_albertlie", "story_16576877", "ask_hn"], "author": "albertlie", "children": [16576957, 16577018, 16577144], "created_at": "2018-03-13T15:26:49Z", "created_at_i": 1520954809, "num_comments": 11, "objectID": "16576877", "points": 11, "story_id": 16576877, "story_text": "Hi all,<p>I&#x27;m starting a project in my company for upgrading our deployment infrastructure across cloud providers. Our current system is mainly using ansible for both provisioning and configuration management.<p>I&#x27;m trying to see Terraform as well for this option. And I wonder anyone has experience on migrating from ansible to Terraform or using both of them? And maybe can share the benefit and drawback of both of them when using them in production?", "title": "Ask HN: Ansible vs. Terraform", "updated_at": "2024-09-20T02:12:51Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "netingle"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["terraform"], "value": "How we run our upgradable Kubernetes clusters, using <em>Terraform</em> and Ansible"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "https://www.weave.works/provisioning-lifecycle-<em>production</em>-ready-kubernetes-cluster/"}}, "_tags": ["story", "author_netingle", "story_13707167"], "author": "netingle", "children": [13707238], "created_at": "2017-02-22T17:22:23Z", "created_at_i": 1487784143, "num_comments": 3, "objectID": "13707167", "points": 9, "story_id": 13707167, "title": "How we run our upgradable Kubernetes clusters, using Terraform and Ansible", "updated_at": "2024-09-20T00:22:43Z", "url": "https://www.weave.works/provisioning-lifecycle-production-ready-kubernetes-cluster/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "Teknomancer"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["terraform", "production"], "value": "Large-scale <em>production</em> of e-fuel is now feasible, argues <em>Terraform</em> Industries"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://www.economist.com/the-world-ahead/2024/11/20/casey-handmer-says-solar-power-is-changing-the-economics-of-energy"}}, "_tags": ["story", "author_Teknomancer", "story_42326003"], "author": "Teknomancer", "children": [42326004], "created_at": "2024-12-05T08:02:08Z", "created_at_i": 1733385728, "num_comments": 2, "objectID": "42326003", "points": 4, "story_id": 42326003, "title": "Large-scale production of e-fuel is now feasible, argues Terraform Industries", "updated_at": "2024-12-18T15:07:40Z", "url": "https://www.economist.com/the-world-ahead/2024/11/20/casey-handmer-says-solar-power-is-changing-the-economics-of-energy"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "drskyle"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["terraform", "production"], "value": "Hi HN,<p>I\u2019ve built an open-source CLI tool that identifies wasted cloud resources (AWS) , CLoudSlash , and, more importantly, it helps you delete them without the fear of breaking <em>production</em>.<p>The Problem:\nMost &quot;cloud cost&quot; tools give you a CSV of &quot;unused&quot; resources. But deleting them is terrifying. Is that unattached EBS volume actually a <em>production</em> database backup? Is that idle NAT Gateway the only route for a silent legacy lambda?<p>I realized that detection is easy, but safe remediation is an unsolved distributed systems problem.<p>The Solution:\nCloudSlash builds an in-memory Directed Acyclic Graph (DAG) of your infrastructure to understand dependencies, not just utilization metrics. It effectively treats your infrastructure as a graph traversal problem.<p>Key Technical Features:<p>1. The &quot;Lazarus Protocol&quot; (Infrastructure Undo Button):\n   If you choose to delete a resource (e.g., a Security Group), CloudSlash doesn\u2019t just make the API call. It first:<p>- Snapshots the live configuration.\n- Generates a restore.tf file with the HCL definition.\n- Generates a precise <em>terraform</em> import command.<p>If you make a mistake, you can resurrect the resource and bridge it back into your <em>Terraform</em> state in seconds. It turns &quot;destructive&quot; operations into reversible transactions.<p>2. Graph-Based Forensic Engine:\n   Instead of simple rules (&quot;CPU &lt; 5%&quot;), it builds a dependency graph.<p>- Example: It won't flag a NAT Gateway as waste\u2014even if it has 0 bytes of traffic\u2014if it detects an active Route Table creating a &quot;FlowsTo&quot; edge targeting it.\n- The engine is written in Go, using custom string interning and contiguous memory layouts for the graph nodes to handle large enterprise accounts (10k+ resources) without GC thrashing.<p>3. Bin Packing, Not Just &quot;Right-Sizing&quot;:\n   For compute optimization, it uses a 2D Bin Packing algorithm (Best Fit Decreasing) to simulate how your current pods/workloads would fit into modern instance types. It visualizes the &quot;fragmentation&quot; of your clusters rather than just looking at average CPU usage.<p>Why Use This?<p>- Locally Run: No SaaS, no API keys leaving your machine.\n- Heuristics Catalog: All detection logic is open source. You can see exactly why an RDS instance was flagged (e.g., Connections == 0 for 7 days AND SnapshotCreated == true).\n- TUI: It includes a terminal UI (using Bubble Tea) for interactive graph exploration.<p>Repo: <a href=\"https://github.com/DrSkyle/CloudSlash\" rel=\"nofollow\">https://github.com/DrSkyle/CloudSlash</a><p>I\u2019m eager for feedback on the graph traversal logic and the &quot;Lazarus&quot; restoration flow.<p>:) DrSkyle"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["terraform"], "value": "Show HN: CloudSlash \u2013 Graph-based AWS cleaner with <em>Terraform</em> undo"}}, "_tags": ["story", "author_drskyle", "story_46603968", "show_hn"], "author": "drskyle", "created_at": "2026-01-13T17:08:12Z", "created_at_i": 1768324092, "num_comments": 0, "objectID": "46603968", "points": 3, "story_id": 46603968, "story_text": "Hi HN,<p>I\u2019ve built an open-source CLI tool that identifies wasted cloud resources (AWS) , CLoudSlash , and, more importantly, it helps you delete them without the fear of breaking production.<p>The Problem:\nMost &quot;cloud cost&quot; tools give you a CSV of &quot;unused&quot; resources. But deleting them is terrifying. Is that unattached EBS volume actually a production database backup? Is that idle NAT Gateway the only route for a silent legacy lambda?<p>I realized that detection is easy, but safe remediation is an unsolved distributed systems problem.<p>The Solution:\nCloudSlash builds an in-memory Directed Acyclic Graph (DAG) of your infrastructure to understand dependencies, not just utilization metrics. It effectively treats your infrastructure as a graph traversal problem.<p>Key Technical Features:<p>1. The &quot;Lazarus Protocol&quot; (Infrastructure Undo Button):\n   If you choose to delete a resource (e.g., a Security Group), CloudSlash doesn\u2019t just make the API call. It first:<p>- Snapshots the live configuration.\n- Generates a restore.tf file with the HCL definition.\n- Generates a precise terraform import command.<p>If you make a mistake, you can resurrect the resource and bridge it back into your Terraform state in seconds. It turns &quot;destructive&quot; operations into reversible transactions.<p>2. Graph-Based Forensic Engine:\n   Instead of simple rules (&quot;CPU &lt; 5%&quot;), it builds a dependency graph.<p>- Example: It won&#x27;t flag a NAT Gateway as waste\u2014even if it has 0 bytes of traffic\u2014if it detects an active Route Table creating a &quot;FlowsTo&quot; edge targeting it.\n- The engine is written in Go, using custom string interning and contiguous memory layouts for the graph nodes to handle large enterprise accounts (10k+ resources) without GC thrashing.<p>3. Bin Packing, Not Just &quot;Right-Sizing&quot;:\n   For compute optimization, it uses a 2D Bin Packing algorithm (Best Fit Decreasing) to simulate how your current pods&#x2F;workloads would fit into modern instance types. It visualizes the &quot;fragmentation&quot; of your clusters rather than just looking at average CPU usage.<p>Why Use This?<p>- Locally Run: No SaaS, no API keys leaving your machine.\n- Heuristics Catalog: All detection logic is open source. You can see exactly why an RDS instance was flagged (e.g., Connections == 0 for 7 days AND SnapshotCreated == true).\n- TUI: It includes a terminal UI (using Bubble Tea) for interactive graph exploration.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;DrSkyle&#x2F;CloudSlash\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;DrSkyle&#x2F;CloudSlash</a><p>I\u2019m eager for feedback on the graph traversal logic and the &quot;Lazarus&quot; restoration flow.<p>:) DrSkyle", "title": "Show HN: CloudSlash \u2013 Graph-based AWS cleaner with Terraform undo", "updated_at": "2026-01-14T07:11:52Z"}], "hitsPerPage": 15, "nbHits": 66, "nbPages": 5, "page": 0, "params": "query=terraform+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 13, "processingTimingsMS": {"_request": {"roundTrip": 14}, "afterFetch": {"format": {"highlighting": 2, "total": 3}}, "fetch": {"query": 8, "scanning": 3, "total": 12}, "total": 13}, "query": "terraform production", "serverTimeMS": 17}}