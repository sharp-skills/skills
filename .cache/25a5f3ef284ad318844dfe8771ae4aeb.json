{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "sethvargo"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["vault", "production"], "value": "HashiCorp <em>Vault</em> <em>Production</em> Hardening Guide"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "https://www.vaultproject.io/docs/guides/<em>production</em>.html"}}, "_tags": ["story", "author_sethvargo", "story_14636608"], "author": "sethvargo", "created_at": "2017-06-26T13:29:17Z", "created_at_i": 1498483757, "num_comments": 0, "objectID": "14636608", "points": 2, "story_id": 14636608, "title": "HashiCorp Vault Production Hardening Guide", "updated_at": "2024-09-20T00:58:10Z", "url": "https://www.vaultproject.io/docs/guides/production.html"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "Amorymeltzer"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["vault"], "value": "Arctic Code <em>Vault</em>: your open source projects are being archived"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["vault", "production"], "value": "https://github.blog/2020-02-03-the-arctic-code-<em>vault</em>-starts-<em>production</em>-and-your-open-source-projects-are-being-archived/"}}, "_tags": ["story", "author_Amorymeltzer", "story_22226193"], "author": "Amorymeltzer", "created_at": "2020-02-03T17:09:31Z", "created_at_i": 1580749771, "num_comments": 0, "objectID": "22226193", "points": 2, "story_id": 22226193, "title": "Arctic Code Vault: your open source projects are being archived", "updated_at": "2024-09-20T05:38:11Z", "url": "https://github.blog/2020-02-03-the-arctic-code-vault-starts-production-and-your-open-source-projects-are-being-archived/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "kiyanwang"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["vault", "production"], "value": "Best practices to get to <em>production</em> readiness with HashiCorp <em>Vault</em> in Kubernetes"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["vault", "production"], "value": "https://expel.io/blog/<em>production</em>-readiness-hashicorp-<em>vault</em>-kubernetes/"}}, "_tags": ["story", "author_kiyanwang", "story_26455504"], "author": "kiyanwang", "created_at": "2021-03-14T14:02:06Z", "created_at_i": 1615730526, "num_comments": 0, "objectID": "26455504", "points": 1, "story_id": 26455504, "title": "Best practices to get to production readiness with HashiCorp Vault in Kubernetes", "updated_at": "2024-09-20T08:10:23Z", "url": "https://expel.io/blog/production-readiness-hashicorp-vault-kubernetes/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "albertlie"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["vault", "production"], "value": "Hi all,<p>I'm looking for centralized tools for managing secrets for my engineering team right now. Is there any recommended tools from your experience using them in <em>production</em>?<p>For example like <em>Vault</em> (Hashicorp product).<p>Thanks"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Ask HN: Tools for Managing Secret in <em>Production</em> Scale?"}}, "_tags": ["story", "author_albertlie", "story_16878333", "ask_hn"], "author": "albertlie", "children": [16880840, 16881902, 16882174, 16890253, 16891614], "created_at": "2018-04-19T18:03:25Z", "created_at_i": 1524161005, "num_comments": 11, "objectID": "16878333", "points": 12, "story_id": 16878333, "story_text": "Hi all,<p>I&#x27;m looking for centralized tools for managing secrets for my engineering team right now. Is there any recommended tools from your experience using them in production?<p>For example like Vault (Hashicorp product).<p>Thanks", "title": "Ask HN: Tools for Managing Secret in Production Scale?", "updated_at": "2024-09-20T02:23:38Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "yoyo250"}, "story_text": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Warning: pre-release, unaudited, not for <em>production</em> use. (Though my password was generated with it)<p>Instead of saving secrets, it derives them on demand using domain + username + a short passphrase + a physical OpenPGP key (smartcard/YubiKey).<p>Passwords are reproducible but never persisted.<p>Currently tested only with RSA4096 on Windows + GnuPG 2.4.x."}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["vault"], "value": "Show HN: Paasword \u2013 a password <em>vault</em> that never stores your passwords"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/biliyoyo520/paasword"}}, "_tags": ["story", "author_yoyo250", "story_45239484", "show_hn"], "author": "yoyo250", "children": [45239504], "created_at": "2025-09-14T13:00:29Z", "created_at_i": 1757854829, "num_comments": 2, "objectID": "45239484", "points": 2, "story_id": 45239484, "story_text": "Warning: pre-release, unaudited, not for production use. (Though my password was generated with it)<p>Instead of saving secrets, it derives them on demand using domain + username + a short passphrase + a physical OpenPGP key (smartcard&#x2F;YubiKey).<p>Passwords are reproducible but never persisted.<p>Currently tested only with RSA4096 on Windows + GnuPG 2.4.x.", "title": "Show HN: Paasword \u2013 a password vault that never stores your passwords", "updated_at": "2025-09-15T13:05:59Z", "url": "https://github.com/biliyoyo520/paasword"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "maxivak"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["vault", "production"], "value": "As a team of DevOps engineers, we've helped people to design and implement reliable infrastructure.<p>A lot of our projects needed a solution for a secure storage and management of passwords, tokens and protecting of sensitive data.\nHashicorp <em>Vault</em> is a good choice for small and mid-size organizations.<p>We built a SaaS managed Hashicorp <em>Vault</em> solution and opened it for everyone. \nIt is suitable for small companies when solutions based on AWS KMS and <em>Vault</em> Enterprise are too expensive. \nWe setup a Hashicorp <em>Vault</em> cluster in the cloud which is fully-managed and supported by our team. It satisfies compliance needs and fulfill the <em>production</em> requirements by Hashicorp. Customer data is stored encrypted on AWS S3.<p>We're inviting early adopters to join our private beta. Get your <em>Vault</em> cluster ready in a few minutes.<p><a href=\"https://rockos.io/managed-vault\" rel=\"nofollow\">https://rockos.io/managed-<em>vault</em></a>"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["vault"], "value": "Show HN: <em>Vault</em> as a Service"}}, "_tags": ["story", "author_maxivak", "story_19372079", "show_hn"], "author": "maxivak", "children": [19372600], "created_at": "2019-03-12T19:36:55Z", "created_at_i": 1552419415, "num_comments": 1, "objectID": "19372079", "points": 2, "story_id": 19372079, "story_text": "As a team of DevOps engineers, we&#x27;ve helped people to design and implement reliable infrastructure.<p>A lot of our projects needed a solution for a secure storage and management of passwords, tokens and protecting of sensitive data.\nHashicorp Vault is a good choice for small and mid-size organizations.<p>We built a SaaS managed Hashicorp Vault solution and opened it for everyone. \nIt is suitable for small companies when solutions based on AWS KMS and Vault Enterprise are too expensive. \nWe setup a Hashicorp Vault cluster in the cloud which is fully-managed and supported by our team. It satisfies compliance needs and fulfill the production requirements by Hashicorp. Customer data is stored encrypted on AWS S3.<p>We&#x27;re inviting early adopters to join our private beta. Get your Vault cluster ready in a few minutes.<p><a href=\"https:&#x2F;&#x2F;rockos.io&#x2F;managed-vault\" rel=\"nofollow\">https:&#x2F;&#x2F;rockos.io&#x2F;managed-vault</a>", "title": "Show HN: Vault as a Service", "updated_at": "2024-09-20T03:54:44Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "6teepees"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["vault", "production"], "value": "Hey HN! I built OmnAI because enterprises keep telling me they can't deploy AI due to compliance barriers.<p>The problem: Defense contractors need air-gapped LLMs. Hospitals want AI but fear HIPAA violations. Banks need audit trails for every AI decision. Current solutions either lock you into cloud providers or leave you on your own for security.<p>OmnAI provides:\n- 16 isolated vaults using gVisor sandboxing (zero data leakage between tenants)\n- Trust-based governance - mandatory human review when confidence drops below 0.90\n- Three deployment tiers: SUPERFLY (air-gap/DoD IL6), SOVEREIGN (on-prem/finance), EXCEED (hybrid/R&amp;D)\n- Compliance-ready architecture (FedRAMP, HIPAA, SOC, ITAR)<p>Technical stack: vLLM/Triton for inference, offline PKI with AES-GCM-256, per-<em>vault</em> fine-tuning pipelines.<p>It's in pilot state - I'm looking for feedback on whether this architecture resonates with <em>production</em> AI challenges you're seeing, especially around data sovereignty and regulatory compliance.<p><a href=\"https://github.com/TadTanyaTalaTadenTadhgTaya/OmnAI-v3.5\" rel=\"nofollow\">https://github.com/TadTanyaTalaTadenTadhgTaya/OmnAI-v3.5</a><p>Happy to answer questions about the design decisions, particularly around the trust system and <em>vault</em> isolation model."}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["vault"], "value": "Show HN: OmnAI \u2013 Sovereign AI infrastructure with multi-<em>vault</em> isolation"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/TadTanyaTalaTadenTadhgTaya/OmnAI-v3.5"}}, "_tags": ["story", "author_6teepees", "story_46313634", "show_hn"], "author": "6teepees", "created_at": "2025-12-18T15:19:41Z", "created_at_i": 1766071181, "num_comments": 0, "objectID": "46313634", "points": 2, "story_id": 46313634, "story_text": "Hey HN! I built OmnAI because enterprises keep telling me they can&#x27;t deploy AI due to compliance barriers.<p>The problem: Defense contractors need air-gapped LLMs. Hospitals want AI but fear HIPAA violations. Banks need audit trails for every AI decision. Current solutions either lock you into cloud providers or leave you on your own for security.<p>OmnAI provides:\n- 16 isolated vaults using gVisor sandboxing (zero data leakage between tenants)\n- Trust-based governance - mandatory human review when confidence drops below 0.90\n- Three deployment tiers: SUPERFLY (air-gap&#x2F;DoD IL6), SOVEREIGN (on-prem&#x2F;finance), EXCEED (hybrid&#x2F;R&amp;D)\n- Compliance-ready architecture (FedRAMP, HIPAA, SOC, ITAR)<p>Technical stack: vLLM&#x2F;Triton for inference, offline PKI with AES-GCM-256, per-vault fine-tuning pipelines.<p>It&#x27;s in pilot state - I&#x27;m looking for feedback on whether this architecture resonates with production AI challenges you&#x27;re seeing, especially around data sovereignty and regulatory compliance.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;TadTanyaTalaTadenTadhgTaya&#x2F;OmnAI-v3.5\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;TadTanyaTalaTadenTadhgTaya&#x2F;OmnAI-v3.5</a><p>Happy to answer questions about the design decisions, particularly around the trust system and vault isolation model.", "title": "Show HN: OmnAI \u2013 Sovereign AI infrastructure with multi-vault isolation", "updated_at": "2025-12-18T15:24:33Z", "url": "https://github.com/TadTanyaTalaTadenTadhgTaya/OmnAI-v3.5"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "prismatic"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Nearly 1,000 Photo Postcards of 19th-Century Stage <em>Productions</em> of Shakespeare"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["vault"], "value": "http://www.slate.com/blogs/the_<em>vault</em>/2016/06/08/a_database_of_1_000_photo_postcards_shows_how_shakespeare_was_produced_in.html"}}, "_tags": ["story", "author_prismatic", "story_11935624"], "author": "prismatic", "created_at": "2016-06-20T01:41:13Z", "created_at_i": 1466386873, "num_comments": 0, "objectID": "11935624", "points": 2, "story_id": 11935624, "title": "Nearly 1,000 Photo Postcards of 19th-Century Stage Productions of Shakespeare", "updated_at": "2024-09-19T23:20:24Z", "url": "http://www.slate.com/blogs/the_vault/2016/06/08/a_database_of_1_000_photo_postcards_shows_how_shakespeare_was_produced_in.html"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "camil"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["vault", "production"], "value": "Hi HN,<p>I\u2019ve been working with Kubernetes for over a decade, since the alpha days, and was involved in kube-aws project before AWS launched EKS. For the past four years, I\u2019ve been helping friends and small businesses cut costs by running Kubernetes on Hetzner Cloud, which I\u2019ve found to be rock solid and by far the best priced provider.<p>Provisioning a cluster on Hetzner is now straightforward, thanks to tools like k3s and hetzner-k3s, but configuring it for your specific needs still takes time and expertise. I built Edka to make that part easy: spin up a <em>production</em> ready cluster in ~2 minutes, then choose how low level or automated you want to go.<p>How it works:<p>Layer 1 \u2013 Cluster provisioning\n - Creates a k3s-based Kubernetes cluster on Hetzner (lightweight, easy to manage, scales well).<p>Layer 2 \u2013 Add-ons\n - One-click deploy for metrics-server, cert-manager, and various operators; preconfigured for Hetzner, no extra setup needed.<p>Layer 3 \u2013 Applications\n - Minimal config UIs for apps built on top of add-ons.\n - Example: Need PostgreSQL? Fill a few fields \u2192 platform installs CloudNativePG \u2192 provisions HA PostgreSQL with PITR \u2192 gives ready to use endpoints. Backups can be restored to any point in time with a click. Quick demo: <a href=\"https://edka.io/apps/\" rel=\"nofollow\">https://edka.io/apps/</a><p>Layer 4 \u2013 Deployments\n - Connect your CI to push container images to a public/private registry.\n - Edka updates deployments automatically (with semantic versioning rules), supports instant rollbacks, autoscaling, persistent volumes, secrets/env imports, and quick public exposure. Quick demo: <a href=\"https://edka.io/deployments/\" rel=\"nofollow\">https://edka.io/deployments/</a><p>Tech stack: TypeScript, React + Tailwind CSS, PostgreSQL, Redis, BullMQ, <em>Vault</em> + AWS KMS to encrypted sensitive data.<p>The platform is still in beta and I\u2019m building it in my spare time, so there are some rough edges, but I\u2019d love feedback from anyone running Kubernetes on Hetzner, exploring alternatives to EKS/GKE/AKS or looking to automate their infrastructure with Kubernetes.<p>More details: <a href=\"https://edka.io/\" rel=\"nofollow\">https://edka.io/</a><p>Thank you!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Edka \u2013 Kubernetes clusters on your own Hetzner account"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://edka.io"}}, "_tags": ["story", "author_camil", "story_44915164", "show_hn"], "author": "camil", "children": [44915369, 44915534, 44915572, 44915588, 44915604, 44915644, 44915660, 44915794, 44915836, 44915908, 44915929, 44915951, 44916083, 44916110, 44916126, 44916210, 44916212, 44916507, 44916620, 44916636, 44916841, 44916985, 44917026, 44917067, 44917080, 44917128, 44917146, 44917187, 44917237, 44917331, 44917364, 44917421, 44917471, 44917491, 44918462, 44919085, 44919151, 44919227, 44919427, 44920830, 44921038, 44921089, 44921168, 44921893, 44922664, 44923079, 44923160, 44923580, 44924358, 44924399, 44925365, 44929577, 44940740, 44941619, 44941751, 44955600, 44955606, 44999646], "created_at": "2025-08-15T17:34:54Z", "created_at_i": 1755279294, "num_comments": 130, "objectID": "44915164", "points": 437, "story_id": 44915164, "story_text": "Hi HN,<p>I\u2019ve been working with Kubernetes for over a decade, since the alpha days, and was involved in kube-aws project before AWS launched EKS. For the past four years, I\u2019ve been helping friends and small businesses cut costs by running Kubernetes on Hetzner Cloud, which I\u2019ve found to be rock solid and by far the best priced provider.<p>Provisioning a cluster on Hetzner is now straightforward, thanks to tools like k3s and hetzner-k3s, but configuring it for your specific needs still takes time and expertise. I built Edka to make that part easy: spin up a production ready cluster in ~2 minutes, then choose how low level or automated you want to go.<p>How it works:<p>Layer 1 \u2013 Cluster provisioning\n - Creates a k3s-based Kubernetes cluster on Hetzner (lightweight, easy to manage, scales well).<p>Layer 2 \u2013 Add-ons\n - One-click deploy for metrics-server, cert-manager, and various operators; preconfigured for Hetzner, no extra setup needed.<p>Layer 3 \u2013 Applications\n - Minimal config UIs for apps built on top of add-ons.\n - Example: Need PostgreSQL? Fill a few fields \u2192 platform installs CloudNativePG \u2192 provisions HA PostgreSQL with PITR \u2192 gives ready to use endpoints. Backups can be restored to any point in time with a click. Quick demo: <a href=\"https:&#x2F;&#x2F;edka.io&#x2F;apps&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;edka.io&#x2F;apps&#x2F;</a><p>Layer 4 \u2013 Deployments\n - Connect your CI to push container images to a public&#x2F;private registry.\n - Edka updates deployments automatically (with semantic versioning rules), supports instant rollbacks, autoscaling, persistent volumes, secrets&#x2F;env imports, and quick public exposure. Quick demo: <a href=\"https:&#x2F;&#x2F;edka.io&#x2F;deployments&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;edka.io&#x2F;deployments&#x2F;</a><p>Tech stack: TypeScript, React + Tailwind CSS, PostgreSQL, Redis, BullMQ, Vault + AWS KMS to encrypted sensitive data.<p>The platform is still in beta and I\u2019m building it in my spare time, so there are some rough edges, but I\u2019d love feedback from anyone running Kubernetes on Hetzner, exploring alternatives to EKS&#x2F;GKE&#x2F;AKS or looking to automate their infrastructure with Kubernetes.<p>More details: <a href=\"https:&#x2F;&#x2F;edka.io&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;edka.io&#x2F;</a><p>Thank you!", "title": "Show HN: Edka \u2013 Kubernetes clusters on your own Hetzner account", "updated_at": "2026-02-08T12:55:42Z", "url": "https://edka.io"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "vmatsiiako"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["vault", "production"], "value": "Hi HN, we\u2019re the co-founders of Infisical (<a href=\"https://infisical.com\">https://infisical.com</a>), an open-source platform to sync application secrets and configs across your engineering team and infrastructure. We enable teams to store their secrets in a centralized location and distribute them anywhere from local development processes to staging/<em>production</em> environments.<p>Our Github is at <a href=\"https://github.com/infisical/infisical\">https://github.com/infisical/infisical</a>.<p>We previously worked at AWS, Figma, and another startup, where we frequently ran into problems dealing with secret management. For example, many companies used .env files to maintain their development secrets and struggled to keep secrets in sync amongst their teams (this routinely posed security and efficiency issues \u2014 secrets can get leaked or go missing). Some companies (especially bigger ones) used solutions like <em>Vault</em> which can be difficult to set up, maintain, and afford.<p>While secret managers exist, they\u2019re imperfect for many reasons: open-source solutions are either too complicated, not comprehensive, not user-friendly, or a mix of all three; there are nicer closed-source solutions but with no self-hosted options available. The gap we see is to make something that\u2019s simple, open-source, and powerful.<p>On the open-source front, our goal is to provide full transparency of our codebase and enable anyone in the community to build anything they want in an optimal secret management solution. If you need any feature or integration that we don\u2019t yet support, you can post an issue about it or directly send in a PR to be reviewed immediately.<p>You can inject the right set of secrets for any environment into your application by using the Infisical CLI together with your application start command (e.g. infisical run -- npm run dev). This removes the need to use a .env file. Everything stays encrypted with encryption/decryption operations occurring on the client-side \u2014 under the hood, secrets are encrypted by <em>vault</em> keys for which there are multiple copies of <em>vault</em> keys encrypted under the public key of each member of a <em>vault</em> (ensuring only members of vaults can decrypt secrets pertaining to that <em>vault</em> locally). An alternative way is to use our Open API - though it\u2019s a little complicated, and we\u2019re working on adding SDKs to abstract away the cryptography.<p>Infisical integrates with staging and <em>production</em> cloud services like AWS, Vercel, GitHub Actions, and Circle CI. We also added support for integrations with Docker, Kubernetes, and Terraform. Infisical is now a central source of truth for secrets across the entire development cycle from development to <em>production</em> with new integration releases every week.\nOne interesting thing is that, by default, our platform is end-to-end encrypted but users can opt out of that if they need to integrate with cloud platforms that require secrets to be sent in decrypted format (e.g. GitHub Actions, Vercel, Render). We\u2019re the only solution that we know of that offers this E2EE-with opt-out ability.<p>Since our last Show HN (<a href=\"https://news.ycombinator.com/item?id=34510516\" rel=\"nofollow\">https://news.ycombinator.com/item?id=34510516</a>), we\u2019ve layered authentication with 2FA (more MFA options coming soon) and upgraded all private key encryption/decryption steps to involve a 256-bit protected key decrypted by another key generated via Argon2id KDF from the user\u2019s password. We are starting the process of obtaining SOC2 and other security and compliance certifications. You can read more about our security here: <a href=\"https://infisical.com/docs/security/overview\">https://infisical.com/docs/security/overview</a><p>Beyond this, we\u2019ve added integrations with PM2, AWS Secrets Manager, AWS Parameter Store, Circle CI, Travis CI, GitLab CI/CD, Terraform and more. We\u2019ve also redesigned the main dashboard and added more advanced organizational structure for secrets. Lastly, we have added role-based access control, and improved our Kubernetes operator: your clusters are now auto-redeployed when secrets in Infisical change. In the coming weeks and months, we plan to add features like secret rotation, improved audit logs, SDKs and alerts; as well as increase the range of our integrations; and continue fortifying platform security and stability.<p>We\u2019ve launched this repo under the MIT license so any developer can use the platform. We don\u2019t charge individual developers or small teams\u2014all the integrations are fully available to everyone. We make money by charging a license fee for enterprise features as well as providing a hosted version and support.<p>If you found it interesting, you can see a demo video here: <a href=\"https://www.loom.com/share/9a8904c6ecc84d0899d53ee1f7a36385\" rel=\"nofollow\">https://www.loom.com/share/9a8904c6ecc84d0899d53ee1f7a36385</a><p>We\u2019d love for you to give Infisical a try (<a href=\"https://infisical.com\">https://infisical.com</a>) and provide any feedback. If you're interested, our code is available here: <a href=\"https://github.com/infisical/infisical\">https://github.com/infisical/infisical</a>. If we don\u2019t have something, let us know and we\u2019d be happy to build it for you. We look forward to your comments!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: Infisical (YC W23) \u2013 Open-source secrets manager for developers"}}, "_tags": ["story", "author_vmatsiiako", "story_34955699", "launch_hn"], "author": "vmatsiiako", "children": [34955766, 34956280, 34956303, 34956309, 34956386, 34956484, 34956666, 34956694, 34956746, 34956759, 34956928, 34957054, 34957380, 34957529, 34957673, 34957748, 34958009, 34958209, 34958403, 34959016, 34959650, 34961850, 34962065, 34963142, 34963683, 34964525, 34964797, 34967332, 34967354], "created_at": "2023-02-27T12:39:29Z", "created_at_i": 1677501569, "num_comments": 121, "objectID": "34955699", "points": 231, "story_id": 34955699, "story_text": "Hi HN, we\u2019re the co-founders of Infisical (<a href=\"https:&#x2F;&#x2F;infisical.com\">https:&#x2F;&#x2F;infisical.com</a>), an open-source platform to sync application secrets and configs across your engineering team and infrastructure. We enable teams to store their secrets in a centralized location and distribute them anywhere from local development processes to staging&#x2F;production environments.<p>Our Github is at <a href=\"https:&#x2F;&#x2F;github.com&#x2F;infisical&#x2F;infisical\">https:&#x2F;&#x2F;github.com&#x2F;infisical&#x2F;infisical</a>.<p>We previously worked at AWS, Figma, and another startup, where we frequently ran into problems dealing with secret management. For example, many companies used .env files to maintain their development secrets and struggled to keep secrets in sync amongst their teams (this routinely posed security and efficiency issues \u2014 secrets can get leaked or go missing). Some companies (especially bigger ones) used solutions like Vault which can be difficult to set up, maintain, and afford.<p>While secret managers exist, they\u2019re imperfect for many reasons: open-source solutions are either too complicated, not comprehensive, not user-friendly, or a mix of all three; there are nicer closed-source solutions but with no self-hosted options available. The gap we see is to make something that\u2019s simple, open-source, and powerful.<p>On the open-source front, our goal is to provide full transparency of our codebase and enable anyone in the community to build anything they want in an optimal secret management solution. If you need any feature or integration that we don\u2019t yet support, you can post an issue about it or directly send in a PR to be reviewed immediately.<p>You can inject the right set of secrets for any environment into your application by using the Infisical CLI together with your application start command (e.g. infisical run -- npm run dev). This removes the need to use a .env file. Everything stays encrypted with encryption&#x2F;decryption operations occurring on the client-side \u2014 under the hood, secrets are encrypted by vault keys for which there are multiple copies of vault keys encrypted under the public key of each member of a vault (ensuring only members of vaults can decrypt secrets pertaining to that vault locally). An alternative way is to use our Open API - though it\u2019s a little complicated, and we\u2019re working on adding SDKs to abstract away the cryptography.<p>Infisical integrates with staging and production cloud services like AWS, Vercel, GitHub Actions, and Circle CI. We also added support for integrations with Docker, Kubernetes, and Terraform. Infisical is now a central source of truth for secrets across the entire development cycle from development to production with new integration releases every week.\nOne interesting thing is that, by default, our platform is end-to-end encrypted but users can opt out of that if they need to integrate with cloud platforms that require secrets to be sent in decrypted format (e.g. GitHub Actions, Vercel, Render). We\u2019re the only solution that we know of that offers this E2EE-with opt-out ability.<p>Since our last Show HN (<a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34510516\" rel=\"nofollow\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34510516</a>), we\u2019ve layered authentication with 2FA (more MFA options coming soon) and upgraded all private key encryption&#x2F;decryption steps to involve a 256-bit protected key decrypted by another key generated via Argon2id KDF from the user\u2019s password. We are starting the process of obtaining SOC2 and other security and compliance certifications. You can read more about our security here: <a href=\"https:&#x2F;&#x2F;infisical.com&#x2F;docs&#x2F;security&#x2F;overview\">https:&#x2F;&#x2F;infisical.com&#x2F;docs&#x2F;security&#x2F;overview</a><p>Beyond this, we\u2019ve added integrations with PM2, AWS Secrets Manager, AWS Parameter Store, Circle CI, Travis CI, GitLab CI&#x2F;CD, Terraform and more. We\u2019ve also redesigned the main dashboard and added more advanced organizational structure for secrets. Lastly, we have added role-based access control, and improved our Kubernetes operator: your clusters are now auto-redeployed when secrets in Infisical change. In the coming weeks and months, we plan to add features like secret rotation, improved audit logs, SDKs and alerts; as well as increase the range of our integrations; and continue fortifying platform security and stability.<p>We\u2019ve launched this repo under the MIT license so any developer can use the platform. We don\u2019t charge individual developers or small teams\u2014all the integrations are fully available to everyone. We make money by charging a license fee for enterprise features as well as providing a hosted version and support.<p>If you found it interesting, you can see a demo video here: <a href=\"https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;9a8904c6ecc84d0899d53ee1f7a36385\" rel=\"nofollow\">https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;9a8904c6ecc84d0899d53ee1f7a36385</a><p>We\u2019d love for you to give Infisical a try (<a href=\"https:&#x2F;&#x2F;infisical.com\">https:&#x2F;&#x2F;infisical.com</a>) and provide any feedback. If you&#x27;re interested, our code is available here: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;infisical&#x2F;infisical\">https:&#x2F;&#x2F;github.com&#x2F;infisical&#x2F;infisical</a>. If we don\u2019t have something, let us know and we\u2019d be happy to build it for you. We look forward to your comments!", "title": "Launch HN: Infisical (YC W23) \u2013 Open-source secrets manager for developers", "updated_at": "2025-07-30T03:53:08Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "citguru"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["vault", "production"], "value": "Its been about 10 hours now that our core business operations is down because AWS security system decided that our account has unauthorized service usage and place a restriction on some part of services we can have access to.<p>One of them is obviously AWS Lambda. Two weeks ago we started processing large volume of transactions (We provide wallet and digital assets infrastructure for businesses) and needed to increase our services performance from request time out to memory to even our RDS instance to be able to accommodate the kind of requests we are currently processing.<p>However yesterday (29th of July) at around 5:04PM we got an email from AWS about unautorized service charges due to some unauthorized activity and could be a potential account hack or compromise.<p>My heart first sank because I was just waking up from a nap after reviewing the new lambda functions the teams worked on and planning to promote to <em>production</em> and staging server.<p>The second is this is a very high risk security issues and could be a potential hack. We primarily use MPC base <em>vault</em> to securely store and process transactions. Regardless, this is a very a big issue and had to respond by first of all changing the root passwords, deactivating all API keys, disabling console login access for all other users and removing any type of old keys.<p>After doing this will at least help secure our account for the main time. But then I was curious as well since the suspected activity is because of the unauthorized service charge, decided to go check all services from each region and end up checking our AWS Bill and carefully looking at the bill.<p>At the end it's a bill the team expected following our new changes from increasing our lambda function memory to time out and upgrading our RDS instance, the bill basically makes sense. AWS must have mistakenly detected this as unauthorized charge.<p>However the issue here is it's been 10 hours, and we have literally lost access to AWS Lambda functions the moment they notified us of this issues and one of our core business solutions is down because AWS shut it down.<p>The customer support experience from the AWS support team is the worst I have seen in my entire life. This is outrageous and never wished anyone to experience this. For over 10 hours, our customers (businesses such as payment gateway and exchanges) can't run some business operations because the lambda service (which cant be easily migrated to another alternative service) is down.<p>Their team keep saying they are waiting for their internal team response for over hours and no good response yet. They didn't provide a valid reason nor why this is taking too much time to fix. Its like they are lack of empathy and just robots behind the keyboards.<p>The AWS Support team are very heartless with no sense of urgency and this is not the first time such encounter is happening.<p>This has taught us a lesson not to build our product to be tightly locked with a cloud provider as migrating would be like starting from scratch and be more complicated.<p>If you work in AWS, the technical support team or customer support team and you would like to help us get past this. Please you can reach out here: hi[[at]]powr[[dot]]finance.<p>Thanks."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Tell HN: Worst AWS service and support team experience"}}, "_tags": ["story", "author_citguru", "story_31928266", "ask_hn"], "author": "citguru", "children": [31928701, 31928716, 31928830, 31928892, 31928954, 31929117, 31929660, 31929866, 31929884, 31935874], "created_at": "2022-06-30T02:47:49Z", "created_at_i": 1656557269, "num_comments": 20, "objectID": "31928266", "points": 27, "story_id": 31928266, "story_text": "Its been about 10 hours now that our core business operations is down because AWS security system decided that our account has unauthorized service usage and place a restriction on some part of services we can have access to.<p>One of them is obviously AWS Lambda. Two weeks ago we started processing large volume of transactions (We provide wallet and digital assets infrastructure for businesses) and needed to increase our services performance from request time out to memory to even our RDS instance to be able to accommodate the kind of requests we are currently processing.<p>However yesterday (29th of July) at around 5:04PM we got an email from AWS about unautorized service charges due to some unauthorized activity and could be a potential account hack or compromise.<p>My heart first sank because I was just waking up from a nap after reviewing the new lambda functions the teams worked on and planning to promote to production and staging server.<p>The second is this is a very high risk security issues and could be a potential hack. We primarily use MPC base vault to securely store and process transactions. Regardless, this is a very a big issue and had to respond by first of all changing the root passwords, deactivating all API keys, disabling console login access for all other users and removing any type of old keys.<p>After doing this will at least help secure our account for the main time. But then I was curious as well since the suspected activity is because of the unauthorized service charge, decided to go check all services from each region and end up checking our AWS Bill and carefully looking at the bill.<p>At the end it&#x27;s a bill the team expected following our new changes from increasing our lambda function memory to time out and upgrading our RDS instance, the bill basically makes sense. AWS must have mistakenly detected this as unauthorized charge.<p>However the issue here is it&#x27;s been 10 hours, and we have literally lost access to AWS Lambda functions the moment they notified us of this issues and one of our core business solutions is down because AWS shut it down.<p>The customer support experience from the AWS support team is the worst I have seen in my entire life. This is outrageous and never wished anyone to experience this. For over 10 hours, our customers (businesses such as payment gateway and exchanges) can&#x27;t run some business operations because the lambda service (which cant be easily migrated to another alternative service) is down.<p>Their team keep saying they are waiting for their internal team response for over hours and no good response yet. They didn&#x27;t provide a valid reason nor why this is taking too much time to fix. Its like they are lack of empathy and just robots behind the keyboards.<p>The AWS Support team are very heartless with no sense of urgency and this is not the first time such encounter is happening.<p>This has taught us a lesson not to build our product to be tightly locked with a cloud provider as migrating would be like starting from scratch and be more complicated.<p>If you work in AWS, the technical support team or customer support team and you would like to help us get past this. Please you can reach out here: hi[[at]]powr[[dot]]finance.<p>Thanks.", "title": "Tell HN: Worst AWS service and support team experience", "updated_at": "2024-09-20T11:27:42Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "pacmansyyu"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["vault", "production"], "value": "Hi HN, I've been building this tool for the past couple of weeks to solve a problem that seems universal across development teams: sharing environment variables securely.<p>You know the drill - someone needs the staging database URL, so it gets shared over chat. <em>Production</em> API keys end up in plaintext files. Or you set up some complex secret management system that becomes a single point of failure during critical deployments.<p>At Zerodha, we're a stock broker with strict regulatory requirements. Our infrastructure needs to be auditable, and our data must stay with us for instant recovery. But the deeper issue was that every solution we tried made deployments dependent on external services.<p>We tried GitLab CI's built-in secrets, but they're stored unencrypted and only repository maintainers can access them. HashiCorp <em>Vault</em> was too complex to manage with painful ACL setup, plus it's now crippled by their BSL license change. AWS Secrets Manager would create the vendor lock-in we wanted to avoid.<p>The breaking point came when we wanted to manage secrets through Terraform for idempotency and better infrastructure-as-code practices. But Terraform has no built-in way to encrypt secrets without relying on external providers. We could either store secrets in plaintext in our Terraform configs or add yet another external dependency to our deployment pipeline.<p>That's when I had the idea: what if we could inject encrypted environment variables directly into Terraform, so anyone with the right key could deploy without hunting down secrets from different systems? As I iterated through this idea, I realized the same pattern would work for any application - from personal projects to team deployments.<p>So I built kiln. It encrypts environment variables using age encryption into files that live alongside your code. No servers, no network calls, no external dependencies. Each team member gets their own key, and you control access per environment.<p>Here's how it works:<p><pre><code>  # Generate a new age key, or use your existing SSH keys\n  kiln init key\n  \n  # Initialize with your team's public keys\n  kiln init config --recipients &quot;alice=$(curl https://gitlab.company/alice.keys)&quot; --recipients &quot;me=$(cat ~/.ssh/id_ed25519.pub)&quot;\n  \n  # Set secrets (prompts securely, never shows in terminal)\n  kiln set DATABASE_URL\n  kiln set API_KEY\n  \n  # Run your app with decrypted environment\n  kiln run npm start\n  \n\n  # These encrypted files are safe to commit\n  git add .kiln.env kiln.toml\n\n</code></pre>\nWhy not SOPS? SOPS is great for general file encryption, but kiln is built specifically for the environment variable workflow. It has commands like &quot;run&quot;, &quot;export&quot;, and built-in team management. Think &quot;SOPS for .env files&quot; with a focus on developer UX.<p>Why not raw age encryption? Age is perfect for the crypto layer, but terrible for day-to-day team workflows. Try managing 20 team members across 5 environments with raw age commands - you'll go insane. kiln handles the orchestration.<p>As for technical details, kiln:<p>- Uses age encryption (modern, audited, simple)<p>- Works with existing SSH keys or generates new age keys<p>- Role-based access via TOML configuration<p>- Single, cross-platform Go binary<p>- Zero network dependencies - everything works offline<p>- MIT licensed<p>The game-changer: secrets travel with code. No more &quot;can someone send me the staging secrets?&quot; in chat. No more broken deploys because the secret service is down. No more hoping your vendor doesn't change their pricing or licensing.<p>Try it out - I'm confident it'll help improve your team's deployment workflows. Feel free to ask me any questions!<p>GitHub: <a href=\"https://github.com/thunderbottom/kiln\">https://github.com/thunderbottom/kiln</a><p>Docs: <a href=\"https://kiln.sh\" rel=\"nofollow\">https://kiln.sh</a><p>Or install now: go install github.com/thunderbottom/kiln@latest"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: kiln \u2013 Git-native, decentralized secret management using age"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://kiln.sh/"}}, "_tags": ["story", "author_pacmansyyu", "story_44594367", "show_hn"], "author": "pacmansyyu", "children": [44594618], "created_at": "2025-07-17T15:23:24Z", "created_at_i": 1752765804, "num_comments": 2, "objectID": "44594367", "points": 12, "story_id": 44594367, "story_text": "Hi HN, I&#x27;ve been building this tool for the past couple of weeks to solve a problem that seems universal across development teams: sharing environment variables securely.<p>You know the drill - someone needs the staging database URL, so it gets shared over chat. Production API keys end up in plaintext files. Or you set up some complex secret management system that becomes a single point of failure during critical deployments.<p>At Zerodha, we&#x27;re a stock broker with strict regulatory requirements. Our infrastructure needs to be auditable, and our data must stay with us for instant recovery. But the deeper issue was that every solution we tried made deployments dependent on external services.<p>We tried GitLab CI&#x27;s built-in secrets, but they&#x27;re stored unencrypted and only repository maintainers can access them. HashiCorp Vault was too complex to manage with painful ACL setup, plus it&#x27;s now crippled by their BSL license change. AWS Secrets Manager would create the vendor lock-in we wanted to avoid.<p>The breaking point came when we wanted to manage secrets through Terraform for idempotency and better infrastructure-as-code practices. But Terraform has no built-in way to encrypt secrets without relying on external providers. We could either store secrets in plaintext in our Terraform configs or add yet another external dependency to our deployment pipeline.<p>That&#x27;s when I had the idea: what if we could inject encrypted environment variables directly into Terraform, so anyone with the right key could deploy without hunting down secrets from different systems? As I iterated through this idea, I realized the same pattern would work for any application - from personal projects to team deployments.<p>So I built kiln. It encrypts environment variables using age encryption into files that live alongside your code. No servers, no network calls, no external dependencies. Each team member gets their own key, and you control access per environment.<p>Here&#x27;s how it works:<p><pre><code>  # Generate a new age key, or use your existing SSH keys\n  kiln init key\n  \n  # Initialize with your team&#x27;s public keys\n  kiln init config --recipients &quot;alice=$(curl https:&#x2F;&#x2F;gitlab.company&#x2F;alice.keys)&quot; --recipients &quot;me=$(cat ~&#x2F;.ssh&#x2F;id_ed25519.pub)&quot;\n  \n  # Set secrets (prompts securely, never shows in terminal)\n  kiln set DATABASE_URL\n  kiln set API_KEY\n  \n  # Run your app with decrypted environment\n  kiln run npm start\n  \n\n  # These encrypted files are safe to commit\n  git add .kiln.env kiln.toml\n\n</code></pre>\nWhy not SOPS? SOPS is great for general file encryption, but kiln is built specifically for the environment variable workflow. It has commands like &quot;run&quot;, &quot;export&quot;, and built-in team management. Think &quot;SOPS for .env files&quot; with a focus on developer UX.<p>Why not raw age encryption? Age is perfect for the crypto layer, but terrible for day-to-day team workflows. Try managing 20 team members across 5 environments with raw age commands - you&#x27;ll go insane. kiln handles the orchestration.<p>As for technical details, kiln:<p>- Uses age encryption (modern, audited, simple)<p>- Works with existing SSH keys or generates new age keys<p>- Role-based access via TOML configuration<p>- Single, cross-platform Go binary<p>- Zero network dependencies - everything works offline<p>- MIT licensed<p>The game-changer: secrets travel with code. No more &quot;can someone send me the staging secrets?&quot; in chat. No more broken deploys because the secret service is down. No more hoping your vendor doesn&#x27;t change their pricing or licensing.<p>Try it out - I&#x27;m confident it&#x27;ll help improve your team&#x27;s deployment workflows. Feel free to ask me any questions!<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;thunderbottom&#x2F;kiln\">https:&#x2F;&#x2F;github.com&#x2F;thunderbottom&#x2F;kiln</a><p>Docs: <a href=\"https:&#x2F;&#x2F;kiln.sh\" rel=\"nofollow\">https:&#x2F;&#x2F;kiln.sh</a><p>Or install now: go install github.com&#x2F;thunderbottom&#x2F;kiln@latest", "title": "Show HN: kiln \u2013 Git-native, decentralized secret management using age", "updated_at": "2025-07-17T18:04:21Z", "url": "https://kiln.sh/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "zifeo"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["vault", "production"], "value": "Hey everyone, we built Metatype [0] as a different way to build APIs and backends based on 3 parts:<p>1. a Python package to build virtual graphs connecting all components of your stack (think databases, third-parties, and existing systems)<p>2. an HTTP/GraphQL query engine built in Rust/Deno that authorizes and optimizes queries over the graphs<p>3. a CLI to provide a nice developer experience and fast feedback cycle<p>We developed this platform to tackle some of the challenges we often saw in tech teams we worked with:<p>- most developers (especially backend) still spend too much time on tasks with no real added value (crud, data validation, compliance, etc.)<p>- when growing a product, it is difficult keeping up with business needs and remaining agile/innovative with technology (especially when there is limited funding)<p>We believe it provides multiple advantages over more traditional approaches:<p>- it offers multiple runtimes [1] with pre-defined operations (e.g. Prisma) and can replace the needs for an ad-hoc backend<p>- when the project grows, you can easily introduce new APIs or break existing ones in smaller parts while keeping the same interface<p>- you can write complex business logic directly in Typescript, Python or WebAssembly and run them directly inside the query engine<p>- most of the frontend are today built on composable components, this brings a similar approach to backend development<p>- third-parties APIs can be easily integrated, providing you visibility and control over them<p>- it is interoperable with existing systems, and can be introduced step by step<p>- it can be easily self-hosted or customized according to your needs<p>The project is now in public beta, and is run in <em>production</em> by a few companies. We are looking to collect more feedback and early users to help us improve the platform.<p>For the tech curious reader, we also had to build a few new open source pieces to make this happen:<p>- a WASI runtime for Python [2] to run Python code inside WASM inside the engine<p>- a task runner [3] supporting live reload and managing dependencies as DAGs<p>- a way to inject secrets [4] from your preferred <em>vaults</em> into the engine<p>[0]: <a href=\"http://metatype.dev\" rel=\"nofollow\">http://metatype.dev</a>\n[1]: <a href=\"https://metatype.dev/docs/reference/runtimes\" rel=\"nofollow\">https://metatype.dev/docs/reference/runtimes</a>\n[2]: <a href=\"https://github.com/metatypedev/python-wasi-reactor\">https://github.com/metatypedev/python-wasi-reactor</a>\n[3]: <a href=\"https://github.com/zifeo/whiz\">https://github.com/zifeo/whiz</a>\n[4]: <a href=\"https://github.com/zifeo/lade\">https://github.com/zifeo/lade</a>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Metatype \u2013 an open-source HTTP/GraphQL query engine for APIs/data/WASM"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/metatypedev/metatype"}}, "_tags": ["story", "author_zifeo", "story_35980817", "show_hn"], "author": "zifeo", "children": [35980996, 35981706], "created_at": "2023-05-17T20:25:58Z", "created_at_i": 1684355158, "num_comments": 3, "objectID": "35980817", "points": 10, "story_id": 35980817, "story_text": "Hey everyone, we built Metatype [0] as a different way to build APIs and backends based on 3 parts:<p>1. a Python package to build virtual graphs connecting all components of your stack (think databases, third-parties, and existing systems)<p>2. an HTTP&#x2F;GraphQL query engine built in Rust&#x2F;Deno that authorizes and optimizes queries over the graphs<p>3. a CLI to provide a nice developer experience and fast feedback cycle<p>We developed this platform to tackle some of the challenges we often saw in tech teams we worked with:<p>- most developers (especially backend) still spend too much time on tasks with no real added value (crud, data validation, compliance, etc.)<p>- when growing a product, it is difficult keeping up with business needs and remaining agile&#x2F;innovative with technology (especially when there is limited funding)<p>We believe it provides multiple advantages over more traditional approaches:<p>- it offers multiple runtimes [1] with pre-defined operations (e.g. Prisma) and can replace the needs for an ad-hoc backend<p>- when the project grows, you can easily introduce new APIs or break existing ones in smaller parts while keeping the same interface<p>- you can write complex business logic directly in Typescript, Python or WebAssembly and run them directly inside the query engine<p>- most of the frontend are today built on composable components, this brings a similar approach to backend development<p>- third-parties APIs can be easily integrated, providing you visibility and control over them<p>- it is interoperable with existing systems, and can be introduced step by step<p>- it can be easily self-hosted or customized according to your needs<p>The project is now in public beta, and is run in production by a few companies. We are looking to collect more feedback and early users to help us improve the platform.<p>For the tech curious reader, we also had to build a few new open source pieces to make this happen:<p>- a WASI runtime for Python [2] to run Python code inside WASM inside the engine<p>- a task runner [3] supporting live reload and managing dependencies as DAGs<p>- a way to inject secrets [4] from your preferred vaults into the engine<p>[0]: <a href=\"http:&#x2F;&#x2F;metatype.dev\" rel=\"nofollow\">http:&#x2F;&#x2F;metatype.dev</a>\n[1]: <a href=\"https:&#x2F;&#x2F;metatype.dev&#x2F;docs&#x2F;reference&#x2F;runtimes\" rel=\"nofollow\">https:&#x2F;&#x2F;metatype.dev&#x2F;docs&#x2F;reference&#x2F;runtimes</a>\n[2]: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;metatypedev&#x2F;python-wasi-reactor\">https:&#x2F;&#x2F;github.com&#x2F;metatypedev&#x2F;python-wasi-reactor</a>\n[3]: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;zifeo&#x2F;whiz\">https:&#x2F;&#x2F;github.com&#x2F;zifeo&#x2F;whiz</a>\n[4]: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;zifeo&#x2F;lade\">https:&#x2F;&#x2F;github.com&#x2F;zifeo&#x2F;lade</a>", "title": "Show HN: Metatype \u2013 an open-source HTTP/GraphQL query engine for APIs/data/WASM", "updated_at": "2024-09-20T14:06:10Z", "url": "https://github.com/metatypedev/metatype"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "darksaints"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["vault", "production"], "value": "I'll start out by saying I'm not a security expert, but I know the basics that every engineer should know well and I've previously worked in high-threat environment companies with practically perfect track records, so I've seen what an effective security org does well. That being said, if what I'm saying is wrong, please point it out to me. I'd actually love to be wrong about this.<p>Background: Our security team has been nothing more than a fail factory for at least two decades now, with several high profile breaches. Like we could probably have our own dedicated section on `haveibeenpwned.com`. There was a recent shakeup,  the old team got fired en-masse, and a new team has taken their place. I will gladly admit that the old team needed to be fired, and the new team treats security as a top priority...it just that it seems like they're doing it all wrong.<p>Examples:<p>1) We have gone through 3 network security systems in 2 years. First a standard VPN, then a SDP. The most recent was some newer technology from a company I had never heard of, and only seems to be used at companies several times smaller than ours. Nobody can seem to explain how this software works or how it secures our network, but it has had several extreme unintended consequences, such as breaking local development environments with its custom MITM certificates, breaking automated security scanning software, occupying between 1-2 cores at 100% on our laptops, and worst of all, a whitelist-only access policy. The process for whitelisting a single site involves filling out a survey and writing an essay as to why we need to access it. In the past, when I have done this for things like access to documentation sites for open source software that we use in <em>production</em>, I have gotten blanket denials that have had to be escalated to the VP level. The people reviewing the requests don't seem to know anything about software or telecom at all, and yet they have very strong opinions on what is business critical or not. All to stop phishing, which is really strange because they have treated hardware MFA like an afterthought.<p>2) Our laptops have been locked down, and all admin privileges have been removed. We are to install all software via a software installer app. When we need new software, we have to request it to be added. This can take anywhere from several weeks to several months. If we request that software be updated to a newer version, it will take weeks. <i>Even if the reason for the update is due to security vulnerabilities</i>.<p>3) We have a new team dedicated to tracking PII. The way that they've implemented this is by having contractors contact database owners on slack and asking them for completely uninhibited permissions to scan our databases. When I pressed them for more information about how they store the credentials, they showed me how they collect and store them. I watched as they copied the credentials to their OneNote, then tested them out manually in DBeaver, then added them to a secure <em>vault</em>. There is probably a OneNote notebook floating around where one of these contractors has unrestricted database credentials to every database in the company.<p>This is just a sample due to the 4000 char limit. On top of making our day to day jobs a total nightmare, I feel bad for our customers. These policies have broken customer-facing software, and most of them appear to me to be a step backward in actual security. And any time that criticism happens, we get an extremely hostile and childish response, ranging from &quot;You don't know anything about security&quot; to &quot;If people would stop clicking on phishing links, we wouldn't have to do this&quot;. There is no forum for discussion of security policies, you either accept them or you are framed as part of the problem.<p>Have any of you ever dealt with this before? Is there a professional way to affect meaningful change without risking getting fired? Or do I have to accept that I have no control over the situation?"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: How to deal with a cybersecurity org that has jumped the shark?"}}, "_tags": ["story", "author_darksaints", "story_39982198", "ask_hn"], "author": "darksaints", "children": [39982264, 39982348, 39984065, 39984120, 39986991, 39989629], "created_at": "2024-04-09T17:59:54Z", "created_at_i": 1712685594, "num_comments": 8, "objectID": "39982198", "points": 8, "story_id": 39982198, "story_text": "I&#x27;ll start out by saying I&#x27;m not a security expert, but I know the basics that every engineer should know well and I&#x27;ve previously worked in high-threat environment companies with practically perfect track records, so I&#x27;ve seen what an effective security org does well. That being said, if what I&#x27;m saying is wrong, please point it out to me. I&#x27;d actually love to be wrong about this.<p>Background: Our security team has been nothing more than a fail factory for at least two decades now, with several high profile breaches. Like we could probably have our own dedicated section on `haveibeenpwned.com`. There was a recent shakeup,  the old team got fired en-masse, and a new team has taken their place. I will gladly admit that the old team needed to be fired, and the new team treats security as a top priority...it just that it seems like they&#x27;re doing it all wrong.<p>Examples:<p>1) We have gone through 3 network security systems in 2 years. First a standard VPN, then a SDP. The most recent was some newer technology from a company I had never heard of, and only seems to be used at companies several times smaller than ours. Nobody can seem to explain how this software works or how it secures our network, but it has had several extreme unintended consequences, such as breaking local development environments with its custom MITM certificates, breaking automated security scanning software, occupying between 1-2 cores at 100% on our laptops, and worst of all, a whitelist-only access policy. The process for whitelisting a single site involves filling out a survey and writing an essay as to why we need to access it. In the past, when I have done this for things like access to documentation sites for open source software that we use in production, I have gotten blanket denials that have had to be escalated to the VP level. The people reviewing the requests don&#x27;t seem to know anything about software or telecom at all, and yet they have very strong opinions on what is business critical or not. All to stop phishing, which is really strange because they have treated hardware MFA like an afterthought.<p>2) Our laptops have been locked down, and all admin privileges have been removed. We are to install all software via a software installer app. When we need new software, we have to request it to be added. This can take anywhere from several weeks to several months. If we request that software be updated to a newer version, it will take weeks. <i>Even if the reason for the update is due to security vulnerabilities</i>.<p>3) We have a new team dedicated to tracking PII. The way that they&#x27;ve implemented this is by having contractors contact database owners on slack and asking them for completely uninhibited permissions to scan our databases. When I pressed them for more information about how they store the credentials, they showed me how they collect and store them. I watched as they copied the credentials to their OneNote, then tested them out manually in DBeaver, then added them to a secure vault. There is probably a OneNote notebook floating around where one of these contractors has unrestricted database credentials to every database in the company.<p>This is just a sample due to the 4000 char limit. On top of making our day to day jobs a total nightmare, I feel bad for our customers. These policies have broken customer-facing software, and most of them appear to me to be a step backward in actual security. And any time that criticism happens, we get an extremely hostile and childish response, ranging from &quot;You don&#x27;t know anything about security&quot; to &quot;If people would stop clicking on phishing links, we wouldn&#x27;t have to do this&quot;. There is no forum for discussion of security policies, you either accept them or you are framed as part of the problem.<p>Have any of you ever dealt with this before? Is there a professional way to affect meaningful change without risking getting fired? Or do I have to accept that I have no control over the situation?", "title": "Ask HN: How to deal with a cybersecurity org that has jumped the shark?", "updated_at": "2024-09-20T16:54:32Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "gadr90"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["vault", "production"], "value": "Hey HN! I\u2019m Gui from deco (decocms.com). We\u2019ve been using this tool internally as the foundation for a few customer AI platforms, and today we\u2019re open-sourcing it as MCP Mesh.<p>MCP is quickly becoming the standard for agentic systems, but\u2026 once you go past a couple servers it turns into the same problems for every team:<p>- M\u00d7N config sprawl (every client wired to every server, each with its own JSON + ports + retries)\n- Token + tool bloat (dumping tool definitions into every prompt doesn\u2019t scale)\n- Credentials + blast radius (tokens scattered across clients, hard to audit, hard to revoke)\n- No single place to debug (latency, errors, \u201cwhat tool did it call, with what params?\u201d)<p>MCP Mesh sits between MCP clients and MCP servers and collapses that mess into one <em>production</em> endpoint you can actually operate.<p>What it does:<p>- One endpoint for Cursor / Claude / VS Code / custom agents \u2192 all MCP traffic routes through the mesh   \n- RBAC + policies + audit trails at the control plane (multi-tenant org/workspace/project scoping)   \n- Full observability with OpenTelemetry (traces, errors, latency, cost attribution)\n- Runtime strategies as \u201cgateways\u201d to deal with tool bloat: Full-context (small toolsets), Smart selection (narrow toolset before execution), Code execution (load tools on-demand / run code in a sandbox)   \n- Token <em>vault</em> + OAuth support, proxying remote servers without spraying secrets into every client   \n- MCP Apps + Bindings so apps can target capability contracts and you can swap MCP providers without rewriting everything<p>A small but surprisingly useful thing: the UI shows every call, input/output, who ran it, and lets you replay calls. This ended up being our \u201cWireshark for MCP\u201d during real workflows.<p>It\u2019s open-source + self-hosted (run locally with SQLite; Postgres or Supabase for prod).<p>You can start with `npx @decocms/mesh` or clone + run with Bun.<p>We\u2019d love your feedback!<p>Links below:<p>Repo: <a href=\"https://github.com/decocms/mesh\" rel=\"nofollow\">https://github.com/decocms/mesh</a><p>Landing: <a href=\"https://www.decocms.com/mcp-mesh\" rel=\"nofollow\">https://www.decocms.com/mcp-mesh</a><p>Blog post: <a href=\"https://www.decocms.com/blog/post/mcp-mesh\" rel=\"nofollow\">https://www.decocms.com/blog/post/mcp-mesh</a><p>edit: layout"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: MCP Mesh \u2013 one endpoint for all your MCP servers (OSS self-hosted)"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/decocms/mesh"}}, "_tags": ["story", "author_gadr90", "story_46435078", "show_hn"], "author": "gadr90", "children": [46440693], "created_at": "2025-12-30T16:42:46Z", "created_at_i": 1767112966, "num_comments": 0, "objectID": "46435078", "points": 8, "story_id": 46435078, "story_text": "Hey HN! I\u2019m Gui from deco (decocms.com). We\u2019ve been using this tool internally as the foundation for a few customer AI platforms, and today we\u2019re open-sourcing it as MCP Mesh.<p>MCP is quickly becoming the standard for agentic systems, but\u2026 once you go past a couple servers it turns into the same problems for every team:<p>- M\u00d7N config sprawl (every client wired to every server, each with its own JSON + ports + retries)\n- Token + tool bloat (dumping tool definitions into every prompt doesn\u2019t scale)\n- Credentials + blast radius (tokens scattered across clients, hard to audit, hard to revoke)\n- No single place to debug (latency, errors, \u201cwhat tool did it call, with what params?\u201d)<p>MCP Mesh sits between MCP clients and MCP servers and collapses that mess into one production endpoint you can actually operate.<p>What it does:<p>- One endpoint for Cursor &#x2F; Claude &#x2F; VS Code &#x2F; custom agents \u2192 all MCP traffic routes through the mesh   \n- RBAC + policies + audit trails at the control plane (multi-tenant org&#x2F;workspace&#x2F;project scoping)   \n- Full observability with OpenTelemetry (traces, errors, latency, cost attribution)\n- Runtime strategies as \u201cgateways\u201d to deal with tool bloat: Full-context (small toolsets), Smart selection (narrow toolset before execution), Code execution (load tools on-demand &#x2F; run code in a sandbox)   \n- Token vault + OAuth support, proxying remote servers without spraying secrets into every client   \n- MCP Apps + Bindings so apps can target capability contracts and you can swap MCP providers without rewriting everything<p>A small but surprisingly useful thing: the UI shows every call, input&#x2F;output, who ran it, and lets you replay calls. This ended up being our \u201cWireshark for MCP\u201d during real workflows.<p>It\u2019s open-source + self-hosted (run locally with SQLite; Postgres or Supabase for prod).<p>You can start with `npx @decocms&#x2F;mesh` or clone + run with Bun.<p>We\u2019d love your feedback!<p>Links below:<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;decocms&#x2F;mesh\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;decocms&#x2F;mesh</a><p>Landing: <a href=\"https:&#x2F;&#x2F;www.decocms.com&#x2F;mcp-mesh\" rel=\"nofollow\">https:&#x2F;&#x2F;www.decocms.com&#x2F;mcp-mesh</a><p>Blog post: <a href=\"https:&#x2F;&#x2F;www.decocms.com&#x2F;blog&#x2F;post&#x2F;mcp-mesh\" rel=\"nofollow\">https:&#x2F;&#x2F;www.decocms.com&#x2F;blog&#x2F;post&#x2F;mcp-mesh</a><p>edit: layout", "title": "Show HN: MCP Mesh \u2013 one endpoint for all your MCP servers (OSS self-hosted)", "updated_at": "2026-01-02T00:32:25Z", "url": "https://github.com/decocms/mesh"}], "hitsPerPage": 15, "nbHits": 61, "nbPages": 5, "page": 0, "params": "query=vault+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 9, "processingTimingsMS": {"_request": {"roundTrip": 16}, "afterFetch": {"format": {"highlighting": 1, "total": 2}}, "fetch": {"query": 5, "scanning": 2, "total": 8}, "total": 9}, "query": "vault production", "serverTimeMS": 11}}