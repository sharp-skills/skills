{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "level09"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["websockets", "production"], "value": "Running a <em>production</em>-grade <em>WebSockets</em> server with your Python apps"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["websockets", "production"], "value": "https://medium.com/@level09/a-<em>production</em>-grade-<em>websockets</em>-setup-with-nginx-uwsgi-and-python-c1300fa90e43"}}, "_tags": ["story", "author_level09", "story_28584067"], "author": "level09", "created_at": "2021-09-19T13:12:08Z", "created_at_i": 1632057128, "num_comments": 0, "objectID": "28584067", "points": 1, "story_id": 28584067, "title": "Running a production-grade WebSockets server with your Python apps", "updated_at": "2024-09-20T09:30:07Z", "url": "https://medium.com/@level09/a-production-grade-websockets-setup-with-nginx-uwsgi-and-python-c1300fa90e43"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "edouardb"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["websockets", "production"], "value": "Hi HN!<p>We\u2019re Yann, Edouard, and Bastien from Koyeb (<a href=\"https://www.koyeb.com/\" rel=\"nofollow noreferrer\">https://www.koyeb.com/</a>). We\u2019re building a platform to let you push code to <em>production</em>, everywhere, and on high-performance hardware, in minutes. We aim to provide a \u201cglobal serverless feeling\u201d, without the hassle of re-writing all your apps or managing k8s complexity [1].<p>We built Scaleway, a cloud service provider where we designed ARM servers and provided them as cloud servers. During our time there, we saw customers struggle with the same issues while trying to deploy full-stack applications and APIs resiliently. As it turns out, deploying applications and managing networking across a multi-data center fleet of machines (virtual or physical) requires an overwhelming amount of orchestration and configuration. At the time, that complexity meant that multi-region deployments were simply out-of-reach for most businesses.<p>When thinking about how we wanted to solve those problems, we tried several solutions. We briefly explored offering a FaaS experience [2], but from our first steps, user feedback made us reconsider whether it was the correct abstraction. In most cases, it seemed that functions simply added complexity and required learning how to engineer using provider-specific primitives. In many ways, developing with functions felt like abandoning all of the benefits of frameworks.<p>Another popular option these days is to go with Kubernetes. From an engineering perspective, Kubernetes is extremely powerful, but it also involves massive amounts of overhead. Building software, managing networking, and deploying across regions involves integrating many different components and maintaining them over time. It can be tough to justify the level of effort and investment it takes to keep it all running rather than work on building out your product.<p>We believe you should be able to write your apps and run them without modification with simple scaling, global distribution transparently managed by the provider, and no infrastructure or orchestration management.<p>Koyeb is a cloud platform where you come with a git repository or a Docker image, we build the code into a container (when needed), run the container inside of Firecracker microVMs, and deploy it to multiple regions on top of bare metal servers. There is an edge network in front to accelerate delivery and a global networking layer for inter-service communication (service mesh/discovery) [3].<p>We took a few steps to get the Koyeb platform to where it is today: we built our own serverless engine [4]. We use Nomad and Firecracker for orchestration, and Kuma for the networking layer. In the last year, we spawned two regions in Washington, DC and Frankfurt, added support for native workers, gRPC, HTTP/2 [5], <em>WebSockets</em>, and custom health checks. We are working next on databases, autoscaling, and adding four new regions (US West, Singapore, Tokyo, and Paris).<p>We\u2019re super excited to show you Koyeb today and we\u2019d love to hear your thoughts on the platform and what we are building in the comments. To make getting started easy, we provide $5.50 in free credits every month so you can run up to two services for free.<p>P.S. A payment method is required to access the platform to prevent abuse (we had hard months last year dealing with that). If you\u2019d like to try the platform without adding a card, reach out at support@koyeb.com or @gokoyeb on Twitter.<p>[1] <a href=\"https://www.koyeb.com/blog/the-true-cost-of-kubernetes-people-time-and-productivity\" rel=\"nofollow noreferrer\">https://www.koyeb.com/blog/the-true-cost-of-kubernetes-peopl...</a>\n[2] <a href=\"https://www.koyeb.com/blog/the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions\" rel=\"nofollow noreferrer\">https://www.koyeb.com/blog/the-koyeb-serverless-engine-docke...</a>\n[3] <a href=\"https://www.koyeb.com/blog/building-a-multi-region-service-mesh-with-kuma-envoy-anycast-bgp-and-mtls\" rel=\"nofollow noreferrer\">https://www.koyeb.com/blog/building-a-multi-region-service-m...</a>\n[4] <a href=\"https://www.koyeb.com/blog/the-koyeb-serverless-engine-from-kubernetes-to-nomad-firecracker-and-kuma\" rel=\"nofollow noreferrer\">https://www.koyeb.com/blog/the-koyeb-serverless-engine-from-...</a>\n[5] <a href=\"https://www.koyeb.com/blog/enabling-grpc-and-http2-support-at-edge-with-kuma-and-envoy\" rel=\"nofollow noreferrer\">https://www.koyeb.com/blog/enabling-grpc-and-http2-support-a...</a>"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Show HN: Koyeb \u2013 Deploy code to <em>production</em>, everywhere, in minutes"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://www.koyeb.com"}}, "_tags": ["story", "author_edouardb", "story_36815923", "show_hn"], "author": "edouardb", "created_at": "2023-07-21T16:33:38Z", "created_at_i": 1689957218, "num_comments": 0, "objectID": "36815923", "points": 6, "story_id": 36815923, "story_text": "Hi HN!<p>We\u2019re Yann, Edouard, and Bastien from Koyeb (<a href=\"https:&#x2F;&#x2F;www.koyeb.com&#x2F;\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;www.koyeb.com&#x2F;</a>). We\u2019re building a platform to let you push code to production, everywhere, and on high-performance hardware, in minutes. We aim to provide a \u201cglobal serverless feeling\u201d, without the hassle of re-writing all your apps or managing k8s complexity [1].<p>We built Scaleway, a cloud service provider where we designed ARM servers and provided them as cloud servers. During our time there, we saw customers struggle with the same issues while trying to deploy full-stack applications and APIs resiliently. As it turns out, deploying applications and managing networking across a multi-data center fleet of machines (virtual or physical) requires an overwhelming amount of orchestration and configuration. At the time, that complexity meant that multi-region deployments were simply out-of-reach for most businesses.<p>When thinking about how we wanted to solve those problems, we tried several solutions. We briefly explored offering a FaaS experience [2], but from our first steps, user feedback made us reconsider whether it was the correct abstraction. In most cases, it seemed that functions simply added complexity and required learning how to engineer using provider-specific primitives. In many ways, developing with functions felt like abandoning all of the benefits of frameworks.<p>Another popular option these days is to go with Kubernetes. From an engineering perspective, Kubernetes is extremely powerful, but it also involves massive amounts of overhead. Building software, managing networking, and deploying across regions involves integrating many different components and maintaining them over time. It can be tough to justify the level of effort and investment it takes to keep it all running rather than work on building out your product.<p>We believe you should be able to write your apps and run them without modification with simple scaling, global distribution transparently managed by the provider, and no infrastructure or orchestration management.<p>Koyeb is a cloud platform where you come with a git repository or a Docker image, we build the code into a container (when needed), run the container inside of Firecracker microVMs, and deploy it to multiple regions on top of bare metal servers. There is an edge network in front to accelerate delivery and a global networking layer for inter-service communication (service mesh&#x2F;discovery) [3].<p>We took a few steps to get the Koyeb platform to where it is today: we built our own serverless engine [4]. We use Nomad and Firecracker for orchestration, and Kuma for the networking layer. In the last year, we spawned two regions in Washington, DC and Frankfurt, added support for native workers, gRPC, HTTP&#x2F;2 [5], WebSockets, and custom health checks. We are working next on databases, autoscaling, and adding four new regions (US West, Singapore, Tokyo, and Paris).<p>We\u2019re super excited to show you Koyeb today and we\u2019d love to hear your thoughts on the platform and what we are building in the comments. To make getting started easy, we provide $5.50 in free credits every month so you can run up to two services for free.<p>P.S. A payment method is required to access the platform to prevent abuse (we had hard months last year dealing with that). If you\u2019d like to try the platform without adding a card, reach out at support@koyeb.com or @gokoyeb on Twitter.<p>[1] <a href=\"https:&#x2F;&#x2F;www.koyeb.com&#x2F;blog&#x2F;the-true-cost-of-kubernetes-people-time-and-productivity\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;www.koyeb.com&#x2F;blog&#x2F;the-true-cost-of-kubernetes-peopl...</a>\n[2] <a href=\"https:&#x2F;&#x2F;www.koyeb.com&#x2F;blog&#x2F;the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;www.koyeb.com&#x2F;blog&#x2F;the-koyeb-serverless-engine-docke...</a>\n[3] <a href=\"https:&#x2F;&#x2F;www.koyeb.com&#x2F;blog&#x2F;building-a-multi-region-service-mesh-with-kuma-envoy-anycast-bgp-and-mtls\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;www.koyeb.com&#x2F;blog&#x2F;building-a-multi-region-service-m...</a>\n[4] <a href=\"https:&#x2F;&#x2F;www.koyeb.com&#x2F;blog&#x2F;the-koyeb-serverless-engine-from-kubernetes-to-nomad-firecracker-and-kuma\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;www.koyeb.com&#x2F;blog&#x2F;the-koyeb-serverless-engine-from-...</a>\n[5] <a href=\"https:&#x2F;&#x2F;www.koyeb.com&#x2F;blog&#x2F;enabling-grpc-and-http2-support-at-edge-with-kuma-and-envoy\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;www.koyeb.com&#x2F;blog&#x2F;enabling-grpc-and-http2-support-a...</a>", "title": "Show HN: Koyeb \u2013 Deploy code to production, everywhere, in minutes", "updated_at": "2024-09-20T14:34:35Z", "url": "https://www.koyeb.com"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "kobaltz"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["websockets", "production"], "value": "[Screencast] Faye <em>WebSockets</em> \u2013 Part 2 \u2013 Setting Up the Faye Server in <em>Production</em>"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["websockets"], "value": "https://www.driftingruby.com/episodes/faye-<em>websockets</em>-part-2"}}, "_tags": ["story", "author_kobaltz", "story_11519060"], "author": "kobaltz", "created_at": "2016-04-18T11:32:17Z", "created_at_i": 1460979137, "num_comments": 0, "objectID": "11519060", "points": 1, "story_id": 11519060, "title": "[Screencast] Faye WebSockets \u2013 Part 2 \u2013 Setting Up the Faye Server in Production", "updated_at": "2024-09-19T23:04:54Z", "url": "https://www.driftingruby.com/episodes/faye-websockets-part-2"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "levkk"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["websockets", "production"], "value": "Hi everyone,<p>I've been &quot;funemployed&quot; for a few months and with all that free time and idle hands I wrote a full web framework (think Rails, not Flask) for Rust.<p>It's boring old MVC, has its own ORM, templates, background jobs, auth, <em>websockets</em>, migrations and more. If you're keen but don't feel like rewriting your app in a different language, Rwf has a WSGI server to run Django (or Flask) inside Rust [1], letting you migrate to Rust at your own pace without disrupting your website.<p>I think Rust makes a great prototyping and deploy straight to <em>production</em> language. Now it has yet another framework for y'all to play with.<p>Cheers!<p>[1] <a href=\"https://levkk.github.io/rwf/migrating-from-python/\" rel=\"nofollow\">https://levkk.github.io/rwf/migrating-from-python/</a>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Rust Web Framework"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/levkk/rwf"}}, "_tags": ["story", "author_levkk", "story_41914544", "show_hn"], "author": "levkk", "children": [41914664, 41914675, 41914719, 41914746, 41914761, 41914763, 41914951, 41914959, 41914974, 41914981, 41915030, 41915033, 41915053, 41915116, 41915126, 41915136, 41915193, 41915225, 41915331, 41915387, 41915481, 41915736, 41915779, 41915784, 41916652, 41917290, 41917323, 41917536, 41917561, 41917679, 41917725, 41918459, 41918799, 41918890, 41919064, 41919546, 41919804, 41921213, 41921808, 41921880, 41922263, 41923666, 41923896, 41924477, 41932944], "created_at": "2024-10-22T14:15:54Z", "created_at_i": 1729606554, "num_comments": 258, "objectID": "41914544", "points": 488, "story_id": 41914544, "story_text": "Hi everyone,<p>I&#x27;ve been &quot;funemployed&quot; for a few months and with all that free time and idle hands I wrote a full web framework (think Rails, not Flask) for Rust.<p>It&#x27;s boring old MVC, has its own ORM, templates, background jobs, auth, websockets, migrations and more. If you&#x27;re keen but don&#x27;t feel like rewriting your app in a different language, Rwf has a WSGI server to run Django (or Flask) inside Rust [1], letting you migrate to Rust at your own pace without disrupting your website.<p>I think Rust makes a great prototyping and deploy straight to production language. Now it has yet another framework for y&#x27;all to play with.<p>Cheers!<p>[1] <a href=\"https:&#x2F;&#x2F;levkk.github.io&#x2F;rwf&#x2F;migrating-from-python&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;levkk.github.io&#x2F;rwf&#x2F;migrating-from-python&#x2F;</a>", "title": "Show HN: Rust Web Framework", "updated_at": "2025-06-03T12:11:14Z", "url": "https://github.com/levkk/rwf"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "jahooma"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["websockets", "production"], "value": "Hey HN! We\u2019re James and Brandon building Codebuff (<a href=\"https://codebuff.com\">https://codebuff.com</a>). Codebuff is like Cursor Composer, but in your terminal: it modifies files based on your natural language requests. You can try it with `npm i -g codebuff` and start using it immediately for free. We have no login gate, and we give all accounts up to $20 worth of credits.<p>Codebuff is different because we simplified the input to one step: you type what you want done in your terminal and hit enter. Then Codebuff looks through your whole codebase and makes the edits it wants, to existing source files or new ones. It also can run your tests, the type checker, or install packages to fulfill your request.<p>Demo video: <a href=\"https://www.youtube.com/watch?v=dQ0NOMsu0dA\" rel=\"nofollow\">https://www.youtube.com/watch?v=dQ0NOMsu0dA</a><p>It all started at a hackathon. I was trying out Sonnet 3.5 which had recently come out and seeing if I could use it to write code. The script I cobbled together that day pulled codebase context in one step and used it to rewrite files with changes in the second step. This two step process still exists today. Incidentally, my hackathon script worked rather poorly and my demo failed to produce any useful code.<p>But that weekend I thought about the kind of errors it made, and realized that with more context on our codebase, it might have been able to get the change right. For example, it tried to create an endpoint on our server (at my previous startup), but it didn't know that you needed to edit 3 specific files to do this (yeah... our backend was not that clean). So I hand-wrote a guide to our codebase, like I was instructing a new hire. I put it in a markdown file and passed it into Sonnet 3.5's system prompt.  And the crazy thing is that it started producing wayyy better code. So, I started getting excited. In fact, this code guide idea still exists in Codebuff today as knowledge.md files which are automatically read on every request.<p>I didn't think of this project as a startup idea at first. I thought it was just a simple script anyone could write. But after another week, I could see there were more problems to solve and it should be a product.<p>In the week between applying to YC and the interview, I could not get Codebuff to edit files consistently. I tried many prompting strategies to get it to replace strings in the original file, but nothing worked reliably. How could I face my interviewer if I could not get something basic like this to work? On the day before my interview, in a Hail Mary attempt, I fine-tuned GPT-4o to turn Claude's sketch of changes into a git patch, which would add and remove lines to make the edits. I only finished generating the training data late at night, and the fine-tuning job ran as I slept.<p>And, holy hell, the next morning it worked! I pushed it to <em>production</em> just in time for my YC interview with Dalton. Soon after, Brandon joined and we were off to the races.<p>So, how does Codebuff work exactly? You invoke it in your terminal, and it starts by running through the source files in that directory and subdirectories and parsing out all the function and class names (or equivalents in 11 languages). We use the tree-sitter library to do this. It builds out a codebase map that includes these symbols and the file tree.<p>Then, it fires off a request to Claude Haiku 3.5 to cache this codebase context so user inputs can be responded to with lower latency. (Prompt caching is OP!). We have a stateless server that passes messages along to Anthropic or OpenAI. We use <em>websockets</em> to ferry data back and forth to clients. We didn't have authentication or even a database for the first three months. Codebuff was free to install and used our API keys for all requests. Luckily, no one exploited us for too much free Claude usage haha. Major thanks to Brandon for saving this situation by building out our database (Postgres + Drizzle), server (Bun, hosted on Render, auth (using the free Auth.js), website (NextJS also hosted on Render), billing (Stripe), logging (BetterStack), and dashboard (Retool). This is the best tech stack I\u2019ve ever had.<p>When the user sends an input message, we prompt Claude to pick files that would be relevant (step 1). After picking files, we load them into context and the agent responds. It invokes tools using xml tags that we parse. It literally writes out &lt;edit_file path=&quot;src/app.ts&quot;&gt;\u2026&lt;/edit_file&gt; to edit a particular file, and has other tags to run terminal commands, or to ask to read more files. This is all we really need, since Anthropic has already trained Claude with very similar tools reach state of the art on the SWE benchmark.<p>Codebuff has limited free usage, but if you like it you can pay $99/mo to get more credits. We realize this is a lot more than competitors, but that\u2019s because we do more expensive LLM calls with more context.<p>We\u2019re already seeing Codebuff used in surprising ways. One user racked up a $500 bill by building out two Flutter apps in parallel. He never even looked at the code it generated. Instead, he had long conversations with Codebuff to make progress and fix errors, until the apps were built to his satisfaction. Many users built real apps over a weekend for their teams and personal use.<p>Of course, those aren't the typical use cases. Users also frequently use Codebuff to write unit tests. They would build a feature in parallel with unit tests and have Codebuff do loops to fix up the code until the tests pass. They would also ask it to do drudge work like set up Oauth flows or API scaffolding.<p>What's really exciting with all of these examples is that we're seeing people's creativity becoming unbridled. They're spending more of their time thinking about architecture and design, instead of implementation details. It's so cool that we're just at the beginning, and the technology is only going to improve from here.<p>If you would want to use Codebuff inside your own systems, we have an alpha SDK that exposes the same natural language interface for your apps to call and receive code edits! You can sign up here for early access: <a href=\"https://codebuff.retool.com/form/c8b15919-52d0-4572-aca5-533317403dde\" rel=\"nofollow\">https://codebuff.retool.com/form/c8b15919-52d0-4572-aca5-533...</a>.<p>Thank you for reading! We\u2019re excited for you to try out Codebuff and let us know what you think!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: Codebuff (YC F24) \u2013 CLI tool that writes code for you"}}, "_tags": ["story", "author_jahooma", "story_42078536", "launch_hn"], "author": "jahooma", "children": [42079651, 42079684, 42079745, 42079755, 42079760, 42079761, 42079801, 42079914, 42079916, 42079974, 42080002, 42080028, 42080038, 42080048, 42080181, 42080202, 42080304, 42080313, 42080345, 42080370, 42080643, 42080763, 42080857, 42080940, 42081003, 42081027, 42081067, 42081081, 42081099, 42081197, 42081263, 42081354, 42081471, 42081513, 42081809, 42081925, 42081993, 42082073, 42082218, 42082424, 42082450, 42082536, 42082857, 42082957, 42083312, 42083320, 42083609, 42083688, 42083836, 42084139, 42084221, 42084233, 42084438, 42084508, 42084510, 42084939, 42086083, 42086943, 42087022, 42087814, 42087956, 42088355, 42094932, 42186644], "created_at": "2024-11-07T17:06:28Z", "created_at_i": 1730999188, "num_comments": 239, "objectID": "42078536", "points": 285, "story_id": 42078536, "story_text": "Hey HN! We\u2019re James and Brandon building Codebuff (<a href=\"https:&#x2F;&#x2F;codebuff.com\">https:&#x2F;&#x2F;codebuff.com</a>). Codebuff is like Cursor Composer, but in your terminal: it modifies files based on your natural language requests. You can try it with `npm i -g codebuff` and start using it immediately for free. We have no login gate, and we give all accounts up to $20 worth of credits.<p>Codebuff is different because we simplified the input to one step: you type what you want done in your terminal and hit enter. Then Codebuff looks through your whole codebase and makes the edits it wants, to existing source files or new ones. It also can run your tests, the type checker, or install packages to fulfill your request.<p>Demo video: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=dQ0NOMsu0dA\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=dQ0NOMsu0dA</a><p>It all started at a hackathon. I was trying out Sonnet 3.5 which had recently come out and seeing if I could use it to write code. The script I cobbled together that day pulled codebase context in one step and used it to rewrite files with changes in the second step. This two step process still exists today. Incidentally, my hackathon script worked rather poorly and my demo failed to produce any useful code.<p>But that weekend I thought about the kind of errors it made, and realized that with more context on our codebase, it might have been able to get the change right. For example, it tried to create an endpoint on our server (at my previous startup), but it didn&#x27;t know that you needed to edit 3 specific files to do this (yeah... our backend was not that clean). So I hand-wrote a guide to our codebase, like I was instructing a new hire. I put it in a markdown file and passed it into Sonnet 3.5&#x27;s system prompt.  And the crazy thing is that it started producing wayyy better code. So, I started getting excited. In fact, this code guide idea still exists in Codebuff today as knowledge.md files which are automatically read on every request.<p>I didn&#x27;t think of this project as a startup idea at first. I thought it was just a simple script anyone could write. But after another week, I could see there were more problems to solve and it should be a product.<p>In the week between applying to YC and the interview, I could not get Codebuff to edit files consistently. I tried many prompting strategies to get it to replace strings in the original file, but nothing worked reliably. How could I face my interviewer if I could not get something basic like this to work? On the day before my interview, in a Hail Mary attempt, I fine-tuned GPT-4o to turn Claude&#x27;s sketch of changes into a git patch, which would add and remove lines to make the edits. I only finished generating the training data late at night, and the fine-tuning job ran as I slept.<p>And, holy hell, the next morning it worked! I pushed it to production just in time for my YC interview with Dalton. Soon after, Brandon joined and we were off to the races.<p>So, how does Codebuff work exactly? You invoke it in your terminal, and it starts by running through the source files in that directory and subdirectories and parsing out all the function and class names (or equivalents in 11 languages). We use the tree-sitter library to do this. It builds out a codebase map that includes these symbols and the file tree.<p>Then, it fires off a request to Claude Haiku 3.5 to cache this codebase context so user inputs can be responded to with lower latency. (Prompt caching is OP!). We have a stateless server that passes messages along to Anthropic or OpenAI. We use websockets to ferry data back and forth to clients. We didn&#x27;t have authentication or even a database for the first three months. Codebuff was free to install and used our API keys for all requests. Luckily, no one exploited us for too much free Claude usage haha. Major thanks to Brandon for saving this situation by building out our database (Postgres + Drizzle), server (Bun, hosted on Render, auth (using the free Auth.js), website (NextJS also hosted on Render), billing (Stripe), logging (BetterStack), and dashboard (Retool). This is the best tech stack I\u2019ve ever had.<p>When the user sends an input message, we prompt Claude to pick files that would be relevant (step 1). After picking files, we load them into context and the agent responds. It invokes tools using xml tags that we parse. It literally writes out &lt;edit_file path=&quot;src&#x2F;app.ts&quot;&gt;\u2026&lt;&#x2F;edit_file&gt; to edit a particular file, and has other tags to run terminal commands, or to ask to read more files. This is all we really need, since Anthropic has already trained Claude with very similar tools reach state of the art on the SWE benchmark.<p>Codebuff has limited free usage, but if you like it you can pay $99&#x2F;mo to get more credits. We realize this is a lot more than competitors, but that\u2019s because we do more expensive LLM calls with more context.<p>We\u2019re already seeing Codebuff used in surprising ways. One user racked up a $500 bill by building out two Flutter apps in parallel. He never even looked at the code it generated. Instead, he had long conversations with Codebuff to make progress and fix errors, until the apps were built to his satisfaction. Many users built real apps over a weekend for their teams and personal use.<p>Of course, those aren&#x27;t the typical use cases. Users also frequently use Codebuff to write unit tests. They would build a feature in parallel with unit tests and have Codebuff do loops to fix up the code until the tests pass. They would also ask it to do drudge work like set up Oauth flows or API scaffolding.<p>What&#x27;s really exciting with all of these examples is that we&#x27;re seeing people&#x27;s creativity becoming unbridled. They&#x27;re spending more of their time thinking about architecture and design, instead of implementation details. It&#x27;s so cool that we&#x27;re just at the beginning, and the technology is only going to improve from here.<p>If you would want to use Codebuff inside your own systems, we have an alpha SDK that exposes the same natural language interface for your apps to call and receive code edits! You can sign up here for early access: <a href=\"https:&#x2F;&#x2F;codebuff.retool.com&#x2F;form&#x2F;c8b15919-52d0-4572-aca5-533317403dde\" rel=\"nofollow\">https:&#x2F;&#x2F;codebuff.retool.com&#x2F;form&#x2F;c8b15919-52d0-4572-aca5-533...</a>.<p>Thank you for reading! We\u2019re excited for you to try out Codebuff and let us know what you think!", "title": "Launch HN: Codebuff (YC F24) \u2013 CLI tool that writes code for you", "updated_at": "2025-12-18T16:00:17Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "pea"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["websockets", "production"], "value": "Hello HN! We\u2019re Leo and Mandeep, founders of Datapane (<a href=\"https://datapane.com\" rel=\"nofollow\">https://datapane.com</a>).<p>We're building a way to create reports, dashboards, and web apps from your existing data using Python. Think of it as a combination of React and htmx, specifically designed for the Python data stack.<p>Our GitHub is <a href=\"https://github.com/datapane/datapane\">https://github.com/datapane/datapane</a> and you can try building a report or app in ~2 minutes on Codespaces: <a href=\"https://try.datapane.com\" rel=\"nofollow\">https://try.datapane.com</a><p>We started building Datapane at our previous start-up, where we struggled to deliver ML model results to clients. Much to our surprise, the data science took less time than repeatedly creating reports by copying and pasting plots into PowerPoint decks.<p>It seemed absurd that we had to switch to PowerPoint or legacy BI tools like Tableau to share, and our initial goal was to programmatically generate reports using the datasets and plots we had in Python. To enable this, we started hacking on a Python-based UI framework for constructing HTML views from data-centric blocks \u2013 like plots, data tables, and layout components.<p>You can export these to standalone HTML files, or host them as a web app on somewhere like GitHub Pages or Fly.io. We recently also added the ability to connect Python functions to forms and front-end events so you can build web apps which run backend code. We handle the entire network and RPC layer, so you only need to write plain Python functions that take parameters and return other blocks.<p>You can check out an example of the code to create a simple app: <a href=\"https://github.com/datapane/examples/blob/main/apps/iris-plotter/app.py\">https://github.com/datapane/examples/blob/main/apps/iris-plo...</a><p>Datapane\u2019s philosophy is pretty different from other products in the space.<p>We wanted to keep things simple, but avoid the footguns our users faced with frameworks like Streamlit, where the reactive/network-aware model was hard to move beyond an MVP or POC. For backend interactivity, we believe the original web got a lot right, and unlike reactive models which rely on <em>websockets</em>, Datapane is unashamedly request/response. This takes inspiration from HTTP and our own experiences with htmx, which offers an elegant way to add interactivity to HTML. Under the hood, we actually compile down to a (gasp!) XML-based hypermedia format, akin to HTML, but tailored specifically for constructing data UIs.<p>The result is that not every change in your app requires a server round trip, as much of it can be pre rendered and most interactivity happens on the client-side. In addition to improving performance, this also makes running in <em>production</em> become 10x simpler.<p>This separation between the view and backend compute also makes Datapane modular. If our app server isn\u2019t a good fit for your use-case, serve Datapane views from the web-framework of your choice (we\u2019ve been hacking on serving views from Django). Want to compute blocks from inside Airflow or generate them on a schedule or from a webhook? Computation can happen out of band of the UI. You can even build and host apps from inside of Jupyter, where you can preview blocks live and convert notebook cells to blocks in your view.<p>We currently offer a hosting platform on <a href=\"https://datapane.com\" rel=\"nofollow\">https://datapane.com</a> for sharing reports publicly (free) or with your team (paid), and will be adding serverless app hosting support to it in the next few weeks.<p>Our ultimate goal is to create an open-source toolkit for building data products across the entire stack \u2013 from reports, to dashboards, to full-stack apps \u2013 all using 100% Python. You can see a few we\u2019ve built already in our gallery: <a href=\"https://datapane.com/gallery\" rel=\"nofollow\">https://datapane.com/gallery</a><p>We\u2019d love to hear your feedback.<p>Thanks!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Datapane \u2013 A new way to build reports, dashboards, and apps in Python"}}, "_tags": ["story", "author_pea", "story_35274788", "show_hn"], "author": "pea", "children": [35279091, 35281772, 35283460, 35285212, 35287187, 35297796, 35302758, 35320168], "created_at": "2023-03-23T13:50:53Z", "created_at_i": 1679579453, "num_comments": 14, "objectID": "35274788", "points": 55, "story_id": 35274788, "story_text": "Hello HN! We\u2019re Leo and Mandeep, founders of Datapane (<a href=\"https:&#x2F;&#x2F;datapane.com\" rel=\"nofollow\">https:&#x2F;&#x2F;datapane.com</a>).<p>We&#x27;re building a way to create reports, dashboards, and web apps from your existing data using Python. Think of it as a combination of React and htmx, specifically designed for the Python data stack.<p>Our GitHub is <a href=\"https:&#x2F;&#x2F;github.com&#x2F;datapane&#x2F;datapane\">https:&#x2F;&#x2F;github.com&#x2F;datapane&#x2F;datapane</a> and you can try building a report or app in ~2 minutes on Codespaces: <a href=\"https:&#x2F;&#x2F;try.datapane.com\" rel=\"nofollow\">https:&#x2F;&#x2F;try.datapane.com</a><p>We started building Datapane at our previous start-up, where we struggled to deliver ML model results to clients. Much to our surprise, the data science took less time than repeatedly creating reports by copying and pasting plots into PowerPoint decks.<p>It seemed absurd that we had to switch to PowerPoint or legacy BI tools like Tableau to share, and our initial goal was to programmatically generate reports using the datasets and plots we had in Python. To enable this, we started hacking on a Python-based UI framework for constructing HTML views from data-centric blocks \u2013 like plots, data tables, and layout components.<p>You can export these to standalone HTML files, or host them as a web app on somewhere like GitHub Pages or Fly.io. We recently also added the ability to connect Python functions to forms and front-end events so you can build web apps which run backend code. We handle the entire network and RPC layer, so you only need to write plain Python functions that take parameters and return other blocks.<p>You can check out an example of the code to create a simple app: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;datapane&#x2F;examples&#x2F;blob&#x2F;main&#x2F;apps&#x2F;iris-plotter&#x2F;app.py\">https:&#x2F;&#x2F;github.com&#x2F;datapane&#x2F;examples&#x2F;blob&#x2F;main&#x2F;apps&#x2F;iris-plo...</a><p>Datapane\u2019s philosophy is pretty different from other products in the space.<p>We wanted to keep things simple, but avoid the footguns our users faced with frameworks like Streamlit, where the reactive&#x2F;network-aware model was hard to move beyond an MVP or POC. For backend interactivity, we believe the original web got a lot right, and unlike reactive models which rely on websockets, Datapane is unashamedly request&#x2F;response. This takes inspiration from HTTP and our own experiences with htmx, which offers an elegant way to add interactivity to HTML. Under the hood, we actually compile down to a (gasp!) XML-based hypermedia format, akin to HTML, but tailored specifically for constructing data UIs.<p>The result is that not every change in your app requires a server round trip, as much of it can be pre rendered and most interactivity happens on the client-side. In addition to improving performance, this also makes running in production become 10x simpler.<p>This separation between the view and backend compute also makes Datapane modular. If our app server isn\u2019t a good fit for your use-case, serve Datapane views from the web-framework of your choice (we\u2019ve been hacking on serving views from Django). Want to compute blocks from inside Airflow or generate them on a schedule or from a webhook? Computation can happen out of band of the UI. You can even build and host apps from inside of Jupyter, where you can preview blocks live and convert notebook cells to blocks in your view.<p>We currently offer a hosting platform on <a href=\"https:&#x2F;&#x2F;datapane.com\" rel=\"nofollow\">https:&#x2F;&#x2F;datapane.com</a> for sharing reports publicly (free) or with your team (paid), and will be adding serverless app hosting support to it in the next few weeks.<p>Our ultimate goal is to create an open-source toolkit for building data products across the entire stack \u2013 from reports, to dashboards, to full-stack apps \u2013 all using 100% Python. You can see a few we\u2019ve built already in our gallery: <a href=\"https:&#x2F;&#x2F;datapane.com&#x2F;gallery\" rel=\"nofollow\">https:&#x2F;&#x2F;datapane.com&#x2F;gallery</a><p>We\u2019d love to hear your feedback.<p>Thanks!", "title": "Show HN: Datapane \u2013 A new way to build reports, dashboards, and apps in Python", "updated_at": "2024-09-20T13:41:11Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "kylemathews"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["websockets", "production"], "value": "Hey, I'm a co-founder at ElectricSQL. Durable Streams is the delivery protocol underneath our Postgres sync engine\u2014we've been refining it in <em>production</em> for 18 months.<p>The core idea: streams get their own URL and use opaque, monotonic offsets. Clients persist the last offset they processed and resume with &quot;give me everything after X.&quot; No server-side session state, CDN-cacheable, plain HTTP.<p>We kept seeing teams reinvent this for AI token streaming and real-time apps, so we're standardizing it as a standalone protocol.<p>The repo has a reference Node.js server and TypeScript client. Would love to see implementations in other languages\u2014there's a conformance test suite to validate compatibility.<p>Happy to dig into the design tradeoffs\u2014why plain HTTP over <em>WebSockets</em>, etc."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Durable Streams \u2013 Kafka-style semantics for client streaming over HTTP"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/durable-streams/durable-streams"}}, "_tags": ["story", "author_kylemathews", "story_46209189", "show_hn"], "author": "kylemathews", "children": [46244039], "created_at": "2025-12-09T19:11:05Z", "created_at_i": 1765307465, "num_comments": 3, "objectID": "46209189", "points": 10, "story_id": 46209189, "story_text": "Hey, I&#x27;m a co-founder at ElectricSQL. Durable Streams is the delivery protocol underneath our Postgres sync engine\u2014we&#x27;ve been refining it in production for 18 months.<p>The core idea: streams get their own URL and use opaque, monotonic offsets. Clients persist the last offset they processed and resume with &quot;give me everything after X.&quot; No server-side session state, CDN-cacheable, plain HTTP.<p>We kept seeing teams reinvent this for AI token streaming and real-time apps, so we&#x27;re standardizing it as a standalone protocol.<p>The repo has a reference Node.js server and TypeScript client. Would love to see implementations in other languages\u2014there&#x27;s a conformance test suite to validate compatibility.<p>Happy to dig into the design tradeoffs\u2014why plain HTTP over WebSockets, etc.", "title": "Show HN: Durable Streams \u2013 Kafka-style semantics for client streaming over HTTP", "updated_at": "2025-12-21T13:57:11Z", "url": "https://github.com/durable-streams/durable-streams"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "selfdb_io"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["websockets", "production"], "value": "Hey HN!<p>We're a small team of developers who, like many of you, love the power and convenience of Backend-as-a-Service (BaaS) platforms. However, we've also felt the sting of vendor lock-in, wrestled with the complexities of self-hosting feature-rich open-source alternatives, and worried about unpredictable costs or the sudden disappearance of free tiers that many indie devs and small projects rely on.<p>We believe developers deserve more control and simplicity without sacrificing functionality. After countless hours spent navigating these challenges, we decided to build the solution we wished existed.<p>So, we built SelfDB: a self-hosted, open-source alternative to platforms like Supabase or Firebase. SelfDB provides a PostgreSQL database, secure JWT-based authentication (with anonymous access capabilities), integrated object storage, WebSocket-based real-time updates, and serverless cloud functions powered by Deno 2.0 \u2013 all packaged into a single, easy-to-deploy containerized platform.<p>Our goal is to give you the comprehensive features you expect from a modern BaaS, but with the freedom and control that comes from truly owning your backend stack.<p>Here\u2019s what SelfDB offers:<p>Full PostgreSQL Power: Your data, your schema, no compromises. Direct SQL access when you need it.<p>Robust Authentication: Secure user management with JWT tokens and flexible anonymous access.<p>Integrated Object Storage: A dedicated SelfDB Storage Service for your files and media.<p>Real-time Updates: Keep your applications in sync effortlessly using <em>WebSockets</em>.<p>Modern Cloud Functions: Write custom serverless logic with Deno 2.0, benefiting from its security-first approach and native TypeScript support.<p>Dead-Simple Deployment: This is where we really focused. Forget wrestling with a dozen different containers for a self-hosted BaaS. With SelfDB, you just need to unzip , configure your .env file, and run ./start.sh. That\u2019s it.<p>Truly Open &amp; Yours: Your SelfDB purchase includes full access to our source code, empowering you to redeploy the software as often as you need. While resale is not permitted, you have the freedom to modify the code to perfectly fit your requirements. Your purchase also grants you access to our exclusive customer portal. Here, you'll receive continuous, free updates and can connect with the vibrant SelfDB community to network, report bugs, and provide valuable feedback.<p><em>Production</em>-Ready: We've architected SelfDB with security, logging, and monitoring considerations from the outset, so you can build with confidence.\nUnder the hood, SelfDB leverages a FastAPI backend, known for its high performance and developer-friendly features , ensuring a responsive API. The cloud functions run in a Deno 2.0 environment, offering a modern and secure way to extend your backend. The entire platform is containerized using Docker and Docker Compose, with persistent data managed through Docker named volumes. You can get up and running locally with just a few commands: Full details, including the architecture diagram, are in zip you get when you buy Selfdb.<p>To celebrate our launch and thank the early adopters in the HN community, we're offering. This is a great way to try out the extended features while supporting the project. You can find more details and grab the offer at : <a href=\"https://selfdb.io\" rel=\"nofollow\">https://selfdb.io</a><p>We're incredibly excited to share SelfDB with you today!<p>SelfDB is new, and your feedback is invaluable to us. What are your biggest BaaS pain points? What features would you love to see in a self-hosted platform like SelfDB? We'll be here in the comments all day to answer your questions and hear your thoughts.<p>Thanks for checking out SelfDB!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: SelfDB \u2013 Ditch Supabase and Firebase Lock-In, Self-Host Simply"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://selfdb.io"}}, "_tags": ["story", "author_selfdb_io", "story_44222380", "show_hn"], "author": "selfdb_io", "children": [44222985, 44223865, 44224197, 44224760], "created_at": "2025-06-09T08:13:14Z", "created_at_i": 1749456794, "num_comments": 8, "objectID": "44222380", "points": 6, "story_id": 44222380, "story_text": "Hey HN!<p>We&#x27;re a small team of developers who, like many of you, love the power and convenience of Backend-as-a-Service (BaaS) platforms. However, we&#x27;ve also felt the sting of vendor lock-in, wrestled with the complexities of self-hosting feature-rich open-source alternatives, and worried about unpredictable costs or the sudden disappearance of free tiers that many indie devs and small projects rely on.<p>We believe developers deserve more control and simplicity without sacrificing functionality. After countless hours spent navigating these challenges, we decided to build the solution we wished existed.<p>So, we built SelfDB: a self-hosted, open-source alternative to platforms like Supabase or Firebase. SelfDB provides a PostgreSQL database, secure JWT-based authentication (with anonymous access capabilities), integrated object storage, WebSocket-based real-time updates, and serverless cloud functions powered by Deno 2.0 \u2013 all packaged into a single, easy-to-deploy containerized platform.<p>Our goal is to give you the comprehensive features you expect from a modern BaaS, but with the freedom and control that comes from truly owning your backend stack.<p>Here\u2019s what SelfDB offers:<p>Full PostgreSQL Power: Your data, your schema, no compromises. Direct SQL access when you need it.<p>Robust Authentication: Secure user management with JWT tokens and flexible anonymous access.<p>Integrated Object Storage: A dedicated SelfDB Storage Service for your files and media.<p>Real-time Updates: Keep your applications in sync effortlessly using WebSockets.<p>Modern Cloud Functions: Write custom serverless logic with Deno 2.0, benefiting from its security-first approach and native TypeScript support.<p>Dead-Simple Deployment: This is where we really focused. Forget wrestling with a dozen different containers for a self-hosted BaaS. With SelfDB, you just need to unzip , configure your .env file, and run .&#x2F;start.sh. That\u2019s it.<p>Truly Open &amp; Yours: Your SelfDB purchase includes full access to our source code, empowering you to redeploy the software as often as you need. While resale is not permitted, you have the freedom to modify the code to perfectly fit your requirements. Your purchase also grants you access to our exclusive customer portal. Here, you&#x27;ll receive continuous, free updates and can connect with the vibrant SelfDB community to network, report bugs, and provide valuable feedback.<p>Production-Ready: We&#x27;ve architected SelfDB with security, logging, and monitoring considerations from the outset, so you can build with confidence.\nUnder the hood, SelfDB leverages a FastAPI backend, known for its high performance and developer-friendly features , ensuring a responsive API. The cloud functions run in a Deno 2.0 environment, offering a modern and secure way to extend your backend. The entire platform is containerized using Docker and Docker Compose, with persistent data managed through Docker named volumes. You can get up and running locally with just a few commands: Full details, including the architecture diagram, are in zip you get when you buy Selfdb.<p>To celebrate our launch and thank the early adopters in the HN community, we&#x27;re offering. This is a great way to try out the extended features while supporting the project. You can find more details and grab the offer at : <a href=\"https:&#x2F;&#x2F;selfdb.io\" rel=\"nofollow\">https:&#x2F;&#x2F;selfdb.io</a><p>We&#x27;re incredibly excited to share SelfDB with you today!<p>SelfDB is new, and your feedback is invaluable to us. What are your biggest BaaS pain points? What features would you love to see in a self-hosted platform like SelfDB? We&#x27;ll be here in the comments all day to answer your questions and hear your thoughts.<p>Thanks for checking out SelfDB!", "title": "Show HN: SelfDB \u2013 Ditch Supabase and Firebase Lock-In, Self-Host Simply", "updated_at": "2025-11-23T20:53:54Z", "url": "https://selfdb.io"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "DesaiAshu"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["websockets", "production"], "value": "Hey folks!<p>I've spent the last 8 months building a VST plugin called &quot;The Infinite Crate&quot; on top of Magenta's Lyria RealTime music model on the Gemini API. Doug Eck's research group has been building MusicLM and variants since 2017 (<a href=\"https://www.youtube.com/watch?v=yz-fHidp1M8\" rel=\"nofollow\">https://www.youtube.com/watch?v=yz-fHidp1M8</a>)<p>I bridged a JUCE/C++ audio processing foundation with a React/Typescript UI, using Zustand to sync state. The plugin streams down generated audio from the Lyria RealTime model in the Gemini API via <em>websockets</em><p>You can try it as a VST3 on Mac/Windows or AU/Standalone on Mac. It works in Ableton, Logic, and possibly other DAWs or video <em>production</em> software like DaVinci Resolve<p>The plugin allows you to type in prompts, adjust generation parameters like topk, temperature, bpm, key, and various mutes<p>Please try it out and give us some feedback :)<p><a href=\"https://magenta.withgoogle.com/infinite-crate\" rel=\"nofollow\">https://magenta.withgoogle.com/infinite-crate</a>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: A generative audio VST plugin using Gemini API, JUCE, and React"}}, "_tags": ["story", "author_DesaiAshu", "story_44515999", "show_hn"], "author": "DesaiAshu", "children": [44516044], "created_at": "2025-07-10T00:14:08Z", "created_at_i": 1752106448, "num_comments": 1, "objectID": "44515999", "points": 5, "story_id": 44515999, "story_text": "Hey folks!<p>I&#x27;ve spent the last 8 months building a VST plugin called &quot;The Infinite Crate&quot; on top of Magenta&#x27;s Lyria RealTime music model on the Gemini API. Doug Eck&#x27;s research group has been building MusicLM and variants since 2017 (<a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=yz-fHidp1M8\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=yz-fHidp1M8</a>)<p>I bridged a JUCE&#x2F;C++ audio processing foundation with a React&#x2F;Typescript UI, using Zustand to sync state. The plugin streams down generated audio from the Lyria RealTime model in the Gemini API via websockets<p>You can try it as a VST3 on Mac&#x2F;Windows or AU&#x2F;Standalone on Mac. It works in Ableton, Logic, and possibly other DAWs or video production software like DaVinci Resolve<p>The plugin allows you to type in prompts, adjust generation parameters like topk, temperature, bpm, key, and various mutes<p>Please try it out and give us some feedback :)<p><a href=\"https:&#x2F;&#x2F;magenta.withgoogle.com&#x2F;infinite-crate\" rel=\"nofollow\">https:&#x2F;&#x2F;magenta.withgoogle.com&#x2F;infinite-crate</a>", "title": "Show HN: A generative audio VST plugin using Gemini API, JUCE, and React", "updated_at": "2025-08-12T22:37:46Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "philbe77"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["websockets", "production"], "value": "Hi,<p>I'm Philip Moore - the founder of GizmoData, and creator of GizmoEdge - a Distributed SQL Engine powered by Internet-of-Things (IoT) devices.<p>GizmoEdge is a prototype application - that allows you to run SQL queries that get distributed to many devices - including: Linux, macOS, iOS, iPadOS, Kubernetes Pods, Raspberry Pis, and more.<p>I've built a front-end application from which you can issue distributed SQL queries - here: <a href=\"https://gizmoedge.gizmodata.com\" rel=\"nofollow\">https://gizmoedge.gizmodata.com</a><p>If you have an Apple device - you can install the GizmoEdge Worker app to have it &quot;join the collective&quot; - here is the App Store link: <a href=\"https://apps.apple.com/us/app/gizmoedge/id6738658135\">https://apps.apple.com/us/app/gizmoedge/id6738658135</a><p>Once you install the app, you just connect it up to the running GizmoEdge server - and it will download a shard of TPC-H data at the 1GB foot-print (it is actually smaller, b/c it is compressed parquet - in a ZStandard-compressed tarball).  The app will then create a DuckDB database from the parquet datasets that are on your device.  Right now - queries will only run on your device if the app is open and in the foreground.  To connect your device to the server - click the little blue &quot;server&quot; icon just to the right of the GizmoData logo at the top of the screen - the username, password, etc. are pre-filled for you - just click the blue: &quot;Connect WebSocket&quot; button at the bottom to get started.<p>When you issue a SQL query that is eligible for distribution from the GizmoEdge SQL app (at <a href=\"https://gizmoedge.gizmodata.com\" rel=\"nofollow\">https://gizmoedge.gizmodata.com</a>) - it should distribute and execute on your device (among others) in the collective, provided that they have downloaded a shard of data and are connected to the server.<p>I would be honored if folks tried the engine.  Please bear in mind - this is a prototype - it isn't <em>production</em> ready, yet.  It is currently read-only as well - but I'm working on a way to make it easy for folks to ingest data for distributed SQL execution in the near-future.<p>GizmoEdge is powered by DuckDB on the workers, and uses <em>WebSockets</em> for low-latency connections between the server and workers.  It uses TLS for encryption of communication - and has a robust security model - in which the server and workers have a &quot;trust-but-verify&quot; relationship.<p>Getting started:\nGizmoEdge SQL Navigator app (run interactive SQL queries here): <a href=\"https://gizmoedge.gizmodata.com\" rel=\"nofollow\">https://gizmoedge.gizmodata.com</a>\nGizmoEdge Worker on the App Store: <a href=\"https://apps.apple.com/us/app/gizmoedge/id6738658135\">https://apps.apple.com/us/app/gizmoedge/id6738658135</a>\nGizmoEdge homepage: <a href=\"https://gizmodata.com/gizmoedge\" rel=\"nofollow\">https://gizmodata.com/gizmoedge</a><p>Thank you for your time and feedback - in advance!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: GizmoEdge \u2013 Distributed IoT SQL Engine"}}, "_tags": ["story", "author_philbe77", "story_43728616", "show_hn"], "author": "philbe77", "children": [43746592], "created_at": "2025-04-18T14:51:47Z", "created_at_i": 1744987907, "num_comments": 1, "objectID": "43728616", "points": 4, "story_id": 43728616, "story_text": "Hi,<p>I&#x27;m Philip Moore - the founder of GizmoData, and creator of GizmoEdge - a Distributed SQL Engine powered by Internet-of-Things (IoT) devices.<p>GizmoEdge is a prototype application - that allows you to run SQL queries that get distributed to many devices - including: Linux, macOS, iOS, iPadOS, Kubernetes Pods, Raspberry Pis, and more.<p>I&#x27;ve built a front-end application from which you can issue distributed SQL queries - here: <a href=\"https:&#x2F;&#x2F;gizmoedge.gizmodata.com\" rel=\"nofollow\">https:&#x2F;&#x2F;gizmoedge.gizmodata.com</a><p>If you have an Apple device - you can install the GizmoEdge Worker app to have it &quot;join the collective&quot; - here is the App Store link: <a href=\"https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;gizmoedge&#x2F;id6738658135\">https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;gizmoedge&#x2F;id6738658135</a><p>Once you install the app, you just connect it up to the running GizmoEdge server - and it will download a shard of TPC-H data at the 1GB foot-print (it is actually smaller, b&#x2F;c it is compressed parquet - in a ZStandard-compressed tarball).  The app will then create a DuckDB database from the parquet datasets that are on your device.  Right now - queries will only run on your device if the app is open and in the foreground.  To connect your device to the server - click the little blue &quot;server&quot; icon just to the right of the GizmoData logo at the top of the screen - the username, password, etc. are pre-filled for you - just click the blue: &quot;Connect WebSocket&quot; button at the bottom to get started.<p>When you issue a SQL query that is eligible for distribution from the GizmoEdge SQL app (at <a href=\"https:&#x2F;&#x2F;gizmoedge.gizmodata.com\" rel=\"nofollow\">https:&#x2F;&#x2F;gizmoedge.gizmodata.com</a>) - it should distribute and execute on your device (among others) in the collective, provided that they have downloaded a shard of data and are connected to the server.<p>I would be honored if folks tried the engine.  Please bear in mind - this is a prototype - it isn&#x27;t production ready, yet.  It is currently read-only as well - but I&#x27;m working on a way to make it easy for folks to ingest data for distributed SQL execution in the near-future.<p>GizmoEdge is powered by DuckDB on the workers, and uses WebSockets for low-latency connections between the server and workers.  It uses TLS for encryption of communication - and has a robust security model - in which the server and workers have a &quot;trust-but-verify&quot; relationship.<p>Getting started:\nGizmoEdge SQL Navigator app (run interactive SQL queries here): <a href=\"https:&#x2F;&#x2F;gizmoedge.gizmodata.com\" rel=\"nofollow\">https:&#x2F;&#x2F;gizmoedge.gizmodata.com</a>\nGizmoEdge Worker on the App Store: <a href=\"https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;gizmoedge&#x2F;id6738658135\">https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;gizmoedge&#x2F;id6738658135</a>\nGizmoEdge homepage: <a href=\"https:&#x2F;&#x2F;gizmodata.com&#x2F;gizmoedge\" rel=\"nofollow\">https:&#x2F;&#x2F;gizmodata.com&#x2F;gizmoedge</a><p>Thank you for your time and feedback - in advance!", "title": "Show HN: GizmoEdge \u2013 Distributed IoT SQL Engine", "updated_at": "2025-04-21T04:24:26Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "Artix187"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["websockets", "production"], "value": "Hi HN,<p>I built a live experiment called &quot;Twitch Plays Claude&quot;. It\u2019s exactly what it sounds like: inspired by Twitch Plays Pok\u00e9mon, but instead of moving a sprite, the crowd controls an LLM (Claude 4.5 Opus) to live-code a single index.html file.<p>I\u2019m really curious to see if this results in a chaotic mess or if a &quot;wisdom of the crowd&quot; effect kicks in to build a coherent application.<p>How it works:<p>Any user in the chat can submit a prompt using !idea &lt;prompt&gt;. This can be as simple as &quot;Add a small button here&quot;, or it can try to modify the whole page like &quot;Make the website a 3D space simulation using Three.js&quot;. The composition is where the chaos emerge. You can for instance write &quot;!idea add a mario movie projected automatically on a screen in the space&quot;.<p>I implemented two modes to manage the chaos:<p>- Anarchy: Chat inputs are batched. I included a &quot;pressure estimate&quot; logic in the system prompt so the AI tries to satisfy the weighted demand of the crowd.<p>- Democracy: Inputs are synthesized by Claude, then voted on by chat before execution. Each complete cycle lasts about 1:30-2 mins.<p>To keep it interesting, the crowd sets a &quot;Collective Goal&quot; every 30 minutes. If the goal changes, the page resets; if kept, iteration continues.<p>The stack:<p>- Backend: FastAPI, Gunicorn, Nginx, and a custom Twitch bot.\n- Frontend: The stream updates the DOM using morphdom via <em>websockets</em> (used only to signal that something has changed). This was important to prevent full page refreshes and keep the visual experience smooth. If needed in the event of any refresh bug, the chat can reload the page using !refresh \n- Sandbox: It's heavily sandboxed, but I allowlisted libraries like Three.js so people can try to build 3D scenes or mini-games.\n- The AI used is Claude Opus 4.5 for both democratic synthesis and code (patchs) <em>production</em>. I implemented a custom system to make Claude not have to rewrite the full index.html each time.<p>I plan to keep this running for a few days. The GitHub repo auto-updates with every commit from the stream.<p>Depending on how it goes, I might implement hierarchical clustering on semantic embeddings to improve the Democracy mode, or give the chat control over the system prompt itself and/or reset the page.<p>Links:<p>- Live Stream: <a href=\"https://www.twitch.tv/artix187\" rel=\"nofollow\">https://www.twitch.tv/artix187</a><p>- Result (Live Website, <i>at your own risks</i>): <a href=\"https://artix.tech/tpc\" rel=\"nofollow\">https://artix.tech/tpc</a><p>- Crowd-produced code: <a href=\"https://github.com/ArtixJP/twitch-plays-claude\" rel=\"nofollow\">https://github.com/ArtixJP/twitch-plays-claude</a><p>Please let me know what you think or if you have any idea to improve the system!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Twitch Plays Claude \u2013 Crowd-controlled live coding experiment"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://www.twitch.tv/artix187"}}, "_tags": ["story", "author_Artix187", "story_46347669", "show_hn"], "author": "Artix187", "children": [46347828], "created_at": "2025-12-21T19:42:37Z", "created_at_i": 1766346157, "num_comments": 1, "objectID": "46347669", "points": 3, "story_id": 46347669, "story_text": "Hi HN,<p>I built a live experiment called &quot;Twitch Plays Claude&quot;. It\u2019s exactly what it sounds like: inspired by Twitch Plays Pok\u00e9mon, but instead of moving a sprite, the crowd controls an LLM (Claude 4.5 Opus) to live-code a single index.html file.<p>I\u2019m really curious to see if this results in a chaotic mess or if a &quot;wisdom of the crowd&quot; effect kicks in to build a coherent application.<p>How it works:<p>Any user in the chat can submit a prompt using !idea &lt;prompt&gt;. This can be as simple as &quot;Add a small button here&quot;, or it can try to modify the whole page like &quot;Make the website a 3D space simulation using Three.js&quot;. The composition is where the chaos emerge. You can for instance write &quot;!idea add a mario movie projected automatically on a screen in the space&quot;.<p>I implemented two modes to manage the chaos:<p>- Anarchy: Chat inputs are batched. I included a &quot;pressure estimate&quot; logic in the system prompt so the AI tries to satisfy the weighted demand of the crowd.<p>- Democracy: Inputs are synthesized by Claude, then voted on by chat before execution. Each complete cycle lasts about 1:30-2 mins.<p>To keep it interesting, the crowd sets a &quot;Collective Goal&quot; every 30 minutes. If the goal changes, the page resets; if kept, iteration continues.<p>The stack:<p>- Backend: FastAPI, Gunicorn, Nginx, and a custom Twitch bot.\n- Frontend: The stream updates the DOM using morphdom via websockets (used only to signal that something has changed). This was important to prevent full page refreshes and keep the visual experience smooth. If needed in the event of any refresh bug, the chat can reload the page using !refresh \n- Sandbox: It&#x27;s heavily sandboxed, but I allowlisted libraries like Three.js so people can try to build 3D scenes or mini-games.\n- The AI used is Claude Opus 4.5 for both democratic synthesis and code (patchs) production. I implemented a custom system to make Claude not have to rewrite the full index.html each time.<p>I plan to keep this running for a few days. The GitHub repo auto-updates with every commit from the stream.<p>Depending on how it goes, I might implement hierarchical clustering on semantic embeddings to improve the Democracy mode, or give the chat control over the system prompt itself and&#x2F;or reset the page.<p>Links:<p>- Live Stream: <a href=\"https:&#x2F;&#x2F;www.twitch.tv&#x2F;artix187\" rel=\"nofollow\">https:&#x2F;&#x2F;www.twitch.tv&#x2F;artix187</a><p>- Result (Live Website, <i>at your own risks</i>): <a href=\"https:&#x2F;&#x2F;artix.tech&#x2F;tpc\" rel=\"nofollow\">https:&#x2F;&#x2F;artix.tech&#x2F;tpc</a><p>- Crowd-produced code: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ArtixJP&#x2F;twitch-plays-claude\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ArtixJP&#x2F;twitch-plays-claude</a><p>Please let me know what you think or if you have any idea to improve the system!", "title": "Show HN: Twitch Plays Claude \u2013 Crowd-controlled live coding experiment", "updated_at": "2025-12-22T14:37:15Z", "url": "https://www.twitch.tv/artix187"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "gdcbe"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["websockets", "production"], "value": "We've been working on Rama for over 3 years \u2014 it's a modular Rust framework for moving and transforming network packets. It\u2019s already in <em>production</em> at several companies handling terabytes of traffic daily.<p>Rama gives you:\n- Full control over transport (TCP/UDP), TLS (Rustls/BoringSSL), HTTP routing\n- User-agent detection fingerprinting (JA3/JA4/JA4H) and emulation\n- A composable Tower-like service/layer model\n- Part of the Tokio ecosystem\n- Lots of built-in services, but easy to extend or replace anything<p>This 0.2 release solidifies the core concept. We\u2019re already working on 0.3 (socks5, <em>WebSockets</em>, improvements to our crypto/tls story, removal of `Context` concept, etc.). Learn more about our release cycles in the announcement post.<p>Initial socks5 support is finished since today in main branch, which I believe is the most complete socks5 support within the Rust ecosystem, and similar to the entire rama framework it is there to empower you to execute wherever your creativity drives you (e.g. traffic interception, socks5 within tls, ...).<p>More at <a href=\"https://ramaproxy.org/\" rel=\"nofollow\">https://ramaproxy.org/</a> and our book at <a href=\"https://ramaproxy.org/book\" rel=\"nofollow\">https://ramaproxy.org/book</a> \u2014 happy to answer questions, but I might be slow to respond due to kids and business.<p>It's possible that some of your questions might already been answered in a recent reddit post: <a href=\"https://www.reddit.com/r/rust/comments/1kk8q14/rama_02_modular_rust_framework_for_building/\" rel=\"nofollow\">https://www.reddit.com/r/rust/comments/1kk8q14/rama_02_modul...</a><p>We're not claiming that this is the best framework or that everyone should use it. We realize this is for pretty niche use cases. And even though it has been a labor of love for 3 years already there is still a lot of room for improvement and even more missing features. It is however at a point where it is useful to use in <em>production</em> and is indeed been used by my own FOSS company as well as already a handful of customers. We're open to partnerships, service contracts and sponsorships. Rama itself however will always remain free and open source as we are just a small family business. As such building this with a wider community (together and for) is one hope to keep this sustainable in the future."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Rama 0.2 \u2013 Modular Rust framework for proxies, servers, and clients"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/plabayo/rama/discussions/544"}}, "_tags": ["story", "author_gdcbe", "story_43972280", "show_hn"], "author": "gdcbe", "created_at": "2025-05-13T12:42:13Z", "created_at_i": 1747140133, "num_comments": 0, "objectID": "43972280", "points": 3, "story_id": 43972280, "story_text": "We&#x27;ve been working on Rama for over 3 years \u2014 it&#x27;s a modular Rust framework for moving and transforming network packets. It\u2019s already in production at several companies handling terabytes of traffic daily.<p>Rama gives you:\n- Full control over transport (TCP&#x2F;UDP), TLS (Rustls&#x2F;BoringSSL), HTTP routing\n- User-agent detection fingerprinting (JA3&#x2F;JA4&#x2F;JA4H) and emulation\n- A composable Tower-like service&#x2F;layer model\n- Part of the Tokio ecosystem\n- Lots of built-in services, but easy to extend or replace anything<p>This 0.2 release solidifies the core concept. We\u2019re already working on 0.3 (socks5, WebSockets, improvements to our crypto&#x2F;tls story, removal of `Context` concept, etc.). Learn more about our release cycles in the announcement post.<p>Initial socks5 support is finished since today in main branch, which I believe is the most complete socks5 support within the Rust ecosystem, and similar to the entire rama framework it is there to empower you to execute wherever your creativity drives you (e.g. traffic interception, socks5 within tls, ...).<p>More at <a href=\"https:&#x2F;&#x2F;ramaproxy.org&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;ramaproxy.org&#x2F;</a> and our book at <a href=\"https:&#x2F;&#x2F;ramaproxy.org&#x2F;book\" rel=\"nofollow\">https:&#x2F;&#x2F;ramaproxy.org&#x2F;book</a> \u2014 happy to answer questions, but I might be slow to respond due to kids and business.<p>It&#x27;s possible that some of your questions might already been answered in a recent reddit post: <a href=\"https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;rust&#x2F;comments&#x2F;1kk8q14&#x2F;rama_02_modular_rust_framework_for_building&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;rust&#x2F;comments&#x2F;1kk8q14&#x2F;rama_02_modul...</a><p>We&#x27;re not claiming that this is the best framework or that everyone should use it. We realize this is for pretty niche use cases. And even though it has been a labor of love for 3 years already there is still a lot of room for improvement and even more missing features. It is however at a point where it is useful to use in production and is indeed been used by my own FOSS company as well as already a handful of customers. We&#x27;re open to partnerships, service contracts and sponsorships. Rama itself however will always remain free and open source as we are just a small family business. As such building this with a wider community (together and for) is one hope to keep this sustainable in the future.", "title": "Show HN: Rama 0.2 \u2013 Modular Rust framework for proxies, servers, and clients", "updated_at": "2025-05-14T12:13:10Z", "url": "https://github.com/plabayo/rama/discussions/544"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "bsenftner"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["websockets", "production"], "value": "INTRACT is a 3D infrastructure agency providing 3D modeling, animation, format translation and automated photo-real 3D avatar creation services to our roster of global gaming, computer vision, advertising, and related technological industry clients.<p>Candidates should have experience with:\n- React\n- React-Three-Fiber\n- Material UI\n- Redux Toolkit &amp; Query\n- <em>Websockets</em> (pusher specifically)\n- Typescript\n- Yarn &amp; NPM\n- Git<p>We currently have two general timezones with active staff: all USA time zones, and Pakistan - several staff live there. We also have Latin America staff, working in USA time zones.<p>Experienced and qualified candidates can submit a professional resume, including links to a minimum of three React web sites you have worked, and a brief description of the type of work that gets you energized. (We like motivated people.) Preference will be given to experienced React-Three-Fiber candidates who can demonstrate intermediate to advanced knowledge of 3D graphics and using Three.js's features such as recreation and playback of skinned, biped character animations from motion capture.<p>Additional preference if you also have any of the following: python development, computer vision experience, 2D or 3D animation media <em>production</em> experience.<p>If your email is anything more sophisticated than a flat text file, please put your resume somewhere online and deliver a link. Please send your employment information to blake.senftner@INTRACT.com."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Intract is hiring React-Three-fiber developers (remote)"}}, "_tags": ["story", "author_bsenftner", "story_30845279", "ask_hn"], "author": "bsenftner", "created_at": "2022-03-29T17:01:31Z", "created_at_i": 1648573291, "num_comments": 0, "objectID": "30845279", "points": 3, "story_id": 30845279, "story_text": "INTRACT is a 3D infrastructure agency providing 3D modeling, animation, format translation and automated photo-real 3D avatar creation services to our roster of global gaming, computer vision, advertising, and related technological industry clients.<p>Candidates should have experience with:\n- React\n- React-Three-Fiber\n- Material UI\n- Redux Toolkit &amp; Query\n- Websockets (pusher specifically)\n- Typescript\n- Yarn &amp; NPM\n- Git<p>We currently have two general timezones with active staff: all USA time zones, and Pakistan - several staff live there. We also have Latin America staff, working in USA time zones.<p>Experienced and qualified candidates can submit a professional resume, including links to a minimum of three React web sites you have worked, and a brief description of the type of work that gets you energized. (We like motivated people.) Preference will be given to experienced React-Three-Fiber candidates who can demonstrate intermediate to advanced knowledge of 3D graphics and using Three.js&#x27;s features such as recreation and playback of skinned, biped character animations from motion capture.<p>Additional preference if you also have any of the following: python development, computer vision experience, 2D or 3D animation media production experience.<p>If your email is anything more sophisticated than a flat text file, please put your resume somewhere online and deliver a link. Please send your employment information to blake.senftner@INTRACT.com.", "title": "Intract is hiring React-Three-fiber developers (remote)", "updated_at": "2024-09-20T10:47:16Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "roseway4"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["websockets", "production"], "value": "Mortgage Chat is a GPT-3.5-powered chatbot that answers your mortgage lending and home buying questions you were too afraid to ask.<p>Working with mortgage loan officers can be challenging, off-putting, and frustrating.<p>My goals for this project were:<p>- Familiarizing myself with in-context learning using GPT3<p>- Exploring AI's potential in complex domains (non-technology) domains like mortgage lending<p>- Creating a user-friendly, non-judgmental, and non-commercially motivated tool for 24x7 guidance on anything mortgage-related<p>How I built it:<p>- I built the bot using Langchain and used their sample chatbot as a base, although did significant prompt and other tweakings, including building the &quot;next questions to ask&quot; functionality.<p>- I crawled the Consumer Finance Protection Bureau's website for mortgage content. Relevant content is fed to the bot from a FAISS index (Langchain makes this super easy). I used the CFPB as it struck me as the most neutral and factual of various online content sources.<p>- I also provide the bot with up-to-date mortgage rate data from the Federal Reserve's FRED service.<p>The bot could definitely be improved:<p>- I tried letting GPT3 ask the user questions about their mortgage situation in order to be more helpful but found it overly aggressive and off-putting. I think this is definitely feasible, but requires more thought.<p>- <em>Websockets</em> can be a pain, and I'd probably want to use server-side events in <em>production</em> to stream results to the bot client.<p>h/t to:<p>- Langchain and community.<p>- The Consumer Finance Protection Bureau."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Mortgage Chat \u2013 A bot that answers your awkward home buying questions"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://demo.mortgagelab.ai/"}}, "_tags": ["story", "author_roseway4", "story_35291305", "show_hn"], "author": "roseway4", "children": [35291594], "created_at": "2023-03-24T16:19:29Z", "created_at_i": 1679674769, "num_comments": 1, "objectID": "35291305", "points": 2, "story_id": 35291305, "story_text": "Mortgage Chat is a GPT-3.5-powered chatbot that answers your mortgage lending and home buying questions you were too afraid to ask.<p>Working with mortgage loan officers can be challenging, off-putting, and frustrating.<p>My goals for this project were:<p>- Familiarizing myself with in-context learning using GPT3<p>- Exploring AI&#x27;s potential in complex domains (non-technology) domains like mortgage lending<p>- Creating a user-friendly, non-judgmental, and non-commercially motivated tool for 24x7 guidance on anything mortgage-related<p>How I built it:<p>- I built the bot using Langchain and used their sample chatbot as a base, although did significant prompt and other tweakings, including building the &quot;next questions to ask&quot; functionality.<p>- I crawled the Consumer Finance Protection Bureau&#x27;s website for mortgage content. Relevant content is fed to the bot from a FAISS index (Langchain makes this super easy). I used the CFPB as it struck me as the most neutral and factual of various online content sources.<p>- I also provide the bot with up-to-date mortgage rate data from the Federal Reserve&#x27;s FRED service.<p>The bot could definitely be improved:<p>- I tried letting GPT3 ask the user questions about their mortgage situation in order to be more helpful but found it overly aggressive and off-putting. I think this is definitely feasible, but requires more thought.<p>- Websockets can be a pain, and I&#x27;d probably want to use server-side events in production to stream results to the bot client.<p>h&#x2F;t to:<p>- Langchain and community.<p>- The Consumer Finance Protection Bureau.", "title": "Show HN: Mortgage Chat \u2013 A bot that answers your awkward home buying questions", "updated_at": "2024-09-20T13:42:53Z", "url": "https://demo.mortgagelab.ai/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "chirau"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["websockets", "production"], "value": "My friend asked me this. I don't think I answered him fairly. I told him to learn RESTful architecture and then jump on a sample project. He knows JS and Python, I think.<p>The truth is, whilst I can build one, I really don't know what resource to point other people to. I started off with SOAP APIs so our resources back then were prett different from those of today for <em>websockets</em>, RESTful APIs and all that jazz. Hell, I haven't even worked with GraphQL myself. So I thought I'd ask the community.<p>What is the typical journey today to build a <em>production</em> grade API with authentications and throttling etc?<p>Books, videos, courses, blogs, forums, communities etc."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: I want to build a Web API, where do I start?"}}, "_tags": ["story", "author_chirau", "story_21126051", "ask_hn"], "author": "chirau", "children": [21126226], "created_at": "2019-10-01T15:02:31Z", "created_at_i": 1569942151, "num_comments": 1, "objectID": "21126051", "points": 2, "story_id": 21126051, "story_text": "My friend asked me this. I don&#x27;t think I answered him fairly. I told him to learn RESTful architecture and then jump on a sample project. He knows JS and Python, I think.<p>The truth is, whilst I can build one, I really don&#x27;t know what resource to point other people to. I started off with SOAP APIs so our resources back then were prett different from those of today for websockets, RESTful APIs and all that jazz. Hell, I haven&#x27;t even worked with GraphQL myself. So I thought I&#x27;d ask the community.<p>What is the typical journey today to build a production grade API with authentications and throttling etc?<p>Books, videos, courses, blogs, forums, communities etc.", "title": "Ask HN: I want to build a Web API, where do I start?", "updated_at": "2024-09-20T04:57:04Z"}], "hitsPerPage": 15, "nbHits": 44, "nbPages": 3, "page": 0, "params": "query=websockets+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 11, "processingTimingsMS": {"_request": {"roundTrip": 16}, "afterFetch": {"format": {"highlighting": 2, "total": 3}}, "fetch": {"query": 7, "scanning": 2, "total": 10}, "total": 11}, "query": "websockets production", "serverTimeMS": 15}}