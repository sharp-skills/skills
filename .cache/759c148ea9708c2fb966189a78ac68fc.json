{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "nbrad"}, "story_text": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["drizzle"], "value": "I\u2019m hoping for something battle-tested that supports async/await and migrations. If your answer is some variation of \u201creal programmers don\u2019t use ORMs\u201d... fair enough, I suppose. But here are the options as I see them:<p>- Django: very mature ORM, migration support is great. But it doesn\u2019t support async/await (https://docs.djangoproject.com/en/5.0/topics/async/), and these days FastAPI seems like a better option. FastAPI just needs an ORM, so =&gt;<p>- SQLModel: from @tiangolo who created FastAPI, clean and good Pydantic support, so this would be my default option, but even though it seems to support async/await the doc page is blank (https://sqlmodel.tiangolo.com/advanced/), and for migrations you resort to the underlying =&gt;<p>- SQLAlchemy: seems by far the largest/best supported, has async/await, has migrations through Alembic (it seems not as fully-featured as Django\u2019s?), but trying to use it has felt very kludgy/painful/verbose.<p>- Tortoise: the README claims to fulfill my dreams, but I haven\u2019t met anyone yet using it in prod? Anyone have experience they can share?<p>- Any others I missed?<p>Meanwhile in the JS/TS ecosystem, Prisma just added <i>preview</i> support for JOINs 2 weeks ago (https://github.com/prisma/prisma/releases/tag/5.7.0 !?!) and yet it seems ubiquitous (though I hear everyone\u2019s moving to <em>Drizzle</em>).<p>Advice greatly appreciated"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Any Python ORMs worthy of <em>production</em>?"}}, "_tags": ["story", "author_nbrad", "story_38689836", "ask_hn"], "author": "nbrad", "children": [38689939, 38690028, 38690114, 38690916, 38692665], "created_at": "2023-12-18T23:27:45Z", "created_at_i": 1702942065, "num_comments": 8, "objectID": "38689836", "points": 2, "story_id": 38689836, "story_text": "I\u2019m hoping for something battle-tested that supports async&#x2F;await and migrations. If your answer is some variation of \u201creal programmers don\u2019t use ORMs\u201d... fair enough, I suppose. But here are the options as I see them:<p>- Django: very mature ORM, migration support is great. But it doesn\u2019t support async&#x2F;await (https:&#x2F;&#x2F;docs.djangoproject.com&#x2F;en&#x2F;5.0&#x2F;topics&#x2F;async&#x2F;), and these days FastAPI seems like a better option. FastAPI just needs an ORM, so =&gt;<p>- SQLModel: from @tiangolo who created FastAPI, clean and good Pydantic support, so this would be my default option, but even though it seems to support async&#x2F;await the doc page is blank (https:&#x2F;&#x2F;sqlmodel.tiangolo.com&#x2F;advanced&#x2F;), and for migrations you resort to the underlying =&gt;<p>- SQLAlchemy: seems by far the largest&#x2F;best supported, has async&#x2F;await, has migrations through Alembic (it seems not as fully-featured as Django\u2019s?), but trying to use it has felt very kludgy&#x2F;painful&#x2F;verbose.<p>- Tortoise: the README claims to fulfill my dreams, but I haven\u2019t met anyone yet using it in prod? Anyone have experience they can share?<p>- Any others I missed?<p>Meanwhile in the JS&#x2F;TS ecosystem, Prisma just added <i>preview</i> support for JOINs 2 weeks ago (https:&#x2F;&#x2F;github.com&#x2F;prisma&#x2F;prisma&#x2F;releases&#x2F;tag&#x2F;5.7.0 !?!) and yet it seems ubiquitous (though I hear everyone\u2019s moving to Drizzle).<p>Advice greatly appreciated", "title": "Any Python ORMs worthy of production?", "updated_at": "2025-08-11T11:34:41Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "jahooma"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["drizzle", "production"], "value": "Hey HN! We\u2019re James and Brandon building Codebuff (<a href=\"https://codebuff.com\">https://codebuff.com</a>). Codebuff is like Cursor Composer, but in your terminal: it modifies files based on your natural language requests. You can try it with `npm i -g codebuff` and start using it immediately for free. We have no login gate, and we give all accounts up to $20 worth of credits.<p>Codebuff is different because we simplified the input to one step: you type what you want done in your terminal and hit enter. Then Codebuff looks through your whole codebase and makes the edits it wants, to existing source files or new ones. It also can run your tests, the type checker, or install packages to fulfill your request.<p>Demo video: <a href=\"https://www.youtube.com/watch?v=dQ0NOMsu0dA\" rel=\"nofollow\">https://www.youtube.com/watch?v=dQ0NOMsu0dA</a><p>It all started at a hackathon. I was trying out Sonnet 3.5 which had recently come out and seeing if I could use it to write code. The script I cobbled together that day pulled codebase context in one step and used it to rewrite files with changes in the second step. This two step process still exists today. Incidentally, my hackathon script worked rather poorly and my demo failed to produce any useful code.<p>But that weekend I thought about the kind of errors it made, and realized that with more context on our codebase, it might have been able to get the change right. For example, it tried to create an endpoint on our server (at my previous startup), but it didn't know that you needed to edit 3 specific files to do this (yeah... our backend was not that clean). So I hand-wrote a guide to our codebase, like I was instructing a new hire. I put it in a markdown file and passed it into Sonnet 3.5's system prompt.  And the crazy thing is that it started producing wayyy better code. So, I started getting excited. In fact, this code guide idea still exists in Codebuff today as knowledge.md files which are automatically read on every request.<p>I didn't think of this project as a startup idea at first. I thought it was just a simple script anyone could write. But after another week, I could see there were more problems to solve and it should be a product.<p>In the week between applying to YC and the interview, I could not get Codebuff to edit files consistently. I tried many prompting strategies to get it to replace strings in the original file, but nothing worked reliably. How could I face my interviewer if I could not get something basic like this to work? On the day before my interview, in a Hail Mary attempt, I fine-tuned GPT-4o to turn Claude's sketch of changes into a git patch, which would add and remove lines to make the edits. I only finished generating the training data late at night, and the fine-tuning job ran as I slept.<p>And, holy hell, the next morning it worked! I pushed it to <em>production</em> just in time for my YC interview with Dalton. Soon after, Brandon joined and we were off to the races.<p>So, how does Codebuff work exactly? You invoke it in your terminal, and it starts by running through the source files in that directory and subdirectories and parsing out all the function and class names (or equivalents in 11 languages). We use the tree-sitter library to do this. It builds out a codebase map that includes these symbols and the file tree.<p>Then, it fires off a request to Claude Haiku 3.5 to cache this codebase context so user inputs can be responded to with lower latency. (Prompt caching is OP!). We have a stateless server that passes messages along to Anthropic or OpenAI. We use websockets to ferry data back and forth to clients. We didn't have authentication or even a database for the first three months. Codebuff was free to install and used our API keys for all requests. Luckily, no one exploited us for too much free Claude usage haha. Major thanks to Brandon for saving this situation by building out our database (Postgres + <em>Drizzle</em>), server (Bun, hosted on Render, auth (using the free Auth.js), website (NextJS also hosted on Render), billing (Stripe), logging (BetterStack), and dashboard (Retool). This is the best tech stack I\u2019ve ever had.<p>When the user sends an input message, we prompt Claude to pick files that would be relevant (step 1). After picking files, we load them into context and the agent responds. It invokes tools using xml tags that we parse. It literally writes out &lt;edit_file path=&quot;src/app.ts&quot;&gt;\u2026&lt;/edit_file&gt; to edit a particular file, and has other tags to run terminal commands, or to ask to read more files. This is all we really need, since Anthropic has already trained Claude with very similar tools reach state of the art on the SWE benchmark.<p>Codebuff has limited free usage, but if you like it you can pay $99/mo to get more credits. We realize this is a lot more than competitors, but that\u2019s because we do more expensive LLM calls with more context.<p>We\u2019re already seeing Codebuff used in surprising ways. One user racked up a $500 bill by building out two Flutter apps in parallel. He never even looked at the code it generated. Instead, he had long conversations with Codebuff to make progress and fix errors, until the apps were built to his satisfaction. Many users built real apps over a weekend for their teams and personal use.<p>Of course, those aren't the typical use cases. Users also frequently use Codebuff to write unit tests. They would build a feature in parallel with unit tests and have Codebuff do loops to fix up the code until the tests pass. They would also ask it to do drudge work like set up Oauth flows or API scaffolding.<p>What's really exciting with all of these examples is that we're seeing people's creativity becoming unbridled. They're spending more of their time thinking about architecture and design, instead of implementation details. It's so cool that we're just at the beginning, and the technology is only going to improve from here.<p>If you would want to use Codebuff inside your own systems, we have an alpha SDK that exposes the same natural language interface for your apps to call and receive code edits! You can sign up here for early access: <a href=\"https://codebuff.retool.com/form/c8b15919-52d0-4572-aca5-533317403dde\" rel=\"nofollow\">https://codebuff.retool.com/form/c8b15919-52d0-4572-aca5-533...</a>.<p>Thank you for reading! We\u2019re excited for you to try out Codebuff and let us know what you think!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: Codebuff (YC F24) \u2013 CLI tool that writes code for you"}}, "_tags": ["story", "author_jahooma", "story_42078536", "launch_hn"], "author": "jahooma", "children": [42079651, 42079684, 42079745, 42079755, 42079760, 42079761, 42079801, 42079914, 42079916, 42079974, 42080002, 42080028, 42080038, 42080048, 42080181, 42080202, 42080304, 42080313, 42080345, 42080370, 42080643, 42080763, 42080857, 42080940, 42081003, 42081027, 42081067, 42081081, 42081099, 42081197, 42081263, 42081354, 42081471, 42081513, 42081809, 42081925, 42081993, 42082073, 42082218, 42082424, 42082450, 42082536, 42082857, 42082957, 42083312, 42083320, 42083609, 42083688, 42083836, 42084139, 42084221, 42084233, 42084438, 42084508, 42084510, 42084939, 42086083, 42086943, 42087022, 42087814, 42087956, 42088355, 42094932, 42186644], "created_at": "2024-11-07T17:06:28Z", "created_at_i": 1730999188, "num_comments": 239, "objectID": "42078536", "points": 285, "story_id": 42078536, "story_text": "Hey HN! We\u2019re James and Brandon building Codebuff (<a href=\"https:&#x2F;&#x2F;codebuff.com\">https:&#x2F;&#x2F;codebuff.com</a>). Codebuff is like Cursor Composer, but in your terminal: it modifies files based on your natural language requests. You can try it with `npm i -g codebuff` and start using it immediately for free. We have no login gate, and we give all accounts up to $20 worth of credits.<p>Codebuff is different because we simplified the input to one step: you type what you want done in your terminal and hit enter. Then Codebuff looks through your whole codebase and makes the edits it wants, to existing source files or new ones. It also can run your tests, the type checker, or install packages to fulfill your request.<p>Demo video: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=dQ0NOMsu0dA\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=dQ0NOMsu0dA</a><p>It all started at a hackathon. I was trying out Sonnet 3.5 which had recently come out and seeing if I could use it to write code. The script I cobbled together that day pulled codebase context in one step and used it to rewrite files with changes in the second step. This two step process still exists today. Incidentally, my hackathon script worked rather poorly and my demo failed to produce any useful code.<p>But that weekend I thought about the kind of errors it made, and realized that with more context on our codebase, it might have been able to get the change right. For example, it tried to create an endpoint on our server (at my previous startup), but it didn&#x27;t know that you needed to edit 3 specific files to do this (yeah... our backend was not that clean). So I hand-wrote a guide to our codebase, like I was instructing a new hire. I put it in a markdown file and passed it into Sonnet 3.5&#x27;s system prompt.  And the crazy thing is that it started producing wayyy better code. So, I started getting excited. In fact, this code guide idea still exists in Codebuff today as knowledge.md files which are automatically read on every request.<p>I didn&#x27;t think of this project as a startup idea at first. I thought it was just a simple script anyone could write. But after another week, I could see there were more problems to solve and it should be a product.<p>In the week between applying to YC and the interview, I could not get Codebuff to edit files consistently. I tried many prompting strategies to get it to replace strings in the original file, but nothing worked reliably. How could I face my interviewer if I could not get something basic like this to work? On the day before my interview, in a Hail Mary attempt, I fine-tuned GPT-4o to turn Claude&#x27;s sketch of changes into a git patch, which would add and remove lines to make the edits. I only finished generating the training data late at night, and the fine-tuning job ran as I slept.<p>And, holy hell, the next morning it worked! I pushed it to production just in time for my YC interview with Dalton. Soon after, Brandon joined and we were off to the races.<p>So, how does Codebuff work exactly? You invoke it in your terminal, and it starts by running through the source files in that directory and subdirectories and parsing out all the function and class names (or equivalents in 11 languages). We use the tree-sitter library to do this. It builds out a codebase map that includes these symbols and the file tree.<p>Then, it fires off a request to Claude Haiku 3.5 to cache this codebase context so user inputs can be responded to with lower latency. (Prompt caching is OP!). We have a stateless server that passes messages along to Anthropic or OpenAI. We use websockets to ferry data back and forth to clients. We didn&#x27;t have authentication or even a database for the first three months. Codebuff was free to install and used our API keys for all requests. Luckily, no one exploited us for too much free Claude usage haha. Major thanks to Brandon for saving this situation by building out our database (Postgres + Drizzle), server (Bun, hosted on Render, auth (using the free Auth.js), website (NextJS also hosted on Render), billing (Stripe), logging (BetterStack), and dashboard (Retool). This is the best tech stack I\u2019ve ever had.<p>When the user sends an input message, we prompt Claude to pick files that would be relevant (step 1). After picking files, we load them into context and the agent responds. It invokes tools using xml tags that we parse. It literally writes out &lt;edit_file path=&quot;src&#x2F;app.ts&quot;&gt;\u2026&lt;&#x2F;edit_file&gt; to edit a particular file, and has other tags to run terminal commands, or to ask to read more files. This is all we really need, since Anthropic has already trained Claude with very similar tools reach state of the art on the SWE benchmark.<p>Codebuff has limited free usage, but if you like it you can pay $99&#x2F;mo to get more credits. We realize this is a lot more than competitors, but that\u2019s because we do more expensive LLM calls with more context.<p>We\u2019re already seeing Codebuff used in surprising ways. One user racked up a $500 bill by building out two Flutter apps in parallel. He never even looked at the code it generated. Instead, he had long conversations with Codebuff to make progress and fix errors, until the apps were built to his satisfaction. Many users built real apps over a weekend for their teams and personal use.<p>Of course, those aren&#x27;t the typical use cases. Users also frequently use Codebuff to write unit tests. They would build a feature in parallel with unit tests and have Codebuff do loops to fix up the code until the tests pass. They would also ask it to do drudge work like set up Oauth flows or API scaffolding.<p>What&#x27;s really exciting with all of these examples is that we&#x27;re seeing people&#x27;s creativity becoming unbridled. They&#x27;re spending more of their time thinking about architecture and design, instead of implementation details. It&#x27;s so cool that we&#x27;re just at the beginning, and the technology is only going to improve from here.<p>If you would want to use Codebuff inside your own systems, we have an alpha SDK that exposes the same natural language interface for your apps to call and receive code edits! You can sign up here for early access: <a href=\"https:&#x2F;&#x2F;codebuff.retool.com&#x2F;form&#x2F;c8b15919-52d0-4572-aca5-533317403dde\" rel=\"nofollow\">https:&#x2F;&#x2F;codebuff.retool.com&#x2F;form&#x2F;c8b15919-52d0-4572-aca5-533...</a>.<p>Thank you for reading! We\u2019re excited for you to try out Codebuff and let us know what you think!", "title": "Launch HN: Codebuff (YC F24) \u2013 CLI tool that writes code for you", "updated_at": "2025-12-18T16:00:17Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "kiwicopple"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["drizzle", "production"], "value": "hey hn, supabase ceo here<p>this is a postgres connection pooler. it\u2019s similar to pgbouncer, but built with Elixir and specifically designed for multi-tenancy.<p>it\u2019s still under development, but it\u2019s at a stage where we can gather a feedback from the community and you can try it yourself. we aren\u2019t using this in <em>production</em> yet, but aiming to deploy it for a subset of databases in the next 2 months.<p>We have the following benchmarks (details in the readme):<p><pre><code>  - Elixir Cluster maintaining 400 connections to a single Postgres database\n  - 1_000_000 clients connecting to the Elixir cluster\n  - Sending 20_000 transactions per second\n  - Consuming 7.8G RAM and ~50% CPU on a 64vCPU machine\n</code></pre>\nsupavisor can be run as a cluster or a single node/binary.  It\u2019s handling 90%+ of the throughput of pgbouncer on a local machine (running pgbench)<p>we will place this in front of all supabase databases. It will eventually be able to handle multiple types of connections: traditional TCP connections, and HTTP connections for developers who are connecting to Postgres in serverless environments using Prisma, Kysely, <em>Drizzle</em>, etc<p>the proxy will serve as a connection buffer while we scale databases: scaling up compute with zero-downtime, and for scale-to-zero - triggering a server restart when a connection is initiated<p>finally, i want to shout out to Jose and the Dashbit/elixir team. They were extremely helpful with the design &amp; architecture. they have been valuable partners, and elixir continues to be an amazing language for tools like this and our Realtime server."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Supavisor \u2013 a Postgres connection pooler written in Elixir"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/supabase/supavisor"}}, "_tags": ["story", "author_kiwicopple", "story_35501718", "show_hn"], "author": "kiwicopple", "children": [35501733, 35501924, 35501972, 35502113, 35502158, 35502285, 35506930, 35507608, 35507840, 35507875, 35508467, 35508611, 35510363, 35512570, 35514589], "created_at": "2023-04-09T11:29:25Z", "created_at_i": 1681039765, "num_comments": 49, "objectID": "35501718", "points": 149, "story_id": 35501718, "story_text": "hey hn, supabase ceo here<p>this is a postgres connection pooler. it\u2019s similar to pgbouncer, but built with Elixir and specifically designed for multi-tenancy.<p>it\u2019s still under development, but it\u2019s at a stage where we can gather a feedback from the community and you can try it yourself. we aren\u2019t using this in production yet, but aiming to deploy it for a subset of databases in the next 2 months.<p>We have the following benchmarks (details in the readme):<p><pre><code>  - Elixir Cluster maintaining 400 connections to a single Postgres database\n  - 1_000_000 clients connecting to the Elixir cluster\n  - Sending 20_000 transactions per second\n  - Consuming 7.8G RAM and ~50% CPU on a 64vCPU machine\n</code></pre>\nsupavisor can be run as a cluster or a single node&#x2F;binary.  It\u2019s handling 90%+ of the throughput of pgbouncer on a local machine (running pgbench)<p>we will place this in front of all supabase databases. It will eventually be able to handle multiple types of connections: traditional TCP connections, and HTTP connections for developers who are connecting to Postgres in serverless environments using Prisma, Kysely, Drizzle, etc<p>the proxy will serve as a connection buffer while we scale databases: scaling up compute with zero-downtime, and for scale-to-zero - triggering a server restart when a connection is initiated<p>finally, i want to shout out to Jose and the Dashbit&#x2F;elixir team. They were extremely helpful with the design &amp; architecture. they have been valuable partners, and elixir continues to be an amazing language for tools like this and our Realtime server.", "title": "Show HN: Supavisor \u2013 a Postgres connection pooler written in Elixir", "updated_at": "2024-09-20T13:44:34Z", "url": "https://github.com/supabase/supavisor"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "adam_gyroscope"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["drizzle", "production"], "value": "Here\u2019s how we\u2019re working with LLMs at my startup.<p>We have a monorepo with scheduled Python data workflows, two Next.js apps, and a small engineering team. We use GitHub for SCM and CI/CD, deploy to GCP and Vercel, and lean heavily on automation.<p>Local development:\nEvery engineer gets Cursor Pro (plus Bugbot), Gemini Pro, OpenAI Pro, and optionally Claude Pro. We don\u2019t really care which model people use. In practice, LLMs are worth about 1.5 excellent junior/mid-level engineers per engineer, so paying for multiple models is easily worth it.<p>We rely heavily on pre-commit hooks: ty, ruff, TypeScript checks, tests across all languages, formatting, and other guards. Everything is auto-formatted. LLMs make types and tests much easier to write, though complex typing still needs some hand-holding.<p>GitHub + Copilot workflow:\nWe pay for GitHub Enterprise primarily because it allows assigning issues to Copilot, which then opens a PR. Our rule is simple: if you open an issue, you assign it to Copilot. Every issue gets a code attempt attached to it.<p>There\u2019s no stigma around lots of PRs. We frequently delete ones we don\u2019t use.<p>We use Turborepo for the monorepo and are fully uv on the Python side.<p>All coding practices are encoded in .cursor/rules files. For example: \u201cIf you are doing database work, only edit <em>Drizzle</em>\u2019s schema.ts and don\u2019t hand-write SQL.\u201d Cursor generally respects this, but other tools struggle to consistently read or follow these rules no matter how many agent.md-style files we add.<p>My personal dev loop:\nIf I\u2019m on the go and see a bug or have an idea, I open a GitHub issue (via Slack, mobile, or web) and assign it to Copilot. Sometimes the issue is detailed; sometimes a single sentence. Copilot opens a PR, and I review it later.<p>If I\u2019m at the keyboard, I start in Cursor as an agent in a Git worktree, using whatever the best model is. I iterate until I\u2019m happy, ask the LLM to write tests, review everything, and push to GitHub. Before a human review, I let Cursor Bugbot, Copilot, and GitHub CodeQL review the code, and ask Copilot to fix anything they flag.<p>Things that are still painful:\nTo really know if code works, I need to run Temporal, two Next.js apps, several Python workers, and a Node worker. Some of this is Dockerized, some isn\u2019t. Then I need a browser to run manual checks.<p>AFAICT, there\u2019s no service that lets me: give a prompt, write the code, spin up all this infra, run Playwright, handle database migrations, and let me manually poke at the system. We approximate this with GitHub Actions, but that doesn\u2019t help with manual verification or DB work.<p>Copilot doesn\u2019t let you choose a model when assigning an issue or during code review. The model it uses is generally bad. You can pick a model in Copilot chat, but not in issues, PRs or reviews.<p>Cursor + worktrees + agents suck. Worktrees clone from the source repo including unstaged files, so if you want a clean agent environment, your main repo has to be clean. At times it feels simpler to just clone the repo into a new directory instead of using worktrees.<p>What\u2019s working well:\nBecause we constantly spin up agents, our monorepo setup scripts are well-tested and reliable. They also translate cleanly into CI/CD.<p>Roughly 25% of \u201copen issue \u2192 Copilot PR\u201d results are mergeable as-is. That\u2019s not amazing, but better than zero, and it gets to ~50% with a few comments. This would be higher if Copilot followed our setup instructions more reliably or let us use stronger models.<p>Overall, for roughly $1k/month, we\u2019re getting the equivalent of 1.5 additional junior/mid engineers per engineer. Those \u201cLLM engineers\u201d always write tests, follow standards, produce good commit messages, and work 24/7. There\u2019s friction in reviewing and context-switching across agents, but it\u2019s manageable.<p>What are you doing for vibe coding in a <em>production</em> system?"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: How are you LLM-coding in an established code base?"}}, "_tags": ["story", "author_adam_gyroscope", "story_46292682", "ask_hn"], "author": "adam_gyroscope", "children": [46294747, 46294779, 46295422, 46307422, 46330999, 46331023, 46331073, 46331080, 46331132, 46331161, 46331170, 46331255, 46331263, 46331367, 46331493, 46331549, 46331691, 46331805, 46331868, 46331893, 46331919, 46331988, 46332013, 46332047, 46332068, 46332139, 46334444, 46334841, 46335104], "created_at": "2025-12-16T18:54:37Z", "created_at_i": 1765911277, "num_comments": 66, "objectID": "46292682", "points": 70, "story_id": 46292682, "story_text": "Here\u2019s how we\u2019re working with LLMs at my startup.<p>We have a monorepo with scheduled Python data workflows, two Next.js apps, and a small engineering team. We use GitHub for SCM and CI&#x2F;CD, deploy to GCP and Vercel, and lean heavily on automation.<p>Local development:\nEvery engineer gets Cursor Pro (plus Bugbot), Gemini Pro, OpenAI Pro, and optionally Claude Pro. We don\u2019t really care which model people use. In practice, LLMs are worth about 1.5 excellent junior&#x2F;mid-level engineers per engineer, so paying for multiple models is easily worth it.<p>We rely heavily on pre-commit hooks: ty, ruff, TypeScript checks, tests across all languages, formatting, and other guards. Everything is auto-formatted. LLMs make types and tests much easier to write, though complex typing still needs some hand-holding.<p>GitHub + Copilot workflow:\nWe pay for GitHub Enterprise primarily because it allows assigning issues to Copilot, which then opens a PR. Our rule is simple: if you open an issue, you assign it to Copilot. Every issue gets a code attempt attached to it.<p>There\u2019s no stigma around lots of PRs. We frequently delete ones we don\u2019t use.<p>We use Turborepo for the monorepo and are fully uv on the Python side.<p>All coding practices are encoded in .cursor&#x2F;rules files. For example: \u201cIf you are doing database work, only edit Drizzle\u2019s schema.ts and don\u2019t hand-write SQL.\u201d Cursor generally respects this, but other tools struggle to consistently read or follow these rules no matter how many agent.md-style files we add.<p>My personal dev loop:\nIf I\u2019m on the go and see a bug or have an idea, I open a GitHub issue (via Slack, mobile, or web) and assign it to Copilot. Sometimes the issue is detailed; sometimes a single sentence. Copilot opens a PR, and I review it later.<p>If I\u2019m at the keyboard, I start in Cursor as an agent in a Git worktree, using whatever the best model is. I iterate until I\u2019m happy, ask the LLM to write tests, review everything, and push to GitHub. Before a human review, I let Cursor Bugbot, Copilot, and GitHub CodeQL review the code, and ask Copilot to fix anything they flag.<p>Things that are still painful:\nTo really know if code works, I need to run Temporal, two Next.js apps, several Python workers, and a Node worker. Some of this is Dockerized, some isn\u2019t. Then I need a browser to run manual checks.<p>AFAICT, there\u2019s no service that lets me: give a prompt, write the code, spin up all this infra, run Playwright, handle database migrations, and let me manually poke at the system. We approximate this with GitHub Actions, but that doesn\u2019t help with manual verification or DB work.<p>Copilot doesn\u2019t let you choose a model when assigning an issue or during code review. The model it uses is generally bad. You can pick a model in Copilot chat, but not in issues, PRs or reviews.<p>Cursor + worktrees + agents suck. Worktrees clone from the source repo including unstaged files, so if you want a clean agent environment, your main repo has to be clean. At times it feels simpler to just clone the repo into a new directory instead of using worktrees.<p>What\u2019s working well:\nBecause we constantly spin up agents, our monorepo setup scripts are well-tested and reliable. They also translate cleanly into CI&#x2F;CD.<p>Roughly 25% of \u201copen issue \u2192 Copilot PR\u201d results are mergeable as-is. That\u2019s not amazing, but better than zero, and it gets to ~50% with a few comments. This would be higher if Copilot followed our setup instructions more reliably or let us use stronger models.<p>Overall, for roughly $1k&#x2F;month, we\u2019re getting the equivalent of 1.5 additional junior&#x2F;mid engineers per engineer. Those \u201cLLM engineers\u201d always write tests, follow standards, produce good commit messages, and work 24&#x2F;7. There\u2019s friction in reviewing and context-switching across agents, but it\u2019s manageable.<p>What are you doing for vibe coding in a production system?", "title": "Ask HN: How are you LLM-coding in an established code base?", "updated_at": "2026-01-27T04:05:40Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "jobsdone"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["drizzle", "production"], "value": "Hey HN, Dan here from Payload (YC S22), an open-source headless CMS that closes the gap between CMS and traditional app frameworks. We\u2019re excited to announce Payload 2.0!<p>https://github.com/payloadcms/payload<p>If you\u2019ve not heard of Payload you\u2019re probably wondering why the world needs another CMS. Payload connects to your database and runs without the vendor lock-in and black box of SaaS based CMS solutions, and it\u2019s far more extensible than off-the-shelf SaaS options. Enterprises in specific have been finding value in this control, and they\u2019re using Payload to power content infrastructure that simply isn\u2019t possible through integrating with SaaS webhooks alone.<p>Today\u2019s announcement is all about features that strike at two neglected areas in the world of CMS. The first is application framework level control over your database that you\u2019d expect with tools like Ruby on Rails or Laravel and the second area is making content editors effective by seeing their edits in realtime.<p>Here are the highlights on what we\u2019ve been working on:<p>*Postgres Support*\u2014in the same week we launched about two years ago,people asked for Postgres support. It brings me pure cathartic joy to finally give this to our community. To be fair, MongoDB has been a perfect solution for our architecture and it\u2019s still recommended. But with a new adapter pattern for databases, you can stand your Payload project up on Postgres and run the same functionality as you can with MongoDB now. The crazy part is that we didn\u2019t compromise on how nesting complex fields works. We could have taken the \u201ceasy\u201d road and wrote things to JSON, but we leaned fully into the relational way and built the right tables and native column types for fields all the way throughout.<p>*Database Migrations*\u2014maintaining a <em>production</em> app while deploying schema changes is something you come to expect from ORMs and backend frameworks, but rarely CMS. Payload 2.0 delivers full, first-party migration support all in TypeScript. We took a lot of care on the developer experience here so that when working with Postgres, thanks to our friends at <em>Drizzle</em>, we generate the migration files in TS that add the tables and fields for you. If you have to manipulate data before or after, you have a clear way forward now.<p>*Database Transactions*\u2014when a request involves multiple inserts, updates or deletes to the database, you need control to rollback all changes when one part fails. The built-in Payload CRUD operations do this now for you and your custom hooks and other code can too.<p>*Live Preview*\u2014the ability to quickly draft content and see it in context of a website is a literal game changer. We have taken the best dev experience of any headless CMS and given the editors a reason to demand Payload over the others.<p>*Lexical Richtext Editor*\u2014our original Slate based editor has seen some great features added, like storing related documents directly in the JSON, uploads and any customizations. Unfortunately Slate leaves a lot to be desired on how to extend it, especially compared to Lexical. In a few short weeks we\u2019ve built up a new editor experience inspired by Medium and Notion. Now type \u201c/\u201d and have embedded relationships, uploads, and custom blocks popping right up to be dropped in. Then drag and drop them to reorder your content. If you still want Slate, we continue to support that too.<p>We\u2019re not compromising on editor experience. This is how we\u2019re bringing the \u201chead\u201d to the headless CMS.<p>Building critical applications on top of a CMS may sound like blasphemy but it doesn\u2019t have to be that way.<p>Thanks for reading! I look forward to hearing what you think."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Payload 2.0 released, TypeScript headless CMS and app framework"}}, "_tags": ["story", "author_jobsdone", "story_37819539", "ask_hn"], "author": "jobsdone", "children": [37820164, 37820272, 37820405, 37825994, 37825997], "created_at": "2023-10-09T12:04:13Z", "created_at_i": 1696853053, "num_comments": 5, "objectID": "37819539", "points": 24, "story_id": 37819539, "story_text": "Hey HN, Dan here from Payload (YC S22), an open-source headless CMS that closes the gap between CMS and traditional app frameworks. We\u2019re excited to announce Payload 2.0!<p>https:&#x2F;&#x2F;github.com&#x2F;payloadcms&#x2F;payload<p>If you\u2019ve not heard of Payload you\u2019re probably wondering why the world needs another CMS. Payload connects to your database and runs without the vendor lock-in and black box of SaaS based CMS solutions, and it\u2019s far more extensible than off-the-shelf SaaS options. Enterprises in specific have been finding value in this control, and they\u2019re using Payload to power content infrastructure that simply isn\u2019t possible through integrating with SaaS webhooks alone.<p>Today\u2019s announcement is all about features that strike at two neglected areas in the world of CMS. The first is application framework level control over your database that you\u2019d expect with tools like Ruby on Rails or Laravel and the second area is making content editors effective by seeing their edits in realtime.<p>Here are the highlights on what we\u2019ve been working on:<p>*Postgres Support*\u2014in the same week we launched about two years ago,people asked for Postgres support. It brings me pure cathartic joy to finally give this to our community. To be fair, MongoDB has been a perfect solution for our architecture and it\u2019s still recommended. But with a new adapter pattern for databases, you can stand your Payload project up on Postgres and run the same functionality as you can with MongoDB now. The crazy part is that we didn\u2019t compromise on how nesting complex fields works. We could have taken the \u201ceasy\u201d road and wrote things to JSON, but we leaned fully into the relational way and built the right tables and native column types for fields all the way throughout.<p>*Database Migrations*\u2014maintaining a production app while deploying schema changes is something you come to expect from ORMs and backend frameworks, but rarely CMS. Payload 2.0 delivers full, first-party migration support all in TypeScript. We took a lot of care on the developer experience here so that when working with Postgres, thanks to our friends at Drizzle, we generate the migration files in TS that add the tables and fields for you. If you have to manipulate data before or after, you have a clear way forward now.<p>*Database Transactions*\u2014when a request involves multiple inserts, updates or deletes to the database, you need control to rollback all changes when one part fails. The built-in Payload CRUD operations do this now for you and your custom hooks and other code can too.<p>*Live Preview*\u2014the ability to quickly draft content and see it in context of a website is a literal game changer. We have taken the best dev experience of any headless CMS and given the editors a reason to demand Payload over the others.<p>*Lexical Richtext Editor*\u2014our original Slate based editor has seen some great features added, like storing related documents directly in the JSON, uploads and any customizations. Unfortunately Slate leaves a lot to be desired on how to extend it, especially compared to Lexical. In a few short weeks we\u2019ve built up a new editor experience inspired by Medium and Notion. Now type \u201c&#x2F;\u201d and have embedded relationships, uploads, and custom blocks popping right up to be dropped in. Then drag and drop them to reorder your content. If you still want Slate, we continue to support that too.<p>We\u2019re not compromising on editor experience. This is how we\u2019re bringing the \u201chead\u201d to the headless CMS.<p>Building critical applications on top of a CMS may sound like blasphemy but it doesn\u2019t have to be that way.<p>Thanks for reading! I look forward to hearing what you think.", "title": "Payload 2.0 released, TypeScript headless CMS and app framework", "updated_at": "2024-09-20T15:20:47Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "jkcorrea"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["drizzle", "production"], "value": "tldr: someone PLEASE build a modern SQL editor. I would pay upwards of $20/seat/mo for a good one. strong suspicion many others would too.<p>-- The problem/rant<p>I've grown increasingly frustrated with how archaic the modern story for basic database adminning has become. So many aspects of the developer experience have improved dramatically in recent years, but it feels like database tooling is one massive vertical hasn't received much the same TLC.<p>Do people just not use SQL editors that often? I find myself constantly cmd-tabbing to Postico to check/modify some rows either during development or to resolve prod issues. But the second I need a more advanced/relational filter it's either a lot of painful clicks away or just impossible to do through the table UI and now I have to write a query from scratch.<p>If it's a commonly recurring task you can save the query, but now I have hundreds of these saved queries all with slightly different names to the point where it's less taxing to just write a new query then hunt down &amp; slightly modify an old one.<p>Collaboration is non-existant. I'm forced to share these queries via slack or committing to a `misc/*.sql` folder in our repo which feels awkward.<p>Tools I've tried include Postico, DBeaver, TablePlus, Beekeeper Studio, PopSQL, and various VSCode extensions. I don't need features around DB Ops, I use Neon/Supabase/etc and just hope I never have to think about DB ops. I almost don't care about SDL tasks either, I mainly do that through my ORM (s/o <em>Drizzle</em>)<p>-- My request<p>Here's a braindump of features I frequently desire. I would pay for a tool that did even ONE of these, but I think all are very possible and would 100x the value of an editor to me:<p><pre><code>    - Intuitive filtering UI. You know my `id` column is a text, why is the default filter operation `&gt;`. I almost never want that for string cols. Let me type &quot;yesterday at 3pm&quot; in a timestamp filter. Let me fuzzy search my entire DB (obv this is hard for large dbs)\n    - Relational filters. I should be able to filter by properties on relations. I'm often only given a username when solving a prod issue, and now finding their records in other tables becomes a 2-step process of finding the user's ID then using that in a filter on the table I care about\n    - Embedding &amp; formatted columns. I have various reports as custom queries/views that I export as CSVs weekly to give to teammates. I wish I could just embed this view as an iframe in our internal dashboard. If you're feeling generous, allow me to format the columns like Airtable or even make charts based on the view. This could easily become a massive business in its own right.\n    - SQL language server/intellisense (h/t https://github.com/supabase-community/postgres_lsp). Need I say more?\n    - AI autocompletion &amp; generation (a la Cursor). My current workflow is to cmd+tab to my ORM definition file, ask cursor to come up with a PSQL query for X table for Y problem, then cmd+tab back to Postico to run it.\n    - Notebooks. I want to create playbooks to share with my team. Post-mortems, &quot;here's how  I debug XYZ <em>production</em> issue&quot;, etc.\n    - Omnisearch. Let me CMD+K and fuzzy/semantic search across my saved queries, tables, etc.\n</code></pre>\nI'll be honest, been sitting on this idea for over a year and have tried and failed multiple times to build it myself (skill issue). Throwing this out there in hopes that a more cracked engineer is interested in taking a stab at it. I would immediately pay upwards of $20/mo for even a partial solution and probably more for some of the team related features.<p>Email in bio if you're interested in taking this up and want to chat more"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: RFS: Modern SQL/db editor"}}, "_tags": ["story", "author_jkcorrea", "story_41286912", "ask_hn"], "author": "jkcorrea", "children": [41289870, 41290666, 41290885, 41295149, 41299910, 41300491], "created_at": "2024-08-19T01:03:51Z", "created_at_i": 1724029431, "num_comments": 15, "objectID": "41286912", "points": 11, "story_id": 41286912, "story_text": "tldr: someone PLEASE build a modern SQL editor. I would pay upwards of $20&#x2F;seat&#x2F;mo for a good one. strong suspicion many others would too.<p>-- The problem&#x2F;rant<p>I&#x27;ve grown increasingly frustrated with how archaic the modern story for basic database adminning has become. So many aspects of the developer experience have improved dramatically in recent years, but it feels like database tooling is one massive vertical hasn&#x27;t received much the same TLC.<p>Do people just not use SQL editors that often? I find myself constantly cmd-tabbing to Postico to check&#x2F;modify some rows either during development or to resolve prod issues. But the second I need a more advanced&#x2F;relational filter it&#x27;s either a lot of painful clicks away or just impossible to do through the table UI and now I have to write a query from scratch.<p>If it&#x27;s a commonly recurring task you can save the query, but now I have hundreds of these saved queries all with slightly different names to the point where it&#x27;s less taxing to just write a new query then hunt down &amp; slightly modify an old one.<p>Collaboration is non-existant. I&#x27;m forced to share these queries via slack or committing to a `misc&#x2F;*.sql` folder in our repo which feels awkward.<p>Tools I&#x27;ve tried include Postico, DBeaver, TablePlus, Beekeeper Studio, PopSQL, and various VSCode extensions. I don&#x27;t need features around DB Ops, I use Neon&#x2F;Supabase&#x2F;etc and just hope I never have to think about DB ops. I almost don&#x27;t care about SDL tasks either, I mainly do that through my ORM (s&#x2F;o Drizzle)<p>-- My request<p>Here&#x27;s a braindump of features I frequently desire. I would pay for a tool that did even ONE of these, but I think all are very possible and would 100x the value of an editor to me:<p><pre><code>    - Intuitive filtering UI. You know my `id` column is a text, why is the default filter operation `&gt;`. I almost never want that for string cols. Let me type &quot;yesterday at 3pm&quot; in a timestamp filter. Let me fuzzy search my entire DB (obv this is hard for large dbs)\n    - Relational filters. I should be able to filter by properties on relations. I&#x27;m often only given a username when solving a prod issue, and now finding their records in other tables becomes a 2-step process of finding the user&#x27;s ID then using that in a filter on the table I care about\n    - Embedding &amp; formatted columns. I have various reports as custom queries&#x2F;views that I export as CSVs weekly to give to teammates. I wish I could just embed this view as an iframe in our internal dashboard. If you&#x27;re feeling generous, allow me to format the columns like Airtable or even make charts based on the view. This could easily become a massive business in its own right.\n    - SQL language server&#x2F;intellisense (h&#x2F;t https:&#x2F;&#x2F;github.com&#x2F;supabase-community&#x2F;postgres_lsp). Need I say more?\n    - AI autocompletion &amp; generation (a la Cursor). My current workflow is to cmd+tab to my ORM definition file, ask cursor to come up with a PSQL query for X table for Y problem, then cmd+tab back to Postico to run it.\n    - Notebooks. I want to create playbooks to share with my team. Post-mortems, &quot;here&#x27;s how  I debug XYZ production issue&quot;, etc.\n    - Omnisearch. Let me CMD+K and fuzzy&#x2F;semantic search across my saved queries, tables, etc.\n</code></pre>\nI&#x27;ll be honest, been sitting on this idea for over a year and have tried and failed multiple times to build it myself (skill issue). Throwing this out there in hopes that a more cracked engineer is interested in taking a stab at it. I would immediately pay upwards of $20&#x2F;mo for even a partial solution and probably more for some of the team related features.<p>Email in bio if you&#x27;re interested in taking this up and want to chat more", "title": "Ask HN: RFS: Modern SQL/db editor", "updated_at": "2024-09-20T17:42:27Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "creativedg"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["drizzle", "production"], "value": "I started this boilerplate in July 2020 and I\u2019ve been maintaining it for 5 years. It began on Next.js 9 and kept upgrading to Next.js 15+ (App Router), while upgrading the stack over time (Tailwind 1 \u2192 4, ESLint 8, swapping Cypress \u2192 Playwright, etc.). The goal is simple: I kept rebuilding the same setup, so I packaged it and kept it updated.<p>What you get (preconfigured, keep only what you need):<p>- Next.js 15 (App Router) + TypeScript + Tailwind 4<p>- Auth with Clerk (magic links, MFA, social, passkeys)<p>- I18n via next-intl<p>- DB with <em>Drizzle</em> ORM (PGlite locally)<p>- Forms with React Hook Form + Zod validation<p>- Testing: Vitest (unit), Playwright (integration/E2E)<p>- CI with GitHub Actions; Storybook for UI work<p>- SEO (Open Graph, JSON-LD, sitemap, robots)<p>- Observability: Sentry, logging with LogTape, log management &amp; uptime/monitoring<p>- Security: Arcjet (bot detection, rate limiting, shield rules)<p>- DX details: ESLint/Prettier, Lefthook + lint-staged, Commitlint, absolute imports, bundle analyzer<p>- AI code review<p>It\u2019s free and open source (MIT). Today the project sits around 11.8k GitHub stars and 2.2k forks. I\u2019m still actively maintaining it and adding features.<p>Repo: <a href=\"https://github.com/ixartz/Next-js-Boilerplate\" rel=\"nofollow\">https://github.com/ixartz/Next-js-Boilerplate</a><p>Why I built it<p>Spinning up auth, a DB, i18n, tests, and lint/format/CI for each new app was repetitive. This gives me (and hopefully you) a <em>production</em>-ready base in minutes, with opinionated defaults you can start.<p>I\u2019m open to suggestions and feedback, what would you like to see next? I\u2019ll hang around in the comments to answer questions."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Open-source Next.js 15 boilerplate \u2013 auth, DB, intl, tests, monitoring"}}, "_tags": ["story", "author_creativedg", "story_45052744", "show_hn"], "author": "creativedg", "created_at": "2025-08-28T14:38:31Z", "created_at_i": 1756391911, "num_comments": 0, "objectID": "45052744", "points": 4, "story_id": 45052744, "story_text": "I started this boilerplate in July 2020 and I\u2019ve been maintaining it for 5 years. It began on Next.js 9 and kept upgrading to Next.js 15+ (App Router), while upgrading the stack over time (Tailwind 1 \u2192 4, ESLint 8, swapping Cypress \u2192 Playwright, etc.). The goal is simple: I kept rebuilding the same setup, so I packaged it and kept it updated.<p>What you get (preconfigured, keep only what you need):<p>- Next.js 15 (App Router) + TypeScript + Tailwind 4<p>- Auth with Clerk (magic links, MFA, social, passkeys)<p>- I18n via next-intl<p>- DB with Drizzle ORM (PGlite locally)<p>- Forms with React Hook Form + Zod validation<p>- Testing: Vitest (unit), Playwright (integration&#x2F;E2E)<p>- CI with GitHub Actions; Storybook for UI work<p>- SEO (Open Graph, JSON-LD, sitemap, robots)<p>- Observability: Sentry, logging with LogTape, log management &amp; uptime&#x2F;monitoring<p>- Security: Arcjet (bot detection, rate limiting, shield rules)<p>- DX details: ESLint&#x2F;Prettier, Lefthook + lint-staged, Commitlint, absolute imports, bundle analyzer<p>- AI code review<p>It\u2019s free and open source (MIT). Today the project sits around 11.8k GitHub stars and 2.2k forks. I\u2019m still actively maintaining it and adding features.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ixartz&#x2F;Next-js-Boilerplate\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ixartz&#x2F;Next-js-Boilerplate</a><p>Why I built it<p>Spinning up auth, a DB, i18n, tests, and lint&#x2F;format&#x2F;CI for each new app was repetitive. This gives me (and hopefully you) a production-ready base in minutes, with opinionated defaults you can start.<p>I\u2019m open to suggestions and feedback, what would you like to see next? I\u2019ll hang around in the comments to answer questions.", "title": "Show HN: Open-source Next.js 15 boilerplate \u2013 auth, DB, intl, tests, monitoring", "updated_at": "2025-08-29T18:59:31Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "twwch"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["drizzle", "production"], "value": "URL: <a href=\"https://github.com/twwch/next-chat-skills\" rel=\"nofollow\">https://github.com/twwch/next-chat-skills</a><p>---<p>Text (paste into the &quot;text&quot; field):<p>Hi HN,<p>I built an open-source AI assistant that can autonomously discover, install, and execute Skills to actually complete tasks for you.<p>The Problem:<p>Most AI chatbots today are stuck in &quot;read-only&quot; mode. They can tell you how to do something, but they can't do it. Want to convert a PPTX to PDF? The AI will explain how, but you still have to run the commands yourself.<p>The Solution:<p>Next-Chat-Skills is a self-hosted AI assistant with a plugin system called Skills. When you ask the AI to do something it can't handle natively, it:<p>1. Searches for a relevant Skill (like an app store for AI capabilities)\n2. Installs it automatically (npx skills add ...)\n3. Executes the Skill's scripts (Python, Node.js, Shell)\n4. Streams real-time output back to you in a terminal UI\n5. Recovers from errors by installing missing dependencies and retrying<p>For example:<p><pre><code>  User: &quot;Summarize this YouTube video for me&quot;\n  AI:   -&gt; Searches for a video-summarizer Skill\n        -&gt; Installs it (yt-dlp + Whisper)\n        -&gt; Downloads the video, transcribes audio\n        -&gt; Returns a structured summary\n</code></pre>\nNo manual setup. No copy-pasting commands. The AI handles the entire workflow.<p>What is a Skill?<p>A Skill is just a folder with a SKILL.md descriptor and some scripts:<p><pre><code>  ~/.agents/skills/video-summarizer/\n  \u251c\u2500\u2500 SKILL.md              # Metadata + description\n  \u251c\u2500\u2500 scripts/\n  \u2502   \u251c\u2500\u2500 download.py       # Download video\n  \u2502   \u251c\u2500\u2500 transcribe.py     # Whisper transcription\n  \u2502   \u2514\u2500\u2500 summarize.js      # Generate summary\n  \u2514\u2500\u2500 rules/                # Usage guidelines for the AI\n</code></pre>\nAnyone can create and share Skills. The AI reads the SKILL.md to understand when and how to invoke each script. It's composable \u2014 the more Skills you add, the more capable your assistant becomes.<p>Key Features:<p>- Autonomous Skill discovery &amp; installation \u2014 AI finds and installs what it needs\n- Real-time script execution \u2014 streams terminal output via SSE, supports Python/Node.js/Shell\n- File generation &amp; download \u2014 scripts can generate files (PPTX, PDF, images) that users can download directly from chat\n- Multi-file upload &amp; parsing \u2014 supports images, PDF, DOCX, XLSX, PPTX\n- Dual database \u2014 SQLite (zero-config) or PostgreSQL (<em>production</em>)\n- Optional auth \u2014 Google OAuth or fingerprint-based, works without login too\n- Docker-ready \u2014 pre-built image with Python, FFmpeg, LibreOffice, and popular Skills pre-installed\n- Works with any OpenAI-compatible API \u2014 GPT-4o, Claude (via proxy), local models, etc.<p>Tech Stack: Next.js 16, React 19, TypeScript, Vercel AI SDK, Tailwind CSS 4, shadcn/ui, <em>Drizzle</em> ORM (SQLite / PostgreSQL), Docker (Node.js 20 + Python 3)<p>Quick Start:<p><pre><code>  # Docker (fastest)\n  docker run -p 3000:3000 \\\n    -e OPENAI_API_KEY=sk-xxx \\\n    -e OPENAI_BASE_URL=https://api.openai.com/v1 \\\n    twwch/next-chat-skills:latest\n\n  # Or from source\n  git clone https://github.com/twwch/next-chat-skills\n  cd next-chat-skills\n  npm install &amp;&amp; npm run dev\n</code></pre>\nWhy I Built This:<p>I got tired of AI assistants that stop at &quot;here's a code snippet.&quot; I wanted an AI that could actually run the code, handle failures, install dependencies, and deliver the final result \u2014 like having a junior developer who can use any Skill you point them at.<p>The Skills system makes this extensible without modifying the core app. Anyone can package a workflow as a Skill and share it.<p>What's Next:<p>- Skill marketplace / registry for community sharing\n- Multi-step workflow chaining (Skill A output -&gt; Skill B input)\n- Better sandboxing for script execution\n- MCP (Model Context Protocol) integration<p>I'd love to hear your feedback. What Skills would you want to see? What's missing?<p>GitHub: <a href=\"https://github.com/twwch/next-chat-skills\" rel=\"nofollow\">https://github.com/twwch/next-chat-skills</a>\nLicense: Apache 2.0"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Give Your AI the Ability to Find, Install, and Use Skill Autonomously"}}, "_tags": ["story", "author_twwch", "story_46942091", "show_hn"], "author": "twwch", "created_at": "2026-02-09T06:13:22Z", "created_at_i": 1770617602, "num_comments": 0, "objectID": "46942091", "points": 2, "story_id": 46942091, "story_text": "URL: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;twwch&#x2F;next-chat-skills\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;twwch&#x2F;next-chat-skills</a><p>---<p>Text (paste into the &quot;text&quot; field):<p>Hi HN,<p>I built an open-source AI assistant that can autonomously discover, install, and execute Skills to actually complete tasks for you.<p>The Problem:<p>Most AI chatbots today are stuck in &quot;read-only&quot; mode. They can tell you how to do something, but they can&#x27;t do it. Want to convert a PPTX to PDF? The AI will explain how, but you still have to run the commands yourself.<p>The Solution:<p>Next-Chat-Skills is a self-hosted AI assistant with a plugin system called Skills. When you ask the AI to do something it can&#x27;t handle natively, it:<p>1. Searches for a relevant Skill (like an app store for AI capabilities)\n2. Installs it automatically (npx skills add ...)\n3. Executes the Skill&#x27;s scripts (Python, Node.js, Shell)\n4. Streams real-time output back to you in a terminal UI\n5. Recovers from errors by installing missing dependencies and retrying<p>For example:<p><pre><code>  User: &quot;Summarize this YouTube video for me&quot;\n  AI:   -&gt; Searches for a video-summarizer Skill\n        -&gt; Installs it (yt-dlp + Whisper)\n        -&gt; Downloads the video, transcribes audio\n        -&gt; Returns a structured summary\n</code></pre>\nNo manual setup. No copy-pasting commands. The AI handles the entire workflow.<p>What is a Skill?<p>A Skill is just a folder with a SKILL.md descriptor and some scripts:<p><pre><code>  ~&#x2F;.agents&#x2F;skills&#x2F;video-summarizer&#x2F;\n  \u251c\u2500\u2500 SKILL.md              # Metadata + description\n  \u251c\u2500\u2500 scripts&#x2F;\n  \u2502   \u251c\u2500\u2500 download.py       # Download video\n  \u2502   \u251c\u2500\u2500 transcribe.py     # Whisper transcription\n  \u2502   \u2514\u2500\u2500 summarize.js      # Generate summary\n  \u2514\u2500\u2500 rules&#x2F;                # Usage guidelines for the AI\n</code></pre>\nAnyone can create and share Skills. The AI reads the SKILL.md to understand when and how to invoke each script. It&#x27;s composable \u2014 the more Skills you add, the more capable your assistant becomes.<p>Key Features:<p>- Autonomous Skill discovery &amp; installation \u2014 AI finds and installs what it needs\n- Real-time script execution \u2014 streams terminal output via SSE, supports Python&#x2F;Node.js&#x2F;Shell\n- File generation &amp; download \u2014 scripts can generate files (PPTX, PDF, images) that users can download directly from chat\n- Multi-file upload &amp; parsing \u2014 supports images, PDF, DOCX, XLSX, PPTX\n- Dual database \u2014 SQLite (zero-config) or PostgreSQL (production)\n- Optional auth \u2014 Google OAuth or fingerprint-based, works without login too\n- Docker-ready \u2014 pre-built image with Python, FFmpeg, LibreOffice, and popular Skills pre-installed\n- Works with any OpenAI-compatible API \u2014 GPT-4o, Claude (via proxy), local models, etc.<p>Tech Stack: Next.js 16, React 19, TypeScript, Vercel AI SDK, Tailwind CSS 4, shadcn&#x2F;ui, Drizzle ORM (SQLite &#x2F; PostgreSQL), Docker (Node.js 20 + Python 3)<p>Quick Start:<p><pre><code>  # Docker (fastest)\n  docker run -p 3000:3000 \\\n    -e OPENAI_API_KEY=sk-xxx \\\n    -e OPENAI_BASE_URL=https:&#x2F;&#x2F;api.openai.com&#x2F;v1 \\\n    twwch&#x2F;next-chat-skills:latest\n\n  # Or from source\n  git clone https:&#x2F;&#x2F;github.com&#x2F;twwch&#x2F;next-chat-skills\n  cd next-chat-skills\n  npm install &amp;&amp; npm run dev\n</code></pre>\nWhy I Built This:<p>I got tired of AI assistants that stop at &quot;here&#x27;s a code snippet.&quot; I wanted an AI that could actually run the code, handle failures, install dependencies, and deliver the final result \u2014 like having a junior developer who can use any Skill you point them at.<p>The Skills system makes this extensible without modifying the core app. Anyone can package a workflow as a Skill and share it.<p>What&#x27;s Next:<p>- Skill marketplace &#x2F; registry for community sharing\n- Multi-step workflow chaining (Skill A output -&gt; Skill B input)\n- Better sandboxing for script execution\n- MCP (Model Context Protocol) integration<p>I&#x27;d love to hear your feedback. What Skills would you want to see? What&#x27;s missing?<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;twwch&#x2F;next-chat-skills\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;twwch&#x2F;next-chat-skills</a>\nLicense: Apache 2.0", "title": "Show HN: Give Your AI the Ability to Find, Install, and Use Skill Autonomously", "updated_at": "2026-02-09T06:36:16Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "vfssantos"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["drizzle", "production"], "value": "I built Ominipg, a PostgreSQL toolkit for Deno that lets you:<p>1. Start with an in-memory database for quick prototyping/tests<p>2. Switch to a local on-disk PGlite DB<p>3. Move to a real remote PostgreSQL instance<p>\u2026all using the same API and code, with an optional local\u2194remote sync mode for offline-first apps.<p>Why?<p>Most apps go through these stages:<p>1. Prototyping/Testing \u2013 you just want a fast, zero-setup in-memory DB.<p>2. Local-first \u2013 you want offline capability but still sync to the cloud.<p>3. <em>Production</em> \u2013 you want a full PostgreSQL instance, without rewriting your data layer.<p>Ominipg is my attempt to make that path smoother.<p>Modes<p>- url: &quot;:memory:&quot; \u2013 PGlite in WASM, in-memory. Great for tests, demos, or quick spikes. No Postgres install required.\n - url: &quot;path/to/db&quot; \u2013 PGlite with disk storage. Nice for desktop apps, CLIs, or local development.\n - url: &quot;postgresql://...&quot; \u2013 Direct connection to your remote/<em>production</em> Postgres.<p>Local + Remote sync (both URLs) \u2013 Use a local PGlite DB that automatically syncs with remote Postgres, so you can build offline-first apps or just get faster reads while still persisting everything remotely.<p>Under the hood, PGlite runs in a Web Worker automatically (when available), so heavy queries don\u2019t block your main thread \u2013 you don\u2019t have to think about workers yourself.<p>Typed CRUD with Mongo-style queries<p>Instead of writing SQL, you can use MongoDB-style queries with TypeScript types inferred from JSON Schema definitions:<p>const adults = await db.crud.users.find({ \n   age: { $gte: 18 },\n   status: { $in: [&quot;active&quot;, &quot;premium&quot;] },\n }); \n // `adults` is fully typed based on your `users` schema<p>If you prefer, you can also use <em>Drizzle</em> ORM on top, or drop down to raw SQL. Ominipg doesn\u2019t force you into one style.<p>Example<p>import { Ominipg, defineSchema } from &quot;jsr:@oxian/ominipg&quot;;<p>const schemas = defineSchema({\n   users: {\n     schema: {\n       type: &quot;object&quot;,\n       properties: {\n         id: { type: &quot;string&quot; },\n         name: { type: &quot;string&quot; },\n       },\n       required: [&quot;id&quot;, &quot;name&quot;],\n     },\n     keys: [{ property: &quot;id&quot; }],\n   },\n });<p>// Start in-memory, later point this to postgresql://... or  ./local.db\n const db = await Ominipg.connect({\n   url: &quot;:memory:&quot;,\n   schemas,\n });<p>await db.crud.users.insertOne({\n   id: &quot;1&quot;,\n   name: &quot;Alice&quot;,\n });<p>const activeUsers = await db.crud.users.find({\n   name: { $in: [&quot;Alice&quot;] },\n });<p>Links:<p>- JSR: <a href=\"https://jsr.io/@oxian/ominipg\" rel=\"nofollow\">https://jsr.io/@oxian/ominipg</a><p>- GitHub: <a href=\"https://github.com/AxionCompany/ominipg\" rel=\"nofollow\">https://github.com/AxionCompany/ominipg</a><p>\u2022 A bit about me / what I\u2019m looking for<p>I\u2019m a co-founder of a software development agency in Brazil. We\u2019ve shipped 500+ projects (many enterprise), and a lot of our success has come from investing in developer productivity and internal tooling, including early bets on the Deno ecosystem. We recently decided to open-source some of these tools. Ominipg is the first of several, I\u2019d love to get feedback from the JS (specially Deno) ecosystem.<p>In particular, I\u2019d appreciate thoughts on:\n - The API design (especially the CRUD + schema approach)\n - The local + remote sync model\n - Rough edges you hit trying it in a small demo or side project"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Ominipg \u2013 Local-First Postgres for Deno"}}, "_tags": ["story", "author_vfssantos", "story_45979763", "show_hn"], "author": "vfssantos", "created_at": "2025-11-19T14:17:16Z", "created_at_i": 1763561836, "num_comments": 0, "objectID": "45979763", "points": 2, "story_id": 45979763, "story_text": "I built Ominipg, a PostgreSQL toolkit for Deno that lets you:<p>1. Start with an in-memory database for quick prototyping&#x2F;tests<p>2. Switch to a local on-disk PGlite DB<p>3. Move to a real remote PostgreSQL instance<p>\u2026all using the same API and code, with an optional local\u2194remote sync mode for offline-first apps.<p>Why?<p>Most apps go through these stages:<p>1. Prototyping&#x2F;Testing \u2013 you just want a fast, zero-setup in-memory DB.<p>2. Local-first \u2013 you want offline capability but still sync to the cloud.<p>3. Production \u2013 you want a full PostgreSQL instance, without rewriting your data layer.<p>Ominipg is my attempt to make that path smoother.<p>Modes<p>- url: &quot;:memory:&quot; \u2013 PGlite in WASM, in-memory. Great for tests, demos, or quick spikes. No Postgres install required.\n - url: &quot;path&#x2F;to&#x2F;db&quot; \u2013 PGlite with disk storage. Nice for desktop apps, CLIs, or local development.\n - url: &quot;postgresql:&#x2F;&#x2F;...&quot; \u2013 Direct connection to your remote&#x2F;production Postgres.<p>Local + Remote sync (both URLs) \u2013 Use a local PGlite DB that automatically syncs with remote Postgres, so you can build offline-first apps or just get faster reads while still persisting everything remotely.<p>Under the hood, PGlite runs in a Web Worker automatically (when available), so heavy queries don\u2019t block your main thread \u2013 you don\u2019t have to think about workers yourself.<p>Typed CRUD with Mongo-style queries<p>Instead of writing SQL, you can use MongoDB-style queries with TypeScript types inferred from JSON Schema definitions:<p>const adults = await db.crud.users.find({ \n   age: { $gte: 18 },\n   status: { $in: [&quot;active&quot;, &quot;premium&quot;] },\n }); \n &#x2F;&#x2F; `adults` is fully typed based on your `users` schema<p>If you prefer, you can also use Drizzle ORM on top, or drop down to raw SQL. Ominipg doesn\u2019t force you into one style.<p>Example<p>import { Ominipg, defineSchema } from &quot;jsr:@oxian&#x2F;ominipg&quot;;<p>const schemas = defineSchema({\n   users: {\n     schema: {\n       type: &quot;object&quot;,\n       properties: {\n         id: { type: &quot;string&quot; },\n         name: { type: &quot;string&quot; },\n       },\n       required: [&quot;id&quot;, &quot;name&quot;],\n     },\n     keys: [{ property: &quot;id&quot; }],\n   },\n });<p>&#x2F;&#x2F; Start in-memory, later point this to postgresql:&#x2F;&#x2F;... or  .&#x2F;local.db\n const db = await Ominipg.connect({\n   url: &quot;:memory:&quot;,\n   schemas,\n });<p>await db.crud.users.insertOne({\n   id: &quot;1&quot;,\n   name: &quot;Alice&quot;,\n });<p>const activeUsers = await db.crud.users.find({\n   name: { $in: [&quot;Alice&quot;] },\n });<p>Links:<p>- JSR: <a href=\"https:&#x2F;&#x2F;jsr.io&#x2F;@oxian&#x2F;ominipg\" rel=\"nofollow\">https:&#x2F;&#x2F;jsr.io&#x2F;@oxian&#x2F;ominipg</a><p>- GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;AxionCompany&#x2F;ominipg\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;AxionCompany&#x2F;ominipg</a><p>\u2022 A bit about me &#x2F; what I\u2019m looking for<p>I\u2019m a co-founder of a software development agency in Brazil. We\u2019ve shipped 500+ projects (many enterprise), and a lot of our success has come from investing in developer productivity and internal tooling, including early bets on the Deno ecosystem. We recently decided to open-source some of these tools. Ominipg is the first of several, I\u2019d love to get feedback from the JS (specially Deno) ecosystem.<p>In particular, I\u2019d appreciate thoughts on:\n - The API design (especially the CRUD + schema approach)\n - The local + remote sync model\n - Rough edges you hit trying it in a small demo or side project", "title": "Show HN: Ominipg \u2013 Local-First Postgres for Deno", "updated_at": "2025-11-19T16:22:24Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "nickjj"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["drizzle", "production"], "value": "I recently started a podcast / interview site called Running in <em>Production</em> at https://runninginproduction.com.<p>There's 1 podcast episode and 1 text interview up on the site if you want to take a look.<p>I'll be honest with you, since this is a guest based podcast / interview site it's very much a community driven project and I could really use your help by sharing your story on how you've built and deployed some type of web application. This could be a small or large personal site or some type of SAAS app / service you've built.<p>Anyone is welcome to come on as a guest or request to be interviewed by email. So if you're using Flask, Phoenix, Rails, Node, Django, Go, Laravel or anything else -- it's all good. I've love to have you on. We'll talk all about your tech stack from development to <em>production</em>.<p>If you want to be on the site, here's 1 of 2 short forms to fill out so I can get a better idea of what questions to ask you:<p>- Become a podcast guest (audio only): https://forms.gle/4fmWDJWfpoBPbwNg6<p>- Or do an email interview (text only): https://forms.gle/oPMErBbx3njisLZs6<p>Also, if you want to know more about the site in general, I made a short video here: https://www.youtube.com/watch?v=Wgvs30l3QpE<p>Lastly, just to give you the TL;DR on myself. I've been consistently blogging about technical topics for ~5 years over at https://nickjanetakis.com/blog/ and also create videos and video courses. I really want to go at this 100%, so this isn't going to be a half assed thing where it <em>drizzles</em> out after 2 months. As long as people are willing to be a guest on the site I am more than willing to put it all up."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: A podcast/interview site focused on tech stacks and web app deployment"}}, "_tags": ["story", "author_nickjj", "story_21536486", "show_hn"], "author": "nickjj", "created_at": "2019-11-14T16:04:21Z", "created_at_i": 1573747461, "num_comments": 0, "objectID": "21536486", "points": 2, "story_id": 21536486, "story_text": "I recently started a podcast &#x2F; interview site called Running in Production at https:&#x2F;&#x2F;runninginproduction.com.<p>There&#x27;s 1 podcast episode and 1 text interview up on the site if you want to take a look.<p>I&#x27;ll be honest with you, since this is a guest based podcast &#x2F; interview site it&#x27;s very much a community driven project and I could really use your help by sharing your story on how you&#x27;ve built and deployed some type of web application. This could be a small or large personal site or some type of SAAS app &#x2F; service you&#x27;ve built.<p>Anyone is welcome to come on as a guest or request to be interviewed by email. So if you&#x27;re using Flask, Phoenix, Rails, Node, Django, Go, Laravel or anything else -- it&#x27;s all good. I&#x27;ve love to have you on. We&#x27;ll talk all about your tech stack from development to production.<p>If you want to be on the site, here&#x27;s 1 of 2 short forms to fill out so I can get a better idea of what questions to ask you:<p>- Become a podcast guest (audio only): https:&#x2F;&#x2F;forms.gle&#x2F;4fmWDJWfpoBPbwNg6<p>- Or do an email interview (text only): https:&#x2F;&#x2F;forms.gle&#x2F;oPMErBbx3njisLZs6<p>Also, if you want to know more about the site in general, I made a short video here: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Wgvs30l3QpE<p>Lastly, just to give you the TL;DR on myself. I&#x27;ve been consistently blogging about technical topics for ~5 years over at https:&#x2F;&#x2F;nickjanetakis.com&#x2F;blog&#x2F; and also create videos and video courses. I really want to go at this 100%, so this isn&#x27;t going to be a half assed thing where it drizzles out after 2 months. As long as people are willing to be a guest on the site I am more than willing to put it all up.", "title": "Show HN: A podcast/interview site focused on tech stacks and web app deployment", "updated_at": "2024-09-20T05:08:44Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "linesofcode"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["drizzle", "production"], "value": "Say hello to <a href=\"https://pongo.sh/\" rel=\"nofollow\">https://pongo.sh/</a><p>self-hosted uptime monitoring, configured entirely in TypeScript and built on NextJS and Bun.<p>No UI forms. No vendor lock-in. Just code in your repo.<p>Monitors, dashboards, alerts, incidents, and status pages \u2014 all defined as TypeScript files and Markdown, version-controlled alongside your application.<p>You can one-click deploy it to Vercel or anywhere you can run node/bun/docker.<p>Your monitoring config lives in your repo like everything else.<p>Want to know what's monitored and why? Read the code.<p>Need to review a change? It's in the PR. Need to roll back a bad alert? Git revert.<p>No more clicking through dashboards wondering who changed what and when.<p>Built with Next.js, <em>Drizzle</em> ORM, and Bun. Runs with SQLite for simplicity or PostgreSQL for <em>production</em>.<p>Fully open source and ready to use today.<p>Would love to hear what you think and what features you'd want to see next, leave a star on GitHub<p><a href=\"https://github.com/TimMikeladze/pongo\" rel=\"nofollow\">https://github.com/TimMikeladze/pongo</a>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Pongo \u2013 a self hosted uptime monitor using configuration as code"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://www.pongo.sh/"}}, "_tags": ["story", "author_linesofcode", "story_47149982", "show_hn"], "author": "linesofcode", "children": [47150287, 47160587, 47163697], "created_at": "2026-02-25T11:02:31Z", "created_at_i": 1772017351, "num_comments": 2, "objectID": "47149982", "points": 1, "story_id": 47149982, "story_text": "Say hello to <a href=\"https:&#x2F;&#x2F;pongo.sh&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;pongo.sh&#x2F;</a><p>self-hosted uptime monitoring, configured entirely in TypeScript and built on NextJS and Bun.<p>No UI forms. No vendor lock-in. Just code in your repo.<p>Monitors, dashboards, alerts, incidents, and status pages \u2014 all defined as TypeScript files and Markdown, version-controlled alongside your application.<p>You can one-click deploy it to Vercel or anywhere you can run node&#x2F;bun&#x2F;docker.<p>Your monitoring config lives in your repo like everything else.<p>Want to know what&#x27;s monitored and why? Read the code.<p>Need to review a change? It&#x27;s in the PR. Need to roll back a bad alert? Git revert.<p>No more clicking through dashboards wondering who changed what and when.<p>Built with Next.js, Drizzle ORM, and Bun. Runs with SQLite for simplicity or PostgreSQL for production.<p>Fully open source and ready to use today.<p>Would love to hear what you think and what features you&#x27;d want to see next, leave a star on GitHub<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;TimMikeladze&#x2F;pongo\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;TimMikeladze&#x2F;pongo</a>", "title": "Show HN: Pongo \u2013 a self hosted uptime monitor using configuration as code", "updated_at": "2026-02-26T09:08:33Z", "url": "https://www.pongo.sh/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "frostfrazer"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["drizzle", "production"], "value": "Show HN: ForgeLink \u2013 a marketplace for MCP servers and AI agent integrations<p>I built ForgeLink because discovering <em>production</em>-ready MCP servers is still a GitHub treasure hunt.<p>What it is: a directory/marketplace where you can browse, compare, and submit MCP servers, GPT Actions, and LangChain tools \u2014 organized by category with real install commands, ratings, and GitHub links.<p>Currently seeded with 28 real servers across Database, Development, Communication, Cloud, Finance, AI/ML, Productivity, and Analytics.<p>Tech: Next.js 14, <em>Drizzle</em> ORM, Supabase auth, Paystack for payments, Vercel hosting. Built solo in a few weeks.<p>Features:\n- Browse + filter by category, protocol, and tags\n- Side-by-side comparison tool\n- Owner dashboard with analytics (for Featured tier)\n- Submit free, claim existing listings\n- Weekly trending section<p>Live: forgelink-pi.vercel.app<p>Would love feedback on the listing quality, UX, and whether this scratches the itch you've felt when searching for MCP servers."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Forgelink Is Here"}}, "_tags": ["story", "author_frostfrazer", "story_47108710", "ask_hn"], "author": "frostfrazer", "created_at": "2026-02-22T06:19:05Z", "created_at_i": 1771741145, "num_comments": 0, "objectID": "47108710", "points": 1, "story_id": 47108710, "story_text": "Show HN: ForgeLink \u2013 a marketplace for MCP servers and AI agent integrations<p>I built ForgeLink because discovering production-ready MCP servers is still a GitHub treasure hunt.<p>What it is: a directory&#x2F;marketplace where you can browse, compare, and submit MCP servers, GPT Actions, and LangChain tools \u2014 organized by category with real install commands, ratings, and GitHub links.<p>Currently seeded with 28 real servers across Database, Development, Communication, Cloud, Finance, AI&#x2F;ML, Productivity, and Analytics.<p>Tech: Next.js 14, Drizzle ORM, Supabase auth, Paystack for payments, Vercel hosting. Built solo in a few weeks.<p>Features:\n- Browse + filter by category, protocol, and tags\n- Side-by-side comparison tool\n- Owner dashboard with analytics (for Featured tier)\n- Submit free, claim existing listings\n- Weekly trending section<p>Live: forgelink-pi.vercel.app<p>Would love feedback on the listing quality, UX, and whether this scratches the itch you&#x27;ve felt when searching for MCP servers.", "title": "Forgelink Is Here", "updated_at": "2026-02-22T06:22:30Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "tomhan245"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["drizzle", "production"], "value": "I\u2019ve spent months building SaaS apps with Nuxt and kept hitting the same wall \u2014 setup time.<p>Every project needed auth, payments, a dashboard layout, SEO setup, and deployment config from scratch.<p>So I built *ShipAhead*, a Nuxt 4 boilerplate that\u2019s <em>production</em>-ready out of the box.\nIt\u2019s designed for developers who want to skip the repetitive setup and start building real features immediately.<p>*Tech stack:*\nNuxt 4, Vue 3, TailwindCSS, DaisyUI\nAuth: Better Auth\nDB: <em>Drizzle</em> ORM + Postgres (Neon)\nStorage: Cloudflare R2\nEmail: Resend + Vue Email\nPayments: Stripe\nAnalytics: Umami\nAI: OpenRouter API\nDeploy: Cloudflare Workers / Vercel\nPWA: Vite PWA<p>Demo and details at shipahe.ad<p>Would love feedback \u2014 especially from devs who\u2019ve tried building SaaS with Nuxt before."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: I made ShipAhead so devs can stop wasting weeks setting up SaaS apps"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://shipahe.ad/"}}, "_tags": ["story", "author_tomhan245", "story_45511046", "show_hn"], "author": "tomhan245", "created_at": "2025-10-08T01:27:57Z", "created_at_i": 1759886877, "num_comments": 0, "objectID": "45511046", "points": 1, "story_id": 45511046, "story_text": "I\u2019ve spent months building SaaS apps with Nuxt and kept hitting the same wall \u2014 setup time.<p>Every project needed auth, payments, a dashboard layout, SEO setup, and deployment config from scratch.<p>So I built *ShipAhead*, a Nuxt 4 boilerplate that\u2019s production-ready out of the box.\nIt\u2019s designed for developers who want to skip the repetitive setup and start building real features immediately.<p>*Tech stack:*\nNuxt 4, Vue 3, TailwindCSS, DaisyUI\nAuth: Better Auth\nDB: Drizzle ORM + Postgres (Neon)\nStorage: Cloudflare R2\nEmail: Resend + Vue Email\nPayments: Stripe\nAnalytics: Umami\nAI: OpenRouter API\nDeploy: Cloudflare Workers &#x2F; Vercel\nPWA: Vite PWA<p>Demo and details at shipahe.ad<p>Would love feedback \u2014 especially from devs who\u2019ve tried building SaaS with Nuxt before.", "title": "Show HN: I made ShipAhead so devs can stop wasting weeks setting up SaaS apps", "updated_at": "2025-10-08T01:32:06Z", "url": "https://shipahe.ad/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "guangzhengli"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["drizzle", "production"], "value": "After spending months wrestling with Next.js deployment complexity across different platforms, I built NextDevKit - a <em>production</em>-ready SaaS template that works natively on Vercel, Cloudflare Workers, and AWS.<p>Why I Built This\nMost Next.js templates either:\n* Work great on Vercel but nowhere else\n* Sacrifice features for platform compatibility\n* Require extensive modifications for each deployment target<p>I needed something that could deploy to Cloudflare Workers (for $5/month projects) or AWS (for enterprise clients) with the same feature set as Vercel deployments.<p>Key Features\nCore SaaS Stack:\n* Authentication (Better Auth)\n* Payments (Stripe)\n* Database (<em>Drizzle</em> ORM)\n* Email (Resend)\n* File storage (S3/R2)\n* Blog &amp; docs (FumaDocs)\n* i18n support\n* GDPR-compliant analytics<p>Deployment Options:\n* Vercel: Standard deployment\n* Cloudflare Workers: Uses OpenNext + D1/KV/R2 integration\n* AWS: SST-based deployment with RDS/Lambda/CloudFront\n* Containers: Railway, Fly.io, etc.<p>Technical Highlights\n* OpenNext Integration: Compatible Node.js API support on Cloudflare Workers\n* SST for AWS: One-command infrastructure deployment\n* AI-Friendly Stack: Next.js 15, Tailwind CSS v4, Shadcn UI\n* Multi-theme Support: Easy color scheme switching\n* SEO Optimized: 100/100 Google PageSpeed score<p>The Cloudflare Workers version uses D1 for database, KV for caching/ISR, and R2 for storage - all within the $5/month Worker Standard plan.\nThe AWS version leverages RDS Proxy, Lambda, and CloudFront with proper security configurations for enterprise deployments.<p>Links<p>* Website: <a href=\"https://nextdevkit.com\" rel=\"nofollow\">https://nextdevkit.com</a>\n* Vercel Demo: <a href=\"https://demo.nextdevkit.com\" rel=\"nofollow\">https://demo.nextdevkit.com</a>\n* Workers Demo: <a href=\"https://workers.nextdevkit.com\" rel=\"nofollow\">https://workers.nextdevkit.com</a>\n* AWS Demo: <a href=\"https://aws.nextdevkit.com\" rel=\"nofollow\">https://aws.nextdevkit.com</a>\n* Documentation: <a href=\"https://nextdevkit.com/docs\" rel=\"nofollow\">https://nextdevkit.com/docs</a><p>Built this because I was tired of rebuilding the same infrastructure for every project. Would love feedback from the HN community on the deployment approach and feature set!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: NextDevKit \u2013 Next.js and OpenNext SaaS Template, Goodbye Vercel Bills"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://nextdevkit.com"}}, "_tags": ["story", "author_guangzhengli", "story_44655818", "show_hn"], "author": "guangzhengli", "created_at": "2025-07-23T04:54:02Z", "created_at_i": 1753246442, "num_comments": 0, "objectID": "44655818", "points": 1, "story_id": 44655818, "story_text": "After spending months wrestling with Next.js deployment complexity across different platforms, I built NextDevKit - a production-ready SaaS template that works natively on Vercel, Cloudflare Workers, and AWS.<p>Why I Built This\nMost Next.js templates either:\n* Work great on Vercel but nowhere else\n* Sacrifice features for platform compatibility\n* Require extensive modifications for each deployment target<p>I needed something that could deploy to Cloudflare Workers (for $5&#x2F;month projects) or AWS (for enterprise clients) with the same feature set as Vercel deployments.<p>Key Features\nCore SaaS Stack:\n* Authentication (Better Auth)\n* Payments (Stripe)\n* Database (Drizzle ORM)\n* Email (Resend)\n* File storage (S3&#x2F;R2)\n* Blog &amp; docs (FumaDocs)\n* i18n support\n* GDPR-compliant analytics<p>Deployment Options:\n* Vercel: Standard deployment\n* Cloudflare Workers: Uses OpenNext + D1&#x2F;KV&#x2F;R2 integration\n* AWS: SST-based deployment with RDS&#x2F;Lambda&#x2F;CloudFront\n* Containers: Railway, Fly.io, etc.<p>Technical Highlights\n* OpenNext Integration: Compatible Node.js API support on Cloudflare Workers\n* SST for AWS: One-command infrastructure deployment\n* AI-Friendly Stack: Next.js 15, Tailwind CSS v4, Shadcn UI\n* Multi-theme Support: Easy color scheme switching\n* SEO Optimized: 100&#x2F;100 Google PageSpeed score<p>The Cloudflare Workers version uses D1 for database, KV for caching&#x2F;ISR, and R2 for storage - all within the $5&#x2F;month Worker Standard plan.\nThe AWS version leverages RDS Proxy, Lambda, and CloudFront with proper security configurations for enterprise deployments.<p>Links<p>* Website: <a href=\"https:&#x2F;&#x2F;nextdevkit.com\" rel=\"nofollow\">https:&#x2F;&#x2F;nextdevkit.com</a>\n* Vercel Demo: <a href=\"https:&#x2F;&#x2F;demo.nextdevkit.com\" rel=\"nofollow\">https:&#x2F;&#x2F;demo.nextdevkit.com</a>\n* Workers Demo: <a href=\"https:&#x2F;&#x2F;workers.nextdevkit.com\" rel=\"nofollow\">https:&#x2F;&#x2F;workers.nextdevkit.com</a>\n* AWS Demo: <a href=\"https:&#x2F;&#x2F;aws.nextdevkit.com\" rel=\"nofollow\">https:&#x2F;&#x2F;aws.nextdevkit.com</a>\n* Documentation: <a href=\"https:&#x2F;&#x2F;nextdevkit.com&#x2F;docs\" rel=\"nofollow\">https:&#x2F;&#x2F;nextdevkit.com&#x2F;docs</a><p>Built this because I was tired of rebuilding the same infrastructure for every project. Would love feedback from the HN community on the deployment approach and feature set!", "title": "Show HN: NextDevKit \u2013 Next.js and OpenNext SaaS Template, Goodbye Vercel Bills", "updated_at": "2025-07-23T04:57:26Z", "url": "https://nextdevkit.com"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "codegeek"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["drizzle", "production"], "value": "I m building a web app in python/flask framework on my own (side project) but have plans to convert it into a commercial app soon. I have coded a good amount of backend and feel like I am at a point where some designing can be introduced (may be, you tell me as a designer). I mean I got barebone HTML pages right now and <i>trying</i> to work (note the emphasis on trying)  on some rough wireframes sketches. This is where my design skills stop.<p>I would love to hire a designer (part time) on a contractual basis and willing to pay \"decent\" going rate for good designers. Question is:<p>1. How do I search for \"good\" designers? Heck,what does that even mean ? I mean I can look at <em>dribble</em> etc but what else ?<p>2. If I do get a chance to talk to these designers, what are the questions to ask them ?<p>3. What kind of rates are charged by these \"good\" designers ? I am primiarly looking around NYC area but remote work within US is a possibility.<p>I am not a complete dummy when it comes to HTML/CSS/JS and all that good stuff. Just that I don't think I have the skills to design it for <em>production</em> quality."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: Finding good designers (NYC Area or remote)"}, "url": {"matchLevel": "none", "matchedWords": [], "value": ""}}, "_tags": ["story", "author_codegeek", "story_5167733", "ask_hn"], "author": "codegeek", "children": [5168494, 5171069, 5187946, 5199529], "created_at": "2013-02-04T22:46:27Z", "created_at_i": 1360017987, "num_comments": 6, "objectID": "5167733", "points": 5, "story_id": 5167733, "story_text": "I m building a web app in python/flask framework on my own (side project) but have plans to convert it into a commercial app soon. I have coded a good amount of backend and feel like I am at a point where some designing can be introduced (may be, you tell me as a designer). I mean I got barebone HTML pages right now and <i>trying</i> to work (note the emphasis on trying)  on some rough wireframes sketches. This is where my design skills stop.<p>I would love to hire a designer (part time) on a contractual basis and willing to pay \"decent\" going rate for good designers. Question is:<p>1. How do I search for \"good\" designers? Heck,what does that even mean ? I mean I can look at dribble etc but what else ?<p>2. If I do get a chance to talk to these designers, what are the questions to ask them ?<p>3. What kind of rates are charged by these \"good\" designers ? I am primiarly looking around NYC area but remote work within US is a possibility.<p>I am not a complete dummy when it comes to HTML/CSS/JS and all that good stuff. Just that I don't think I have the skills to design it for production quality.", "title": "Ask HN: Finding good designers (NYC Area or remote)", "updated_at": "2024-09-19T19:18:47Z", "url": ""}], "hitsPerPage": 15, "nbHits": 17, "nbPages": 2, "page": 0, "params": "query=drizzle+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 11, "processingTimingsMS": {"_request": {"roundTrip": 17}, "afterFetch": {"format": {"highlighting": 2, "total": 2}}, "fetch": {"query": 8, "scanning": 1, "total": 10}, "total": 11}, "query": "drizzle production", "serverTimeMS": 15}}