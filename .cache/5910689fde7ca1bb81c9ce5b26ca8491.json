{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "mgarfias"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["varnish", "production"], "value": "So I saw the other posting and decided I should post something, as I also need help finding a remote job.<p>What I do:<p>I'm a *nix systems administrator (14 years of experience now) who worked for the past five years at sphere.com.  Been through an acquisition and all that.  I've lived for the past 4 years inside puppet's DSL automating services in puppet rather than in perl or python.<p>What I've done<p>Scaled sphere to almost 200 servers; saved us additional ops hires by implementing config management early (10 minutes from box delivery to operational); and saved something like $1.2M over 4 years in additional webserver costs by implementing <em>varnish</em> cache and tuning it to get an 82% hit rate.<p>What people say about me:<p>\u201cMike joined Sphere as one of its earliest employees, right before our first public beta launch. Mike has an impressive grasp of a wide range of technologies and keeps abreast of new developments. His constant drive to optimize kept Sphere running smoothly and cost-effectively during that first beta and throughout the many subsequent product launches and steep growth.\u201d<p>\u201cMike joined Sphere during the early startup days as one of the first full-time employees. He juggled activities spanning a wide spectrum of system administration tasks. Mike impressed early on with a high degree of dedication, essentially responding to emails or phone calls at almost any time of the day, while maintaining a can-do, problem-solving attitude. He made significant contributions to our success.\u201d<p>\u201cI worked very closely with Mike at Sphere, designing our <em>production</em> infrastructure and stepping back to let him run with it. Despite our steep growth and continuous development strategy, Mike was always on top of our needs. His attention to detail, willingness to tackle any challenge, and aggressive pursuit of better solutions not only saved us many times, but laid a solid foundation for the company's success.\u201d<p>Why I need remote:<p>I live on a farm in rural Oregon, about an hour out of portland.  I'll commute there if I have to, but I would rather give the commute time to my family.<p>Why I'm looking now:<p>Sphere was just spun out of AOL over to a new place, and they had four SAs already, and I'm nearly done with the transition assistance.  I've been looking for remote gigs, but haven't had luck finding opportunities.  In the mean time, I've been doing a bit of outside extra consulting to keep the skills sharp.<p>I'll happily send a resume out if requested.<p>Thanks!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "I also need help finding a remote job"}, "url": {"matchLevel": "none", "matchedWords": [], "value": ""}}, "_tags": ["story", "author_mgarfias", "story_2533633", "ask_hn"], "author": "mgarfias", "children": [2533727], "created_at": "2011-05-10T18:45:32Z", "created_at_i": 1305053132, "num_comments": 2, "objectID": "2533633", "points": 13, "story_id": 2533633, "story_text": "So I saw the other posting and decided I should post something, as I also need help finding a remote job.<p>What I do:<p>I'm a *nix systems administrator (14 years of experience now) who worked for the past five years at sphere.com.  Been through an acquisition and all that.  I've lived for the past 4 years inside puppet's DSL automating services in puppet rather than in perl or python.<p>What I've done<p>Scaled sphere to almost 200 servers; saved us additional ops hires by implementing config management early (10 minutes from box delivery to operational); and saved something like $1.2M over 4 years in additional webserver costs by implementing varnish cache and tuning it to get an 82% hit rate.<p>What people say about me:<p>\u201cMike joined Sphere as one of its earliest employees, right before our first public beta launch. Mike has an impressive grasp of a wide range of technologies and keeps abreast of new developments. His constant drive to optimize kept Sphere running smoothly and cost-effectively during that first beta and throughout the many subsequent product launches and steep growth.\u201d<p>\u201cMike joined Sphere during the early startup days as one of the first full-time employees. He juggled activities spanning a wide spectrum of system administration tasks. Mike impressed early on with a high degree of dedication, essentially responding to emails or phone calls at almost any time of the day, while maintaining a can-do, problem-solving attitude. He made significant contributions to our success.\u201d<p>\u201cI worked very closely with Mike at Sphere, designing our production infrastructure and stepping back to let him run with it. Despite our steep growth and continuous development strategy, Mike was always on top of our needs. His attention to detail, willingness to tackle any challenge, and aggressive pursuit of better solutions not only saved us many times, but laid a solid foundation for the company's success.\u201d<p>Why I need remote:<p>I live on a farm in rural Oregon, about an hour out of portland.  I'll commute there if I have to, but I would rather give the commute time to my family.<p>Why I'm looking now:<p>Sphere was just spun out of AOL over to a new place, and they had four SAs already, and I'm nearly done with the transition assistance.  I've been looking for remote gigs, but haven't had luck finding opportunities.  In the mean time, I've been doing a bit of outside extra consulting to keep the skills sharp.<p>I'll happily send a resume out if requested.<p>Thanks!", "title": "I also need help finding a remote job", "updated_at": "2023-09-06T19:47:55Z", "url": ""}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "workmonster"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["varnish", "production"], "value": "Looking for some advice on High Availability Wordpress and AWS.\nWe were on Digital Ocean but had outgrown what we had and so decided it was time to build a real hosting platform.<p>However, we have built out an AWS stack but is really slow compared to Digital Ocean. Page loads on AWS are 2seconds &gt; 12 seconds - random. Where DO was stable around 2.9seconds.<p>AWS Current stack<p>TeraForm for AWS and Ansible Scripts for box setup (looking at RunDeck for Ansible running)<p>CloudFlare CDN &gt; Amazon AWS (Large RDS (mySQL) + Micro EC2 Ubuntu 16.04 + PHP + NGNX + Redis cache + EFS<p>Controller Server for Ansible and looking at RunDeck to control it.<p>Auto Scaling<p>NewRelic and PapertailsApp for Monitoring.<p>BitBucket for core plugins, themes, base WP etc<p>Finding EFS is really slow :( . We have done the trick with 256gb file to go up to the next speed level but did not seem to make a difference.<p>Now trying .....<p>CloudFlare &gt; AWS (Large RDS (mySQL) + XLarge EC2 Ubuntu 16.04 + PHP + <em>Varnish</em> in front of NGNX + Memcached (AWS ElastiCache) + EFS / S3 which looks to be a better solution so far - but feeling like we are just plugging stuff together without really having past experience so looking for someone who has been through this before.<p>Some blogs/posts reading that never put PHP on EFS and always use scripts to copy to EBS first. While Amazon best practice for high-availability Wordpress says EFS is fine - clearly not the case!<p>We also have Ansible scripts in place to move Wordpress sites between development &gt; Staging &gt; <em>production</em> instances. Before it used to take hours to move a site, with the scripts now takes around 10-20mins and seems to work.<p>Thanks"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: Advice on High-Availability Wordpress and Amazon AWS"}}, "_tags": ["story", "author_workmonster", "story_17599256", "ask_hn"], "author": "workmonster", "children": [17600842], "created_at": "2018-07-24T09:05:01Z", "created_at_i": 1532423101, "num_comments": 1, "objectID": "17599256", "points": 1, "story_id": 17599256, "story_text": "Looking for some advice on High Availability Wordpress and AWS.\nWe were on Digital Ocean but had outgrown what we had and so decided it was time to build a real hosting platform.<p>However, we have built out an AWS stack but is really slow compared to Digital Ocean. Page loads on AWS are 2seconds &gt; 12 seconds - random. Where DO was stable around 2.9seconds.<p>AWS Current stack<p>TeraForm for AWS and Ansible Scripts for box setup (looking at RunDeck for Ansible running)<p>CloudFlare CDN &gt; Amazon AWS (Large RDS (mySQL) + Micro EC2 Ubuntu 16.04 + PHP + NGNX + Redis cache + EFS<p>Controller Server for Ansible and looking at RunDeck to control it.<p>Auto Scaling<p>NewRelic and PapertailsApp for Monitoring.<p>BitBucket for core plugins, themes, base WP etc<p>Finding EFS is really slow :( . We have done the trick with 256gb file to go up to the next speed level but did not seem to make a difference.<p>Now trying .....<p>CloudFlare &gt; AWS (Large RDS (mySQL) + XLarge EC2 Ubuntu 16.04 + PHP + Varnish in front of NGNX + Memcached (AWS ElastiCache) + EFS &#x2F; S3 which looks to be a better solution so far - but feeling like we are just plugging stuff together without really having past experience so looking for someone who has been through this before.<p>Some blogs&#x2F;posts reading that never put PHP on EFS and always use scripts to copy to EBS first. While Amazon best practice for high-availability Wordpress says EFS is fine - clearly not the case!<p>We also have Ansible scripts in place to move Wordpress sites between development &gt; Staging &gt; production instances. Before it used to take hours to move a site, with the scripts now takes around 10-20mins and seems to work.<p>Thanks", "title": "Ask HN: Advice on High-Availability Wordpress and Amazon AWS", "updated_at": "2024-09-20T02:51:37Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "LukeEF"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["varnish", "production"], "value": "Existing headless CMS tools are mostly making it up as they go along - starting with the idea of \u2018I want to build a company that delivers a headless CMS\u2019 and then quickly slapping a bunch of technologies together and ending up with a pile of JSONs floating around a MongoDB or another similar frankenstein. As we\u2019d already built the document graph data layer from the ground up, we could properly integrate the CMS features to give a seamless developer experience. \nWe are never going to send you to a screen that says, \u2018TerminusCRM requires NodeJS version 10+ and a Mongo database\u2019. It is all contained in one in-memory, highly compressed data management system that we designed and built for this specific purpose.<p>A few of the other offerings are just headless markdown backed by git - which is actually a good idea, but comes with the capacity and performance limitations that git implies.<p>Why not have a highly performant document graph content management system that incorporates the most important concepts from git in the data layer? All the version control features that content needs (clone, push, pull, branch, revert, merge) and are highly awkward in other systems. \nWe also thought that GraphQL was the obvious data manipulation choice for content, but found weak implementations wherever we looked. For TerminusCMS, we\u2019ve implemented a suite of features which allows you to query a TerminusCMS project using GraphQL in such a way that deep linking can be discovered. We can use path queries with GraphQL.<p>To summarize our market thoughts - it seems that devs want:<p>- Deploy anywhere open-source\n- Dev-first in memory, highly compressed, scalable and fast content management so you can build complex and fully featured web apps of every shape and size\n- Git-like features to help with permissions and version control (and - crucially - merge)\n- Best-in-class GraphQL implementation<p>And there was nothing offering that mix until we released TerminusCMS.<p>TerminusCMS is a content platform that sits at the convergence of content and knowledge. It is a model-driven, API-first approach to content management. With TerminusCMS you can use your data as content. The data employed in content has meanings associated with it, and because that content is well structured, the content can also be used as if it were data \u2014 in fact, that content is data. TerminusCMS is structured like Git, so you get all the git-like features for your content engine. History, change management, branching, non-linear development, easy backups, distributed development, and more. You can enrich your content with semantics which can give you the ability to personalize content and build superior recommender and AI/ML systems.<p>Content curation needs change requests: you need to be able to add a new translation, or new content in a branch, which is viewable as an entire site, but which only goes into <em>production</em> when you &quot;merge to main&quot;.<p>TerminusCMS gives devs a powerful way to define schema, query, deliver content and assets to front end. It has schema-as-code; is standards-based for interoperability; has an extremely fast publishing API; and provides workflows made by way of content and network model, not wired into product itself. It give editors a way to manage content automatically so that devs don't need to do much to support them. You can use TerminusCMS to build your complex app, or to manage your organization knowledge.<p>TerminusCMS is open-source all the way down, so if we <em>vanish</em> or piss you off, you can recover and continue.<p>The business is cloud hosting and enterprise delivery, which we hope can keep the wolf from the door. It is freemium with a generous free tier and easily cloned examples, so take a look.<p>[1] https://terminusdb.com/\n[2] https://github.com/GavinMendelGleason/blog/blob/main/entries/content_revolution.md"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: TerminusCMS \u2013 Headless CMS for Devs"}}, "_tags": ["story", "author_LukeEF", "story_34805178", "show_hn"], "author": "LukeEF", "children": [34805380], "created_at": "2023-02-15T15:36:38Z", "created_at_i": 1676475398, "num_comments": 1, "objectID": "34805178", "points": 9, "story_id": 34805178, "story_text": "Existing headless CMS tools are mostly making it up as they go along - starting with the idea of \u2018I want to build a company that delivers a headless CMS\u2019 and then quickly slapping a bunch of technologies together and ending up with a pile of JSONs floating around a MongoDB or another similar frankenstein. As we\u2019d already built the document graph data layer from the ground up, we could properly integrate the CMS features to give a seamless developer experience. \nWe are never going to send you to a screen that says, \u2018TerminusCRM requires NodeJS version 10+ and a Mongo database\u2019. It is all contained in one in-memory, highly compressed data management system that we designed and built for this specific purpose.<p>A few of the other offerings are just headless markdown backed by git - which is actually a good idea, but comes with the capacity and performance limitations that git implies.<p>Why not have a highly performant document graph content management system that incorporates the most important concepts from git in the data layer? All the version control features that content needs (clone, push, pull, branch, revert, merge) and are highly awkward in other systems. \nWe also thought that GraphQL was the obvious data manipulation choice for content, but found weak implementations wherever we looked. For TerminusCMS, we\u2019ve implemented a suite of features which allows you to query a TerminusCMS project using GraphQL in such a way that deep linking can be discovered. We can use path queries with GraphQL.<p>To summarize our market thoughts - it seems that devs want:<p>- Deploy anywhere open-source\n- Dev-first in memory, highly compressed, scalable and fast content management so you can build complex and fully featured web apps of every shape and size\n- Git-like features to help with permissions and version control (and - crucially - merge)\n- Best-in-class GraphQL implementation<p>And there was nothing offering that mix until we released TerminusCMS.<p>TerminusCMS is a content platform that sits at the convergence of content and knowledge. It is a model-driven, API-first approach to content management. With TerminusCMS you can use your data as content. The data employed in content has meanings associated with it, and because that content is well structured, the content can also be used as if it were data \u2014 in fact, that content is data. TerminusCMS is structured like Git, so you get all the git-like features for your content engine. History, change management, branching, non-linear development, easy backups, distributed development, and more. You can enrich your content with semantics which can give you the ability to personalize content and build superior recommender and AI&#x2F;ML systems.<p>Content curation needs change requests: you need to be able to add a new translation, or new content in a branch, which is viewable as an entire site, but which only goes into production when you &quot;merge to main&quot;.<p>TerminusCMS gives devs a powerful way to define schema, query, deliver content and assets to front end. It has schema-as-code; is standards-based for interoperability; has an extremely fast publishing API; and provides workflows made by way of content and network model, not wired into product itself. It give editors a way to manage content automatically so that devs don&#x27;t need to do much to support them. You can use TerminusCMS to build your complex app, or to manage your organization knowledge.<p>TerminusCMS is open-source all the way down, so if we vanish or piss you off, you can recover and continue.<p>The business is cloud hosting and enterprise delivery, which we hope can keep the wolf from the door. It is freemium with a generous free tier and easily cloned examples, so take a look.<p>[1] https:&#x2F;&#x2F;terminusdb.com&#x2F;\n[2] https:&#x2F;&#x2F;github.com&#x2F;GavinMendelGleason&#x2F;blog&#x2F;blob&#x2F;main&#x2F;entries&#x2F;content_revolution.md", "title": "Show HN: TerminusCMS \u2013 Headless CMS for Devs", "updated_at": "2025-04-26T07:10:09Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "pstryder"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["varnish", "production"], "value": "I built MemoryGate because I kept watching context <em>vanish</em>.\nI run multiple AI agents across Claude, ChatGPT, and Cursor. Every time a model updated, a platform changed its API, or a context window rolled over \u2014 everything the agent had learned was gone. Preferences, decisions, project history, relationship context. Just... wiped.\nThe fundamental problem: AI memory is trapped inside the platform that hosts the conversation. Your agent's knowledge dies with the session, the model version, or the provider's business decisions.\nMemoryGate is a persistent semantic memory layer that sits outside any single model or platform. It connects via MCP (Model Context Protocol), so any MCP-compatible agent \u2014 Claude Desktop, ChatGPT, Cursor, custom agents \u2014 can store and retrieve memories through a shared, durable knowledge store.\nWhat it actually does:<p>Semantic memory with vector embeddings \u2014 recall by meaning, not keywords\nConfidence-weighted observations that strengthen or decay based on evidence\nAutomatic lifecycle management \u2014 high-signal stays hot, noise fades to cold storage\nAppend-only architecture \u2014 memories are never overwritten, only superseded with lineage\nKnowledge graphs linking observations, patterns, concepts, and documents\nMulti-tenant with org isolation, roles, and shared memory stores\nOAuth 2.0, audit logs, rate limiting \u2014 <em>production</em> infrastructure, not a toy<p>What it's not:<p>Not a RAG pipeline. MemoryGate stores what the agent learns from interaction, not document chunks.\nNot prompt injection. Memory lives at the infrastructure layer, not stuffed into system prompts.\nNot tied to any model or provider. Switch from Claude to ChatGPT to a local model \u2014 memory persists.<p>Stack: Python/FastAPI, PostgreSQL + pgvector, Redis, deployed on Railway. MCP-native integration \u2014 your agent gets 33 memory tools on connection.\nThe real pitch: Platforms die. Models get deprecated. Context windows roll over. Your AI's memory shouldn't be hostage to your AI's provider.\nOpen source (Apache 2.0), self-hostable, with a hosted SaaS option if you don't want to run infrastructure.<p>GitHub: <a href=\"https://github.com/PStryder/MemoryGate\" rel=\"nofollow\">https://github.com/PStryder/MemoryGate</a>\nSaaS: <a href=\"https://memorygate.ai\" rel=\"nofollow\">https://memorygate.ai</a>\nDocs: <a href=\"https://memorygate.ai/docs/\" rel=\"nofollow\">https://memorygate.ai/docs/</a><p>I'm a solo founder \u2014 built this after leaving a decade in enterprise solutions engineering. Happy to answer questions about the architecture, the MCP integration, or why I think persistent memory is the missing infrastructure layer for AI agents."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: MemoryGate \u2013 Open-source persistent memory for AI agents via MCP"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://www.memorygate.ai"}}, "_tags": ["story", "author_pstryder", "story_46981840", "show_hn"], "author": "pstryder", "created_at": "2026-02-11T22:05:29Z", "created_at_i": 1770847529, "num_comments": 0, "objectID": "46981840", "points": 1, "story_id": 46981840, "story_text": "I built MemoryGate because I kept watching context vanish.\nI run multiple AI agents across Claude, ChatGPT, and Cursor. Every time a model updated, a platform changed its API, or a context window rolled over \u2014 everything the agent had learned was gone. Preferences, decisions, project history, relationship context. Just... wiped.\nThe fundamental problem: AI memory is trapped inside the platform that hosts the conversation. Your agent&#x27;s knowledge dies with the session, the model version, or the provider&#x27;s business decisions.\nMemoryGate is a persistent semantic memory layer that sits outside any single model or platform. It connects via MCP (Model Context Protocol), so any MCP-compatible agent \u2014 Claude Desktop, ChatGPT, Cursor, custom agents \u2014 can store and retrieve memories through a shared, durable knowledge store.\nWhat it actually does:<p>Semantic memory with vector embeddings \u2014 recall by meaning, not keywords\nConfidence-weighted observations that strengthen or decay based on evidence\nAutomatic lifecycle management \u2014 high-signal stays hot, noise fades to cold storage\nAppend-only architecture \u2014 memories are never overwritten, only superseded with lineage\nKnowledge graphs linking observations, patterns, concepts, and documents\nMulti-tenant with org isolation, roles, and shared memory stores\nOAuth 2.0, audit logs, rate limiting \u2014 production infrastructure, not a toy<p>What it&#x27;s not:<p>Not a RAG pipeline. MemoryGate stores what the agent learns from interaction, not document chunks.\nNot prompt injection. Memory lives at the infrastructure layer, not stuffed into system prompts.\nNot tied to any model or provider. Switch from Claude to ChatGPT to a local model \u2014 memory persists.<p>Stack: Python&#x2F;FastAPI, PostgreSQL + pgvector, Redis, deployed on Railway. MCP-native integration \u2014 your agent gets 33 memory tools on connection.\nThe real pitch: Platforms die. Models get deprecated. Context windows roll over. Your AI&#x27;s memory shouldn&#x27;t be hostage to your AI&#x27;s provider.\nOpen source (Apache 2.0), self-hostable, with a hosted SaaS option if you don&#x27;t want to run infrastructure.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;PStryder&#x2F;MemoryGate\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;PStryder&#x2F;MemoryGate</a>\nSaaS: <a href=\"https:&#x2F;&#x2F;memorygate.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;memorygate.ai</a>\nDocs: <a href=\"https:&#x2F;&#x2F;memorygate.ai&#x2F;docs&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;memorygate.ai&#x2F;docs&#x2F;</a><p>I&#x27;m a solo founder \u2014 built this after leaving a decade in enterprise solutions engineering. Happy to answer questions about the architecture, the MCP integration, or why I think persistent memory is the missing infrastructure layer for AI agents.", "title": "Show HN: MemoryGate \u2013 Open-source persistent memory for AI agents via MCP", "updated_at": "2026-02-11T22:08:46Z", "url": "https://www.memorygate.ai"}], "hitsPerPage": 15, "nbHits": 4, "nbPages": 1, "page": 0, "params": "query=varnish+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 11, "processingTimingsMS": {"_request": {"roundTrip": 19}, "fetch": {"query": 9, "scanning": 1, "total": 11}, "total": 11}, "query": "varnish production", "serverTimeMS": 13}}