{"d": {"kind": "Listing", "data": {"modhash": "", "dist": 5, "facets": {}, "after": "t3_1mhqeu5", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "LLMDevs", "selftext": "Hey everyone, I\u2019m Raj. Over the past year I\u2019ve built RAG systems for 10+ enterprise clients \u2013 pharma companies, banks, law firms \u2013 handling everything from 20K+ document repositories, deploying air\u2011gapped on\u2011prem models, complex compliance requirements, and more.\n\nIn this post, I want to share the actual learning path I followed \u2013 what worked, what didn\u2019t, and the skills you really need if you want to go from toy demos to production-ready systems. Even if you\u2019re a beginner just starting out, or an engineer aiming to build enterprise-level RAG and AI agents, this post should support you in some way. I\u2019ll cover the fundamentals I started with, the messy real-world challenges, how I learned from codebases, and the realities of working with enterprise clients.\n\nI recently shared a technical post on building RAG agents at scale and also a business breakdown on how to find and work with enterprise clients, and the response was overwhelming \u2013 thank you. But most importantly, many people wanted to know *how I actually learned these concepts*. So I thought I\u2019d share some of the insights and approaches that worked for me.\n\n**The Reality of Production Work**\n\nBuilding a simple chatbot on top of a vector DB is easy \u2014 but that\u2019s not what companies are paying for. The real value comes from building RAG systems that work at scale and survive the messy realities of production. That\u2019s why companies pay serious money for working systems \u2014 because so few people can actually deliver them.\n\n**Why RAG Isn\u2019t Going Anywhere**\n\nBefore I get into it, I just want to share why RAG is so important and why its need is only going to keep growing. RAG isn\u2019t hype. It solves problems that won\u2019t vanish:\n\n* Context limits: Even 200K-token models choke after \\~100\u2013200 pages. Enterprise repositories are 1,000x bigger. And usable context is really \\~120K before quality drops off.\n* Fine-tuning \u2260 knowledge injection: It changes style, not content. You can teach terminology (like \u201cMI\u201d = myocardial infarction) but you can\u2019t shove in 50K docs without catastrophic forgetting.\n* Enterprise reality: Metadata, quality checks, hybrid retrieval \u2013 these aren\u2019t solved. That\u2019s why RAG engineers are in demand.\n* The future: Data grows faster than context, reliable knowledge injection doesn\u2019t exist yet, and enterprises need audit trails + real-time compliance. RAG isn\u2019t going away.\n\n**Foundation**\n\nBefore I knew what I was doing, I jumped into code too fast and wasted weeks. If I could restart, I\u2019d begin with fundamentals. Andrew Ng\u2019s deeplearning ai courses on RAG and agents are a goldmine. Free, clear, and packed with insights that shortcut months of wasted time. Don\u2019t skip them \u2013 you need a solid base in embeddings, LLMs, prompting, and the overall tool landscape.\n\n**Recommended courses:**\n\n* Retrieval Augmented Generation (RAG)\n* LLMs as Operating Systems: Agent Memory\n* Long-Term Agentic Memory with LangGraph\n* How Transformer LLMs Work\n* Building Agentic RAG with LlamaIndex\n* Knowledge Graphs for RAG\n* Building Apps with Vector Databases\n\nI also found the *AI Engineer* YouTube channel surprisingly helpful. Most of their content is intro-level, but the conference talks helped me see how these systems break down in practice. **First build:** Don\u2019t overthink it. Use LangChain or LlamaIndex to set up a Q&amp;A system with clean docs (Wikipedia, research papers). The point isn\u2019t to impress anyone \u2013 it\u2019s to get comfortable with the retrieval \u2192 generation flow end-to-end.\n\n**Core tech stack I started with:**\n\n* Vector DBs (Qdrant locally, Pinecone in the cloud)\n* Embedding models (OpenAI \u2192 Nomic)\n* Chunking (fixed, semantic, hierarchical)\n* Prompt engineering basics\n\nWhat worked for me was building the same project across multiple frameworks. At first it felt repetitive, but that comparison gave me intuition for tradeoffs you don\u2019t see in docs.\n\n**Project ideas:** A recipe assistant, API doc helper, or personal research bot. Pick something you\u2019ll actually use yourself. When I built a bot to query my own reading list, I suddenly cared much more about fixing its mistakes.\n\n**Real-World Complexity**\n\nHere\u2019s where things get messy \u2013 and where you\u2019ll learn the most. At this point I didn\u2019t have a strong network. To practice, I used ChatGPT and Claude to roleplay different companies and domains. It\u2019s not perfect, but simulating real-world problems gave me enough confidence to approach actual clients later. What you\u2019ll quickly notice is that the easy wins vanish. Edge cases, broken PDFs, inconsistent formats \u2013 they eat your time, and there\u2019s no Stack Overflow post waiting with the answer.\n\n**Key skills that made a difference for me:**\n\n* Document Quality Detection: Spotting OCR glitches, missing text, structural inconsistencies. This is where \u201cgarbage in, garbage out\u201d is most obvious.\n* Advanced Chunking: Preserving hierarchy and adapting chunking to query type. Fixed-size chunks alone won\u2019t cut it.\n* Metadata Architecture: Schemas for classification, temporal tagging, cross-references. This alone ate \\~40% of my dev time.\n\nOne client had half their repository duplicated with tiny format changes. Fixing that felt like pure grunt work, but it taught me lessons about data pipelines no tutorial ever could.\n\n**Learn from Real Codebases**\n\nOne of the fastest ways I leveled up: cloning open-source agent/RAG repos and tearing them apart. Instead of staring blankly at thousands of lines of code, I used Cursor and Claude Code to generate diagrams, trace workflows, and explain design choices. Suddenly gnarly repos became approachable.\n\nFor example, when I studied OpenDevin and Cline (two coding agent projects), I saw two totally different philosophies of handling memory and orchestration. Neither was \u201cright,\u201d but seeing those tradeoffs taught me more than any course.\n\nMy advice: don\u2019t just read the code. Break it, modify it, rebuild it. That\u2019s how you internalize patterns. It felt like an unofficial apprenticeship, except my mentors were GitHub repos.\n\n**When Projects Get Real**\n\nBuilding RAG systems isn\u2019t just about retrieval \u2014 that\u2019s only the starting point. There\u2019s absolutely more to it once you enter production. Everything up to here is enough to put you ahead of most people. But once you start tackling real client projects, the game changes. I\u2019m not giving you a tutorial here \u2013 it\u2019s too big a topic \u2013 but I want you to be aware of the challenges you\u2019ll face so you\u2019re not blindsided. If you want the deep dive on solving these kinds of enterprise-scale issues, I\u2019ve posted a full technical guide in the comments \u2014 worth checking if you\u2019re serious about going beyond the basics.\n\nHere are the realities that hit me once clients actually relied on my systems:\n\n* **Reliability under load**: Systems must handle concurrent searches and ongoing uploads. One client\u2019s setup collapsed without proper queues and monitoring \u2014 resilience matters more than features.\n* **Evaluation and testing**: Demos mean nothing if users can\u2019t trust results. Gold datasets, regression tests, and feedback loops are essential.\n* **Business alignment**: Tech fails if staff aren\u2019t trained or ROI isn\u2019t clear. Adoption and compliance matter as much as embeddings.\n* **Domain messiness**: Healthcare jargon, financial filings, legal precedents \u2014 every industry has quirks that make or break your system.\n* **Security expectations**: Enterprises want guarantees: on\u2011prem deployments, role\u2011based access, audit logs. One law firm required every retrieval call to be logged immutably.\n\nThis is the stage where side projects turn into real production systems.\n\n**The Real Opportunity**\n\nIf you push through this learning curve, you\u2019ll have rare skills. Enterprises everywhere need RAG/agent systems, but very few engineers can actually deliver production-ready solutions. I\u2019ve seen it firsthand \u2013 companies don\u2019t care about flashy demos. They want systems that handle their messy, compliance-heavy data. That\u2019s why deals go for $50K\u2013$200K+. It\u2019s not easy: debugging is nasty, the learning curve steep. But that\u2019s also why demand is so high. If you stick with it, you\u2019ll find companies chasing *you*.\n\nSo start building. Break things. Fix them. Learn. Solve real problems for real people. The demand is there, the money is there, and the learning never stops.\n\nAnd I\u2019m curious: what\u2019s been the hardest real-world roadblock you\u2019ve faced in building or even just experimenting with RAG systems? Or even if you\u2019re just learning more in this space, I\u2019m happy to help in any way.\n\n*Note: I used Claude for grammar/formatting polish and formatting for better readability*", "author_fullname": "t2_aq73dyq8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I Built RAG Systems for Enterprises (20K+ Docs). Here\u2019s the learning path I wish I had (complete guide)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/LLMDevs", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_1nl9oxo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 840, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 840, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "", "edited": 1758303120.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758302531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.LLMDevs", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I\u2019m Raj. Over the past year I\u2019ve built RAG systems for 10+ enterprise clients \u2013 pharma companies, banks, law firms \u2013 handling everything from 20K+ document repositories, deploying air\u2011gapped on\u2011prem models, complex compliance requirements, and more.&lt;/p&gt;\n\n&lt;p&gt;In this post, I want to share the actual learning path I followed \u2013 what worked, what didn\u2019t, and the skills you really need if you want to go from toy demos to production-ready systems. Even if you\u2019re a beginner just starting out, or an engineer aiming to build enterprise-level RAG and AI agents, this post should support you in some way. I\u2019ll cover the fundamentals I started with, the messy real-world challenges, how I learned from codebases, and the realities of working with enterprise clients.&lt;/p&gt;\n\n&lt;p&gt;I recently shared a technical post on building RAG agents at scale and also a business breakdown on how to find and work with enterprise clients, and the response was overwhelming \u2013 thank you. But most importantly, many people wanted to know &lt;em&gt;how I actually learned these concepts&lt;/em&gt;. So I thought I\u2019d share some of the insights and approaches that worked for me.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Reality of Production Work&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Building a simple chatbot on top of a vector DB is easy \u2014 but that\u2019s not what companies are paying for. The real value comes from building RAG systems that work at scale and survive the messy realities of production. That\u2019s why companies pay serious money for working systems \u2014 because so few people can actually deliver them.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why RAG Isn\u2019t Going Anywhere&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Before I get into it, I just want to share why RAG is so important and why its need is only going to keep growing. RAG isn\u2019t hype. It solves problems that won\u2019t vanish:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Context limits: Even 200K-token models choke after ~100\u2013200 pages. Enterprise repositories are 1,000x bigger. And usable context is really ~120K before quality drops off.&lt;/li&gt;\n&lt;li&gt;Fine-tuning \u2260 knowledge injection: It changes style, not content. You can teach terminology (like \u201cMI\u201d = myocardial infarction) but you can\u2019t shove in 50K docs without catastrophic forgetting.&lt;/li&gt;\n&lt;li&gt;Enterprise reality: Metadata, quality checks, hybrid retrieval \u2013 these aren\u2019t solved. That\u2019s why RAG engineers are in demand.&lt;/li&gt;\n&lt;li&gt;The future: Data grows faster than context, reliable knowledge injection doesn\u2019t exist yet, and enterprises need audit trails + real-time compliance. RAG isn\u2019t going away.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Foundation&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Before I knew what I was doing, I jumped into code too fast and wasted weeks. If I could restart, I\u2019d begin with fundamentals. Andrew Ng\u2019s deeplearning ai courses on RAG and agents are a goldmine. Free, clear, and packed with insights that shortcut months of wasted time. Don\u2019t skip them \u2013 you need a solid base in embeddings, LLMs, prompting, and the overall tool landscape.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Recommended courses:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Retrieval Augmented Generation (RAG)&lt;/li&gt;\n&lt;li&gt;LLMs as Operating Systems: Agent Memory&lt;/li&gt;\n&lt;li&gt;Long-Term Agentic Memory with LangGraph&lt;/li&gt;\n&lt;li&gt;How Transformer LLMs Work&lt;/li&gt;\n&lt;li&gt;Building Agentic RAG with LlamaIndex&lt;/li&gt;\n&lt;li&gt;Knowledge Graphs for RAG&lt;/li&gt;\n&lt;li&gt;Building Apps with Vector Databases&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I also found the &lt;em&gt;AI Engineer&lt;/em&gt; YouTube channel surprisingly helpful. Most of their content is intro-level, but the conference talks helped me see how these systems break down in practice. &lt;strong&gt;First build:&lt;/strong&gt; Don\u2019t overthink it. Use LangChain or LlamaIndex to set up a Q&amp;amp;A system with clean docs (Wikipedia, research papers). The point isn\u2019t to impress anyone \u2013 it\u2019s to get comfortable with the retrieval \u2192 generation flow end-to-end.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Core tech stack I started with:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Vector DBs (Qdrant locally, Pinecone in the cloud)&lt;/li&gt;\n&lt;li&gt;Embedding models (OpenAI \u2192 Nomic)&lt;/li&gt;\n&lt;li&gt;Chunking (fixed, semantic, hierarchical)&lt;/li&gt;\n&lt;li&gt;Prompt engineering basics&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What worked for me was building the same project across multiple frameworks. At first it felt repetitive, but that comparison gave me intuition for tradeoffs you don\u2019t see in docs.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Project ideas:&lt;/strong&gt; A recipe assistant, API doc helper, or personal research bot. Pick something you\u2019ll actually use yourself. When I built a bot to query my own reading list, I suddenly cared much more about fixing its mistakes.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Real-World Complexity&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s where things get messy \u2013 and where you\u2019ll learn the most. At this point I didn\u2019t have a strong network. To practice, I used ChatGPT and Claude to roleplay different companies and domains. It\u2019s not perfect, but simulating real-world problems gave me enough confidence to approach actual clients later. What you\u2019ll quickly notice is that the easy wins vanish. Edge cases, broken PDFs, inconsistent formats \u2013 they eat your time, and there\u2019s no Stack Overflow post waiting with the answer.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Key skills that made a difference for me:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Document Quality Detection: Spotting OCR glitches, missing text, structural inconsistencies. This is where \u201cgarbage in, garbage out\u201d is most obvious.&lt;/li&gt;\n&lt;li&gt;Advanced Chunking: Preserving hierarchy and adapting chunking to query type. Fixed-size chunks alone won\u2019t cut it.&lt;/li&gt;\n&lt;li&gt;Metadata Architecture: Schemas for classification, temporal tagging, cross-references. This alone ate ~40% of my dev time.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;One client had half their repository duplicated with tiny format changes. Fixing that felt like pure grunt work, but it taught me lessons about data pipelines no tutorial ever could.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Learn from Real Codebases&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;One of the fastest ways I leveled up: cloning open-source agent/RAG repos and tearing them apart. Instead of staring blankly at thousands of lines of code, I used Cursor and Claude Code to generate diagrams, trace workflows, and explain design choices. Suddenly gnarly repos became approachable.&lt;/p&gt;\n\n&lt;p&gt;For example, when I studied OpenDevin and Cline (two coding agent projects), I saw two totally different philosophies of handling memory and orchestration. Neither was \u201cright,\u201d but seeing those tradeoffs taught me more than any course.&lt;/p&gt;\n\n&lt;p&gt;My advice: don\u2019t just read the code. Break it, modify it, rebuild it. That\u2019s how you internalize patterns. It felt like an unofficial apprenticeship, except my mentors were GitHub repos.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;When Projects Get Real&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Building RAG systems isn\u2019t just about retrieval \u2014 that\u2019s only the starting point. There\u2019s absolutely more to it once you enter production. Everything up to here is enough to put you ahead of most people. But once you start tackling real client projects, the game changes. I\u2019m not giving you a tutorial here \u2013 it\u2019s too big a topic \u2013 but I want you to be aware of the challenges you\u2019ll face so you\u2019re not blindsided. If you want the deep dive on solving these kinds of enterprise-scale issues, I\u2019ve posted a full technical guide in the comments \u2014 worth checking if you\u2019re serious about going beyond the basics.&lt;/p&gt;\n\n&lt;p&gt;Here are the realities that hit me once clients actually relied on my systems:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Reliability under load&lt;/strong&gt;: Systems must handle concurrent searches and ongoing uploads. One client\u2019s setup collapsed without proper queues and monitoring \u2014 resilience matters more than features.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Evaluation and testing&lt;/strong&gt;: Demos mean nothing if users can\u2019t trust results. Gold datasets, regression tests, and feedback loops are essential.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Business alignment&lt;/strong&gt;: Tech fails if staff aren\u2019t trained or ROI isn\u2019t clear. Adoption and compliance matter as much as embeddings.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Domain messiness&lt;/strong&gt;: Healthcare jargon, financial filings, legal precedents \u2014 every industry has quirks that make or break your system.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Security expectations&lt;/strong&gt;: Enterprises want guarantees: on\u2011prem deployments, role\u2011based access, audit logs. One law firm required every retrieval call to be logged immutably.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This is the stage where side projects turn into real production systems.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Real Opportunity&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;If you push through this learning curve, you\u2019ll have rare skills. Enterprises everywhere need RAG/agent systems, but very few engineers can actually deliver production-ready solutions. I\u2019ve seen it firsthand \u2013 companies don\u2019t care about flashy demos. They want systems that handle their messy, compliance-heavy data. That\u2019s why deals go for $50K\u2013$200K+. It\u2019s not easy: debugging is nasty, the learning curve steep. But that\u2019s also why demand is so high. If you stick with it, you\u2019ll find companies chasing &lt;em&gt;you&lt;/em&gt;.&lt;/p&gt;\n\n&lt;p&gt;So start building. Break things. Fix them. Learn. Solve real problems for real people. The demand is there, the money is there, and the learning never stops.&lt;/p&gt;\n\n&lt;p&gt;And I\u2019m curious: what\u2019s been the hardest real-world roadblock you\u2019ve faced in building or even just experimenting with RAG systems? Or even if you\u2019re just learning more in this space, I\u2019m happy to help in any way.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Note: I used Claude for grammar/formatting polish and formatting for better readability&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "df9c6ac8-ae80-11ed-b5ee-dab4a79b804c", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_7xegfq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "1nl9oxo", "is_robot_indexable": true, "report_reasons": null, "author": "Low_Acanthisitta7686", "discussion_type": null, "num_comments": 119, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/LLMDevs/comments/1nl9oxo/i_built_rag_systems_for_enterprises_20k_docs/", "stickied": false, "url": "https://www.reddit.com/r/LLMDevs/comments/1nl9oxo/i_built_rag_systems_for_enterprises_20k_docs/", "subreddit_subscribers": 134343, "created_utc": 1758302531.0, "num_crossposts": 4, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "ArtificialInteligence", "selftext": "Went to the **Agentic AI Summit 2025** at Berkeley and, honestly, I'm still sorting out my thoughts. Thought maybe I'd share my experience here in case anyone else is trying to wrap their head around this \"agentic AI\" thing and how it\u2019s actually playing out, not just in theory.\n\n**Short version:** These agent systems are becoming real, but it\u2019s still early days. There\u2019s progress, but also plenty of rough edges, especially around memory and decisions about which tools to use for what.\n\n# First impressions\n\nAbout 1,500 people showed up (which was way more than I expected), and the online stream was huge too. Most of the talks cut straight to the technical heart of things. This was refreshing, if a bit overwhelming at times.\n\nA big theme was that **the main hold-up isn\u2019t training big models anymore. It\u2019s how you steer and manage them in real systems.** That part was new to me and got repeated a lot.\n\n# Stuff that\u2019s actually working\n\n* **ReAct style feedback loops:** LLMs reason, ask for outside help, try again, repeat. Not rocket science, but seems helpful in practice.\n* **MCP (Model Context Protocol):** Lets different agents/tools talk to each other in a more modular way. It\u2019s early, but people seem excited.\n* **Memory:** There\u2019s a lot of effort going into figuring out what the AI should remember long term, but nobody seems happy with the current solutions yet.\n\n# Frameworks people mentioned:\n\n* CrewAI (multi-agent stuff)\n* LangGraph (orchestrating logic)\n* LlamaIndex (wrangling documents)\n* Goose (an open Claude alternative)\n\n# Hype vs. reality (from my take):\n\n\\- The dream of \u201cmedia-to-media\u201d agents isn\u2019t here yet; everything still gets converted to text.  \n\\- Full-on \u201cautonomy\u201d feels like a stretch; there are a bunch of workarounds for handling context.  \n\\+ Form filling and coding agents are about to start outperforming humans in some tasks.  \n\\+ Document analysis is also improving, mostly in look-back duration.\n\n# Panel highlights (with a grain of salt):\n\n* One of the NVIDIA speakers thinks CPUs aren\u2019t dead yet, even though everyone obsesses about GPUs.\n* OpenAI\u2019s Sherwin Wu called 2025 the \u201cYear of Agents\u201d but also pointed out how pricey fast 24/7 access is ($27/month for o3).\n* DeepMind\u2019s Ed Chi demoed some pretty wild multi-modal stuff with Gemini Assistant, a single model that does many things in parallel.\n\n# Real bottlenecks right now (as far as I could tell):\n\n1. **Memory that actually remembers:** agents forget after each session, which is both funny and frustrating.\n2. **Picking the right tool:** connecting more tools, especially custom, makes agents confused.\n3. **How to test/evaluate:** not super clear yet, but involves reading \"traces\".\n4. **Cost:** the fees to run these things add up fast. what is the balance between human tokens and agent tokens?\n\n# Cool/weird ideas I saw:\n\n* An agent working inside hospital software (Oracle Health)\n* One that spits out optimization algorithms on the fly (OpenEvolve)\n* An agent that learns and grows (LinkedIn)\n* Agents that try to break themselves, like a built-in bug-hunt mode\n* Supervisors running right on the GPU for real-time orchestration of complex workflows\n* When monitoring food crops, each sensor becomes an MCP tool\n\nKind of new standards:\n\n* [Agntcy.org](http://Agntcy.org) for getting agents to talk to each other\n* FRAMES for measuring how factual/retrievable/reasonable things are\n* Mozilla\u2019s set of open-source agent tools (\u201cany-agent\u201d, \"any-guardrail\", \"any-llm\")\n\n# My own main takeaway\n\nHonestly, the tech can do some amazing stuff, but the rough bits are really rough. The teams making the most headway are focused less on model size, more on handling context, logistics, and actually measuring performance.\n\nMost of the sessions are up on Berkeley RDI's [site](https://rdi.berkeley.edu/events/agentic-ai-summit) if you want to dig deeper. I liked the infrastructure and frameworks panels myself.\n\nWould love to hear from anyone else tinkering with this - what\u2019s breaking for you? My experiments with multi-agent setups keep running into memory limits, which, I guess, is on theme.\n\n*Posted by someone whose agents definitely won\u2019t remember this post tomorrow.*\n\nP.S. If you want even more details, [my notes](https://www.paologabriel.com/swamp/agentic-ai-summit-2025/) are up in my swamp. I couldn't see everything, and am hoping to find other folks who attended and took notes. Thanks for reading! ", "author_fullname": "t2_558nbeg5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My notes from the Agentic AI Summit 2025 at UC Berkeley", "link_flair_richtext": [], "subreddit_name_prefixed": "r/ArtificialInteligence", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_1miv64t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 541, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 541, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1754454477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.ArtificialInteligence", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Went to the &lt;strong&gt;Agentic AI Summit 2025&lt;/strong&gt; at Berkeley and, honestly, I&amp;#39;m still sorting out my thoughts. Thought maybe I&amp;#39;d share my experience here in case anyone else is trying to wrap their head around this &amp;quot;agentic AI&amp;quot; thing and how it\u2019s actually playing out, not just in theory.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Short version:&lt;/strong&gt; These agent systems are becoming real, but it\u2019s still early days. There\u2019s progress, but also plenty of rough edges, especially around memory and decisions about which tools to use for what.&lt;/p&gt;\n\n&lt;h1&gt;First impressions&lt;/h1&gt;\n\n&lt;p&gt;About 1,500 people showed up (which was way more than I expected), and the online stream was huge too. Most of the talks cut straight to the technical heart of things. This was refreshing, if a bit overwhelming at times.&lt;/p&gt;\n\n&lt;p&gt;A big theme was that &lt;strong&gt;the main hold-up isn\u2019t training big models anymore. It\u2019s how you steer and manage them in real systems.&lt;/strong&gt; That part was new to me and got repeated a lot.&lt;/p&gt;\n\n&lt;h1&gt;Stuff that\u2019s actually working&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;ReAct style feedback loops:&lt;/strong&gt; LLMs reason, ask for outside help, try again, repeat. Not rocket science, but seems helpful in practice.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;MCP (Model Context Protocol):&lt;/strong&gt; Lets different agents/tools talk to each other in a more modular way. It\u2019s early, but people seem excited.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Memory:&lt;/strong&gt; There\u2019s a lot of effort going into figuring out what the AI should remember long term, but nobody seems happy with the current solutions yet.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Frameworks people mentioned:&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;CrewAI (multi-agent stuff)&lt;/li&gt;\n&lt;li&gt;LangGraph (orchestrating logic)&lt;/li&gt;\n&lt;li&gt;LlamaIndex (wrangling documents)&lt;/li&gt;\n&lt;li&gt;Goose (an open Claude alternative)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Hype vs. reality (from my take):&lt;/h1&gt;\n\n&lt;p&gt;- The dream of \u201cmedia-to-media\u201d agents isn\u2019t here yet; everything still gets converted to text.&lt;br/&gt;\n- Full-on \u201cautonomy\u201d feels like a stretch; there are a bunch of workarounds for handling context.&lt;br/&gt;\n+ Form filling and coding agents are about to start outperforming humans in some tasks.&lt;br/&gt;\n+ Document analysis is also improving, mostly in look-back duration.&lt;/p&gt;\n\n&lt;h1&gt;Panel highlights (with a grain of salt):&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;One of the NVIDIA speakers thinks CPUs aren\u2019t dead yet, even though everyone obsesses about GPUs.&lt;/li&gt;\n&lt;li&gt;OpenAI\u2019s Sherwin Wu called 2025 the \u201cYear of Agents\u201d but also pointed out how pricey fast 24/7 access is ($27/month for o3).&lt;/li&gt;\n&lt;li&gt;DeepMind\u2019s Ed Chi demoed some pretty wild multi-modal stuff with Gemini Assistant, a single model that does many things in parallel.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Real bottlenecks right now (as far as I could tell):&lt;/h1&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Memory that actually remembers:&lt;/strong&gt; agents forget after each session, which is both funny and frustrating.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Picking the right tool:&lt;/strong&gt; connecting more tools, especially custom, makes agents confused.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;How to test/evaluate:&lt;/strong&gt; not super clear yet, but involves reading &amp;quot;traces&amp;quot;.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Cost:&lt;/strong&gt; the fees to run these things add up fast. what is the balance between human tokens and agent tokens?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;Cool/weird ideas I saw:&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;An agent working inside hospital software (Oracle Health)&lt;/li&gt;\n&lt;li&gt;One that spits out optimization algorithms on the fly (OpenEvolve)&lt;/li&gt;\n&lt;li&gt;An agent that learns and grows (LinkedIn)&lt;/li&gt;\n&lt;li&gt;Agents that try to break themselves, like a built-in bug-hunt mode&lt;/li&gt;\n&lt;li&gt;Supervisors running right on the GPU for real-time orchestration of complex workflows&lt;/li&gt;\n&lt;li&gt;When monitoring food crops, each sensor becomes an MCP tool&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Kind of new standards:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"http://Agntcy.org\"&gt;Agntcy.org&lt;/a&gt; for getting agents to talk to each other&lt;/li&gt;\n&lt;li&gt;FRAMES for measuring how factual/retrievable/reasonable things are&lt;/li&gt;\n&lt;li&gt;Mozilla\u2019s set of open-source agent tools (\u201cany-agent\u201d, &amp;quot;any-guardrail&amp;quot;, &amp;quot;any-llm&amp;quot;)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;My own main takeaway&lt;/h1&gt;\n\n&lt;p&gt;Honestly, the tech can do some amazing stuff, but the rough bits are really rough. The teams making the most headway are focused less on model size, more on handling context, logistics, and actually measuring performance.&lt;/p&gt;\n\n&lt;p&gt;Most of the sessions are up on Berkeley RDI&amp;#39;s &lt;a href=\"https://rdi.berkeley.edu/events/agentic-ai-summit\"&gt;site&lt;/a&gt; if you want to dig deeper. I liked the infrastructure and frameworks panels myself.&lt;/p&gt;\n\n&lt;p&gt;Would love to hear from anyone else tinkering with this - what\u2019s breaking for you? My experiments with multi-agent setups keep running into memory limits, which, I guess, is on theme.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Posted by someone whose agents definitely won\u2019t remember this post tomorrow.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;P.S. If you want even more details, &lt;a href=\"https://www.paologabriel.com/swamp/agentic-ai-summit-2025/\"&gt;my notes&lt;/a&gt; are up in my swamp. I couldn&amp;#39;t see everything, and am hoping to find other folks who attended and took notes. Thanks for reading! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "top", "banned_at_utc": null, "view_count": null, "archived": true, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "57e75850-9467-11ed-ac06-76e0ad5355fd", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_3crzr", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#014980", "id": "1miv64t", "is_robot_indexable": true, "report_reasons": null, "author": "plausible_statement", "discussion_type": null, "num_comments": 70, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/ArtificialInteligence/comments/1miv64t/my_notes_from_the_agentic_ai_summit_2025_at_uc/", "stickied": false, "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1miv64t/my_notes_from_the_agentic_ai_summit_2025_at_uc/", "subreddit_subscribers": 1709311, "created_utc": 1754454477.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "learnmachinelearning", "selftext": "Need to vent because Im mass frustrated with how I spent my time\n\nSaw langchain everywhere in job postings so I went deep. Like really deep. Six months of tutorials, built rag systems, built agent chains, built all the stuff the courses tell you to build. Portfolio looked legit. Felt ready.\n\nFirst interview: \"oh we use llamaindex, langchain experience doesnt really transfer\" ok cool\n\nSecond interview: \"we rolled our own, langchain was too bloated\" great\n\nThird interview: \"how would you deploy this to production\" and I realize all my projects just run in jupyter notebooks like an idiot\n\nFourth interview: \"what monitoring would you set up for agents in prod\" literally had nothing\n\nFifth interview: they were just using basic api calls with some simple orchestration in vellum, way less complex than anything I spent months building because it\u2019s just an ai builder.\n\nGot an offer eventually and you know what they actually cared about? That I could explain what I built to normal people. That I had debugging stories. My fancy chains? Barely came up.\n\nSix months mass wasted learning the wrong stuff. The gap between tutorials and actual jobs is insane and nobody warns you.", "author_fullname": "t2_ed4kmv3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spent 6 months learning langchain and mass regret it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/learnmachinelearning", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_1piciah", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 440, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 440, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1765299079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnmachinelearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need to vent because Im mass frustrated with how I spent my time&lt;/p&gt;\n\n&lt;p&gt;Saw langchain everywhere in job postings so I went deep. Like really deep. Six months of tutorials, built rag systems, built agent chains, built all the stuff the courses tell you to build. Portfolio looked legit. Felt ready.&lt;/p&gt;\n\n&lt;p&gt;First interview: &amp;quot;oh we use llamaindex, langchain experience doesnt really transfer&amp;quot; ok cool&lt;/p&gt;\n\n&lt;p&gt;Second interview: &amp;quot;we rolled our own, langchain was too bloated&amp;quot; great&lt;/p&gt;\n\n&lt;p&gt;Third interview: &amp;quot;how would you deploy this to production&amp;quot; and I realize all my projects just run in jupyter notebooks like an idiot&lt;/p&gt;\n\n&lt;p&gt;Fourth interview: &amp;quot;what monitoring would you set up for agents in prod&amp;quot; literally had nothing&lt;/p&gt;\n\n&lt;p&gt;Fifth interview: they were just using basic api calls with some simple orchestration in vellum, way less complex than anything I spent months building because it\u2019s just an ai builder.&lt;/p&gt;\n\n&lt;p&gt;Got an offer eventually and you know what they actually cared about? That I could explain what I built to normal people. That I had debugging stories. My fancy chains? Barely came up.&lt;/p&gt;\n\n&lt;p&gt;Six months mass wasted learning the wrong stuff. The gap between tutorials and actual jobs is insane and nobody warns you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_3cqa1", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1piciah", "is_robot_indexable": true, "report_reasons": null, "author": "Hungry-Confection762", "discussion_type": null, "num_comments": 108, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/learnmachinelearning/comments/1piciah/spent_6_months_learning_langchain_and_mass_regret/", "stickied": false, "url": "https://www.reddit.com/r/learnmachinelearning/comments/1piciah/spent_6_months_learning_langchain_and_mass_regret/", "subreddit_subscribers": 611743, "created_utc": 1765299079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "Rag", "selftext": "I've spent the past 8 months the trenches, I want to share what actually worked vs. wasted our time. We built RAG for Usul AI (9M pages) and an unnamed legal AI enterprise (4M pages).\n\n# Langchain + Llamaindex\n\nWe started out with youtube tutorials. First Langchain -&gt; Llamaindex. Got to a working prototype in a couple of days and were optimistic with the progress. We run tests on subset of the data (100 documents) and the results looked great. We spend the next few days running the pipeline on the production dataset and got everything working in a week \u2014 incredible.\n\nExcept it wasn\u2019t, the results were subpar and only the end users could tell. We spent the following few months rewriting pieces of the system, one at a time, until the performance was at the level we wanted. Here are things we did ranked by ROI.\n\n# What moved the needle\n\n1. **Query Generation**: not all context can be captured by the user\u2019s last query. We had an LLM review the thread and generate a number of semantic + keyword queries. We processed all of those queries in parallel, and passed them to a reranker. This made us cover a larger surface area and not be dependent on a computed score for hybrid search.\n2. **Reranking**: the highest value 5 lines of code you\u2019ll add. The chunk ranking shifted *a lot*. More than you\u2019d expect. Reranking can many times make up for a bad setup if you pass in enough chunks. We found the ideal reranker set-up to be 50 chunk input -&gt; 15 output.\n3. **Chunking Strategy**: this takes a lot of effort, you\u2019ll probably be spending most of your time on it. We built a custom flow for both enterprises, make sure to understand the data, review the chunks, and check that a) chunks are not getting cut mid-word or sentence b) \\~each chunk is a logical unit and captures information on its own\n4. **Metadata to LLM**: we started by passing the chunk text to the LLM, we ran an experiment and found that injecting relevant metadata as well (title, author, etc.) improves context and answers by a lot.\n5. **Query routing**: many users asked questions that can\u2019t be answered by RAG (e.g. summarize the article, who wrote this). We created a small router that detects these questions and answers them using an API call + LLM instead of the full-blown RAG set-ups.\n\n# Our stack\n\n* **Vector database:** Azure \u2192 Pinecone \u2192 Turbopuffer (cheap, supports keyword search natively)\n* **Document Extraction:** Custom\n* **Chunking:** Unstructured.io by default, custom for enterprises (heard that Chonkie is good)\n* **Embedding:** text-embedding-3-large, haven\u2019t tested others\n* **Reranker:** None \u2192 Cohere 3.5 \u2192 Zerank (less known but actually good)\n* **LLM:** GPT-4.1 \u2192 GPT-5 \u2192 GPT-4.1 (covered by Azure credits)\n\n# Going Open-source\n\nWe put all our learning into an open-source project: [https://github.com/agentset-ai/agentset](https://github.com/agentset-ai/agentset) under an MIT license. Happy to share any learnings.", "author_fullname": "t2_1wzu8s8m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Production RAG: what we learned from processing 5M+ documents", "link_flair_richtext": [], "subreddit_name_prefixed": "r/Rag", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_1oblymp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 368, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools &amp; Resources", "can_mod_post": false, "score": 368, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760974796.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.Rag", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve spent the past 8 months the trenches, I want to share what actually worked vs. wasted our time. We built RAG for Usul AI (9M pages) and an unnamed legal AI enterprise (4M pages).&lt;/p&gt;\n\n&lt;h1&gt;Langchain + Llamaindex&lt;/h1&gt;\n\n&lt;p&gt;We started out with youtube tutorials. First Langchain -&amp;gt; Llamaindex. Got to a working prototype in a couple of days and were optimistic with the progress. We run tests on subset of the data (100 documents) and the results looked great. We spend the next few days running the pipeline on the production dataset and got everything working in a week \u2014 incredible.&lt;/p&gt;\n\n&lt;p&gt;Except it wasn\u2019t, the results were subpar and only the end users could tell. We spent the following few months rewriting pieces of the system, one at a time, until the performance was at the level we wanted. Here are things we did ranked by ROI.&lt;/p&gt;\n\n&lt;h1&gt;What moved the needle&lt;/h1&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Query Generation&lt;/strong&gt;: not all context can be captured by the user\u2019s last query. We had an LLM review the thread and generate a number of semantic + keyword queries. We processed all of those queries in parallel, and passed them to a reranker. This made us cover a larger surface area and not be dependent on a computed score for hybrid search.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Reranking&lt;/strong&gt;: the highest value 5 lines of code you\u2019ll add. The chunk ranking shifted &lt;em&gt;a lot&lt;/em&gt;. More than you\u2019d expect. Reranking can many times make up for a bad setup if you pass in enough chunks. We found the ideal reranker set-up to be 50 chunk input -&amp;gt; 15 output.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Chunking Strategy&lt;/strong&gt;: this takes a lot of effort, you\u2019ll probably be spending most of your time on it. We built a custom flow for both enterprises, make sure to understand the data, review the chunks, and check that a) chunks are not getting cut mid-word or sentence b) ~each chunk is a logical unit and captures information on its own&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Metadata to LLM&lt;/strong&gt;: we started by passing the chunk text to the LLM, we ran an experiment and found that injecting relevant metadata as well (title, author, etc.) improves context and answers by a lot.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Query routing&lt;/strong&gt;: many users asked questions that can\u2019t be answered by RAG (e.g. summarize the article, who wrote this). We created a small router that detects these questions and answers them using an API call + LLM instead of the full-blown RAG set-ups.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;Our stack&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Vector database:&lt;/strong&gt; Azure \u2192 Pinecone \u2192 Turbopuffer (cheap, supports keyword search natively)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Document Extraction:&lt;/strong&gt; Custom&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Chunking:&lt;/strong&gt; Unstructured.io by default, custom for enterprises (heard that Chonkie is good)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Embedding:&lt;/strong&gt; text-embedding-3-large, haven\u2019t tested others&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Reranker:&lt;/strong&gt; None \u2192 Cohere 3.5 \u2192 Zerank (less known but actually good)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;LLM:&lt;/strong&gt; GPT-4.1 \u2192 GPT-5 \u2192 GPT-4.1 (covered by Azure credits)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Going Open-source&lt;/h1&gt;\n\n&lt;p&gt;We put all our learning into an open-source project: &lt;a href=\"https://github.com/agentset-ai/agentset\"&gt;https://github.com/agentset-ai/agentset&lt;/a&gt; under an MIT license. Happy to share any learnings.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a1d03608-5f0e-11ef-b320-eeb1e130e095", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_4wxz5h", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#8a2be2", "id": "1oblymp", "is_robot_indexable": true, "report_reasons": null, "author": "tifa2up", "discussion_type": null, "num_comments": 77, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/Rag/comments/1oblymp/production_rag_what_we_learned_from_processing_5m/", "stickied": false, "url": "https://www.reddit.com/r/Rag/comments/1oblymp/production_rag_what_we_learned_from_processing_5m/", "subreddit_subscribers": 63354, "created_utc": 1760974796.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "AgentsOfAI", "selftext": "", "author_fullname": "t2_1rnw0nwure", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This guy literally mapped out all the AI agents tools [HQ]", "link_flair_richtext": [{"e": "text", "t": "Agents"}], "subreddit_name_prefixed": "r/AgentsOfAI", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_1mhqeu5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 343, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Agents", "can_mod_post": false, "score": 343, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1754343027.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "top", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/a0edtacgm2hf1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8a30caa4-f75b-11ef-adf9-5610ec7e6d32", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_dnu2d3", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffd635", "id": "1mhqeu5", "is_robot_indexable": true, "report_reasons": null, "author": "Adorable_Tailor_6067", "discussion_type": null, "num_comments": 36, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/AgentsOfAI/comments/1mhqeu5/this_guy_literally_mapped_out_all_the_ai_agents/", "stickied": false, "url": "https://i.redd.it/a0edtacgm2hf1.jpeg", "subreddit_subscribers": 98930, "created_utc": 1754343027.0, "num_crossposts": 1, "media": null, "is_video": false}}], "before": null}}}