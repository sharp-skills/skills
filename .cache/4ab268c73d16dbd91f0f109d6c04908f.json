{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "yompal"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["knex", "production"], "value": "Hey HN, we\u2019re building an open specification that lets agents discover and invoke APIs with natural language, built on the OpenAPI standard. agents.json clearly defines the contract between LLMs and API as a standard that's open, observable, and replicable.\nHere\u2019s a walkthrough of how it works: <a href=\"https://youtu.be/kby2Wdt2Dtk?si=59xGCDy48Zzwr7ND\" rel=\"nofollow\">https://youtu.be/kby2Wdt2Dtk?si=59xGCDy48Zzwr7ND</a>.<p>There\u2019s 2 parts to this:<p>1. An agents.json file describes how to link API calls together into outcome-based tools for LLMs. This file sits alongside an OpenAPI file.<p>2. The agents.json SDK loads agents.json files as tools for an LLM that can then be executed as a series of API calls.<p>Why is this worth building?\nDevelopers are realizing that to use tools with their LLMs in a stateless way, they have to implement an API manually to work with LLMs. We see devs sacrifice agentic, non-deterministic behavior for hard-coded workflows to create outcomes that can work. agents.json lets LLMs be non-deterministic for the outcomes they want to achieve and deterministic for the API calls it takes to get there.<p>We\u2019ve put together some real examples if you're curious what the final output looks like. Under the hood, these LLMs have the same system prompt and we plug in a different agents.json to give access to different APIs. It\u2019s all templatized.<p>- Resend (<a href=\"https://demo.wild-card.ai/resend\">https://demo.wild-card.ai/resend</a>)<p>- Google Sheets (<a href=\"https://demo.wild-card.ai/googlesheets\">https://demo.wild-card.ai/googlesheets</a>)<p>- Slack (<a href=\"https://demo.wild-card.ai/slack\">https://demo.wild-card.ai/slack</a>)<p>- Stripe (<a href=\"https://demo.wild-card.ai/stripe\">https://demo.wild-card.ai/stripe</a>)<p>We really wanted to solve real <em>production</em> use cases, and <em>knew</em> this couldn\u2019t just be a proxy. Our approach allows you to make API calls from your own infrastructure. The open-source specification + runner package make this paradigm possible. Agents.json is truly stateless; the client manages all memory/state and it can be deployed on existing infra like serverless environments.<p>You might be wondering - <i>isn\u2019t OpenAPI enough?</i> Why can\u2019t I just put that in the LLM\u2019s context?<p>We thought so too, at first, when building an agent with access to Gmail. But putting the API spec into LLM context gave us poor accuracy in tool selection and in tool calling. Even with cutting down our output space to 5-10 endpoints, we\u2019d see the LLMs fail to select the right tool. We wanted the LLM to just work given an outcome rather than having it reason each time which series of API calls to make.<p>The Gmail API, for example, has endpoints to search for threads, list the emails in a thread, and reply with an email given base64 RFC 822 content. All that has to happen in order with the right arguments for our agent to reply to a thread. We found that APIs are designed for developers, not for LLMs.<p>So we implemented agents.json. It started off as a config file we were using internally that we slowly started adding features to like auth registration, tool search, and multiple API sources. 3 weeks ago, Dharmesh (CTO of Hubspot) posted about the concept of a specification that could translate APIs for LLMs. It sounded a lot like what we already had working internally and we decided to make it open source. We built agents.json for ourselves but we\u2019re excited to share it.<p>In the weeks since we\u2019ve put it out there, agents.json has 10 vetted API integrations (some of them official) and more are being added every day. We recently made the tool search and custom collection platform free for everyone so it\u2019s even easier for devs to scale the number of tools. (<a href=\"https://wild-card.ai\">https://wild-card.ai</a>)<p>Please tell us what you think! Especially if you\u2019re building agents or creating APIs!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Agents.json \u2013 OpenAPI Specification for LLMs"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/wild-card-ai/agents-json"}}, "_tags": ["story", "author_yompal", "story_43243893", "show_hn"], "author": "yompal", "children": [43244328, 43244443, 43244506, 43244622, 43244738, 43244998, 43245239, 43246039, 43246159, 43246337, 43246674, 43246984, 43247767, 43249233, 43249872, 43249940, 43250250, 43251589, 43254940, 43258213, 43263277, 43264874], "created_at": "2025-03-03T17:01:59Z", "created_at_i": 1741021319, "num_comments": 69, "objectID": "43243893", "points": 212, "story_id": 43243893, "story_text": "Hey HN, we\u2019re building an open specification that lets agents discover and invoke APIs with natural language, built on the OpenAPI standard. agents.json clearly defines the contract between LLMs and API as a standard that&#x27;s open, observable, and replicable.\nHere\u2019s a walkthrough of how it works: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;kby2Wdt2Dtk?si=59xGCDy48Zzwr7ND\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;kby2Wdt2Dtk?si=59xGCDy48Zzwr7ND</a>.<p>There\u2019s 2 parts to this:<p>1. An agents.json file describes how to link API calls together into outcome-based tools for LLMs. This file sits alongside an OpenAPI file.<p>2. The agents.json SDK loads agents.json files as tools for an LLM that can then be executed as a series of API calls.<p>Why is this worth building?\nDevelopers are realizing that to use tools with their LLMs in a stateless way, they have to implement an API manually to work with LLMs. We see devs sacrifice agentic, non-deterministic behavior for hard-coded workflows to create outcomes that can work. agents.json lets LLMs be non-deterministic for the outcomes they want to achieve and deterministic for the API calls it takes to get there.<p>We\u2019ve put together some real examples if you&#x27;re curious what the final output looks like. Under the hood, these LLMs have the same system prompt and we plug in a different agents.json to give access to different APIs. It\u2019s all templatized.<p>- Resend (<a href=\"https:&#x2F;&#x2F;demo.wild-card.ai&#x2F;resend\">https:&#x2F;&#x2F;demo.wild-card.ai&#x2F;resend</a>)<p>- Google Sheets (<a href=\"https:&#x2F;&#x2F;demo.wild-card.ai&#x2F;googlesheets\">https:&#x2F;&#x2F;demo.wild-card.ai&#x2F;googlesheets</a>)<p>- Slack (<a href=\"https:&#x2F;&#x2F;demo.wild-card.ai&#x2F;slack\">https:&#x2F;&#x2F;demo.wild-card.ai&#x2F;slack</a>)<p>- Stripe (<a href=\"https:&#x2F;&#x2F;demo.wild-card.ai&#x2F;stripe\">https:&#x2F;&#x2F;demo.wild-card.ai&#x2F;stripe</a>)<p>We really wanted to solve real production use cases, and knew this couldn\u2019t just be a proxy. Our approach allows you to make API calls from your own infrastructure. The open-source specification + runner package make this paradigm possible. Agents.json is truly stateless; the client manages all memory&#x2F;state and it can be deployed on existing infra like serverless environments.<p>You might be wondering - <i>isn\u2019t OpenAPI enough?</i> Why can\u2019t I just put that in the LLM\u2019s context?<p>We thought so too, at first, when building an agent with access to Gmail. But putting the API spec into LLM context gave us poor accuracy in tool selection and in tool calling. Even with cutting down our output space to 5-10 endpoints, we\u2019d see the LLMs fail to select the right tool. We wanted the LLM to just work given an outcome rather than having it reason each time which series of API calls to make.<p>The Gmail API, for example, has endpoints to search for threads, list the emails in a thread, and reply with an email given base64 RFC 822 content. All that has to happen in order with the right arguments for our agent to reply to a thread. We found that APIs are designed for developers, not for LLMs.<p>So we implemented agents.json. It started off as a config file we were using internally that we slowly started adding features to like auth registration, tool search, and multiple API sources. 3 weeks ago, Dharmesh (CTO of Hubspot) posted about the concept of a specification that could translate APIs for LLMs. It sounded a lot like what we already had working internally and we decided to make it open source. We built agents.json for ourselves but we\u2019re excited to share it.<p>In the weeks since we\u2019ve put it out there, agents.json has 10 vetted API integrations (some of them official) and more are being added every day. We recently made the tool search and custom collection platform free for everyone so it\u2019s even easier for devs to scale the number of tools. (<a href=\"https:&#x2F;&#x2F;wild-card.ai\">https:&#x2F;&#x2F;wild-card.ai</a>)<p>Please tell us what you think! Especially if you\u2019re building agents or creating APIs!", "title": "Show HN: Agents.json \u2013 OpenAPI Specification for LLMs", "updated_at": "2025-04-25T17:29:48Z", "url": "https://github.com/wild-card-ai/agents-json"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "yompal"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["knex", "production"], "value": "Hey HN, we\u2019re building an open specification (<a href=\"https://github.com/wild-card-ai/agents-json\">https://github.com/wild-card-ai/agents-json</a>) that lets agents discover and invoke APIs with natural language, built on the OpenAPI standard.<p>Here\u2019s a walkthrough of how it works: (<a href=\"https://youtu.be/kby2Wdt2Dtk?si=59xGCDy48Zzwr7ND\" rel=\"nofollow\">https://youtu.be/kby2Wdt2Dtk?si=59xGCDy48Zzwr7ND</a>).<p>There\u2019s 2 parts to this:<p>1. The agents.json specification describes how to link API calls together into outcome-based tools for LLMs. This file sits alongside an OpenAPI file.<p>2. The runner package loads agents.json files as tools for an LLM that can then be executed as a series of API calls.<p>We\u2019ve put together some real examples if you're curious what the final output looks like. Under the hood, these LLMs have the same system prompt and we plug in a different agents.json to give access to different APIs. It\u2019s all templatized.<p>- Resend (<a href=\"https://demo.wild-card.ai/resend\">https://demo.wild-card.ai/resend</a>)<p>- Google Sheets (<a href=\"https://demo.wild-card.ai/googlesheets\">https://demo.wild-card.ai/googlesheets</a>)<p>- Slack (<a href=\"https://demo.wild-card.ai/slack\">https://demo.wild-card.ai/slack</a>)<p>- Stripe (<a href=\"https://demo.wild-card.ai/stripe\">https://demo.wild-card.ai/stripe</a>)<p>We really wanted to solve real <em>production</em> use cases, and <em>knew</em> this couldn\u2019t just be a proxy. Our approach allows devs to make API calls from their own infrastructure. The open-source specification + runner package make this paradigm possible. Agents.json is truly stateless; the client manages all memory/state and it can be deployed on existing infra like serverless environments.<p>You might be wondering - isn\u2019t OpenAPI enough? Why can\u2019t I just put that in context?<p>We thought so too when building an agent with access to Gmail. Putting the API spec into context gave us poor accuracy in tool selection and in tool calling. Even with cutting down our output space to 5-10 endpoints, we\u2019d see the LLMs fail to select the right tool. We wanted the LLM to just work given an outcome rather than having it reason each time which series of API calls to make.<p>The Gmail API, for example, has endpoints to search for threads, list the emails in a thread, and reply with an email given base64 RFC 822 content. All that has to happen in order with the right arguments for our agent to reply to a thread. We found that APIs are designed for developers, not for LLMs.<p>So we implemented agents.json. It started off as a config file we were using internally that we slowly started adding features to like auth registration, tool search, and multiple API sources. 3 weeks ago, Dharmesh(CTO of Hubspot) posted about the concept of a specification that could translate APIs for LLMs. It sounded a lot like what we already had working internally and we decided to make it open source. We built agents.json for us and we\u2019re excited to share it with you.<p>In the weeks since we\u2019ve put it out there, agents.json has 10 vetted API integrations (some of them official) and more are being added every day. We recently made the tool search and custom collection platform free for everyone so it\u2019s even easier for devs to scale the number of tools. (<a href=\"https://wild-card.ai\">https://wild-card.ai</a>)<p>This specification isn\u2019t perfect and can\u2019t be without your feedback.  Please tell us what you think! Especially if you\u2019re building agents or creating APIs.<p>Many thanks,\nYagnya and Kaushik from Wildcard"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Agents.json \u2013 Open-source API specification for LLMs"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/wild-card-ai/agents-json"}}, "_tags": ["story", "author_yompal", "story_43130410", "show_hn"], "author": "yompal", "created_at": "2025-02-21T17:36:10Z", "created_at_i": 1740159370, "num_comments": 0, "objectID": "43130410", "points": 4, "story_id": 43130410, "story_text": "Hey HN, we\u2019re building an open specification (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;wild-card-ai&#x2F;agents-json\">https:&#x2F;&#x2F;github.com&#x2F;wild-card-ai&#x2F;agents-json</a>) that lets agents discover and invoke APIs with natural language, built on the OpenAPI standard.<p>Here\u2019s a walkthrough of how it works: (<a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;kby2Wdt2Dtk?si=59xGCDy48Zzwr7ND\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;kby2Wdt2Dtk?si=59xGCDy48Zzwr7ND</a>).<p>There\u2019s 2 parts to this:<p>1. The agents.json specification describes how to link API calls together into outcome-based tools for LLMs. This file sits alongside an OpenAPI file.<p>2. The runner package loads agents.json files as tools for an LLM that can then be executed as a series of API calls.<p>We\u2019ve put together some real examples if you&#x27;re curious what the final output looks like. Under the hood, these LLMs have the same system prompt and we plug in a different agents.json to give access to different APIs. It\u2019s all templatized.<p>- Resend (<a href=\"https:&#x2F;&#x2F;demo.wild-card.ai&#x2F;resend\">https:&#x2F;&#x2F;demo.wild-card.ai&#x2F;resend</a>)<p>- Google Sheets (<a href=\"https:&#x2F;&#x2F;demo.wild-card.ai&#x2F;googlesheets\">https:&#x2F;&#x2F;demo.wild-card.ai&#x2F;googlesheets</a>)<p>- Slack (<a href=\"https:&#x2F;&#x2F;demo.wild-card.ai&#x2F;slack\">https:&#x2F;&#x2F;demo.wild-card.ai&#x2F;slack</a>)<p>- Stripe (<a href=\"https:&#x2F;&#x2F;demo.wild-card.ai&#x2F;stripe\">https:&#x2F;&#x2F;demo.wild-card.ai&#x2F;stripe</a>)<p>We really wanted to solve real production use cases, and knew this couldn\u2019t just be a proxy. Our approach allows devs to make API calls from their own infrastructure. The open-source specification + runner package make this paradigm possible. Agents.json is truly stateless; the client manages all memory&#x2F;state and it can be deployed on existing infra like serverless environments.<p>You might be wondering - isn\u2019t OpenAPI enough? Why can\u2019t I just put that in context?<p>We thought so too when building an agent with access to Gmail. Putting the API spec into context gave us poor accuracy in tool selection and in tool calling. Even with cutting down our output space to 5-10 endpoints, we\u2019d see the LLMs fail to select the right tool. We wanted the LLM to just work given an outcome rather than having it reason each time which series of API calls to make.<p>The Gmail API, for example, has endpoints to search for threads, list the emails in a thread, and reply with an email given base64 RFC 822 content. All that has to happen in order with the right arguments for our agent to reply to a thread. We found that APIs are designed for developers, not for LLMs.<p>So we implemented agents.json. It started off as a config file we were using internally that we slowly started adding features to like auth registration, tool search, and multiple API sources. 3 weeks ago, Dharmesh(CTO of Hubspot) posted about the concept of a specification that could translate APIs for LLMs. It sounded a lot like what we already had working internally and we decided to make it open source. We built agents.json for us and we\u2019re excited to share it with you.<p>In the weeks since we\u2019ve put it out there, agents.json has 10 vetted API integrations (some of them official) and more are being added every day. We recently made the tool search and custom collection platform free for everyone so it\u2019s even easier for devs to scale the number of tools. (<a href=\"https:&#x2F;&#x2F;wild-card.ai\">https:&#x2F;&#x2F;wild-card.ai</a>)<p>This specification isn\u2019t perfect and can\u2019t be without your feedback.  Please tell us what you think! Especially if you\u2019re building agents or creating APIs.<p>Many thanks,\nYagnya and Kaushik from Wildcard", "title": "Show HN: Agents.json \u2013 Open-source API specification for LLMs", "updated_at": "2025-03-03T03:40:24Z", "url": "https://github.com/wild-card-ai/agents-json"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "philippelh"}, "story_text": {"matchLevel": "none", "matchedWords": [], "value": ""}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["knex", "production"], "value": "72 Music <em>Production</em> Tips I Wish I <em>Knew</em> When I Started"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["knex"], "value": "http://theproaudiofiles.com/72-tips-i-wish-i-<em>knew</em>-when-i-started-producing-music/"}}, "_tags": ["story", "author_philippelh", "story_9504619"], "author": "philippelh", "created_at": "2015-05-07T12:47:48Z", "created_at_i": 1431002868, "num_comments": 0, "objectID": "9504619", "points": 1, "story_id": 9504619, "story_text": "", "title": "72 Music Production Tips I Wish I Knew When I Started", "updated_at": "2023-09-07T02:42:09Z", "url": "http://theproaudiofiles.com/72-tips-i-wish-i-knew-when-i-started-producing-music/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "misterbowfinger"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["knex", "production"], "value": "With the recent posts about Docker not being <em>production</em> ready for years now (despite having huge conferences), and RethinkDB shutting down, I'm starting to wonder how an open source company actually makes it.<p>Docker often says, &quot;you need to decide for yourself if you want to use Docker in <em>production</em>,&quot; but I'm betting they <em>knew</em> all of the problems people were going to face. RethinkDB, on the other hand, proactively warned us ahead of time. Is the secret to be ambiguous about how good your software really is?"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: How do open source companies succeed?"}}, "_tags": ["story", "author_misterbowfinger", "story_12882491", "ask_hn"], "author": "misterbowfinger", "children": [12883965], "created_at": "2016-11-05T23:31:40Z", "created_at_i": 1478388700, "num_comments": 1, "objectID": "12882491", "points": 1, "story_id": 12882491, "story_text": "With the recent posts about Docker not being production ready for years now (despite having huge conferences), and RethinkDB shutting down, I&#x27;m starting to wonder how an open source company actually makes it.<p>Docker often says, &quot;you need to decide for yourself if you want to use Docker in production,&quot; but I&#x27;m betting they knew all of the problems people were going to face. RethinkDB, on the other hand, proactively warned us ahead of time. Is the secret to be ambiguous about how good your software really is?", "title": "Ask HN: How do open source companies succeed?", "updated_at": "2024-09-19T23:57:42Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "andriosr"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["knex", "production"], "value": "Hello HN! I'm Andrios, from Runops.io - we're building a proxy to commands you run in the terminal that adds Git, code reviews in Slack, and removes sensitive data from results. It's like the Cloud Shells from GCP/AWS, but with more features and using your local zsh/bash terminal.<p>You run an AWS CLI command in the terminal and it goes to Runops instead of AWS. Runops adds the command to Git and gets peer reviews (when required) in Slack before sending it to AWS. After it runs, we deliver the results back in the terminal, but with all sensitive data masked. It works for AWS, Kubernetes, databases, and others.<p>I was leading the Infra team at a Fintech (pismo.io/en), and we wanted to give autonomy to all developers in <em>production</em>. But we couldn\u2019t give them direct access due to compliance requirements. The solution was to have a small number of people (my team) with &quot;full access&quot; to <em>production</em> systems. Engineers would ask us when they needed to run one-off scripts in <em>production</em>. Our goal was to deliver automations so that other teams wouldn't need to ask us to do things. We would build a way for them to do it with compliance, security, and reliability.<p>It didn't work. We were spending 80% of the time processing the queue of requests, and 20% building automations. The backlog was always increasing, and the team was burning out. Engineers were not happy as their requests took a long time to process and clients were angry at them.<p>But some nice automations came out of that. For instance: we needed to review ad-hoc prod database reads to avoid bad queries. So we built a Jenkins pipeline that ran SQL queries from Git after code review using Flyway. Any engineer could run queries in prod, leaving traces on who did it, reviews, when it happened, and why, for every query.<p>When talking to friends at similar companies, I saw the problem was even worse. Some of them weren't trying to automate, they already had dedicated people for running these scripts, i.e., an ops team. I <em>knew</em> there was a better way, so I set out to build it. I quit this job mid last year, with about 8 months' worth of savings to make this work before I'd need to find a job again. It was tough in the beginning, as I\u2019m an engineer and had to learn sales, marketing and product management on the job, but after getting the first few customers things started improving.<p>The goal for Runops is to let any engineer run anything in <em>production</em> as if they had full access, automating as much as possible of security and compliance. When human interaction is needed, we make it synchronous using Slack. Now, instead of having a single team as a bottleneck, you can have everyone do things in <em>production</em>. Centralizing teams with most of the access to AWS, Kubernetes, and databases is bad. It makes for slow Change Management processes using Jira or other tools with manual executions at the end. Runops let\u2019s you add quick reviews from experts (Infra, DBA, security, etc), and automates executions.<p>The primary interface is a CLI, where you run scripts that goes from SQL queries to kubectl exec and AWS CLI commands. We don't create new abstractions, you use the same commands and docs available, we just proxy them. A nice benefit is replacing VPNs and the 10 client tools/credentials you would need today. We also support templates for custom actions in a bunch of languages.<p>We built it using Github Actions for executing commands. We store configurations and credentials as Actions Secrets and they get injected when a command requires them. It's nice because we can run anything that goes in a Docker container in &lt;15 seconds. We have plans to improve it beyond Actions by creating a real-time proxy. That will enable a REPL-like experience.\nRunops doesn't have a web interface, this is on purpose, we don't want to be one more tool engineers have to learn. Most interactions happen with our CLI or Slack. We have a simple admin UI in Retool.<p>We do everything using Lisp. The CLI uses Clojurescript; the REST API uses Clojure. It's great to have the same language everywhere, and Lisp is also a fantastic advantage.<p>Today we have big Fintechs using Runops. They use it to let developers run commands inside Kubernetes pods, like Rails Runner and Elixir IEx, SQL queries, DynamoDB queries, and making internal API calls in private networks using cURL. One of the best parts of building this has been seeing developers doing more <em>production</em> work. Regulated companies that never considered giving this level of autonomy to all developers are changing their minds. It's great to see a tool impacting the culture, increasing trust.<p>We're really happy we get to show this to you all, thank you for reading about it! Please let us know your thoughts and questions."}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Launch HN: Runops (YC W21) \u2013 A better cloud shell for <em>production</em> apps"}}, "_tags": ["story", "author_andriosr", "story_26385434", "launch_hn"], "author": "andriosr", "children": [26386156, 26386190, 26386400, 26386598, 26386627, 26386950, 26387509, 26392287, 26396005], "created_at": "2021-03-08T13:26:18Z", "created_at_i": 1615209978, "num_comments": 23, "objectID": "26385434", "points": 97, "story_id": 26385434, "story_text": "Hello HN! I&#x27;m Andrios, from Runops.io - we&#x27;re building a proxy to commands you run in the terminal that adds Git, code reviews in Slack, and removes sensitive data from results. It&#x27;s like the Cloud Shells from GCP&#x2F;AWS, but with more features and using your local zsh&#x2F;bash terminal.<p>You run an AWS CLI command in the terminal and it goes to Runops instead of AWS. Runops adds the command to Git and gets peer reviews (when required) in Slack before sending it to AWS. After it runs, we deliver the results back in the terminal, but with all sensitive data masked. It works for AWS, Kubernetes, databases, and others.<p>I was leading the Infra team at a Fintech (pismo.io&#x2F;en), and we wanted to give autonomy to all developers in production. But we couldn\u2019t give them direct access due to compliance requirements. The solution was to have a small number of people (my team) with &quot;full access&quot; to production systems. Engineers would ask us when they needed to run one-off scripts in production. Our goal was to deliver automations so that other teams wouldn&#x27;t need to ask us to do things. We would build a way for them to do it with compliance, security, and reliability.<p>It didn&#x27;t work. We were spending 80% of the time processing the queue of requests, and 20% building automations. The backlog was always increasing, and the team was burning out. Engineers were not happy as their requests took a long time to process and clients were angry at them.<p>But some nice automations came out of that. For instance: we needed to review ad-hoc prod database reads to avoid bad queries. So we built a Jenkins pipeline that ran SQL queries from Git after code review using Flyway. Any engineer could run queries in prod, leaving traces on who did it, reviews, when it happened, and why, for every query.<p>When talking to friends at similar companies, I saw the problem was even worse. Some of them weren&#x27;t trying to automate, they already had dedicated people for running these scripts, i.e., an ops team. I knew there was a better way, so I set out to build it. I quit this job mid last year, with about 8 months&#x27; worth of savings to make this work before I&#x27;d need to find a job again. It was tough in the beginning, as I\u2019m an engineer and had to learn sales, marketing and product management on the job, but after getting the first few customers things started improving.<p>The goal for Runops is to let any engineer run anything in production as if they had full access, automating as much as possible of security and compliance. When human interaction is needed, we make it synchronous using Slack. Now, instead of having a single team as a bottleneck, you can have everyone do things in production. Centralizing teams with most of the access to AWS, Kubernetes, and databases is bad. It makes for slow Change Management processes using Jira or other tools with manual executions at the end. Runops let\u2019s you add quick reviews from experts (Infra, DBA, security, etc), and automates executions.<p>The primary interface is a CLI, where you run scripts that goes from SQL queries to kubectl exec and AWS CLI commands. We don&#x27;t create new abstractions, you use the same commands and docs available, we just proxy them. A nice benefit is replacing VPNs and the 10 client tools&#x2F;credentials you would need today. We also support templates for custom actions in a bunch of languages.<p>We built it using Github Actions for executing commands. We store configurations and credentials as Actions Secrets and they get injected when a command requires them. It&#x27;s nice because we can run anything that goes in a Docker container in &lt;15 seconds. We have plans to improve it beyond Actions by creating a real-time proxy. That will enable a REPL-like experience.\nRunops doesn&#x27;t have a web interface, this is on purpose, we don&#x27;t want to be one more tool engineers have to learn. Most interactions happen with our CLI or Slack. We have a simple admin UI in Retool.<p>We do everything using Lisp. The CLI uses Clojurescript; the REST API uses Clojure. It&#x27;s great to have the same language everywhere, and Lisp is also a fantastic advantage.<p>Today we have big Fintechs using Runops. They use it to let developers run commands inside Kubernetes pods, like Rails Runner and Elixir IEx, SQL queries, DynamoDB queries, and making internal API calls in private networks using cURL. One of the best parts of building this has been seeing developers doing more production work. Regulated companies that never considered giving this level of autonomy to all developers are changing their minds. It&#x27;s great to see a tool impacting the culture, increasing trust.<p>We&#x27;re really happy we get to show this to you all, thank you for reading about it! Please let us know your thoughts and questions.", "title": "Launch HN: Runops (YC W21) \u2013 A better cloud shell for production apps", "updated_at": "2024-09-20T08:07:46Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "Dimittri"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["knex", "production"], "value": "Hey HN, I am Dimittri and we\u2019re building Sonarly (<a href=\"https://sonarly.com\">https://sonarly.com</a>), an AI engineer for <em>production</em>. It connects to your observability tools like Sentry, Datadog, or user feedback channels, triages issues, and fixes them to cut your resolution time. Here's a demo: <a href=\"https://www.youtube.com/watch?v=rr3VHv0eRdw\" rel=\"nofollow\">https://www.youtube.com/watch?v=rr3VHv0eRdw</a>.<p>Sonarly is really about removing the noise from <em>production</em> alerts by grouping duplicates and returning a root cause analysis to save time to on-call engineers and literally cut your MTTR.<p>Before starting this company, my co-founder and I had a B2C app in edtech and had, some days, thousands of users using the app. We pushed several times a day, relying on user feedback. Then we set up Sentry, it was catching a lot of bugs, but we had up to 50 alerts a day. With 2 people it's a lot. We took a lot of time filtering the noise to find the real signal so we <em>knew</em> which bug to focus on.<p>At the same time, we saw how important it is to fix a bug fast when it hits users. A bug means in the worst case a churn and at best a frustrated user. And there are always bugs in <em>production</em>, due to code errors, database mismatches, infrastructure overload, and many issues are linked to a specific user behavior. You can't catch all these beforehand, even with E2E tests or AI code reviews (which catch a lot of bugs but obviously not all, plus it takes time to run at each deployment). This is even more true with vibe-coding (or agentic engineering).<p>We started Sonarly with this idea. More software than ever is being built and users should have the best experience possible on every product. The main idea of Sonarly is to reduce the MTTR (Mean Time To Repair).<p>We started by recreating a Sentry-like tool but without the noise, using only text and session replays as the interface. We built our own frontend tracker (based on open-source rrweb) and used the backend Sentry SDK (open source as well). Companies could just add another tracker in the frontend and add a DSN in their Sentry config to send data to us in addition to Sentry.<p>We wanted to build an interface where you don't need to check logs, dashboards, traces, metrics, and code, as the agent would do it for you with plain English to explain the &quot;what,&quot; &quot;why,&quot; and &quot;how do I fix it.&quot;<p>We quickly realized companies don't want to add a new tracker or change their monitoring stack, as these platforms do the job they're supposed to do. So we decided to build above them. Now we connect to tools like Sentry, Datadog, Slack user feedback channels, and other integrations.<p>Claude Code is so good at writing code, but handling runtime issues requires more than just raw coding ability. It demands deep runtime context, immediate reactivity, and intelligent triage, you can\u2019t simply pipe every alert directly into an agent. That\u2019s why our first step is converting noise into signal. We group duplicates and filter false positives to isolate clear issues. Once we have a confirmed signal, we trigger Claude Code with the exact context it needs, like the specific Sentry issue and relevant logs fetched via MCP (mostly using grep on Datadog/Grafana). However, things get exponentially harder with multi-repo and multi-service architectures.<p>So we built an internal map of the <em>production</em> system that is basically a .md file updated dynamically. It shows every link between different services, logs, and metrics so that Claude Code can understand the issue faster.<p>One of our users using Sentry was receiving ~180 alerts/day. Here is what their workflow looked like:<p>- Receive the alert<p>- 1) Defocus from their current task or wake up, or 2) don't look at the alert at all (most of the time)<p>- Go check dashboards to find the root cause (if infra type) or read the stack trace, events, etc.<p>- Try to figure out if it was a false positive or a real problem (or a known problem already in the fixes pipeline)<p>- Then fix by giving Claude Code the correct context<p>We started by cutting the noise and went from 180/day to 50/day (by grouping issues) and giving a severity based on the impact on the user/infra. This brings it down to 5 issues to focus on in the current day. Triage happens in 3 steps: deduplicating before triggering a coding agent, gathering the root cause for each alert, and re-grouping by RCA.<p>We launched self-serve (<a href=\"https://sonarly.com\">https://sonarly.com</a>) and we would love to have feedback from engineers. Especially curious about your current workflows when you receive an alert from any of these channels like Sentry (error tracking), Datadog (APM), or user feedback. How do you assign who should fix it? Where do you take your context from to fix the issue? Do you have any automated workflow to fix every bug, and do you have anything you use currently to filter the noise from alerts?<p>We have a large free tier as we mainly want feedback. You can self-serve under 2 min. I'll be in the thread with my co-founder to answer your questions, give more technical details, and take your feedback: positive, negative, brutal, everything's constructive!"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Launch HN: Sonarly (YC W26) \u2013 AI agent to triage and fix your <em>production</em> alerts"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://sonarly.com/"}}, "_tags": ["story", "author_Dimittri", "story_47049776", "launch_hn"], "author": "Dimittri", "children": [47052409, 47054509, 47055028, 47055342, 47061697], "created_at": "2026-02-17T17:03:09Z", "created_at_i": 1771347789, "num_comments": 17, "objectID": "47049776", "points": 30, "story_id": 47049776, "story_text": "Hey HN, I am Dimittri and we\u2019re building Sonarly (<a href=\"https:&#x2F;&#x2F;sonarly.com\">https:&#x2F;&#x2F;sonarly.com</a>), an AI engineer for production. It connects to your observability tools like Sentry, Datadog, or user feedback channels, triages issues, and fixes them to cut your resolution time. Here&#x27;s a demo: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rr3VHv0eRdw\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rr3VHv0eRdw</a>.<p>Sonarly is really about removing the noise from production alerts by grouping duplicates and returning a root cause analysis to save time to on-call engineers and literally cut your MTTR.<p>Before starting this company, my co-founder and I had a B2C app in edtech and had, some days, thousands of users using the app. We pushed several times a day, relying on user feedback. Then we set up Sentry, it was catching a lot of bugs, but we had up to 50 alerts a day. With 2 people it&#x27;s a lot. We took a lot of time filtering the noise to find the real signal so we knew which bug to focus on.<p>At the same time, we saw how important it is to fix a bug fast when it hits users. A bug means in the worst case a churn and at best a frustrated user. And there are always bugs in production, due to code errors, database mismatches, infrastructure overload, and many issues are linked to a specific user behavior. You can&#x27;t catch all these beforehand, even with E2E tests or AI code reviews (which catch a lot of bugs but obviously not all, plus it takes time to run at each deployment). This is even more true with vibe-coding (or agentic engineering).<p>We started Sonarly with this idea. More software than ever is being built and users should have the best experience possible on every product. The main idea of Sonarly is to reduce the MTTR (Mean Time To Repair).<p>We started by recreating a Sentry-like tool but without the noise, using only text and session replays as the interface. We built our own frontend tracker (based on open-source rrweb) and used the backend Sentry SDK (open source as well). Companies could just add another tracker in the frontend and add a DSN in their Sentry config to send data to us in addition to Sentry.<p>We wanted to build an interface where you don&#x27;t need to check logs, dashboards, traces, metrics, and code, as the agent would do it for you with plain English to explain the &quot;what,&quot; &quot;why,&quot; and &quot;how do I fix it.&quot;<p>We quickly realized companies don&#x27;t want to add a new tracker or change their monitoring stack, as these platforms do the job they&#x27;re supposed to do. So we decided to build above them. Now we connect to tools like Sentry, Datadog, Slack user feedback channels, and other integrations.<p>Claude Code is so good at writing code, but handling runtime issues requires more than just raw coding ability. It demands deep runtime context, immediate reactivity, and intelligent triage, you can\u2019t simply pipe every alert directly into an agent. That\u2019s why our first step is converting noise into signal. We group duplicates and filter false positives to isolate clear issues. Once we have a confirmed signal, we trigger Claude Code with the exact context it needs, like the specific Sentry issue and relevant logs fetched via MCP (mostly using grep on Datadog&#x2F;Grafana). However, things get exponentially harder with multi-repo and multi-service architectures.<p>So we built an internal map of the production system that is basically a .md file updated dynamically. It shows every link between different services, logs, and metrics so that Claude Code can understand the issue faster.<p>One of our users using Sentry was receiving ~180 alerts&#x2F;day. Here is what their workflow looked like:<p>- Receive the alert<p>- 1) Defocus from their current task or wake up, or 2) don&#x27;t look at the alert at all (most of the time)<p>- Go check dashboards to find the root cause (if infra type) or read the stack trace, events, etc.<p>- Try to figure out if it was a false positive or a real problem (or a known problem already in the fixes pipeline)<p>- Then fix by giving Claude Code the correct context<p>We started by cutting the noise and went from 180&#x2F;day to 50&#x2F;day (by grouping issues) and giving a severity based on the impact on the user&#x2F;infra. This brings it down to 5 issues to focus on in the current day. Triage happens in 3 steps: deduplicating before triggering a coding agent, gathering the root cause for each alert, and re-grouping by RCA.<p>We launched self-serve (<a href=\"https:&#x2F;&#x2F;sonarly.com\">https:&#x2F;&#x2F;sonarly.com</a>) and we would love to have feedback from engineers. Especially curious about your current workflows when you receive an alert from any of these channels like Sentry (error tracking), Datadog (APM), or user feedback. How do you assign who should fix it? Where do you take your context from to fix the issue? Do you have any automated workflow to fix every bug, and do you have anything you use currently to filter the noise from alerts?<p>We have a large free tier as we mainly want feedback. You can self-serve under 2 min. I&#x27;ll be in the thread with my co-founder to answer your questions, give more technical details, and take your feedback: positive, negative, brutal, everything&#x27;s constructive!", "title": "Launch HN: Sonarly (YC W26) \u2013 AI agent to triage and fix your production alerts", "updated_at": "2026-02-24T03:55:09Z", "url": "https://sonarly.com/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "adam"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["knex", "production"], "value": "My co-founder, who was the technical genius of the duo, left our company awhile back and I've needed to trial-by-fire learn a bunch of new things to help with product development, make scaling/environment decisions, and help troubleshoot support requests. I've also realized these skills are important so as not to perpetually annoy my technical employees and contractors with idiotic requests (not to mention wasting money.)<p>Short of straight up coding, what, technically, do you wish your favorite non-technical cofounder <em>knew</em> how to do to help you function better in your job or let you focus on the most important things. For example:<p>* deciphering <em>production</em> logs<p>* proficiency in vi or another editor<p>* rails console or similar<p>* reading a postfix or sendmail log<p>* basic git commands, reading commits<p>* analytics and testing<p>* enough HTML/CSS/JS to make content edits on a corporate homepage<p>* decipher server/application alerts to understand what's a real issue, what isn't"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["knex"], "value": "Ask HN: What do you wish your non-technical co-founders <em>knew</em> how to do?"}, "url": {"matchLevel": "none", "matchedWords": [], "value": ""}}, "_tags": ["story", "author_adam", "story_5248194", "ask_hn"], "author": "adam", "children": [5248380, 5248414, 5248594, 5248796, 5249083, 5249505, 5249579, 5249978, 5252993], "created_at": "2013-02-20T00:37:55Z", "created_at_i": 1361320675, "num_comments": 11, "objectID": "5248194", "points": 23, "story_id": 5248194, "story_text": "My co-founder, who was the technical genius of the duo, left our company awhile back and I've needed to trial-by-fire learn a bunch of new things to help with product development, make scaling/environment decisions, and help troubleshoot support requests. I've also realized these skills are important so as not to perpetually annoy my technical employees and contractors with idiotic requests (not to mention wasting money.)<p>Short of straight up coding, what, technically, do you wish your favorite non-technical cofounder knew how to do to help you function better in your job or let you focus on the most important things. For example:<p>* deciphering production logs<p>* proficiency in vi or another editor<p>* rails console or similar<p>* reading a postfix or sendmail log<p>* basic git commands, reading commits<p>* analytics and testing<p>* enough HTML/CSS/JS to make content edits on a corporate homepage<p>* decipher server/application alerts to understand what's a real issue, what isn't", "title": "Ask HN: What do you wish your non-technical co-founders knew how to do?", "updated_at": "2023-09-06T20:51:59Z", "url": ""}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "KnoxProtocol"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["knex", "production"], "value": "Update to the <em>KNOX</em> Protocol: VELOXREPAER<p>Now...\nAllow me a moment to introduce VeloxReaper<p>Someone has gots do it, so I did it. Classical PoW is officially obsolete. While the rest of the industry plays in the ARX-based sandbox of the 90s, Rocka and I  have weaponized the physics of the polynomial ring for the <em>KNOX</em> Protocol. We have  have fully scrapped Argon2 and built + implemented VeloxReaper, the worlds first anti-ASIC lattice bouncer, governed by the immutable law of Cumulative Lattice Hardening (CLH).<p>THE SYBIL BOUNCER: VeloxReaper<p>VeloxReaper isnt just a hash function ,it is a high-entropy memory-hard bouncer that turns silicon into a liability.<p><pre><code>    100% Pure Lattice Arithmetic: VeloxReaper operates entirely within the polynomial ring Rq =Z12289 [X]/(X1024+1). Every state transition is an affine bilinear mix (M[i]=a\u22c5b+Kr \u22c5a+b). There is zero classical hashing, no Keccak, no BLAKE, and no bitwise manipulation.\n</code></pre>\nThe 512MB DRAM Latency Wall: I enforced a 512MB DAG. This is the hardware dead zone....too massive for any CPU L3 cache (SRAM) on Earth, but perfectly optimized for the 1GB RAM footprint of a $5/month VM.<p>Zero Bias Address Mapping: Rocka and I solved the 24MB SRAM Trap using a massive q4 integer division mapping. By packing four coefficients into a Z-scalar (Z=c0 +c1 q+c2 q2+c3 q3), we achieve perfectly uniform addressing across the entire DAG depth. There are no hot spots for ASICs to exploit.<p>Galois Scrambling: To prevent algebraic shortcuts, we apply a cyclotomic automorphism \u03d5t :X\u2192Xt at every step. This shuffles coefficients spatially across the 4KB block, destroying subspace confinement and ensuring total diffusion.<p>Native SIS Proof-of-Work: We replaced hash-counting with a native Short Integer Solution (SIS) witness. Miners solve for a witness v that satisfies the norm bound \u2225Apub \u22c5v(modq)\u2225\u221e &lt;\u03f5.<p>Asymmetric Verification: While the miner must thrash 512MB of RAM to generate the proof, a light client can verify the block in nanoseconds using a single matrix vector multiplication.<p>THE CONSENSUS ENGINE: PROOF OF TIME (CLH) Tick Tock<p>VeloxReaper handles the entry fee; Cumulative Lattice Hardening (CLH) handles the ledger.<p><pre><code>    Time as a Physical Constant: Unlike Nakamoto consensus, where the fastest chip wins the race, <em>KNOX</em> uses a sequential, time based clock. A miner can evaluate VeloxReaper in nanoseconds on a custom ASIC, but they must still wait for the physics enforced time clock to tick before a block can be forged.\n\n    The Anti Race: CLH ensures that block <em>production</em> is a function of sequential time, not parallel hash-power. High-end hardware doesn't win more blocks, it just finishes its math early and sits idle. I have decoupled security from the energy-waste arms race.\n\n    Progress Free Hardening: The ledger hardens as a function of sequential lattice iterations. The more time passes, the more lattice-hardened the history becomes, making reorgs mathematically impossible without a literal time machine.\n\n THE SHORT INTEGER SOLUTION (SIS) WITNESS\n</code></pre>\nI replaced the primitive leading zeros check with a native SIS Proof.<p>Miners solve for a witness v that satisfies the norm bound \u2225Apub \u22c5v(modq)\u2225\u221e &lt;\u03f5.<p><pre><code>   Asymmetric Dominance: While the miner must thrash 512MB of RAM to find the witness, a light client or smartphone can verify the block in nanoseconds using a single matrix-vector multiplication.\n</code></pre>\nVeloxReaper reaps the ASICs. CLH tames the clock. The <em>KNOX</em> Protocol is live once agai.<p>Come check out what my 11 year old son and I built.<p>Lets fucking rock.<p>v1.3.0 <a href=\"https://github.com/ULT7RA/KnoxProtocol/releases\" rel=\"nofollow\">https://github.com/ULT7RA/KnoxProtocol/releases</a> <em>KNOX</em> GUI Wallet + VeloxReaper + Optimized Cuda-NTT Accelerator Kernel"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["knex"], "value": "Show HN: <em>Knox</em> First Full Lattice BLockchain.UPDATE:Veloxreaper"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/ULT7RA/KNOXProtocol/releases"}}, "_tags": ["story", "author_KnoxProtocol", "story_47183346", "show_hn"], "author": "KnoxProtocol", "children": [47183368], "created_at": "2026-02-27T17:55:44Z", "created_at_i": 1772214944, "num_comments": 1, "objectID": "47183346", "points": 2, "story_id": 47183346, "story_text": "Update to the KNOX Protocol: VELOXREPAER<p>Now...\nAllow me a moment to introduce VeloxReaper<p>Someone has gots do it, so I did it. Classical PoW is officially obsolete. While the rest of the industry plays in the ARX-based sandbox of the 90s, Rocka and I  have weaponized the physics of the polynomial ring for the KNOX Protocol. We have  have fully scrapped Argon2 and built + implemented VeloxReaper, the worlds first anti-ASIC lattice bouncer, governed by the immutable law of Cumulative Lattice Hardening (CLH).<p>THE SYBIL BOUNCER: VeloxReaper<p>VeloxReaper isnt just a hash function ,it is a high-entropy memory-hard bouncer that turns silicon into a liability.<p><pre><code>    100% Pure Lattice Arithmetic: VeloxReaper operates entirely within the polynomial ring Rq =Z12289 [X]&#x2F;(X1024+1). Every state transition is an affine bilinear mix (M[i]=a\u22c5b+Kr \u22c5a+b). There is zero classical hashing, no Keccak, no BLAKE, and no bitwise manipulation.\n</code></pre>\nThe 512MB DRAM Latency Wall: I enforced a 512MB DAG. This is the hardware dead zone....too massive for any CPU L3 cache (SRAM) on Earth, but perfectly optimized for the 1GB RAM footprint of a $5&#x2F;month VM.<p>Zero Bias Address Mapping: Rocka and I solved the 24MB SRAM Trap using a massive q4 integer division mapping. By packing four coefficients into a Z-scalar (Z=c0 +c1 q+c2 q2+c3 q3), we achieve perfectly uniform addressing across the entire DAG depth. There are no hot spots for ASICs to exploit.<p>Galois Scrambling: To prevent algebraic shortcuts, we apply a cyclotomic automorphism \u03d5t :X\u2192Xt at every step. This shuffles coefficients spatially across the 4KB block, destroying subspace confinement and ensuring total diffusion.<p>Native SIS Proof-of-Work: We replaced hash-counting with a native Short Integer Solution (SIS) witness. Miners solve for a witness v that satisfies the norm bound \u2225Apub \u22c5v(modq)\u2225\u221e &lt;\u03f5.<p>Asymmetric Verification: While the miner must thrash 512MB of RAM to generate the proof, a light client can verify the block in nanoseconds using a single matrix vector multiplication.<p>THE CONSENSUS ENGINE: PROOF OF TIME (CLH) Tick Tock<p>VeloxReaper handles the entry fee; Cumulative Lattice Hardening (CLH) handles the ledger.<p><pre><code>    Time as a Physical Constant: Unlike Nakamoto consensus, where the fastest chip wins the race, KNOX uses a sequential, time based clock. A miner can evaluate VeloxReaper in nanoseconds on a custom ASIC, but they must still wait for the physics enforced time clock to tick before a block can be forged.\n\n    The Anti Race: CLH ensures that block production is a function of sequential time, not parallel hash-power. High-end hardware doesn&#x27;t win more blocks, it just finishes its math early and sits idle. I have decoupled security from the energy-waste arms race.\n\n    Progress Free Hardening: The ledger hardens as a function of sequential lattice iterations. The more time passes, the more lattice-hardened the history becomes, making reorgs mathematically impossible without a literal time machine.\n\n THE SHORT INTEGER SOLUTION (SIS) WITNESS\n</code></pre>\nI replaced the primitive leading zeros check with a native SIS Proof.<p>Miners solve for a witness v that satisfies the norm bound \u2225Apub \u22c5v(modq)\u2225\u221e &lt;\u03f5.<p><pre><code>   Asymmetric Dominance: While the miner must thrash 512MB of RAM to find the witness, a light client or smartphone can verify the block in nanoseconds using a single matrix-vector multiplication.\n</code></pre>\nVeloxReaper reaps the ASICs. CLH tames the clock. The KNOX Protocol is live once agai.<p>Come check out what my 11 year old son and I built.<p>Lets fucking rock.<p>v1.3.0 <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ULT7RA&#x2F;KnoxProtocol&#x2F;releases\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ULT7RA&#x2F;KnoxProtocol&#x2F;releases</a> KNOX GUI Wallet + VeloxReaper + Optimized Cuda-NTT Accelerator Kernel", "title": "Show HN: Knox First Full Lattice BLockchain.UPDATE:Veloxreaper", "updated_at": "2026-02-27T18:49:09Z", "url": "https://github.com/ULT7RA/KNOXProtocol/releases"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "dpleban"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["knex", "production"], "value": "Hey HN! I'm working on a talk/blog on a related topic and was curious to see what the case is for people here. I think each case is a bit different so I don't want to constrain people too much.<p>If you deploy ML to <em>production</em> in your group/team/company \u2013 what does <em>production</em> mean for you?<p>Examples:\n- &quot;We run a model once a week that predicts some stuff and stores it in a table, then the customer queries it&quot;\n- &quot;We create an inference endpoint on some cloud resource, which our product/users use to predict poses in videos&quot;\n- &quot;I wish I <em>knew</em>, we're still figuring it out&quot;\n- &quot;We deploy a model as part of a larger pipeline in a system of microservices (and other buzzwords)&quot;<p>Also, if you are in an extra-sharing mood \u2013 in your version of <em>production</em>, were there any counter-intuitive things you learned when you first set up the pipeline?<p>Cheers! Enjoy the picture Dall-E2 made for you of a cat asking for upvotes in return.\nhttps://labs.openai.com/s/2enTplV9c9OxU7lyqhyIjXlN"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Ask HN: What does Machine Learning <em>production</em> look like in your case?"}}, "_tags": ["story", "author_dpleban", "story_32593941", "ask_hn"], "author": "dpleban", "created_at": "2022-08-25T14:10:46Z", "created_at_i": 1661436646, "num_comments": 0, "objectID": "32593941", "points": 2, "story_id": 32593941, "story_text": "Hey HN! I&#x27;m working on a talk&#x2F;blog on a related topic and was curious to see what the case is for people here. I think each case is a bit different so I don&#x27;t want to constrain people too much.<p>If you deploy ML to production in your group&#x2F;team&#x2F;company \u2013 what does production mean for you?<p>Examples:\n- &quot;We run a model once a week that predicts some stuff and stores it in a table, then the customer queries it&quot;\n- &quot;We create an inference endpoint on some cloud resource, which our product&#x2F;users use to predict poses in videos&quot;\n- &quot;I wish I knew, we&#x27;re still figuring it out&quot;\n- &quot;We deploy a model as part of a larger pipeline in a system of microservices (and other buzzwords)&quot;<p>Also, if you are in an extra-sharing mood \u2013 in your version of production, were there any counter-intuitive things you learned when you first set up the pipeline?<p>Cheers! Enjoy the picture Dall-E2 made for you of a cat asking for upvotes in return.\nhttps:&#x2F;&#x2F;labs.openai.com&#x2F;s&#x2F;2enTplV9c9OxU7lyqhyIjXlN", "title": "Ask HN: What does Machine Learning production look like in your case?", "updated_at": "2024-09-20T11:55:56Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "asmertgen"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["knex", "production"], "value": "Hi HN community, Anne-Sophie and Vincent here, the founders of Micro Meat. We\u2019ve developed new techniques for producing cultivated meat.<p>Cultivated meat is just real meat based on animal cells, but instead of getting meat by growing animals, it is grown in bioreactors. This will soon be much better for our planet: less land, water and feed required for the animals, less environmental impact from cutting down forests for farmland and feed <em>production</em>, less antibiotics, and of course, far less harm to animals.<p>The basic process for cultivating meat is known, but there remain difficult problems in bringing it to mass <em>production</em>. I\u2019ll describe the process, the problems, and our solution.<p>Cultivating meat is similar to brewing beer, but instead of growing yeast, we grow muscle cells (plus fat cells for deliciousness!). The process begins with a handful of stem cells that are isolated from an animal. Initially, the volume is tiny and the cells are handled very carefully. They are mixed with medium, which is a mixture of growth factors like insulin, along with amino acids, and other nutrients that they need to grow. Then they are proliferated (multiplied) to upwards of 10M cells per mL.<p>After proliferating, the overall volume gets above 250 mL and shear stresses start to become an issue, meaning the cells get damaged and break apart. Traditional bioreactors use large impellers for mixing the cells and medium, along with a sparger which adds gasses like CO2 and O2. The impeller, gas bubbles, baffles, and internal surfaces are all locations where cells encounter damaging shear stresses. That\u2019s not a problem if you\u2019re cultivating bacteria, yeast, or other microorganisms that have a high tolerance for this. But mammal, bird and fish cells are very <i>in</i>tolerant of such stresses, making it hard to cultivate meat. This is the first problem we address.<p>After the cells have proliferated from a very small volume to tens or hundreds of liters, they are still a mass of single, unorganized cells. In order to get delicious meat we need to make those individual cells merge and differentiate together to form actual muscle tissue that has the right texture. When cells differentiate, they change from being stem cells, into specialized cells and structures, for example, inside the cells myosin heavy chains develop along the actin cell-skeleton. These myosin-actin complexes are basically the motors of the muscle. For this, the cells get seeded onto constructs called scaffolds. A scaffold is like housing for the cells, a structure where cells can easily move into and grow. We usually try to make scaffolds that mimic the cells' natural environment in the animal's body so they feel as at home as possible.<p>Traditional methods pour the proliferated cells on top of the scaffold and hope that they \u201cstick\u201d. This is easy, but results in tissues that aren\u2019t uniform\u2014in some places the cells attach well, in other places not at all. Additionally, the scaffolds are not always edible\u2014a major problem if you\u2019re producing meat! Consistent cell distribution throughout the scaffold is the second problem we address, and edibility is the third.<p>The scaffolds are then reintroduced to reactors for another proliferation or differentiation, depending on the process. The cells are given time to mature, where they finalize their structure, orientation and internal make-up. At this point, you have muscle tissue, and the only thing left to add is components such as fat, which add to the taste and texture of the meat.<p>This process is immensely complex and the cost to produce it at scale is tremendous. To bring cultivated meat to the masses, the complexity and cost problems have to be solved. Many companies have spent years on R&amp;D, but are still not able to produce at larger scales. We want to change that.<p>We asked ourselves, how could we protect these cells while they are in the harsh environment of the reactor, while also creating homogenous, high quality 3D scaffolds that are consistent throughout?<p>Our method addresses shear stress by shielding the cells within the scaffold. Because the cells are embedded <i>inside</i> the scaffold they don\u2019t feel the damaging wall shear stresses inside a bioreactor, only the surface of the scaffold itself is exposed to them. Our scaffold composition is designed to maintain typical diffusion properties, so even though the cells are shielded and don\u2019t touch the medium (which contains the nutrients) the nutrients still make it to the cells. As time goes on and the cells differentiate and mature, they now have a 3D construct where they can begin to develop into the texture of meat. This process enables cells to be seeded at nearly any rate, from only a few grams per minute to over thousands of kilograms per minute. This means our technology can be used from the research stage all the way through full <em>production</em>.<p>We don\u2019t intend to sell meat ourselves. Our business aims at helping other companies to go to market faster, by eliminating the complexity associated with scaffold seeding. Our scaffolding technology easily integrates into any bioreactor train on the market. Users can purchase or lease the machine for around $250-$500, depending on their needs. Our scaffold bio-inks are universal for mammals, birds and fish, and can be purchased either as single orders or as a subscription, ranging from volumes of one liter up to thousands. Each liter of scaffold costs less than $2 and produces 2 to 5 kilograms of meat.<p>A word on our backgrounds: I (Anne-Sophie) am a biomedical and tissue engineer with a PhD from ETH Zurich and Masters from Imperial College London. I\u2019ve been working on creating functional biological tissues in the lab most of my professional career. I love animals and have been a vegetarian since I was 8 years old. I also love our planet and decided to use my tissue engineering skills to help change our food system. And I love good food! so the idea of amazing new food products is highly appealing to me.<p>I (Vincent) am a space systems engineer. I\u2019ve been building, testing, launching and analyzing the Delta IV, Atlas V, New Glenn and SLS rockets for the last 7 years. I\u2019ve probably had my hands in almost every stage of launch system development, from napkin sketches to saying go for launch. Space has always been awe-inspiring to me, but the climate crisis needs direct attention in order to stop, reverse and survive the impacts of climate change. After researching the impact the livestock industry has on our planet, I <em>knew</em> I wanted to get involved to stop it.<p>If you\u2019re interested in learning more or collaborating, you\u2019re warmly welcome to reach out to us at founders@micromeat.com. We\u2019d love to hear your thoughts on any of the above, from cultivated meat in general to the details of the <em>production</em> process, and whatever else you\u2019d like to ask or share!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: Micro Meat (YC S21) \u2013 Technology for scaling cultivated meat"}}, "_tags": ["story", "author_asmertgen", "story_30627418", "launch_hn"], "author": "asmertgen", "children": [30627730, 30627762, 30627791, 30627816, 30627847, 30627898, 30627901, 30627927, 30628000, 30628114, 30628159, 30628184, 30628411, 30628428, 30628474, 30628519, 30628569, 30628668, 30628706, 30628748, 30629281, 30629563, 30629946, 30630347, 30630371, 30630394, 30630479, 30630532, 30630547, 30630604, 30630726, 30630901, 30631051, 30631104, 30631222, 30631366, 30631488, 30631505, 30631576, 30631939, 30631970, 30632177, 30632185, 30632415, 30632483, 30632613, 30632620, 30632794, 30632986, 30633022, 30633281, 30633452, 30633502, 30633539, 30633645, 30634234, 30634561, 30635050, 30636777, 30640284, 30651730, 30655693, 30659039], "created_at": "2022-03-10T14:40:48Z", "created_at_i": 1646923248, "num_comments": 194, "objectID": "30627418", "points": 390, "story_id": 30627418, "story_text": "Hi HN community, Anne-Sophie and Vincent here, the founders of Micro Meat. We\u2019ve developed new techniques for producing cultivated meat.<p>Cultivated meat is just real meat based on animal cells, but instead of getting meat by growing animals, it is grown in bioreactors. This will soon be much better for our planet: less land, water and feed required for the animals, less environmental impact from cutting down forests for farmland and feed production, less antibiotics, and of course, far less harm to animals.<p>The basic process for cultivating meat is known, but there remain difficult problems in bringing it to mass production. I\u2019ll describe the process, the problems, and our solution.<p>Cultivating meat is similar to brewing beer, but instead of growing yeast, we grow muscle cells (plus fat cells for deliciousness!). The process begins with a handful of stem cells that are isolated from an animal. Initially, the volume is tiny and the cells are handled very carefully. They are mixed with medium, which is a mixture of growth factors like insulin, along with amino acids, and other nutrients that they need to grow. Then they are proliferated (multiplied) to upwards of 10M cells per mL.<p>After proliferating, the overall volume gets above 250 mL and shear stresses start to become an issue, meaning the cells get damaged and break apart. Traditional bioreactors use large impellers for mixing the cells and medium, along with a sparger which adds gasses like CO2 and O2. The impeller, gas bubbles, baffles, and internal surfaces are all locations where cells encounter damaging shear stresses. That\u2019s not a problem if you\u2019re cultivating bacteria, yeast, or other microorganisms that have a high tolerance for this. But mammal, bird and fish cells are very <i>in</i>tolerant of such stresses, making it hard to cultivate meat. This is the first problem we address.<p>After the cells have proliferated from a very small volume to tens or hundreds of liters, they are still a mass of single, unorganized cells. In order to get delicious meat we need to make those individual cells merge and differentiate together to form actual muscle tissue that has the right texture. When cells differentiate, they change from being stem cells, into specialized cells and structures, for example, inside the cells myosin heavy chains develop along the actin cell-skeleton. These myosin-actin complexes are basically the motors of the muscle. For this, the cells get seeded onto constructs called scaffolds. A scaffold is like housing for the cells, a structure where cells can easily move into and grow. We usually try to make scaffolds that mimic the cells&#x27; natural environment in the animal&#x27;s body so they feel as at home as possible.<p>Traditional methods pour the proliferated cells on top of the scaffold and hope that they \u201cstick\u201d. This is easy, but results in tissues that aren\u2019t uniform\u2014in some places the cells attach well, in other places not at all. Additionally, the scaffolds are not always edible\u2014a major problem if you\u2019re producing meat! Consistent cell distribution throughout the scaffold is the second problem we address, and edibility is the third.<p>The scaffolds are then reintroduced to reactors for another proliferation or differentiation, depending on the process. The cells are given time to mature, where they finalize their structure, orientation and internal make-up. At this point, you have muscle tissue, and the only thing left to add is components such as fat, which add to the taste and texture of the meat.<p>This process is immensely complex and the cost to produce it at scale is tremendous. To bring cultivated meat to the masses, the complexity and cost problems have to be solved. Many companies have spent years on R&amp;D, but are still not able to produce at larger scales. We want to change that.<p>We asked ourselves, how could we protect these cells while they are in the harsh environment of the reactor, while also creating homogenous, high quality 3D scaffolds that are consistent throughout?<p>Our method addresses shear stress by shielding the cells within the scaffold. Because the cells are embedded <i>inside</i> the scaffold they don\u2019t feel the damaging wall shear stresses inside a bioreactor, only the surface of the scaffold itself is exposed to them. Our scaffold composition is designed to maintain typical diffusion properties, so even though the cells are shielded and don\u2019t touch the medium (which contains the nutrients) the nutrients still make it to the cells. As time goes on and the cells differentiate and mature, they now have a 3D construct where they can begin to develop into the texture of meat. This process enables cells to be seeded at nearly any rate, from only a few grams per minute to over thousands of kilograms per minute. This means our technology can be used from the research stage all the way through full production.<p>We don\u2019t intend to sell meat ourselves. Our business aims at helping other companies to go to market faster, by eliminating the complexity associated with scaffold seeding. Our scaffolding technology easily integrates into any bioreactor train on the market. Users can purchase or lease the machine for around $250-$500, depending on their needs. Our scaffold bio-inks are universal for mammals, birds and fish, and can be purchased either as single orders or as a subscription, ranging from volumes of one liter up to thousands. Each liter of scaffold costs less than $2 and produces 2 to 5 kilograms of meat.<p>A word on our backgrounds: I (Anne-Sophie) am a biomedical and tissue engineer with a PhD from ETH Zurich and Masters from Imperial College London. I\u2019ve been working on creating functional biological tissues in the lab most of my professional career. I love animals and have been a vegetarian since I was 8 years old. I also love our planet and decided to use my tissue engineering skills to help change our food system. And I love good food! so the idea of amazing new food products is highly appealing to me.<p>I (Vincent) am a space systems engineer. I\u2019ve been building, testing, launching and analyzing the Delta IV, Atlas V, New Glenn and SLS rockets for the last 7 years. I\u2019ve probably had my hands in almost every stage of launch system development, from napkin sketches to saying go for launch. Space has always been awe-inspiring to me, but the climate crisis needs direct attention in order to stop, reverse and survive the impacts of climate change. After researching the impact the livestock industry has on our planet, I knew I wanted to get involved to stop it.<p>If you\u2019re interested in learning more or collaborating, you\u2019re warmly welcome to reach out to us at founders@micromeat.com. We\u2019d love to hear your thoughts on any of the above, from cultivated meat in general to the details of the production process, and whatever else you\u2019d like to ask or share!", "title": "Launch HN: Micro Meat (YC S21) \u2013 Technology for scaling cultivated meat", "updated_at": "2025-10-06T20:54:11Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "pdrummond"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["knex", "production"], "value": "Last year I gave in to the temptation of doing my own startup and quit my job, just like many others have done on this site.  Since then, I\u2019ve severely changed my lifestyle and reduced my living costs to a crazy low figure and worked my ass off for the last 8 months to achieve this:<p>www.openloopz.com<p>I have written more about it on Medium here: http://goo.gl/JN03yf<p>I <em>knew</em> from the start the odds were stacked against me. I\u2019m almost 36, I have a family and I live in the North East of England where - without wanting to sound negative - the opportunities are few and far between compared to what I see on here.  When I made the BETA announcement, I <em>knew</em> no-one would just magically sign-up, but I watched and waited anyway and became extremely pissed off when it didn\u2019t happen. \u201cIt\u2019s been 2 hours - why haven\u2019t I got 100 sign-ups already?\u201d.  Silly really.<p>I used up all my savings to get this far and I don\u2019t regret any of it (except maybe the weight gain, lack of a social life, and development of bad sleeping habits!). I wanted to prove to myself I can build a <em>production</em> quality app that I honestly believe in without bias, and I can truly say I have achieved that now.<p>But now comes the hard part.  I need to force myself to stop coding and start actually talking about OpenLoopz and trying to spread the word. I am the first to admit I am not very good at this. I am struggling to even write this post because I already know that probably no-one will read it.  But I just have to learn to get over that and keep going. Any feedback - good or bad - will be greatly appreciated, thanks."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Slack Meets GitHub Issues"}}, "_tags": ["story", "author_pdrummond", "story_9144271", "show_hn"], "author": "pdrummond", "children": [9144420, 9144491, 9144509, 9144525, 9144534, 9144536, 9144547, 9144573, 9144585, 9144595, 9144624, 9144632, 9144749, 9144763, 9144770, 9144787, 9144794, 9144803, 9144811, 9144813, 9144834, 9144843, 9144863, 9144900, 9144928, 9144944, 9144945, 9144980, 9144992, 9145053, 9145063, 9145105, 9145114, 9145198, 9145254, 9145304, 9145351, 9145397, 9145402, 9145404, 9145528, 9145559, 9145562, 9145847, 9145876, 9145894, 9145961, 9145973, 9146003, 9146056, 9146124, 9146149, 9146181, 9146290, 9146392, 9146482, 9146588, 9146792, 9146815, 9146816, 9147012, 9147611, 9147677, 9148007, 9148078, 9148585, 9148909, 9149104, 9149507, 9149621, 9149808, 9150001, 9150156, 9155601, 9158719], "created_at": "2015-03-04T14:13:48Z", "created_at_i": 1425478428, "num_comments": 156, "objectID": "9144271", "points": 373, "story_id": 9144271, "story_text": "Last year I gave in to the temptation of doing my own startup and quit my job, just like many others have done on this site.  Since then, I\u2019ve severely changed my lifestyle and reduced my living costs to a crazy low figure and worked my ass off for the last 8 months to achieve this:<p>www.openloopz.com<p>I have written more about it on Medium here: http:&#x2F;&#x2F;goo.gl&#x2F;JN03yf<p>I knew from the start the odds were stacked against me. I\u2019m almost 36, I have a family and I live in the North East of England where - without wanting to sound negative - the opportunities are few and far between compared to what I see on here.  When I made the BETA announcement, I knew no-one would just magically sign-up, but I watched and waited anyway and became extremely pissed off when it didn\u2019t happen. \u201cIt\u2019s been 2 hours - why haven\u2019t I got 100 sign-ups already?\u201d.  Silly really.<p>I used up all my savings to get this far and I don\u2019t regret any of it (except maybe the weight gain, lack of a social life, and development of bad sleeping habits!). I wanted to prove to myself I can build a production quality app that I honestly believe in without bias, and I can truly say I have achieved that now.<p>But now comes the hard part.  I need to force myself to stop coding and start actually talking about OpenLoopz and trying to spread the word. I am the first to admit I am not very good at this. I am struggling to even write this post because I already know that probably no-one will read it.  But I just have to learn to get over that and keep going. Any feedback - good or bad - will be greatly appreciated, thanks.", "title": "Show HN: Slack Meets GitHub Issues", "updated_at": "2023-09-07T02:13:39Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "codekansas"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["knex", "production"], "value": "Hi HN, I'm Ben, from K-Scale Labs (<a href=\"https://kscale.dev\">https://kscale.dev</a>). We're building open-source humanoid robots.<p>Hardware video: <a href=\"https://www.youtube.com/watch?v=qhZi9rtdEKg\" rel=\"nofollow\">https://www.youtube.com/watch?v=qhZi9rtdEKg</a><p>Software video: <a href=\"https://www.youtube.com/watch?v=hXi3b3xXJFw\" rel=\"nofollow\">https://www.youtube.com/watch?v=hXi3b3xXJFw</a><p>Docs: <a href=\"https://docs.kscale.dev\">https://docs.kscale.dev</a><p>Github: <a href=\"https://github.com/kscalelabs\">https://github.com/kscalelabs</a><p>HN thread from back in May: <a href=\"https://news.ycombinator.com/item?id=44023680\">https://news.ycombinator.com/item?id=44023680</a><p>I started K-Scale because I really wanted a humanoid robot to hack on, so I <em>knew</em> that if I built one, I would have at least one customer. It was before the Unitree G1 came out so the cheapest option at the time costed over $50k, but I figured I could build one for about $10k using COTS (Commercial Off-the-Shelf) components, which would be a much better price point for indie hackers and developers.<p>We built the first version using some 3D printers and parts that I bought off of Amazon and Alibaba. It was not great, but it let us build out the full pipeline, from designing and building the hardware to training control policies in simulation. We actually did most of this in about two months, and had a standing, waving robot by YC Demo Day (although it wasn't good for much else!).<p>Since then, our focus has been on figuring out how to go from a hobby-grade robot to a consumer-grade robot, without inflating our BOM (Bill of Materials, i.e. cost of all the parts) or having to set up our own factories. This is surprisingly difficult. A lot of the supply chain for robotics components currently goes through China, but tariffs have made it difficult to rely on Chinese suppliers for components. Also, even a $10k price point is pretty expensive for most customers, for a humanoid robot that has fairly limited capabilities.<p>Our solution to this is to open-source our hardware and software. This makes it easier for us to navigate tariffs and manufacturing challenges. By making our reference design public, our suppliers have a much easier time figuring out how to offer us competitive solutions, and our manufacturing partners are able to more easily adjust our design for their <em>production</em> processes.<p>On the demand side, the basic problem with humanoid robots is that they're mostly useless right now, and it will probably be a long and fairly capital-intensive journey to make them useful. My expectation was that there is a large pool of latent interest from people like me who are interested in hacking on humanoids, and that this customer segment is a much better customer segment to sell into than more traditional business-focused robotics applications. As someone in this customer segment myself, I felt that open-source software and hardware would be a strong value proposition, particularly for developers exploring bringing humanoids into their own business verticals.<p>More philosophically, I think it is important that there is a good, open-source humanoid robot. I think the technology is likely to mature much more rapidly than many people currently expect, and the idea of armies of humanoids owned by some single company walking around is pretty dystopian.<p>Right now, we're selling our base humanoid robot, K-Bot, for $8999. The main reason we're selling it now, instead of waiting to do more R&amp;D, is because we're trying to negotiate volume prices with our own suppliers before we do final DfM (Design for Manufacturing). For example, we are able to negotiate better volume pricing for actuators and end effectors than what the average indie developer would be able to get for low-volume orders.<p>However, a lot of the people who want to buy a humanoid robot today do so because they want a completely autonomous robot to do all their chores, which is a pretty hard (although exciting) thing to build. To square this circle, we're offering a &quot;Full Autonomy&quot; option - it is the same robot hardware, but we will provide free hardware and software upgrades until we are able to make the robot fully autonomous. This way, we can have some extra cash upfront to kickstart development, and start to build a core group of people who are aligned with helping us improve the robot's capabilities across a diverse set of environments. From our customers' perspective, it's a way to de-risk buying a first-generation product from a young hardware company, and to have a bigger influence on how the technology unfolds.<p>The best part about building open source software and hardware is getting torn apart by people smarter than us, so we'd love your feedback!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: K-Scale Labs (YC W24) \u2013 Open-Source Humanoid Robots"}}, "_tags": ["story", "author_codekansas", "story_44456904", "launch_hn"], "author": "codekansas", "children": [44456975, 44457096, 44457199, 44457232, 44457321, 44457324, 44457393, 44457558, 44457658, 44457777, 44458745, 44458775, 44458787, 44458970, 44459393, 44459422, 44459558, 44459616, 44459711, 44460037, 44460360, 44460444, 44460526, 44460653, 44461482, 44466807, 44470441], "created_at": "2025-07-03T16:44:18Z", "created_at_i": 1751561058, "num_comments": 95, "objectID": "44456904", "points": 233, "story_id": 44456904, "story_text": "Hi HN, I&#x27;m Ben, from K-Scale Labs (<a href=\"https:&#x2F;&#x2F;kscale.dev\">https:&#x2F;&#x2F;kscale.dev</a>). We&#x27;re building open-source humanoid robots.<p>Hardware video: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=qhZi9rtdEKg\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=qhZi9rtdEKg</a><p>Software video: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=hXi3b3xXJFw\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=hXi3b3xXJFw</a><p>Docs: <a href=\"https:&#x2F;&#x2F;docs.kscale.dev\">https:&#x2F;&#x2F;docs.kscale.dev</a><p>Github: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;kscalelabs\">https:&#x2F;&#x2F;github.com&#x2F;kscalelabs</a><p>HN thread from back in May: <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=44023680\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=44023680</a><p>I started K-Scale because I really wanted a humanoid robot to hack on, so I knew that if I built one, I would have at least one customer. It was before the Unitree G1 came out so the cheapest option at the time costed over $50k, but I figured I could build one for about $10k using COTS (Commercial Off-the-Shelf) components, which would be a much better price point for indie hackers and developers.<p>We built the first version using some 3D printers and parts that I bought off of Amazon and Alibaba. It was not great, but it let us build out the full pipeline, from designing and building the hardware to training control policies in simulation. We actually did most of this in about two months, and had a standing, waving robot by YC Demo Day (although it wasn&#x27;t good for much else!).<p>Since then, our focus has been on figuring out how to go from a hobby-grade robot to a consumer-grade robot, without inflating our BOM (Bill of Materials, i.e. cost of all the parts) or having to set up our own factories. This is surprisingly difficult. A lot of the supply chain for robotics components currently goes through China, but tariffs have made it difficult to rely on Chinese suppliers for components. Also, even a $10k price point is pretty expensive for most customers, for a humanoid robot that has fairly limited capabilities.<p>Our solution to this is to open-source our hardware and software. This makes it easier for us to navigate tariffs and manufacturing challenges. By making our reference design public, our suppliers have a much easier time figuring out how to offer us competitive solutions, and our manufacturing partners are able to more easily adjust our design for their production processes.<p>On the demand side, the basic problem with humanoid robots is that they&#x27;re mostly useless right now, and it will probably be a long and fairly capital-intensive journey to make them useful. My expectation was that there is a large pool of latent interest from people like me who are interested in hacking on humanoids, and that this customer segment is a much better customer segment to sell into than more traditional business-focused robotics applications. As someone in this customer segment myself, I felt that open-source software and hardware would be a strong value proposition, particularly for developers exploring bringing humanoids into their own business verticals.<p>More philosophically, I think it is important that there is a good, open-source humanoid robot. I think the technology is likely to mature much more rapidly than many people currently expect, and the idea of armies of humanoids owned by some single company walking around is pretty dystopian.<p>Right now, we&#x27;re selling our base humanoid robot, K-Bot, for $8999. The main reason we&#x27;re selling it now, instead of waiting to do more R&amp;D, is because we&#x27;re trying to negotiate volume prices with our own suppliers before we do final DfM (Design for Manufacturing). For example, we are able to negotiate better volume pricing for actuators and end effectors than what the average indie developer would be able to get for low-volume orders.<p>However, a lot of the people who want to buy a humanoid robot today do so because they want a completely autonomous robot to do all their chores, which is a pretty hard (although exciting) thing to build. To square this circle, we&#x27;re offering a &quot;Full Autonomy&quot; option - it is the same robot hardware, but we will provide free hardware and software upgrades until we are able to make the robot fully autonomous. This way, we can have some extra cash upfront to kickstart development, and start to build a core group of people who are aligned with helping us improve the robot&#x27;s capabilities across a diverse set of environments. From our customers&#x27; perspective, it&#x27;s a way to de-risk buying a first-generation product from a young hardware company, and to have a bigger influence on how the technology unfolds.<p>The best part about building open source software and hardware is getting torn apart by people smarter than us, so we&#x27;d love your feedback!", "title": "Launch HN: K-Scale Labs (YC W24) \u2013 Open-Source Humanoid Robots", "updated_at": "2025-11-19T19:59:13Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "red_throwaway"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["knex", "production"], "value": "TLDR: I bought a $30K professional cinema camera that doesn't work unless I sign away my rights to privacy and possibly the video content I make with it ( at least it seems )<p>Over the past few years my photography business has seen a surge in demand for ultra high quality video <em>production</em> work.  In an effort to meet this demand, I picked up one of RED Digital Cinema's newest pro camera bodies, the RED V-RAPTOR.  Considering this camera is used by professional filmmakers to create films destined for cinemas, it's not surprising that it came with a $30k price tag.<p>After unboxing and assembling it, I power the camera on and the first thing I see is a wall of legal text on the embedded LCD.  Turns out it's a &quot;Software License Agreement&quot; that I'm required to consent to using the on-camera menu buttons before any of the camera's functionality becomes available.  I can give consent or power the camera off.<p>The full text can be found on the manufacturer's website at https://www.red.com/legal/license-agreements .  Here are a few highlights<p>&gt; 4. CONSENT TO USE OF DATA. You agree that RED and its affiliates may collect, maintain, process, transmit, and use technical, diagnostic, usage and related information, including but not limited to information about your RED Camera, Camera Module, computer, system and application software, usage, content, and peripherals. RED may use the information to provide and improve RED\u2019s products and services, including providing the information to RED\u2019s licensors. RED may also provide the information to third party advertisers for the purpose of providing advertising statistics without identifying you personally ...<p>&gt; 5. UPDATES. RED and its licensors have no obligation to provide updates, bug fixes or error correction. If RED provides updates, such updates may be automatic and may delete or change the nature or features of the Software, including functions you may rely upon and you may lose data. You consent to updates by RED ...<p>I snapped a few photos of the camera and the on-screen license agreement for those interested<p>https://ibb.co/ZzBMPWm<p>https://ibb.co/wy5Qjq7<p>I'm annoyed that I must consent to accepting all software updates which they admit could result in the loss of my data but the part that really has me stuck is section 4.  I'm interpreting it to mean that RED and whoever they see fit may access not only data on and about my personal computer but also the actual video content that I create with my camera.  Furthermore, they are permitted to share all that with advertisers.<p>It seems like I must be misunderstanding this because I can't imagine professional videographers being willing to consent to such blatant violations of their own customer's expectations of privacy and discretion.  Many of the jobs I get are product shoots for prototypes and things yet to be released.  Some of them even require an NDA from me.  There's no way my clients would work with me if they <em>knew</em> that my camera might be capturing frames from their commissioned videos and transmitting them behind the scenes to advertisers.<p>This camera has been assembled but collecting dust for over a week now.  I'm on the verge of returning it and eating the 2k I spent on compatible peripherals.  I would love some input from anyone who can offer clarity.  My questions are as follows:<p>1. Is my assessment of the implications of this license agreement correct or am I misunderstanding the legalese?<p>2. Is this type of EULA, where the most basic functionality of a hardware device is held hostage pending the user consents to some arbitrary agreement legal in the USA and/or Europe?  Is there actually a legal precedent allowing for it?<p>3. For film pros, do the top of the line Arris and Panavisions take these same liberties?"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: Is the EULA on my new $30k RED cinema camera legal?"}}, "_tags": ["story", "author_red_throwaway", "story_31208232", "ask_hn"], "author": "red_throwaway", "children": [31208482, 31208492, 31208552, 31208563, 31208565, 31208574, 31208616, 31208650, 31208803, 31208874, 31209046, 31209076, 31209094, 31209153, 31209209, 31209216, 31209223, 31209248, 31209301, 31209505, 31209603, 31209695, 31209893, 31209927, 31209951, 31209990, 31210078, 31210303, 31210377, 31210384, 31210453, 31210650, 31210945, 31211090, 31211322, 31211342, 31211517, 31211529, 31212938, 31213023, 31214396], "created_at": "2022-04-29T17:31:17Z", "created_at_i": 1651253477, "num_comments": 221, "objectID": "31208232", "points": 199, "story_id": 31208232, "story_text": "TLDR: I bought a $30K professional cinema camera that doesn&#x27;t work unless I sign away my rights to privacy and possibly the video content I make with it ( at least it seems )<p>Over the past few years my photography business has seen a surge in demand for ultra high quality video production work.  In an effort to meet this demand, I picked up one of RED Digital Cinema&#x27;s newest pro camera bodies, the RED V-RAPTOR.  Considering this camera is used by professional filmmakers to create films destined for cinemas, it&#x27;s not surprising that it came with a $30k price tag.<p>After unboxing and assembling it, I power the camera on and the first thing I see is a wall of legal text on the embedded LCD.  Turns out it&#x27;s a &quot;Software License Agreement&quot; that I&#x27;m required to consent to using the on-camera menu buttons before any of the camera&#x27;s functionality becomes available.  I can give consent or power the camera off.<p>The full text can be found on the manufacturer&#x27;s website at https:&#x2F;&#x2F;www.red.com&#x2F;legal&#x2F;license-agreements .  Here are a few highlights<p>&gt; 4. CONSENT TO USE OF DATA. You agree that RED and its affiliates may collect, maintain, process, transmit, and use technical, diagnostic, usage and related information, including but not limited to information about your RED Camera, Camera Module, computer, system and application software, usage, content, and peripherals. RED may use the information to provide and improve RED\u2019s products and services, including providing the information to RED\u2019s licensors. RED may also provide the information to third party advertisers for the purpose of providing advertising statistics without identifying you personally ...<p>&gt; 5. UPDATES. RED and its licensors have no obligation to provide updates, bug fixes or error correction. If RED provides updates, such updates may be automatic and may delete or change the nature or features of the Software, including functions you may rely upon and you may lose data. You consent to updates by RED ...<p>I snapped a few photos of the camera and the on-screen license agreement for those interested<p>https:&#x2F;&#x2F;ibb.co&#x2F;ZzBMPWm<p>https:&#x2F;&#x2F;ibb.co&#x2F;wy5Qjq7<p>I&#x27;m annoyed that I must consent to accepting all software updates which they admit could result in the loss of my data but the part that really has me stuck is section 4.  I&#x27;m interpreting it to mean that RED and whoever they see fit may access not only data on and about my personal computer but also the actual video content that I create with my camera.  Furthermore, they are permitted to share all that with advertisers.<p>It seems like I must be misunderstanding this because I can&#x27;t imagine professional videographers being willing to consent to such blatant violations of their own customer&#x27;s expectations of privacy and discretion.  Many of the jobs I get are product shoots for prototypes and things yet to be released.  Some of them even require an NDA from me.  There&#x27;s no way my clients would work with me if they knew that my camera might be capturing frames from their commissioned videos and transmitting them behind the scenes to advertisers.<p>This camera has been assembled but collecting dust for over a week now.  I&#x27;m on the verge of returning it and eating the 2k I spent on compatible peripherals.  I would love some input from anyone who can offer clarity.  My questions are as follows:<p>1. Is my assessment of the implications of this license agreement correct or am I misunderstanding the legalese?<p>2. Is this type of EULA, where the most basic functionality of a hardware device is held hostage pending the user consents to some arbitrary agreement legal in the USA and&#x2F;or Europe?  Is there actually a legal precedent allowing for it?<p>3. For film pros, do the top of the line Arris and Panavisions take these same liberties?", "title": "Ask HN: Is the EULA on my new $30k RED cinema camera legal?", "updated_at": "2024-09-20T10:59:28Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "alexmrv"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["knex", "production"], "value": "Hey HN! I built a proof-of-concept for AI memory using Git instead of vector databases.<p>The insight: Git already solved versioned document management. Why are we building complex vector stores when we could just use markdown files with Git's built-in diff/blame/history?<p>How it works:<p>Memories stored as markdown files in a Git repo\nEach conversation = one commit\ngit diff shows how understanding evolves over time\nBM25 for search (no embeddings needed)\nLLMs generate search queries from conversation context\nExample: Ask &quot;how has my project evolved?&quot; and it uses git diff to show actual changes in understanding, not just similarity scores.<p>This is very much a PoC - rough edges everywhere, not <em>production</em> ready. But it's been working surprisingly well for personal use. The entire index for a year of conversations fits in ~100MB RAM with sub-second retrieval.<p>The cool part: You can git checkout to any point in time and see exactly what the AI <em>knew</em> then. Perfect reproducibility, human-readable storage, and you can manually edit memories if needed.<p>GitHub: <a href=\"https://github.com/Growth-Kinetics/DiffMem\" rel=\"nofollow\">https://github.com/Growth-Kinetics/DiffMem</a><p>Stack: Python, GitPython, rank-bm25, OpenRouter for LLM orchestration. MIT licensed.<p>Would love feedback on the approach. Is this crazy or clever? What am I missing that will bite me later?"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: I replaced vector databases with Git for AI memory (PoC)"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/Growth-Kinetics/DiffMem"}}, "_tags": ["story", "author_alexmrv", "story_44969622", "show_hn"], "author": "alexmrv", "children": [44969976, 44969992, 44969997, 44970011, 44970015, 44970042, 44970057, 44970109, 44970132, 44970168, 44970308, 44970433, 44970439, 44970643, 44970646, 44970670, 44970745, 44970801, 44971010, 44971239, 44971269, 44971300, 44971316, 44973543, 44976171, 44978795, 44980773, 45015749], "created_at": "2025-08-21T06:20:11Z", "created_at_i": 1755757211, "num_comments": 45, "objectID": "44969622", "points": 198, "story_id": 44969622, "story_text": "Hey HN! I built a proof-of-concept for AI memory using Git instead of vector databases.<p>The insight: Git already solved versioned document management. Why are we building complex vector stores when we could just use markdown files with Git&#x27;s built-in diff&#x2F;blame&#x2F;history?<p>How it works:<p>Memories stored as markdown files in a Git repo\nEach conversation = one commit\ngit diff shows how understanding evolves over time\nBM25 for search (no embeddings needed)\nLLMs generate search queries from conversation context\nExample: Ask &quot;how has my project evolved?&quot; and it uses git diff to show actual changes in understanding, not just similarity scores.<p>This is very much a PoC - rough edges everywhere, not production ready. But it&#x27;s been working surprisingly well for personal use. The entire index for a year of conversations fits in ~100MB RAM with sub-second retrieval.<p>The cool part: You can git checkout to any point in time and see exactly what the AI knew then. Perfect reproducibility, human-readable storage, and you can manually edit memories if needed.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Growth-Kinetics&#x2F;DiffMem\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Growth-Kinetics&#x2F;DiffMem</a><p>Stack: Python, GitPython, rank-bm25, OpenRouter for LLM orchestration. MIT licensed.<p>Would love feedback on the approach. Is this crazy or clever? What am I missing that will bite me later?", "title": "Show HN: I replaced vector databases with Git for AI memory (PoC)", "updated_at": "2025-10-02T15:46:47Z", "url": "https://github.com/Growth-Kinetics/DiffMem"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "FullNameAndy"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["knex", "production"], "value": "Hey HN! I\u2019m Andy, founder of Aviron (<a href=\"https://avironactive.com/\" rel=\"nofollow\">https://avironactive.com/</a>). We make a high-intensity version of Peloton for rowing, with competitive games, live races and strength programs. Our content puts a focus on HIIT (high intensity interval training) due to its physical and cognitive benefits.<p>I feel like sometimes this pisses the hardcore rowers off but I\u2019m not a rower, I\u2019m a tech guy. I also think fitness is important and have been working out all of my adult life. Before Aviron, I worked full time and long hours so I did a lot of my thinking during late night gym sessions. Like many people I avoided the rower because not only did I not enjoy cardio but damn that machine was hard and boring. There was a moment at some point in 2016 when I realized I could do something with this. The connected fitness market in the US at that time was small but growing rapidly.<p>Aviron is a rowing machine because it\u2019s the most efficient and effective workout you can have in a short amount of time on one machine. The rowing motion is low impact, engages 85% of muscles, is very difficult and as a result can also be boring. This makes the rowing machine an ideal \u2018candidate\u2019 to pair with the gaming-inspired, competitive content I began thinking about in 2016.<p>The research was telling me there was a definite potential market niche I could fill but what I didn't know was that no manufacturer would speak to me. I probably called and emailed 50 manufacturers. I eventually kickstarted a few conversations and finally a relationship, by flying to Taiwan, connecting with a local who could translate, and knocking on doors in person. It sounds reasonable in hindsight but the process to finalizing a <em>production</em> contract start to finish took me a full year. A year of trying to understand the manufacturing landscape, developing relationships and convincing potential suppliers that I would eventually be worth their time.<p>Ultimately my key takeaway is that Taiwanese manufacturing relationships are just that - relationships. Manufacturers are looking for long-term trusting partnerships and they are much less motivated by money than my initial assumption. I\u2019m reminded of this constantly - this month alone I have received emails re: product delays twice - and I stupidly tried to throw money at the problem, in the process offending the Taiwan team by implying they would work harder if money was on the table.<p>Finding and building a solid relationship with a <em>production</em> partner was challenging but I would give it a 7/10 relative to the hurdles that came later. The manufacturer had no experience or interest in getting the machine to work along with our custom android touchscreen. As much as I see myself as a \u201ctech guy\u201d, I don\u2019t have an engineering degree. My dad does and so does my brother but I went the business degree route. Long story short, figuring out the details of making these two pieces work together was a nightmare. Again, in hindsight, it\u2019s kind of cool - I understand my machine inside and out; I\u2019m confident I could take it apart down to the screws and put it back together. I can also work comfortably with an oscilloscope and understand how most of the components work on a typical fitness equipment circuit board - there was a lot of circuit board soldering trial and error at one point.<p>I <em>knew</em> that I was taking on a lot with a software and hardware venture but what nobody tells you is how many miles you\u2019re going to drive and fly when you\u2019re taking on hardware. During our slow tip-toe pivot from B2B to B2C sales, we discovered home customers would find 10x the problems a gym would. There was a week in 2019 I drove to a customer\u2019s home 6 hours away multiple times a week for nearly a month. Each trip I thought we had found the solution; the ride back was crushing. This was one of many problems we faced.<p>I\u2019m happy to be able to say the bugs are mostly worked out! Our customers navigate a 22\u201d touchscreen to browse 250ish content options - like my favorite and the first game we ever developed - Last Hope, an end-of-the-world inspired game where you\u2019re being chased by zombies. As your row to escape the Ai will benchmark your fitness output and adjust the zombies\u2019 speed to maintain a challenging pace for your fitness level.<p>The content for Aviron was developed with strength training and High Intensity Interval Training (HIIT) in mind. For example, one of our 6 workouts categories is \u201cPros vs. Joes\u201d, a program that allows you to compete against pre-recorded Olympians and professional athletes in a race.<p>Our customers are fitness enthusiasts who don\u2019t enjoy long cardio workouts and crave the competitive and challenging pace of activities like CrossFit and F45, at home - especially throughout Covid. HIIT workouts tend to be shorter, have been proven to improve cognitive ability and help slow the aging process via preservation of DNA.<p>To me, the dual cognitive and physical benefits were really key. I began to work out in my teens, physically I felt better and my self esteem improved. Cognitively, I went from dealing with undiagnosed ADHD and struggling my way through school to slowly noticing an improvement. People told me I was \u201cgrowing out of\u201d ADHD - which is probably partially true - but something clicked when I was researching fitness programming for Aviron. Learning about HIIT and it\u2019s (data proven) benefits, I started to realize that my commitment to consistent and challenging physical fitness had likely paid a large part in my \u201cgrowing out it\u201d as well.<p>Currently, we have bootstrapped Aviron to a good place; we\u2019ve sold nearly a thousand rowers to gyms, hotels, schools and even Nike headquarters as well as homes. Or churn rate is &lt;1% and our customers are telling us they\u2019re happy. And they\u2019re paying their membership every month so we believe them. :)<p>We are continually working on Aviron to improve the software, content and customer experience so if you have a chance please check us out and let me know what you think. I\u2019m excited to hear from the community. I\u2019ll be hanging out in the comments all day."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: Aviron (YC W21) \u2013 High-Intensity Peloton for Rowing"}}, "_tags": ["story", "author_FullNameAndy", "story_25905467", "launch_hn"], "author": "FullNameAndy", "children": [25905591, 25905598, 25905617, 25905767, 25905775, 25905786, 25905788, 25905800, 25905809, 25905866, 25905867, 25905877, 25905913, 25905932, 25906033, 25906140, 25906483, 25906558, 25906560, 25906690, 25906696, 25906741, 25906812, 25906923, 25906948, 25907173, 25907250, 25907563, 25908149, 25908273, 25908292, 25908336, 25908522, 25908718, 25908748, 25908768, 25908779, 25908832, 25908961, 25909145, 25909522, 25909525, 25909612, 25909965, 25910394, 25910506, 25911241, 25911428, 25911682, 25911737, 25912573, 25912908, 25913001, 25913444, 25914594, 25915370, 25916089, 25916321, 25916985, 25918197, 25919039, 25921067, 25965590], "created_at": "2021-01-25T16:53:41Z", "created_at_i": 1611593621, "num_comments": 263, "objectID": "25905467", "points": 184, "story_id": 25905467, "story_text": "Hey HN! I\u2019m Andy, founder of Aviron (<a href=\"https:&#x2F;&#x2F;avironactive.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;avironactive.com&#x2F;</a>). We make a high-intensity version of Peloton for rowing, with competitive games, live races and strength programs. Our content puts a focus on HIIT (high intensity interval training) due to its physical and cognitive benefits.<p>I feel like sometimes this pisses the hardcore rowers off but I\u2019m not a rower, I\u2019m a tech guy. I also think fitness is important and have been working out all of my adult life. Before Aviron, I worked full time and long hours so I did a lot of my thinking during late night gym sessions. Like many people I avoided the rower because not only did I not enjoy cardio but damn that machine was hard and boring. There was a moment at some point in 2016 when I realized I could do something with this. The connected fitness market in the US at that time was small but growing rapidly.<p>Aviron is a rowing machine because it\u2019s the most efficient and effective workout you can have in a short amount of time on one machine. The rowing motion is low impact, engages 85% of muscles, is very difficult and as a result can also be boring. This makes the rowing machine an ideal \u2018candidate\u2019 to pair with the gaming-inspired, competitive content I began thinking about in 2016.<p>The research was telling me there was a definite potential market niche I could fill but what I didn&#x27;t know was that no manufacturer would speak to me. I probably called and emailed 50 manufacturers. I eventually kickstarted a few conversations and finally a relationship, by flying to Taiwan, connecting with a local who could translate, and knocking on doors in person. It sounds reasonable in hindsight but the process to finalizing a production contract start to finish took me a full year. A year of trying to understand the manufacturing landscape, developing relationships and convincing potential suppliers that I would eventually be worth their time.<p>Ultimately my key takeaway is that Taiwanese manufacturing relationships are just that - relationships. Manufacturers are looking for long-term trusting partnerships and they are much less motivated by money than my initial assumption. I\u2019m reminded of this constantly - this month alone I have received emails re: product delays twice - and I stupidly tried to throw money at the problem, in the process offending the Taiwan team by implying they would work harder if money was on the table.<p>Finding and building a solid relationship with a production partner was challenging but I would give it a 7&#x2F;10 relative to the hurdles that came later. The manufacturer had no experience or interest in getting the machine to work along with our custom android touchscreen. As much as I see myself as a \u201ctech guy\u201d, I don\u2019t have an engineering degree. My dad does and so does my brother but I went the business degree route. Long story short, figuring out the details of making these two pieces work together was a nightmare. Again, in hindsight, it\u2019s kind of cool - I understand my machine inside and out; I\u2019m confident I could take it apart down to the screws and put it back together. I can also work comfortably with an oscilloscope and understand how most of the components work on a typical fitness equipment circuit board - there was a lot of circuit board soldering trial and error at one point.<p>I knew that I was taking on a lot with a software and hardware venture but what nobody tells you is how many miles you\u2019re going to drive and fly when you\u2019re taking on hardware. During our slow tip-toe pivot from B2B to B2C sales, we discovered home customers would find 10x the problems a gym would. There was a week in 2019 I drove to a customer\u2019s home 6 hours away multiple times a week for nearly a month. Each trip I thought we had found the solution; the ride back was crushing. This was one of many problems we faced.<p>I\u2019m happy to be able to say the bugs are mostly worked out! Our customers navigate a 22\u201d touchscreen to browse 250ish content options - like my favorite and the first game we ever developed - Last Hope, an end-of-the-world inspired game where you\u2019re being chased by zombies. As your row to escape the Ai will benchmark your fitness output and adjust the zombies\u2019 speed to maintain a challenging pace for your fitness level.<p>The content for Aviron was developed with strength training and High Intensity Interval Training (HIIT) in mind. For example, one of our 6 workouts categories is \u201cPros vs. Joes\u201d, a program that allows you to compete against pre-recorded Olympians and professional athletes in a race.<p>Our customers are fitness enthusiasts who don\u2019t enjoy long cardio workouts and crave the competitive and challenging pace of activities like CrossFit and F45, at home - especially throughout Covid. HIIT workouts tend to be shorter, have been proven to improve cognitive ability and help slow the aging process via preservation of DNA.<p>To me, the dual cognitive and physical benefits were really key. I began to work out in my teens, physically I felt better and my self esteem improved. Cognitively, I went from dealing with undiagnosed ADHD and struggling my way through school to slowly noticing an improvement. People told me I was \u201cgrowing out of\u201d ADHD - which is probably partially true - but something clicked when I was researching fitness programming for Aviron. Learning about HIIT and it\u2019s (data proven) benefits, I started to realize that my commitment to consistent and challenging physical fitness had likely paid a large part in my \u201cgrowing out it\u201d as well.<p>Currently, we have bootstrapped Aviron to a good place; we\u2019ve sold nearly a thousand rowers to gyms, hotels, schools and even Nike headquarters as well as homes. Or churn rate is &lt;1% and our customers are telling us they\u2019re happy. And they\u2019re paying their membership every month so we believe them. :)<p>We are continually working on Aviron to improve the software, content and customer experience so if you have a chance please check us out and let me know what you think. I\u2019m excited to hear from the community. I\u2019ll be hanging out in the comments all day.", "title": "Launch HN: Aviron (YC W21) \u2013 High-Intensity Peloton for Rowing", "updated_at": "2025-03-13T19:11:16Z"}], "hitsPerPage": 15, "nbHits": 63, "nbPages": 5, "page": 0, "params": "query=knex+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 8, "processingTimingsMS": {"_request": {"roundTrip": 22}, "afterFetch": {"format": {"highlighting": 3, "total": 3}}, "fetch": {"query": 5, "scanning": 1, "total": 7}, "total": 8}, "query": "knex production", "serverTimeMS": 12}}