{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "zerotolerance"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["consul", "production"], "value": "Toward a <em>Production</em>-Ready Docker Swarm Cluster with <em>Consul</em>"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["consul", "production"], "value": "https://medium.com/on-docker/toward-a-<em>production</em>-ready-docker-swarm-cluster-with-<em>consul</em>-9ecd36533bb8#.b30f14tfu"}}, "_tags": ["story", "author_zerotolerance", "story_11235263"], "author": "zerotolerance", "created_at": "2016-03-06T19:54:28Z", "created_at_i": 1457294068, "num_comments": 0, "objectID": "11235263", "points": 2, "story_id": 11235263, "title": "Toward a Production-Ready Docker Swarm Cluster with Consul", "updated_at": "2024-09-19T22:55:14Z", "url": "https://medium.com/on-docker/toward-a-production-ready-docker-swarm-cluster-with-consul-9ecd36533bb8#.b30f14tfu"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "aprdm"}, "story_text": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["consul"], "value": "We are evaluating a scheduler to use for our services and we came across Nomad (http://nomadproject.io)<p>This article (https://medium.com/@copyconstruct/schedulers-kubernetes-and-nomad-b0f2e14a896) which a co-worker sent has a very good reasoning / introduction to why this particular company uses Nomad and it does seem to match our requirements.<p>Plus we already use <em>Consul</em> and Nomad plugs really well with <em>Consul</em>.<p>Are there more stories about people using (or not using and why) Nomad? Haven't found much in hacker news through Algolia search<p>Cheers"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Ask HN: Do you use Nomad in <em>production</em>?"}}, "_tags": ["story", "author_aprdm", "story_15866768", "ask_hn"], "author": "aprdm", "created_at": "2017-12-07T01:18:23Z", "created_at_i": 1512609503, "num_comments": 0, "objectID": "15866768", "points": 4, "story_id": 15866768, "story_text": "We are evaluating a scheduler to use for our services and we came across Nomad (http:&#x2F;&#x2F;nomadproject.io)<p>This article (https:&#x2F;&#x2F;medium.com&#x2F;@copyconstruct&#x2F;schedulers-kubernetes-and-nomad-b0f2e14a896) which a co-worker sent has a very good reasoning &#x2F; introduction to why this particular company uses Nomad and it does seem to match our requirements.<p>Plus we already use Consul and Nomad plugs really well with Consul.<p>Are there more stories about people using (or not using and why) Nomad? Haven&#x27;t found much in hacker news through Algolia search<p>Cheers", "title": "Ask HN: Do you use Nomad in production?", "updated_at": "2024-09-20T01:44:05Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "johnnycarcin"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["consul", "production"], "value": "We are looking at bringing our apps back in-house and running them in some type of hypervisor on bare metal so I was curious as to what others are using? I know awhile back KVM was the way to go because it was in the mainline kernel but I believe that has changed and now XEN is pretty painless to get up and going. Docker is not an option sadly.<p>We are not looking to build a &quot;cloud&quot; or anything as most of our applications do not need architecture like that. Basically just a physical cluster we can deploy VMs to. \nWe do use <em>consul</em> for service discovery so we essentially just need some type of solution that allows us to hit an API (or run a command locally) that will fire up a pre-defined virtual machine on one of our various servers. Performance of the virtual machines is our top priority with ease of management being a close second.<p>Currently we use salt which appears to have good support for working with KVM which is a major bonus but not something that ties us to KVM 100%<p>Anyone out there using barebones hypervisors in <em>production</em> who can share their experiences? Right now it honestly seems like a toss up from what I've been reading."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: What hypervisor are you using?"}}, "_tags": ["story", "author_johnnycarcin", "story_10839707", "ask_hn"], "author": "johnnycarcin", "children": [10839808, 10840314, 10840351, 10840415, 10840487, 10840537, 10840584, 10840640, 10840647, 10840673, 10840780, 10841112, 10841791, 10842435, 10843373], "created_at": "2016-01-04T23:40:15Z", "created_at_i": 1451950815, "num_comments": 30, "objectID": "10839707", "points": 34, "story_id": 10839707, "story_text": "We are looking at bringing our apps back in-house and running them in some type of hypervisor on bare metal so I was curious as to what others are using? I know awhile back KVM was the way to go because it was in the mainline kernel but I believe that has changed and now XEN is pretty painless to get up and going. Docker is not an option sadly.<p>We are not looking to build a &quot;cloud&quot; or anything as most of our applications do not need architecture like that. Basically just a physical cluster we can deploy VMs to. \nWe do use consul for service discovery so we essentially just need some type of solution that allows us to hit an API (or run a command locally) that will fire up a pre-defined virtual machine on one of our various servers. Performance of the virtual machines is our top priority with ease of management being a close second.<p>Currently we use salt which appears to have good support for working with KVM which is a major bonus but not something that ties us to KVM 100%<p>Anyone out there using barebones hypervisors in production who can share their experiences? Right now it honestly seems like a toss up from what I&#x27;ve been reading.", "title": "Ask HN: What hypervisor are you using?", "updated_at": "2023-09-07T00:28:32Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "joe-stanton"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["consul", "production"], "value": "I've found that many of my colleagues are eager to learn more about modern infrastructure techniques. In an effort to become more full-stack and better support some of our apps in <em>production</em>. This is especially true of developers arriving via Code Schools rather than from a traditional CS background.<p>Topic Ideas:<p><pre><code>  * Docker/Containerisation (ECS)\n  * Service Discovery (Etcd, Serf, <em>Consul</em>)\n  * Infrastructure as Code (Terraform, Ansible etc.)\n  * Monitoring techniques\n  * Capacity planning\n  * Security best practices\n</code></pre>\nThere doesn't seem to be much out there addressing this &quot;need&quot;, except https://sysadmincasts.com/ which seems abandoned these days.<p>Would this kind of screencast be of interest to anyone? I'm thinking I could charge a subscription fee for it. Small bite size lessons. Any further thoughts or topic ideas?<p>Thanks!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: Would you watch Infrastructure/DevOps Screencasts?"}}, "_tags": ["story", "author_joe-stanton", "story_11670776", "ask_hn"], "author": "joe-stanton", "children": [11670844, 11670868, 11670948, 11670974, 11671011, 11671053, 11672041, 11672289, 11675306, 11694949], "created_at": "2016-05-10T21:23:52Z", "created_at_i": 1462915432, "num_comments": 22, "objectID": "11670776", "points": 24, "story_id": 11670776, "story_text": "I&#x27;ve found that many of my colleagues are eager to learn more about modern infrastructure techniques. In an effort to become more full-stack and better support some of our apps in production. This is especially true of developers arriving via Code Schools rather than from a traditional CS background.<p>Topic Ideas:<p><pre><code>  * Docker&#x2F;Containerisation (ECS)\n  * Service Discovery (Etcd, Serf, Consul)\n  * Infrastructure as Code (Terraform, Ansible etc.)\n  * Monitoring techniques\n  * Capacity planning\n  * Security best practices\n</code></pre>\nThere doesn&#x27;t seem to be much out there addressing this &quot;need&quot;, except https:&#x2F;&#x2F;sysadmincasts.com&#x2F; which seems abandoned these days.<p>Would this kind of screencast be of interest to anyone? I&#x27;m thinking I could charge a subscription fee for it. Small bite size lessons. Any further thoughts or topic ideas?<p>Thanks!", "title": "Ask HN: Would you watch Infrastructure/DevOps Screencasts?", "updated_at": "2024-09-19T23:12:58Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "vlebo"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["consul", "production"], "value": "Hey HN,<p>I built ctx because I was tired of the mental overhead of managing multiple client environments. Every context switch meant: change AWS profile, switch kubeconfig, start the right SSH tunnels, set the right env vars, remember which VPN i need to connect to.\nMiss one step and you're deploying to the wrong environment.<p>The problem: Existing tools are siloed. kubectx handles Kubernetes. aws-vault handles AWS. direnv needs .envrc files everywhere. SSH tunnel managers don't know about your cloud context. Nothing ties them together.<p>ctx does one thing: Atomic context switches across all of these at once.<p>ctx use client-a-prod<p># Now your shell has:<p># - AWS_PROFILE=client-a-prod<p># - KUBECONFIG pointing to their cluster<p># - Nomad/<em>Consul</em> env vars set<p># - SSH tunnels to their bastion started<p># - VPN connected<p># - Secrets loaded in env<p>Key features:<p>- Single YAML per context defines everything<p>- CLoud SSO integration - detects expired sessions, triggers login automatically, caches tokens so switching back is instant<p>- Browser profiles - ctx open grafana opens Chrome/Firefox with the right profile (useful when each client has different SSO/Google accounts)<p>- SSH tunnels auto-start on context switch, auto-reconnect on failure<p>- <em>Production</em> safety: color-coded prompts, confirmation required for prod contexts<p>- Per-terminal isolation - different terminals can be in different contexts simultaneously<p>- Shell integration for bash/zsh/fish<p>Written in Go, single binary, no dependencies.<p>GitHub: [<a href=\"https://github.com/vlebo/ctx/\" rel=\"nofollow\">https://github.com/vlebo/ctx/</a>]<p>I'd love feedback on the design. The config format took a few iterations to get right - balancing simplicity with flexibility for complex setups."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Ctx \u2013 Context manager for Cloud,K8s VPNs, SSH tunnels, secret managers"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/vlebo/ctx"}}, "_tags": ["story", "author_vlebo", "story_46737344", "show_hn"], "author": "vlebo", "children": [46737370, 46742137], "created_at": "2026-01-23T20:19:19Z", "created_at_i": 1769199559, "num_comments": 3, "objectID": "46737344", "points": 7, "story_id": 46737344, "story_text": "Hey HN,<p>I built ctx because I was tired of the mental overhead of managing multiple client environments. Every context switch meant: change AWS profile, switch kubeconfig, start the right SSH tunnels, set the right env vars, remember which VPN i need to connect to.\nMiss one step and you&#x27;re deploying to the wrong environment.<p>The problem: Existing tools are siloed. kubectx handles Kubernetes. aws-vault handles AWS. direnv needs .envrc files everywhere. SSH tunnel managers don&#x27;t know about your cloud context. Nothing ties them together.<p>ctx does one thing: Atomic context switches across all of these at once.<p>ctx use client-a-prod<p># Now your shell has:<p># - AWS_PROFILE=client-a-prod<p># - KUBECONFIG pointing to their cluster<p># - Nomad&#x2F;Consul env vars set<p># - SSH tunnels to their bastion started<p># - VPN connected<p># - Secrets loaded in env<p>Key features:<p>- Single YAML per context defines everything<p>- CLoud SSO integration - detects expired sessions, triggers login automatically, caches tokens so switching back is instant<p>- Browser profiles - ctx open grafana opens Chrome&#x2F;Firefox with the right profile (useful when each client has different SSO&#x2F;Google accounts)<p>- SSH tunnels auto-start on context switch, auto-reconnect on failure<p>- Production safety: color-coded prompts, confirmation required for prod contexts<p>- Per-terminal isolation - different terminals can be in different contexts simultaneously<p>- Shell integration for bash&#x2F;zsh&#x2F;fish<p>Written in Go, single binary, no dependencies.<p>GitHub: [<a href=\"https:&#x2F;&#x2F;github.com&#x2F;vlebo&#x2F;ctx&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;vlebo&#x2F;ctx&#x2F;</a>]<p>I&#x27;d love feedback on the design. The config format took a few iterations to get right - balancing simplicity with flexibility for complex setups.", "title": "Show HN: Ctx \u2013 Context manager for Cloud,K8s VPNs, SSH tunnels, secret managers", "updated_at": "2026-01-27T17:44:16Z", "url": "https://github.com/vlebo/ctx"}], "hitsPerPage": 15, "nbHits": 5, "nbPages": 1, "page": 0, "params": "query=consul+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 9, "processingTimingsMS": {"_request": {"roundTrip": 21}, "fetch": {"query": 7, "total": 8}, "total": 9}, "query": "consul production", "serverTimeMS": 10}}