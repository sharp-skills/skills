{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "pdknsk"}, "story_text": {"matchLevel": "none", "matchedWords": [], "value": ""}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "<em>Sharp</em> starts <em>production</em> of 3200x1800 notebook LCD panels in June"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["sharp"], "value": "http://<em>sharp</em>-world.com/corporate/news/130514-6.html"}}, "_tags": ["story", "author_pdknsk", "story_5719021"], "author": "pdknsk", "children": [5720492], "created_at": "2013-05-16T15:14:27Z", "created_at_i": 1368717267, "num_comments": 1, "objectID": "5719021", "points": 7, "story_id": 5719021, "story_text": "", "title": "Sharp starts production of 3200x1800 notebook LCD panels in June", "updated_at": "2024-09-19T19:35:21Z", "url": "http://sharp-world.com/corporate/news/130514-6.html"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "Rexxar"}, "story_text": {"matchLevel": "none", "matchedWords": [], "value": ""}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "Apple Moves <em>Production</em> to <em>Sharp</em> for TV Debut"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "http://www.businessweek.com/news/2011-11-25/apple-moves-<em>production</em>-to-<em>sharp</em>-for-tv-debut-jefferies-says.html"}}, "_tags": ["story", "author_Rexxar", "story_3278475"], "author": "Rexxar", "children": [3278535], "created_at": "2011-11-25T22:55:35Z", "created_at_i": 1322261735, "num_comments": 1, "objectID": "3278475", "points": 2, "story_id": 3278475, "story_text": "", "title": "Apple Moves Production to Sharp for TV Debut", "updated_at": "2024-09-19T18:09:49Z", "url": "http://www.businessweek.com/news/2011-11-25/apple-moves-production-to-sharp-for-tv-debut-jefferies-says.html"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "esolyt"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "<em>Sharp</em> starts mass <em>production</em> of 5-inch 1080p displays for smartphones"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "http://www.theverge.com/2012/10/1/3436644/<em>sharp</em>-starts-mass-<em>production</em>-of-5-inch-1080p-displays-for-smartphones"}}, "_tags": ["story", "author_esolyt", "story_4598017"], "author": "esolyt", "created_at": "2012-10-01T16:52:56Z", "created_at_i": 1349110376, "num_comments": 0, "objectID": "4598017", "points": 1, "story_id": 4598017, "title": "Sharp starts mass production of 5-inch 1080p displays for smartphones", "updated_at": "2024-09-19T19:01:44Z", "url": "http://www.theverge.com/2012/10/1/3436644/sharp-starts-mass-production-of-5-inch-1080p-displays-for-smartphones"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "tosh"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Apple Supplier's Plans Fall Through, Macs and iPads May Be Impacted"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "https://www.macrumors.com/2026/02/11/<em>sharp</em>-factory-ceasing-<em>production</em>-report/"}}, "_tags": ["story", "author_tosh", "story_46976647"], "author": "tosh", "created_at": "2026-02-11T16:06:11Z", "created_at_i": 1770825971, "num_comments": 0, "objectID": "46976647", "points": 1, "story_id": 46976647, "title": "Apple Supplier's Plans Fall Through, Macs and iPads May Be Impacted", "updated_at": "2026-02-11T16:06:45Z", "url": "https://www.macrumors.com/2026/02/11/sharp-factory-ceasing-production-report/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "bitcartel"}, "story_text": {"matchLevel": "none", "matchedWords": [], "value": ""}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "<em>Sharp</em> has nearly halted <em>production</em> of 9.7-inch screens for Apple's iPad"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["sharp"], "value": "http://www.reuters.com/article/2013/01/18/us-<em>sharp</em>-ipad-idUSBRE90H0BZ20130118"}}, "_tags": ["story", "author_bitcartel", "story_5079492"], "author": "bitcartel", "created_at": "2013-01-18T16:37:14Z", "created_at_i": 1358527034, "num_comments": 0, "objectID": "5079492", "points": 1, "story_id": 5079492, "story_text": "", "title": "Sharp has nearly halted production of 9.7-inch screens for Apple's iPad", "updated_at": "2024-09-19T19:13:00Z", "url": "http://www.reuters.com/article/2013/01/18/us-sharp-ipad-idUSBRE90H0BZ20130118"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "mbales"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "<em>Sharp</em> curbs iPad screen <em>production</em> as demand shifts to smaller tablets"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "http://business.mpelembe.net/home/<em>sharp</em>-curbs-ipad-screen-<em>production</em>-as-demand-shifts-to-smaller-tablets"}}, "_tags": ["story", "author_mbales", "story_5078231"], "author": "mbales", "created_at": "2013-01-18T12:01:10Z", "created_at_i": 1358510470, "num_comments": 0, "objectID": "5078231", "points": 1, "story_id": 5078231, "title": "Sharp curbs iPad screen production as demand shifts to smaller tablets", "updated_at": "2024-09-19T19:12:54Z", "url": "http://business.mpelembe.net/home/sharp-curbs-ipad-screen-production-as-demand-shifts-to-smaller-tablets"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "anigbrowl"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "At plastic treaty talks, <em>sharp</em> disagreements on whether to limit <em>production</em>"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://apnews.com/article/plastic-pollution-treaty-negotiations-ottawa-united-nations-e291d64f4f55846973be4f78f33f0fdf"}}, "_tags": ["story", "author_anigbrowl", "story_40215942"], "author": "anigbrowl", "children": [40216195], "created_at": "2024-04-30T20:31:35Z", "created_at_i": 1714509095, "num_comments": 0, "objectID": "40215942", "points": 2, "story_id": 40215942, "title": "At plastic treaty talks, sharp disagreements on whether to limit production", "updated_at": "2024-09-20T16:57:04Z", "url": "https://apnews.com/article/plastic-pollution-treaty-negotiations-ottawa-united-nations-e291d64f4f55846973be4f78f33f0fdf"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "antr"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "<em>Production</em> of iPhone Screens Delayed at <em>Sharp</em>"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "http://online.wsj.com/article/SB10000872396390444914904577622420471289302.html?mod=WSJ_hp_us_mostpop_read"}}, "_tags": ["story", "author_antr", "story_4464346"], "author": "antr", "created_at": "2012-09-01T17:13:04Z", "created_at_i": 1346519584, "num_comments": 0, "objectID": "4464346", "points": 2, "story_id": 4464346, "title": "Production of iPhone Screens Delayed at Sharp", "updated_at": "2024-09-19T18:50:18Z", "url": "http://online.wsj.com/article/SB10000872396390444914904577622420471289302.html?mod=WSJ_hp_us_mostpop_read"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "arsalanb"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "Hi HN, I'm Arsalan, founder of LiveDocs (<a href=\"https://livedocs.com\">https://livedocs.com</a>). We're building an AI-native data workspace that lets teams ask questions of their real data and have the system plan, execute, and maintain the analysis end-to-end.<p>We previously posted about LiveDocs four years ago (<a href=\"https://news.ycombinator.com/item?id=30735058\">https://news.ycombinator.com/item?id=30735058</a>). Back then, LiveDocs was a no-code analytics tool for stitching together metrics from tools like Stripe and Google Analytics. It worked for basic reporting, but over time we ran into the same ceiling our users did. Dashboards are fine until the questions get messy, and notebooks slowly turn into hard-to-maintain piles of glue.<p>Over the last few years, we rebuilt LiveDocs almost entirely around a different idea. Data work should behave like a living system, not a static document or a chat transcript.<p>Today, LiveDocs is a reactive notebook environment backed by real execution engines. Notebooks are not linear. Each cell participates in a dependency graph, so when data or logic changes, only the affected parts recompute. You can freely mix SQL, Python, charts, tables, and text in the same document and everything stays in sync. Locally we run on DuckDB and Polars, and when you connect a warehouse like Snowflake, BigQuery, or Postgres, queries are pushed down instead of copying data out. Every result is inspectable and reproducible.<p>On top of this environment sits an AI agent, but it is not &quot;chat with your data.&quot; The agent works inside the notebook itself. It can plan multi-step analyses, write and debug SQL or Python, spawn specialized sub-agents for different tasks, run code in a terminal, and browse documentation or the web when it lacks context. Because it operates inside the same execution graph as humans, you can see exactly what it ran, edit it, or take over at any point.<p>We also support a canvas mode where the agent can build custom UI for your analysis, not just charts. This includes tables with controls, comparisons, and derived views that stay wired to the underlying data. When a notebook is not the right interface, you can publish parts of it as an interactive app. These behave more like lightweight internal tools, similar in spirit to Retool, but backed by the same analysis logic.<p>Everything in LiveDocs is fully real-time collaborative. Multiple people can edit the same notebook, see results update live, comment inline, and share documents or apps without exposing raw code unless they want to.<p>Teams use LiveDocs to investigate questions that do not fit cleanly into dashboards, build analyses that evolve over time without constant rewrites, and automate recurring questions without turning them into brittle pipelines.<p>Pricing is pay-as-you-go, starting at $15 per month, with a free tier so people can try it without talking to us. You'll have to sign up, as it requires us to provision a sandbox for your to run your notebook. Here's a video demo: <a href=\"https://youtu.be/Hl12su9Jn_I\" rel=\"nofollow\">https://youtu.be/Hl12su9Jn_I</a><p>We are still learning where this breaks. Long-running agent workflows on <em>production</em> data surface a lot of <em>sharp</em> edges. We would love feedback from people who have built or lived with analytics systems, notebooks, or &quot;chat with your data&quot; tools and felt their limits. Happy to go deep on technical details and trade notes."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: Livedocs (YC W22) \u2013 An AI-native notebook for data analysis"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://livedocs.com"}}, "_tags": ["story", "author_arsalanb", "story_46964162", "launch_hn"], "author": "arsalanb", "children": [46964462, 46965208, 46965378, 46965384, 46965743, 46966242, 46966512, 46969689], "created_at": "2026-02-10T18:09:14Z", "created_at_i": 1770746954, "num_comments": 19, "objectID": "46964162", "points": 48, "story_id": 46964162, "story_text": "Hi HN, I&#x27;m Arsalan, founder of LiveDocs (<a href=\"https:&#x2F;&#x2F;livedocs.com\">https:&#x2F;&#x2F;livedocs.com</a>). We&#x27;re building an AI-native data workspace that lets teams ask questions of their real data and have the system plan, execute, and maintain the analysis end-to-end.<p>We previously posted about LiveDocs four years ago (<a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=30735058\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=30735058</a>). Back then, LiveDocs was a no-code analytics tool for stitching together metrics from tools like Stripe and Google Analytics. It worked for basic reporting, but over time we ran into the same ceiling our users did. Dashboards are fine until the questions get messy, and notebooks slowly turn into hard-to-maintain piles of glue.<p>Over the last few years, we rebuilt LiveDocs almost entirely around a different idea. Data work should behave like a living system, not a static document or a chat transcript.<p>Today, LiveDocs is a reactive notebook environment backed by real execution engines. Notebooks are not linear. Each cell participates in a dependency graph, so when data or logic changes, only the affected parts recompute. You can freely mix SQL, Python, charts, tables, and text in the same document and everything stays in sync. Locally we run on DuckDB and Polars, and when you connect a warehouse like Snowflake, BigQuery, or Postgres, queries are pushed down instead of copying data out. Every result is inspectable and reproducible.<p>On top of this environment sits an AI agent, but it is not &quot;chat with your data.&quot; The agent works inside the notebook itself. It can plan multi-step analyses, write and debug SQL or Python, spawn specialized sub-agents for different tasks, run code in a terminal, and browse documentation or the web when it lacks context. Because it operates inside the same execution graph as humans, you can see exactly what it ran, edit it, or take over at any point.<p>We also support a canvas mode where the agent can build custom UI for your analysis, not just charts. This includes tables with controls, comparisons, and derived views that stay wired to the underlying data. When a notebook is not the right interface, you can publish parts of it as an interactive app. These behave more like lightweight internal tools, similar in spirit to Retool, but backed by the same analysis logic.<p>Everything in LiveDocs is fully real-time collaborative. Multiple people can edit the same notebook, see results update live, comment inline, and share documents or apps without exposing raw code unless they want to.<p>Teams use LiveDocs to investigate questions that do not fit cleanly into dashboards, build analyses that evolve over time without constant rewrites, and automate recurring questions without turning them into brittle pipelines.<p>Pricing is pay-as-you-go, starting at $15 per month, with a free tier so people can try it without talking to us. You&#x27;ll have to sign up, as it requires us to provision a sandbox for your to run your notebook. Here&#x27;s a video demo: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;Hl12su9Jn_I\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;Hl12su9Jn_I</a><p>We are still learning where this breaks. Long-running agent workflows on production data surface a lot of sharp edges. We would love feedback from people who have built or lived with analytics systems, notebooks, or &quot;chat with your data&quot; tools and felt their limits. Happy to go deep on technical details and trade notes.", "title": "Launch HN: Livedocs (YC W22) \u2013 An AI-native notebook for data analysis", "updated_at": "2026-02-15T13:00:40Z", "url": "https://livedocs.com"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "smaili"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "<em>Sharp</em> Corp lays off 3,000 foreign staff, moves <em>production</em> to China"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "https://www.reuters.com/article/us-<em>sharp</em>-job-cuts/<em>sharp</em>-corp-lays-off-3000-foreign-staff-moves-<em>production</em>-to-china-nikkei-idUSKBN1O22RL"}}, "_tags": ["story", "author_smaili", "story_18596160"], "author": "smaili", "created_at": "2018-12-04T04:11:04Z", "created_at_i": 1543896664, "num_comments": 0, "objectID": "18596160", "points": 3, "story_id": 18596160, "title": "Sharp Corp lays off 3,000 foreign staff, moves production to China", "updated_at": "2024-09-20T03:25:50Z", "url": "https://www.reuters.com/article/us-sharp-job-cuts/sharp-corp-lays-off-3000-foreign-staff-moves-production-to-china-nikkei-idUSKBN1O22RL"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "mark01"}, "story_text": {"matchLevel": "none", "matchedWords": [], "value": ""}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "<em>Sharp</em> slows down on the 9.7-Inch iPad screens <em>production</em>"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "http://www.ihelplounge.com/<em>sharp</em>-slows-down-on-the-9-7-inch-ipad-screens-<em>production</em>/"}}, "_tags": ["story", "author_mark01", "story_5081438"], "author": "mark01", "created_at": "2013-01-18T22:27:04Z", "created_at_i": 1358548024, "num_comments": 0, "objectID": "5081438", "points": 1, "story_id": 5081438, "story_text": "", "title": "Sharp slows down on the 9.7-Inch iPad screens production", "updated_at": "2023-09-06T20:38:15Z", "url": "http://www.ihelplounge.com/sharp-slows-down-on-the-9-7-inch-ipad-screens-production/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "radhakrsna"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "Hi HN,<p>Today, we are excited to be open-sourcing GPTRouter, an LLMOps tool we have been using internally at Writesonic for handling millions of monthly requests for our users.<p>Universal API for 30+ LLMs, Vision and Image Models\n Smart Fallbacks based on latency and uptime\n Automatic Retries\n Supports streaming<p>Since embracing OpenAI GPT-3 in <em>production</em> in 2020, we at Writesonic have been serving millions of users and faced the typical scaling pains with generative AI models:<p>1. Dependency on a single model risked total downtime.\n2. Latency issues with models like GPT-4 affected user experience.\n3. Integrating various models was tough due to different APIs and SDKs.<p>Early this year at Writesonic, we set out with a clear vision: to become model agnostic.<p>Faced with single-model limitations and diverse AI challenges, we began building GPTRouter - our bespoke solution to navigate and thrive in a multi-model AI world.<p>With GPTRouter's Universal API, you're the master of AI models.\nSwap between OpenAI, Azure, Anthropic, Replicate, Cohere &amp; more with just one line of code.\nIt simplifies model management to a great extent.<p>Downtime isn't an option.\nGPTRouter's Smart Fallbacks mean your service is always on.\nYou can define a hierarchy of models for each use case. GPTRouter will constantly check for uptime/downtime, latency and other factors, and automatically fallback to the next best model with zero interruption.<p>Say goodbye to manual retries.\nGPTRouter does the heavy lifting with Automatic Retries for failed requests, keeping your AI services <em>sharp</em> and consistent.<p>GPTRouter's Edge:\n Universal API for seamless model switching.\n Smart, automatic fallbacks for continuous service.\n Reduced latencies for quick interactions.<p>Additionally, we will also be open sourcing our frontend LLMOps layer that provides a playground to test multiple models in parallel, keep a tab on the latencies for each model, track tokens and costs for each model and user all in one place.<p>We are looking forward to seeing how developers leverage GPTRouter in their own use cases.<p>Thank you!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: GPT Router \u2013 Open-Source API Gateway for LLMs (OpenAI, Anthropic, etc.)"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/Writesonic/GPTRouter"}}, "_tags": ["story", "author_radhakrsna", "story_38733891", "show_hn"], "author": "radhakrsna", "children": [38733926, 38733941, 38733951, 38733953, 38733959, 38733960, 38733965, 38733978, 38733995, 38734010, 38734054, 38734139, 38736848, 38742877], "created_at": "2023-12-22T13:24:32Z", "created_at_i": 1703251472, "num_comments": 11, "objectID": "38733891", "points": 15, "story_id": 38733891, "story_text": "Hi HN,<p>Today, we are excited to be open-sourcing GPTRouter, an LLMOps tool we have been using internally at Writesonic for handling millions of monthly requests for our users.<p>Universal API for 30+ LLMs, Vision and Image Models\n Smart Fallbacks based on latency and uptime\n Automatic Retries\n Supports streaming<p>Since embracing OpenAI GPT-3 in production in 2020, we at Writesonic have been serving millions of users and faced the typical scaling pains with generative AI models:<p>1. Dependency on a single model risked total downtime.\n2. Latency issues with models like GPT-4 affected user experience.\n3. Integrating various models was tough due to different APIs and SDKs.<p>Early this year at Writesonic, we set out with a clear vision: to become model agnostic.<p>Faced with single-model limitations and diverse AI challenges, we began building GPTRouter - our bespoke solution to navigate and thrive in a multi-model AI world.<p>With GPTRouter&#x27;s Universal API, you&#x27;re the master of AI models.\nSwap between OpenAI, Azure, Anthropic, Replicate, Cohere &amp; more with just one line of code.\nIt simplifies model management to a great extent.<p>Downtime isn&#x27;t an option.\nGPTRouter&#x27;s Smart Fallbacks mean your service is always on.\nYou can define a hierarchy of models for each use case. GPTRouter will constantly check for uptime&#x2F;downtime, latency and other factors, and automatically fallback to the next best model with zero interruption.<p>Say goodbye to manual retries.\nGPTRouter does the heavy lifting with Automatic Retries for failed requests, keeping your AI services sharp and consistent.<p>GPTRouter&#x27;s Edge:\n Universal API for seamless model switching.\n Smart, automatic fallbacks for continuous service.\n Reduced latencies for quick interactions.<p>Additionally, we will also be open sourcing our frontend LLMOps layer that provides a playground to test multiple models in parallel, keep a tab on the latencies for each model, track tokens and costs for each model and user all in one place.<p>We are looking forward to seeing how developers leverage GPTRouter in their own use cases.<p>Thank you!", "title": "Show HN: GPT Router \u2013 Open-Source API Gateway for LLMs (OpenAI, Anthropic, etc.)", "updated_at": "2025-08-14T22:50:02Z", "url": "https://github.com/Writesonic/GPTRouter"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "mgarfias"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "So I saw the other posting and decided I should post something, as I also need help finding a remote job.<p>What I do:<p>I'm a *nix systems administrator (14 years of experience now) who worked for the past five years at sphere.com.  Been through an acquisition and all that.  I've lived for the past 4 years inside puppet's DSL automating services in puppet rather than in perl or python.<p>What I've done<p>Scaled sphere to almost 200 servers; saved us additional ops hires by implementing config management early (10 minutes from box delivery to operational); and saved something like $1.2M over 4 years in additional webserver costs by implementing varnish cache and tuning it to get an 82% hit rate.<p>What people say about me:<p>\u201cMike joined Sphere as one of its earliest employees, right before our first public beta launch. Mike has an impressive grasp of a wide range of technologies and keeps abreast of new developments. His constant drive to optimize kept Sphere running smoothly and cost-effectively during that first beta and throughout the many subsequent product launches and steep growth.\u201d<p>\u201cMike joined Sphere during the early startup days as one of the first full-time employees. He juggled activities spanning a wide spectrum of system administration tasks. Mike impressed early on with a high degree of dedication, essentially responding to emails or phone calls at almost any time of the day, while maintaining a can-do, problem-solving attitude. He made significant contributions to our success.\u201d<p>\u201cI worked very closely with Mike at Sphere, designing our <em>production</em> infrastructure and stepping back to let him run with it. Despite our steep growth and continuous development strategy, Mike was always on top of our needs. His attention to detail, willingness to tackle any challenge, and aggressive pursuit of better solutions not only saved us many times, but laid a solid foundation for the company's success.\u201d<p>Why I need remote:<p>I live on a farm in rural Oregon, about an hour out of portland.  I'll commute there if I have to, but I would rather give the commute time to my family.<p>Why I'm looking now:<p>Sphere was just spun out of AOL over to a new place, and they had four SAs already, and I'm nearly done with the transition assistance.  I've been looking for remote gigs, but haven't had luck finding opportunities.  In the mean time, I've been doing a bit of outside extra consulting to keep the skills <em>sharp</em>.<p>I'll happily send a resume out if requested.<p>Thanks!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "I also need help finding a remote job"}, "url": {"matchLevel": "none", "matchedWords": [], "value": ""}}, "_tags": ["story", "author_mgarfias", "story_2533633", "ask_hn"], "author": "mgarfias", "children": [2533727], "created_at": "2011-05-10T18:45:32Z", "created_at_i": 1305053132, "num_comments": 2, "objectID": "2533633", "points": 13, "story_id": 2533633, "story_text": "So I saw the other posting and decided I should post something, as I also need help finding a remote job.<p>What I do:<p>I'm a *nix systems administrator (14 years of experience now) who worked for the past five years at sphere.com.  Been through an acquisition and all that.  I've lived for the past 4 years inside puppet's DSL automating services in puppet rather than in perl or python.<p>What I've done<p>Scaled sphere to almost 200 servers; saved us additional ops hires by implementing config management early (10 minutes from box delivery to operational); and saved something like $1.2M over 4 years in additional webserver costs by implementing varnish cache and tuning it to get an 82% hit rate.<p>What people say about me:<p>\u201cMike joined Sphere as one of its earliest employees, right before our first public beta launch. Mike has an impressive grasp of a wide range of technologies and keeps abreast of new developments. His constant drive to optimize kept Sphere running smoothly and cost-effectively during that first beta and throughout the many subsequent product launches and steep growth.\u201d<p>\u201cMike joined Sphere during the early startup days as one of the first full-time employees. He juggled activities spanning a wide spectrum of system administration tasks. Mike impressed early on with a high degree of dedication, essentially responding to emails or phone calls at almost any time of the day, while maintaining a can-do, problem-solving attitude. He made significant contributions to our success.\u201d<p>\u201cI worked very closely with Mike at Sphere, designing our production infrastructure and stepping back to let him run with it. Despite our steep growth and continuous development strategy, Mike was always on top of our needs. His attention to detail, willingness to tackle any challenge, and aggressive pursuit of better solutions not only saved us many times, but laid a solid foundation for the company's success.\u201d<p>Why I need remote:<p>I live on a farm in rural Oregon, about an hour out of portland.  I'll commute there if I have to, but I would rather give the commute time to my family.<p>Why I'm looking now:<p>Sphere was just spun out of AOL over to a new place, and they had four SAs already, and I'm nearly done with the transition assistance.  I've been looking for remote gigs, but haven't had luck finding opportunities.  In the mean time, I've been doing a bit of outside extra consulting to keep the skills sharp.<p>I'll happily send a resume out if requested.<p>Thanks!", "title": "I also need help finding a remote job", "updated_at": "2023-09-06T19:47:55Z", "url": ""}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "gano"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "I\u2019ve been experimenting with a graph-based approach to a classic trading problem: why most dip-buying strategies can\u2019t tell the difference between a temporary overreaction and a genuine structural collapse.<p>Most systems treat a \u22125% move the same regardless of context. My hypothesis was that where a company sits in the market\u2019s structure matters more than the price move itself.<p>The engineering idea<p>I built a knowledge graph of the U.S. public markets with ~207k edges across ~21 relationship types, organized into four layers:<p>Operational: supply-chain relationships (SUPPLIES_TO, PRODUCES)<p>Flow: ETF and institutional ownership plumbing<p>Social: board interlocks (SHARES_DIRECTOR_WITH)<p>Environmental: geography / competition<p>For each layer, I compute centrality scores using PageRank-style methods (with inverse-degree weighting to avoid ETF super-nodes dominating).<p>These structural features are then combined with basic price/volume context and fed into a tree-based model (XGBoost) to rank stocks after <em>sharp</em> drawdowns<p>What surprised me<p>When I validated the rankings out-of-sample (2024\u20132025, using Alphalens to avoid look-ahead issues):\n* Operational and Flow edges provided most of the lift\n* Social edges (board interlocks) added much less than I expected\n* Graph features roughly doubled ranking quality versus price-only baselines\nThis wasn\u2019t obvious to me going in \u2014 I expected \u201csocial\u201d connections to matter more.<p>Why I\u2019m posting<p>I\u2019m in the process of turning this from a research notebook into a <em>production</em> dashboard, and before I lock in the graph schema I\u2019d love feedback from people who\u2019ve built large graphs in other domains.\nIn particular:\n* Have you seen board-interlock / social edges be predictive elsewhere?\n* Are there graph normalization tricks you\u2019ve found essential at this scale?\n* Any pitfalls you\u2019ve hit when mixing heterogeneous edge types?<p>Happy to answer questions about the graph construction, centrality calculations, or validation setup."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN:Built a 200k-edge market knowledge graph to filter false dip-buy signals"}}, "_tags": ["story", "author_gano", "story_46416991", "show_hn"], "author": "gano", "children": [46419499], "created_at": "2025-12-29T02:56:52Z", "created_at_i": 1766977012, "num_comments": 2, "objectID": "46416991", "points": 5, "story_id": 46416991, "story_text": "I\u2019ve been experimenting with a graph-based approach to a classic trading problem: why most dip-buying strategies can\u2019t tell the difference between a temporary overreaction and a genuine structural collapse.<p>Most systems treat a \u22125% move the same regardless of context. My hypothesis was that where a company sits in the market\u2019s structure matters more than the price move itself.<p>The engineering idea<p>I built a knowledge graph of the U.S. public markets with ~207k edges across ~21 relationship types, organized into four layers:<p>Operational: supply-chain relationships (SUPPLIES_TO, PRODUCES)<p>Flow: ETF and institutional ownership plumbing<p>Social: board interlocks (SHARES_DIRECTOR_WITH)<p>Environmental: geography &#x2F; competition<p>For each layer, I compute centrality scores using PageRank-style methods (with inverse-degree weighting to avoid ETF super-nodes dominating).<p>These structural features are then combined with basic price&#x2F;volume context and fed into a tree-based model (XGBoost) to rank stocks after sharp drawdowns<p>What surprised me<p>When I validated the rankings out-of-sample (2024\u20132025, using Alphalens to avoid look-ahead issues):\n* Operational and Flow edges provided most of the lift\n* Social edges (board interlocks) added much less than I expected\n* Graph features roughly doubled ranking quality versus price-only baselines\nThis wasn\u2019t obvious to me going in \u2014 I expected \u201csocial\u201d connections to matter more.<p>Why I\u2019m posting<p>I\u2019m in the process of turning this from a research notebook into a production dashboard, and before I lock in the graph schema I\u2019d love feedback from people who\u2019ve built large graphs in other domains.\nIn particular:\n* Have you seen board-interlock &#x2F; social edges be predictive elsewhere?\n* Are there graph normalization tricks you\u2019ve found essential at this scale?\n* Any pitfalls you\u2019ve hit when mixing heterogeneous edge types?<p>Happy to answer questions about the graph construction, centrality calculations, or validation setup.", "title": "Show HN:Built a 200k-edge market knowledge graph to filter false dip-buy signals", "updated_at": "2025-12-29T18:03:45Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "AustinMunday"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["sharp", "production"], "value": "I built QuickImageResize.pro entirely on Replit as a comprehensive web-based image processing tool that handles virtually any image format you throw at it. The tool supports JPEG, PNG, GIF, WebP, BMP, HEIC, TIFF, AVIF, SVG, and even RAW formats (CR2, NEF, ARW, DNG) with automatic conversion capabilities.<p>Key features:<p>Drag-and-drop upload with real-time processing\nSmart format conversion (e.g., HEIC \u2192 JPEG, RAW \u2192 PNG)<p>Quality control and dimension resizing with aspect ratio preservation<p>AVIF support for 50% better compression than JPEG\nNo file uploads to external servers - everything processed locally<p>Professional-grade <em>Sharp</em> library backend for high-quality results<p>Built with React/TypeScript frontend and Express.js backend using the <em>Sharp</em> image processing library, all developed and deployed on Replit. The tool automatically handles format detection and conversion, so you can upload a Canon RAW file and download it as a web-ready JPEG with custom dimensions.<p>Perfect for photographers, web developers, and anyone who needs reliable image processing without installing desktop software. Currently handling 10,000+ image transformations.<p>Replit made it incredibly easy to prototype, develop, and deploy this tool without any infrastructure setup - just pure focus on building features. The integrated environment handled everything from package management to <em>production</em> deployment."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: QuickImageResize.pro \u2013 Free Image Conversion and Resizing Tool"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://quickimageresize.pro/"}}, "_tags": ["story", "author_AustinMunday", "story_44467255", "show_hn"], "author": "AustinMunday", "created_at": "2025-07-04T19:36:51Z", "created_at_i": 1751657811, "num_comments": 0, "objectID": "44467255", "points": 3, "story_id": 44467255, "story_text": "I built QuickImageResize.pro entirely on Replit as a comprehensive web-based image processing tool that handles virtually any image format you throw at it. The tool supports JPEG, PNG, GIF, WebP, BMP, HEIC, TIFF, AVIF, SVG, and even RAW formats (CR2, NEF, ARW, DNG) with automatic conversion capabilities.<p>Key features:<p>Drag-and-drop upload with real-time processing\nSmart format conversion (e.g., HEIC \u2192 JPEG, RAW \u2192 PNG)<p>Quality control and dimension resizing with aspect ratio preservation<p>AVIF support for 50% better compression than JPEG\nNo file uploads to external servers - everything processed locally<p>Professional-grade Sharp library backend for high-quality results<p>Built with React&#x2F;TypeScript frontend and Express.js backend using the Sharp image processing library, all developed and deployed on Replit. The tool automatically handles format detection and conversion, so you can upload a Canon RAW file and download it as a web-ready JPEG with custom dimensions.<p>Perfect for photographers, web developers, and anyone who needs reliable image processing without installing desktop software. Currently handling 10,000+ image transformations.<p>Replit made it incredibly easy to prototype, develop, and deploy this tool without any infrastructure setup - just pure focus on building features. The integrated environment handled everything from package management to production deployment.", "title": "Show HN: QuickImageResize.pro \u2013 Free Image Conversion and Resizing Tool", "updated_at": "2025-07-07T14:42:25Z", "url": "https://quickimageresize.pro/"}], "hitsPerPage": 15, "nbHits": 647, "nbPages": 44, "page": 0, "params": "query=sharp+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 12, "processingTimingsMS": {"_request": {"roundTrip": 24}, "afterFetch": {"format": {"highlighting": 1, "total": 1}}, "fetch": {"query": 7, "scanning": 3, "total": 11}, "total": 12}, "query": "sharp production", "serverTimeMS": 14}}