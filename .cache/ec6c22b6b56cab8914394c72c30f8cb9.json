{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "ssaunier_"}, "story_text": {"matchLevel": "none", "matchedWords": [], "value": ""}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "Dump a <em>PostgreSQL</em> <em>production</em> database and mount it locally"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "http://sebastien.saunier.me/blog/2015/01/07/dump-a-<em>postgresql</em>-<em>production</em>-database-and-mount-it-locally.html"}}, "_tags": ["story", "author_ssaunier_", "story_8849668"], "author": "ssaunier_", "created_at": "2015-01-07T09:58:54Z", "created_at_i": 1420624734, "num_comments": 0, "objectID": "8849668", "points": 4, "story_id": 8849668, "story_text": "", "title": "Dump a PostgreSQL production database and mount it locally", "updated_at": "2023-09-06T23:12:58Z", "url": "http://sebastien.saunier.me/blog/2015/01/07/dump-a-postgresql-production-database-and-mount-it-locally.html"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "swyx"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "<em>PostgreSQL</em> <em>Production</em> Checklist"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "https://www.crunchydata.com/blog/is-your-postgres-ready-for-<em>production</em>"}}, "_tags": ["story", "author_swyx", "story_35415808"], "author": "swyx", "created_at": "2023-04-02T22:10:24Z", "created_at_i": 1680473424, "num_comments": 0, "objectID": "35415808", "points": 4, "story_id": 35415808, "title": "PostgreSQL Production Checklist", "updated_at": "2024-09-20T13:44:43Z", "url": "https://www.crunchydata.com/blog/is-your-postgres-ready-for-production"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "pritambarhate"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "Running <em>production</em> <em>PostgreSQL</em> systems on ARM architecture? [pdf]"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "http://www.cybertec.at/secret/PostgreSQLonARM.pdf"}}, "_tags": ["story", "author_pritambarhate", "story_13500130"], "author": "pritambarhate", "children": [13500137], "created_at": "2017-01-27T14:58:19Z", "created_at_i": 1485529099, "num_comments": 1, "objectID": "13500130", "points": 2, "story_id": 13500130, "title": "Running production PostgreSQL systems on ARM architecture? [pdf]", "updated_at": "2024-09-20T00:15:23Z", "url": "http://www.cybertec.at/secret/PostgreSQLonARM.pdf"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "KristiMKE"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "Making It Easier to Manage a <em>Production</em> <em>PostgreSQL</em> Database"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "https://scalegrid.io/blog/making-it-easier-to-manage-a-<em>production</em>-<em>postgresql</em>-database/"}}, "_tags": ["story", "author_KristiMKE", "story_21525442"], "author": "KristiMKE", "created_at": "2019-11-13T15:50:03Z", "created_at_i": 1573660203, "num_comments": 0, "objectID": "21525442", "points": 2, "story_id": 21525442, "title": "Making It Easier to Manage a Production PostgreSQL Database", "updated_at": "2024-09-20T05:07:41Z", "url": "https://scalegrid.io/blog/making-it-easier-to-manage-a-production-postgresql-database/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "fuzzylizard"}, "story_text": {"matchLevel": "none", "matchedWords": [], "value": ""}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "Replicating a <em>PostgreSQL</em> <em>production</em> database to the office"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "http://engineering.nulogy.com/posts/replicating-a-<em>postgresql</em>-<em>production</em>-database-to-the-office"}}, "_tags": ["story", "author_fuzzylizard", "story_5226918"], "author": "fuzzylizard", "created_at": "2013-02-15T16:24:27Z", "created_at_i": 1360945467, "num_comments": 0, "objectID": "5226918", "points": 1, "story_id": 5226918, "story_text": "", "title": "Replicating a PostgreSQL production database to the office", "updated_at": "2024-09-19T19:15:10Z", "url": "http://engineering.nulogy.com/posts/replicating-a-postgresql-production-database-to-the-office"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "vastbinderj"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "We have spent 3 years building out our ecommerce platform and are successfully selling into the mid-market space where we charge enterprise prices.<p>We just finished a round of performance and scalability tests where we can support up to 500 concurrent shoppers on 2 T2.small instances and easily handle 100 concurrent shoppers on the free tier using a single T2.micro instance.<p>This has us thinking of trying to break into the SMB Market where Shopify and Big Commerce dominate.  We know we cannot compete with their marketing budgets so we are contemplating releasing a free developer version limited to use of only SQLite for the database, (we support mongodb, mysql or <em>postgresql</em> in <em>production</em>) and pulling out some of our more enterprise-like integrations.  Ottemo is built in golang for the API server and our current stores are built in AngularJS 1.x<p>We would provide binaries of our API server which will include SQLite and Open Source our demo store code to allow customization and creation of themes.<p>Will this dilute our value to our mid-market customers paying enterprise prices?  Will this block potential investment from VCs if we expand down market into the SMB space with a free version?"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Should we release a free developer version of Ottemo, our ecommerce platform?"}}, "_tags": ["story", "author_vastbinderj", "story_12005001", "ask_hn"], "author": "vastbinderj", "children": [12005131, 12005332, 12008874], "created_at": "2016-06-29T21:34:05Z", "created_at_i": 1467236045, "num_comments": 5, "objectID": "12005001", "points": 2, "story_id": 12005001, "story_text": "We have spent 3 years building out our ecommerce platform and are successfully selling into the mid-market space where we charge enterprise prices.<p>We just finished a round of performance and scalability tests where we can support up to 500 concurrent shoppers on 2 T2.small instances and easily handle 100 concurrent shoppers on the free tier using a single T2.micro instance.<p>This has us thinking of trying to break into the SMB Market where Shopify and Big Commerce dominate.  We know we cannot compete with their marketing budgets so we are contemplating releasing a free developer version limited to use of only SQLite for the database, (we support mongodb, mysql or postgresql in production) and pulling out some of our more enterprise-like integrations.  Ottemo is built in golang for the API server and our current stores are built in AngularJS 1.x<p>We would provide binaries of our API server which will include SQLite and Open Source our demo store code to allow customization and creation of themes.<p>Will this dilute our value to our mid-market customers paying enterprise prices?  Will this block potential investment from VCs if we expand down market into the SMB space with a free version?", "title": "Should we release a free developer version of Ottemo, our ecommerce platform?", "updated_at": "2024-09-19T23:21:18Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "twwch"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "URL: <a href=\"https://github.com/twwch/next-chat-skills\" rel=\"nofollow\">https://github.com/twwch/next-chat-skills</a><p>---<p>Text (paste into the &quot;text&quot; field):<p>Hi HN,<p>I built an open-source AI assistant that can autonomously discover, install, and execute Skills to actually complete tasks for you.<p>The Problem:<p>Most AI chatbots today are stuck in &quot;read-only&quot; mode. They can tell you how to do something, but they can't do it. Want to convert a PPTX to PDF? The AI will explain how, but you still have to run the commands yourself.<p>The Solution:<p>Next-Chat-Skills is a self-hosted AI assistant with a plugin system called Skills. When you ask the AI to do something it can't handle natively, it:<p>1. Searches for a relevant Skill (like an app store for AI capabilities)\n2. Installs it automatically (npx skills add ...)\n3. Executes the Skill's scripts (Python, Node.js, Shell)\n4. Streams real-time output back to you in a terminal UI\n5. Recovers from errors by installing missing dependencies and retrying<p>For example:<p><pre><code>  User: &quot;Summarize this YouTube video for me&quot;\n  AI:   -&gt; Searches for a video-summarizer Skill\n        -&gt; Installs it (yt-dlp + Whisper)\n        -&gt; Downloads the video, transcribes audio\n        -&gt; Returns a structured summary\n</code></pre>\nNo manual setup. No copy-pasting commands. The AI handles the entire workflow.<p>What is a Skill?<p>A Skill is just a folder with a SKILL.md descriptor and some scripts:<p><pre><code>  ~/.agents/skills/video-summarizer/\n  \u251c\u2500\u2500 SKILL.md              # Metadata + description\n  \u251c\u2500\u2500 scripts/\n  \u2502   \u251c\u2500\u2500 download.py       # Download video\n  \u2502   \u251c\u2500\u2500 transcribe.py     # Whisper transcription\n  \u2502   \u2514\u2500\u2500 summarize.js      # Generate summary\n  \u2514\u2500\u2500 rules/                # Usage guidelines for the AI\n</code></pre>\nAnyone can create and share Skills. The AI reads the SKILL.md to understand when and how to invoke each script. It's composable \u2014 the more Skills you add, the more capable your assistant becomes.<p>Key Features:<p>- Autonomous Skill discovery &amp; installation \u2014 AI finds and installs what it needs\n- Real-time script execution \u2014 streams terminal output via SSE, supports Python/Node.js/Shell\n- File generation &amp; download \u2014 scripts can generate files (PPTX, PDF, images) that users can download directly from chat\n- Multi-file upload &amp; parsing \u2014 supports images, PDF, DOCX, XLSX, PPTX\n- Dual database \u2014 SQLite (zero-config) or <em>PostgreSQL</em> (<em>production</em>)\n- Optional auth \u2014 Google OAuth or fingerprint-based, works without login too\n- Docker-ready \u2014 pre-built image with Python, FFmpeg, LibreOffice, and popular Skills pre-installed\n- Works with any OpenAI-compatible API \u2014 GPT-4o, Claude (via proxy), local models, etc.<p>Tech Stack: Next.js 16, React 19, TypeScript, Vercel AI SDK, Tailwind CSS 4, shadcn/ui, Drizzle ORM (SQLite / <em>PostgreSQL</em>), Docker (Node.js 20 + Python 3)<p>Quick Start:<p><pre><code>  # Docker (fastest)\n  docker run -p 3000:3000 \\\n    -e OPENAI_API_KEY=sk-xxx \\\n    -e OPENAI_BASE_URL=https://api.openai.com/v1 \\\n    twwch/next-chat-skills:latest\n\n  # Or from source\n  git clone https://github.com/twwch/next-chat-skills\n  cd next-chat-skills\n  npm install &amp;&amp; npm run dev\n</code></pre>\nWhy I Built This:<p>I got tired of AI assistants that stop at &quot;here's a code snippet.&quot; I wanted an AI that could actually run the code, handle failures, install dependencies, and deliver the final result \u2014 like having a junior developer who can use any Skill you point them at.<p>The Skills system makes this extensible without modifying the core app. Anyone can package a workflow as a Skill and share it.<p>What's Next:<p>- Skill marketplace / registry for community sharing\n- Multi-step workflow chaining (Skill A output -&gt; Skill B input)\n- Better sandboxing for script execution\n- MCP (Model Context Protocol) integration<p>I'd love to hear your feedback. What Skills would you want to see? What's missing?<p>GitHub: <a href=\"https://github.com/twwch/next-chat-skills\" rel=\"nofollow\">https://github.com/twwch/next-chat-skills</a>\nLicense: Apache 2.0"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Give Your AI the Ability to Find, Install, and Use Skill Autonomously"}}, "_tags": ["story", "author_twwch", "story_46942091", "show_hn"], "author": "twwch", "created_at": "2026-02-09T06:13:22Z", "created_at_i": 1770617602, "num_comments": 0, "objectID": "46942091", "points": 2, "story_id": 46942091, "story_text": "URL: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;twwch&#x2F;next-chat-skills\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;twwch&#x2F;next-chat-skills</a><p>---<p>Text (paste into the &quot;text&quot; field):<p>Hi HN,<p>I built an open-source AI assistant that can autonomously discover, install, and execute Skills to actually complete tasks for you.<p>The Problem:<p>Most AI chatbots today are stuck in &quot;read-only&quot; mode. They can tell you how to do something, but they can&#x27;t do it. Want to convert a PPTX to PDF? The AI will explain how, but you still have to run the commands yourself.<p>The Solution:<p>Next-Chat-Skills is a self-hosted AI assistant with a plugin system called Skills. When you ask the AI to do something it can&#x27;t handle natively, it:<p>1. Searches for a relevant Skill (like an app store for AI capabilities)\n2. Installs it automatically (npx skills add ...)\n3. Executes the Skill&#x27;s scripts (Python, Node.js, Shell)\n4. Streams real-time output back to you in a terminal UI\n5. Recovers from errors by installing missing dependencies and retrying<p>For example:<p><pre><code>  User: &quot;Summarize this YouTube video for me&quot;\n  AI:   -&gt; Searches for a video-summarizer Skill\n        -&gt; Installs it (yt-dlp + Whisper)\n        -&gt; Downloads the video, transcribes audio\n        -&gt; Returns a structured summary\n</code></pre>\nNo manual setup. No copy-pasting commands. The AI handles the entire workflow.<p>What is a Skill?<p>A Skill is just a folder with a SKILL.md descriptor and some scripts:<p><pre><code>  ~&#x2F;.agents&#x2F;skills&#x2F;video-summarizer&#x2F;\n  \u251c\u2500\u2500 SKILL.md              # Metadata + description\n  \u251c\u2500\u2500 scripts&#x2F;\n  \u2502   \u251c\u2500\u2500 download.py       # Download video\n  \u2502   \u251c\u2500\u2500 transcribe.py     # Whisper transcription\n  \u2502   \u2514\u2500\u2500 summarize.js      # Generate summary\n  \u2514\u2500\u2500 rules&#x2F;                # Usage guidelines for the AI\n</code></pre>\nAnyone can create and share Skills. The AI reads the SKILL.md to understand when and how to invoke each script. It&#x27;s composable \u2014 the more Skills you add, the more capable your assistant becomes.<p>Key Features:<p>- Autonomous Skill discovery &amp; installation \u2014 AI finds and installs what it needs\n- Real-time script execution \u2014 streams terminal output via SSE, supports Python&#x2F;Node.js&#x2F;Shell\n- File generation &amp; download \u2014 scripts can generate files (PPTX, PDF, images) that users can download directly from chat\n- Multi-file upload &amp; parsing \u2014 supports images, PDF, DOCX, XLSX, PPTX\n- Dual database \u2014 SQLite (zero-config) or PostgreSQL (production)\n- Optional auth \u2014 Google OAuth or fingerprint-based, works without login too\n- Docker-ready \u2014 pre-built image with Python, FFmpeg, LibreOffice, and popular Skills pre-installed\n- Works with any OpenAI-compatible API \u2014 GPT-4o, Claude (via proxy), local models, etc.<p>Tech Stack: Next.js 16, React 19, TypeScript, Vercel AI SDK, Tailwind CSS 4, shadcn&#x2F;ui, Drizzle ORM (SQLite &#x2F; PostgreSQL), Docker (Node.js 20 + Python 3)<p>Quick Start:<p><pre><code>  # Docker (fastest)\n  docker run -p 3000:3000 \\\n    -e OPENAI_API_KEY=sk-xxx \\\n    -e OPENAI_BASE_URL=https:&#x2F;&#x2F;api.openai.com&#x2F;v1 \\\n    twwch&#x2F;next-chat-skills:latest\n\n  # Or from source\n  git clone https:&#x2F;&#x2F;github.com&#x2F;twwch&#x2F;next-chat-skills\n  cd next-chat-skills\n  npm install &amp;&amp; npm run dev\n</code></pre>\nWhy I Built This:<p>I got tired of AI assistants that stop at &quot;here&#x27;s a code snippet.&quot; I wanted an AI that could actually run the code, handle failures, install dependencies, and deliver the final result \u2014 like having a junior developer who can use any Skill you point them at.<p>The Skills system makes this extensible without modifying the core app. Anyone can package a workflow as a Skill and share it.<p>What&#x27;s Next:<p>- Skill marketplace &#x2F; registry for community sharing\n- Multi-step workflow chaining (Skill A output -&gt; Skill B input)\n- Better sandboxing for script execution\n- MCP (Model Context Protocol) integration<p>I&#x27;d love to hear your feedback. What Skills would you want to see? What&#x27;s missing?<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;twwch&#x2F;next-chat-skills\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;twwch&#x2F;next-chat-skills</a>\nLicense: Apache 2.0", "title": "Show HN: Give Your AI the Ability to Find, Install, and Use Skill Autonomously", "updated_at": "2026-02-09T06:36:16Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "linesofcode"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "Say hello to <a href=\"https://pongo.sh/\" rel=\"nofollow\">https://pongo.sh/</a><p>self-hosted uptime monitoring, configured entirely in TypeScript and built on NextJS and Bun.<p>No UI forms. No vendor lock-in. Just code in your repo.<p>Monitors, dashboards, alerts, incidents, and status pages \u2014 all defined as TypeScript files and Markdown, version-controlled alongside your application.<p>You can one-click deploy it to Vercel or anywhere you can run node/bun/docker.<p>Your monitoring config lives in your repo like everything else.<p>Want to know what's monitored and why? Read the code.<p>Need to review a change? It's in the PR. Need to roll back a bad alert? Git revert.<p>No more clicking through dashboards wondering who changed what and when.<p>Built with Next.js, Drizzle ORM, and Bun. Runs with SQLite for simplicity or <em>PostgreSQL</em> for <em>production</em>.<p>Fully open source and ready to use today.<p>Would love to hear what you think and what features you'd want to see next, leave a star on GitHub<p><a href=\"https://github.com/TimMikeladze/pongo\" rel=\"nofollow\">https://github.com/TimMikeladze/pongo</a>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Pongo \u2013 a self hosted uptime monitor using configuration as code"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://www.pongo.sh/"}}, "_tags": ["story", "author_linesofcode", "story_47149982", "show_hn"], "author": "linesofcode", "children": [47150287, 47160587, 47163697], "created_at": "2026-02-25T11:02:31Z", "created_at_i": 1772017351, "num_comments": 2, "objectID": "47149982", "points": 1, "story_id": 47149982, "story_text": "Say hello to <a href=\"https:&#x2F;&#x2F;pongo.sh&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;pongo.sh&#x2F;</a><p>self-hosted uptime monitoring, configured entirely in TypeScript and built on NextJS and Bun.<p>No UI forms. No vendor lock-in. Just code in your repo.<p>Monitors, dashboards, alerts, incidents, and status pages \u2014 all defined as TypeScript files and Markdown, version-controlled alongside your application.<p>You can one-click deploy it to Vercel or anywhere you can run node&#x2F;bun&#x2F;docker.<p>Your monitoring config lives in your repo like everything else.<p>Want to know what&#x27;s monitored and why? Read the code.<p>Need to review a change? It&#x27;s in the PR. Need to roll back a bad alert? Git revert.<p>No more clicking through dashboards wondering who changed what and when.<p>Built with Next.js, Drizzle ORM, and Bun. Runs with SQLite for simplicity or PostgreSQL for production.<p>Fully open source and ready to use today.<p>Would love to hear what you think and what features you&#x27;d want to see next, leave a star on GitHub<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;TimMikeladze&#x2F;pongo\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;TimMikeladze&#x2F;pongo</a>", "title": "Show HN: Pongo \u2013 a self hosted uptime monitor using configuration as code", "updated_at": "2026-02-26T09:08:33Z", "url": "https://www.pongo.sh/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "fwlymburner"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "Ten Tips for Going into <em>Production</em> with <em>PostgreSQL</em>"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "https://severalnines.com/blog/ten-tips-going-<em>production</em>-<em>postgresql</em>"}}, "_tags": ["story", "author_fwlymburner", "story_16849017"], "author": "fwlymburner", "created_at": "2018-04-16T14:00:24Z", "created_at_i": 1523887224, "num_comments": 0, "objectID": "16849017", "points": 2, "story_id": 16849017, "title": "Ten Tips for Going into Production with PostgreSQL", "updated_at": "2024-09-20T02:20:52Z", "url": "https://severalnines.com/blog/ten-tips-going-production-postgresql"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "luu"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "Running 10M <em>PostgreSQL</em> Indexes in <em>Production</em>"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "http://heap.engineering/running-10-million-<em>postgresql</em>-indexes-in-<em>production</em>/"}}, "_tags": ["story", "author_luu", "story_14542739"], "author": "luu", "children": [14543023, 14543057, 14543079, 14543472, 14543572, 14544188, 14544275, 14544406, 14544469, 14544888, 14550625, 14550627], "created_at": "2017-06-13T03:45:51Z", "created_at_i": 1497325551, "num_comments": 65, "objectID": "14542739", "points": 263, "story_id": 14542739, "title": "Running 10M PostgreSQL Indexes in Production", "updated_at": "2024-09-20T00:56:46Z", "url": "http://heap.engineering/running-10-million-postgresql-indexes-in-production/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "codezero"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "Running 10M <em>PostgreSQL</em> Indexes in <em>Production</em> (And Counting)"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "http://blog.heapanalytics.com/running-10-million-<em>postgresql</em>-indexes-in-<em>production</em>/"}}, "_tags": ["story", "author_codezero", "story_13073223"], "author": "codezero", "children": [13073593], "created_at": "2016-11-30T18:25:08Z", "created_at_i": 1480530308, "num_comments": 3, "objectID": "13073223", "points": 8, "story_id": 13073223, "title": "Running 10M PostgreSQL Indexes in Production (And Counting)", "updated_at": "2024-09-20T00:04:49Z", "url": "http://blog.heapanalytics.com/running-10-million-postgresql-indexes-in-production/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "panrobo"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "Running <em>production</em>-grade <em>PostgreSQL</em> on Kubernetes"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "https://www.simplyblock.io/post/<em>production</em>-grade-<em>postgresql</em>-on-kubernetes-with-\u00e1lvaro-hern\u00e1ndez-tortosa-from-ongres"}}, "_tags": ["story", "author_panrobo", "story_40078302"], "author": "panrobo", "children": [40078310], "created_at": "2024-04-18T16:58:16Z", "created_at_i": 1713459496, "num_comments": 1, "objectID": "40078302", "points": 5, "story_id": 40078302, "title": "Running production-grade PostgreSQL on Kubernetes", "updated_at": "2024-09-20T16:52:22Z", "url": "https://www.simplyblock.io/post/production-grade-postgresql-on-kubernetes-with-\u00e1lvaro-hern\u00e1ndez-tortosa-from-ongres"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "csinaction"}, "story_text": {"matchLevel": "none", "matchedWords": [], "value": ""}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "Smarter Synchronization of Your <em>PostgreSQL</em> Development and <em>Production</em> DBs"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "http://www.csinaction.com/2015/01/17/smarter-synchronization-of-your-<em>postgresql</em>-development-and-<em>production</em>-dbs/"}}, "_tags": ["story", "author_csinaction", "story_8904921"], "author": "csinaction", "created_at": "2015-01-17T17:50:45Z", "created_at_i": 1421517045, "num_comments": 0, "objectID": "8904921", "points": 1, "story_id": 8904921, "story_text": "", "title": "Smarter Synchronization of Your PostgreSQL Development and Production DBs", "updated_at": "2023-09-06T23:18:00Z", "url": "http://www.csinaction.com/2015/01/17/smarter-synchronization-of-your-postgresql-development-and-production-dbs/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "tapan_pandita"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "I am looking to get a managed <em>postgresql</em> server for <em>production</em> use. My requirements are:<p>1. Access control configuration (for PCI-DSS compliance)<p>2. PCI accredited<p>3. Bonus if it's a heroku addon<p>The default heroku postgres doesn't allow me to change the access control config (I only want to allow certain whitelisted IPs), which is a must. Is there a heroku addon which makes this possible or should I just go for another service?"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["postgresql"], "value": "Ask HN: Best managed <em>postgresql</em> server?"}, "url": {"matchLevel": "none", "matchedWords": [], "value": ""}}, "_tags": ["story", "author_tapan_pandita", "story_5353488", "ask_hn"], "author": "tapan_pandita", "created_at": "2013-03-10T21:14:04Z", "created_at_i": 1362950044, "num_comments": 0, "objectID": "5353488", "points": 4, "story_id": 5353488, "story_text": "I am looking to get a managed postgresql server for production use. My requirements are:<p>1. Access control configuration (for PCI-DSS compliance)<p>2. PCI accredited<p>3. Bonus if it's a heroku addon<p>The default heroku postgres doesn't allow me to change the access control config (I only want to allow certain whitelisted IPs), which is a must. Is there a heroku addon which makes this possible or should I just go for another service?", "title": "Ask HN: Best managed postgresql server?", "updated_at": "2024-09-19T19:21:40Z", "url": ""}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "Vonng"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["postgresql", "production"], "value": "Yo, Pigsty is a local-first open-source alternative for RDS <em>PostgreSQL</em>, with monitoring, HA, PITR, IaC, and lots of stuff to run a <em>production</em>-grade <em>PostgreSQL</em> Service on your nodes for free.  Demo: http://demo.pigsty.cc.<p>* Battery-Included <em>PostgreSQL</em> Distribution, with PostGIS, TimescaleDB, Citus united as one.\n* Incredible observability powered by Prometheus &amp; Grafana stack.\n* Self-healing HA PGSQL cluster, powered by patroni, haproxy, etcd\u2026\n* Auto-Configured PITR, powered by pgbackrest and optional MinIO cluster\n* Declarative API, Database-as-Code implemented with Ansible playbooks.\n* Versatile UseCases, Run Docker Apps, Run demos, Visualize data with ECharts panels.\n* Install in one command, provision IaaS with Terraform, and test with local Vagrant sandbox.<p>Features: https://github.com/Vonng/pigsty/blob/master/docs/FEATURE.md<p>I'm Vonng, the author of Pigsty and a <em>PostgreSQL</em> DBA of a large deployment (25K cores, 1PB TP data). Pigsty alleviates my pain of managing such a massive elephant in <em>production</em>.<p>It works well for us, and I'm glad to make it open-source. Since cloud RDS <em>PostgreSQL</em> are so expensive, sometimes it charges 10x compared to underlying EC2 and storage. An open-source alternative could help.<p>I'm happy to answer any questions about Pigsty ;)"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["postgresql"], "value": "How about an open-source RDS alternative for <em>PostgreSQL</em>?"}}, "_tags": ["story", "author_Vonng", "story_34966165", "ask_hn"], "author": "Vonng", "created_at": "2023-02-28T05:59:00Z", "created_at_i": 1677563940, "num_comments": 0, "objectID": "34966165", "points": 4, "story_id": 34966165, "story_text": "Yo, Pigsty is a local-first open-source alternative for RDS PostgreSQL, with monitoring, HA, PITR, IaC, and lots of stuff to run a production-grade PostgreSQL Service on your nodes for free.  Demo: http:&#x2F;&#x2F;demo.pigsty.cc.<p>* Battery-Included PostgreSQL Distribution, with PostGIS, TimescaleDB, Citus united as one.\n* Incredible observability powered by Prometheus &amp; Grafana stack.\n* Self-healing HA PGSQL cluster, powered by patroni, haproxy, etcd\u2026\n* Auto-Configured PITR, powered by pgbackrest and optional MinIO cluster\n* Declarative API, Database-as-Code implemented with Ansible playbooks.\n* Versatile UseCases, Run Docker Apps, Run demos, Visualize data with ECharts panels.\n* Install in one command, provision IaaS with Terraform, and test with local Vagrant sandbox.<p>Features: https:&#x2F;&#x2F;github.com&#x2F;Vonng&#x2F;pigsty&#x2F;blob&#x2F;master&#x2F;docs&#x2F;FEATURE.md<p>I&#x27;m Vonng, the author of Pigsty and a PostgreSQL DBA of a large deployment (25K cores, 1PB TP data). Pigsty alleviates my pain of managing such a massive elephant in production.<p>It works well for us, and I&#x27;m glad to make it open-source. Since cloud RDS PostgreSQL are so expensive, sometimes it charges 10x compared to underlying EC2 and storage. An open-source alternative could help.<p>I&#x27;m happy to answer any questions about Pigsty ;)", "title": "How about an open-source RDS alternative for PostgreSQL?", "updated_at": "2026-01-12T18:44:33Z"}], "hitsPerPage": 15, "nbHits": 161, "nbPages": 11, "page": 0, "params": "query=postgresql+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 25, "processingTimingsMS": {"_request": {"queue": 8, "roundTrip": 19}, "afterFetch": {"format": {"highlighting": 1, "total": 1}}, "fetch": {"query": 10, "scanning": 4, "total": 15}, "getIdx": {"load": {"gens": 2, "synonyms": 4, "total": 8}, "total": 8}, "total": 25}, "query": "postgresql production", "serverTimeMS": 35}}