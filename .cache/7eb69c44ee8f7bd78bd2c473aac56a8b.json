{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "rozumem"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "Simple Measures to Make Axios and <em>Express</em> <em>Production</em> Ready"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://rozumem.xyz/posts/5"}}, "_tags": ["story", "author_rozumem", "story_45050141"], "author": "rozumem", "created_at": "2025-08-28T09:23:57Z", "created_at_i": 1756373037, "num_comments": 0, "objectID": "45050141", "points": 2, "story_id": 45050141, "title": "Simple Measures to Make Axios and Express Production Ready", "updated_at": "2025-08-28T10:01:56Z", "url": "https://rozumem.xyz/posts/5"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "dceddia"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "Create React App with <em>Express</em> in <em>Production</em>"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "https://daveceddia.com/create-react-app-<em>express</em>-<em>production</em>/"}}, "_tags": ["story", "author_dceddia", "story_14547658"], "author": "dceddia", "created_at": "2017-06-13T19:09:49Z", "created_at_i": 1497380989, "num_comments": 0, "objectID": "14547658", "points": 2, "story_id": 14547658, "title": "Create React App with Express in Production", "updated_at": "2024-09-20T00:57:16Z", "url": "https://daveceddia.com/create-react-app-express-production/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "dprophecyguy"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "Hey we are starting to create this application for our startup and this is going to be our MVP. So the stack we were going through was Node(<em>Express</em>) + Angular + SQL. The problem arises when we start looking for ORM for <em>Express</em> - SQL. And then developing Authentication , Authorisation Module and then comes API's. Suddenly we found this miracle baby the solution of everything Loopback. But then i realize nobody in our team has worked on it. We are ready to learn for sake of development but we want to be sure that it is what they are saying it is. \nSo if anyone has any knowledge regarding Loopback and <em>Express</em> in <em>production</em> feel free to <em>express</em> his/her views. \nYou are providing a lot of values in our life so thanks for it already."}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["express"], "value": "Ask HN: <em>Express</em> vs. Loopback. Want a real review for my next startup"}}, "_tags": ["story", "author_dprophecyguy", "story_14775458", "ask_hn"], "author": "dprophecyguy", "children": [14776775], "created_at": "2017-07-15T07:19:50Z", "created_at_i": 1500103190, "num_comments": 0, "objectID": "14775458", "points": 2, "story_id": 14775458, "story_text": "Hey we are starting to create this application for our startup and this is going to be our MVP. So the stack we were going through was Node(Express) + Angular + SQL. The problem arises when we start looking for ORM for Express - SQL. And then developing Authentication , Authorisation Module and then comes API&#x27;s. Suddenly we found this miracle baby the solution of everything Loopback. But then i realize nobody in our team has worked on it. We are ready to learn for sake of development but we want to be sure that it is what they are saying it is. \nSo if anyone has any knowledge regarding Loopback and Express in production feel free to express his&#x2F;her views. \nYou are providing a lot of values in our life so thanks for it already.", "title": "Ask HN: Express vs. Loopback. Want a real review for my next startup", "updated_at": "2024-09-20T01:06:29Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "todsacerdoti"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "Writing a <em>Production</em> Ready <em>Express</em> Server"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "https://hackernoon.com/writing-a-<em>production</em>-ready-<em>express</em>-server-a-step-by-step-guide-2k6732x5"}}, "_tags": ["story", "author_todsacerdoti", "story_23130714"], "author": "todsacerdoti", "created_at": "2020-05-10T06:30:00Z", "created_at_i": 1589092200, "num_comments": 0, "objectID": "23130714", "points": 4, "story_id": 23130714, "title": "Writing a Production Ready Express Server", "updated_at": "2024-09-20T06:10:51Z", "url": "https://hackernoon.com/writing-a-production-ready-express-server-a-step-by-step-guide-2k6732x5"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "Liriel"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "<em>Express</em>.js in <em>production</em> best practices: performance and reliability"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://expressjs.com/en/advanced/best-practice-performance.html"}}, "_tags": ["story", "author_Liriel", "story_24502778"], "author": "Liriel", "created_at": "2020-09-17T09:53:50Z", "created_at_i": 1600336430, "num_comments": 0, "objectID": "24502778", "points": 1, "story_id": 24502778, "title": "Express.js in production best practices: performance and reliability", "updated_at": "2024-09-20T06:53:34Z", "url": "https://expressjs.com/en/advanced/best-practice-performance.html"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "md-adil"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "Hi HN \u2014 I\u2019m building Minima.js, a backend framework that tries to feel \u201cnative\u201d to the platform by leaning into Web standards and keeping request/response handling close to the primitives (e.g., Request/Response style APIs), instead of inventing a big framework-specific universe.<p>Intro: <a href=\"https://minimajs.com/intro.md\" rel=\"nofollow\">https://minimajs.com/intro.md</a><p>The five core ideas I\u2019m most excited about:<p>1. Runtime-Native Support - Built from scratch for Bun and Node.js with zero abstractions<p>2. Web Standard First - Uses native Request, Response, File, Blob, and Uint8Array throughout \u2014 no Node.js-specific buffers or proprietary abstractions<p>3. File-Based Modules - Your folder structure defines your API structure<p>4. Context Functions - Access request data anywhere without prop drilling<p>5. Everything is a Plugin - Hooks, middleware, auth\u2014all follow the same pattern<p>Docs: <a href=\"https://minimajs.com\" rel=\"nofollow\">https://minimajs.com</a><p>LLM-friendly docs index: <a href=\"https://minimajs.com/llms.txt\" rel=\"nofollow\">https://minimajs.com/llms.txt</a><p>Would love feedback from people who\u2019ve shipped <em>production</em> Node/Fastify/<em>Express</em> apps: does \u201cweb-standards + ALS-first context\u201d resonate, and what would you want to see before trying it?"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Minima.js \u2013 a web-standards back end framework with req context via ALS"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://minimajs.com"}}, "_tags": ["story", "author_md-adil", "story_47179206", "show_hn"], "author": "md-adil", "created_at": "2026-02-27T11:19:56Z", "created_at_i": 1772191196, "num_comments": 0, "objectID": "47179206", "points": 1, "story_id": 47179206, "story_text": "Hi HN \u2014 I\u2019m building Minima.js, a backend framework that tries to feel \u201cnative\u201d to the platform by leaning into Web standards and keeping request&#x2F;response handling close to the primitives (e.g., Request&#x2F;Response style APIs), instead of inventing a big framework-specific universe.<p>Intro: <a href=\"https:&#x2F;&#x2F;minimajs.com&#x2F;intro.md\" rel=\"nofollow\">https:&#x2F;&#x2F;minimajs.com&#x2F;intro.md</a><p>The five core ideas I\u2019m most excited about:<p>1. Runtime-Native Support - Built from scratch for Bun and Node.js with zero abstractions<p>2. Web Standard First - Uses native Request, Response, File, Blob, and Uint8Array throughout \u2014 no Node.js-specific buffers or proprietary abstractions<p>3. File-Based Modules - Your folder structure defines your API structure<p>4. Context Functions - Access request data anywhere without prop drilling<p>5. Everything is a Plugin - Hooks, middleware, auth\u2014all follow the same pattern<p>Docs: <a href=\"https:&#x2F;&#x2F;minimajs.com\" rel=\"nofollow\">https:&#x2F;&#x2F;minimajs.com</a><p>LLM-friendly docs index: <a href=\"https:&#x2F;&#x2F;minimajs.com&#x2F;llms.txt\" rel=\"nofollow\">https:&#x2F;&#x2F;minimajs.com&#x2F;llms.txt</a><p>Would love feedback from people who\u2019ve shipped production Node&#x2F;Fastify&#x2F;Express apps: does \u201cweb-standards + ALS-first context\u201d resonate, and what would you want to see before trying it?", "title": "Show HN: Minima.js \u2013 a web-standards back end framework with req context via ALS", "updated_at": "2026-02-27T11:25:38Z", "url": "https://minimajs.com"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "banna2"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "How to write <em>production</em>-ready Node and <em>express</em> app"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "https://101node.io/blog/how-to-write-<em>production</em>-ready-node-<em>express</em>-app/"}}, "_tags": ["story", "author_banna2", "story_18105461"], "author": "banna2", "created_at": "2018-09-30T09:57:57Z", "created_at_i": 1538301477, "num_comments": 0, "objectID": "18105461", "points": 1, "story_id": 18105461, "title": "How to write production-ready Node and express app", "updated_at": "2024-09-20T03:04:39Z", "url": "https://101node.io/blog/how-to-write-production-ready-node-express-app/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "clumsysmurf"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "China's mature chips to make up 28% of world <em>production</em>, creating oversupply"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "https://www.tomshardware.com/tech-industry/chinas-mature-chips-to-make-up-28-percent-of-world-<em>production</em>-creating-oversupply-western-companies-<em>express</em>-concern-for-their-survival"}}, "_tags": ["story", "author_clumsysmurf", "story_43213325"], "author": "clumsysmurf", "children": [43213446, 43213484], "created_at": "2025-02-28T23:35:56Z", "created_at_i": 1740785756, "num_comments": 2, "objectID": "43213325", "points": 4, "story_id": 43213325, "title": "China's mature chips to make up 28% of world production, creating oversupply", "updated_at": "2025-03-01T12:59:20Z", "url": "https://www.tomshardware.com/tech-industry/chinas-mature-chips-to-make-up-28-percent-of-world-production-creating-oversupply-western-companies-express-concern-for-their-survival"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "ksec"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "China's mature chips to make up 28% of world <em>production</em>, creating oversupply"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "https://www.tomshardware.com/tech-industry/chinas-mature-chips-to-make-up-28-percent-of-world-<em>production</em>-creating-oversupply-western-companies-<em>express</em>-concern-for-their-survival"}}, "_tags": ["story", "author_ksec", "story_43220171"], "author": "ksec", "children": [43220326, 43220374], "created_at": "2025-03-01T15:26:06Z", "created_at_i": 1740842766, "num_comments": 1, "objectID": "43220171", "points": 3, "story_id": 43220171, "title": "China's mature chips to make up 28% of world production, creating oversupply", "updated_at": "2025-03-01T17:59:05Z", "url": "https://www.tomshardware.com/tech-industry/chinas-mature-chips-to-make-up-28-percent-of-world-production-creating-oversupply-western-companies-express-concern-for-their-survival"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "rohinbharg"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "A project we've been working on for some time that allows you to incrementally adopt modern open standards on top of existing <em>express</em> endpoints.<p>The framework is being used in <em>production</em> by a handful of companies, while the CLI is still in beta."}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["express"], "value": "Show HN: ForkLaunch framework: Upgrading <em>Express</em> with a fully typed DSL"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/forklaunch/forklaunch-js"}}, "_tags": ["story", "author_rohinbharg", "story_45240417", "show_hn"], "author": "rohinbharg", "children": [45240581], "created_at": "2025-09-14T15:16:01Z", "created_at_i": 1757862961, "num_comments": 1, "objectID": "45240417", "points": 9, "story_id": 45240417, "story_text": "A project we&#x27;ve been working on for some time that allows you to incrementally adopt modern open standards on top of existing express endpoints.<p>The framework is being used in production by a handful of companies, while the CLI is still in beta.", "title": "Show HN: ForkLaunch framework: Upgrading Express with a fully typed DSL", "updated_at": "2025-09-15T14:44:59Z", "url": "https://github.com/forklaunch/forklaunch-js"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "mike210"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "Everyone hates <em>production</em> bugs. Users get frustrated.  Engineers get paged.  Development gets delayed.  But what if many of those bugs could be fixed automatically?<p>Enter Paladin, a tool I built that automatically sends you a pull request to fix bugs shortly after they occur.<p>A little over a month ago, I posted my hacky but effective AI setup for fixing <em>production</em> bugs to Reddit (<a href=\"https://redd.it/1jibmtc\" rel=\"nofollow\">https://redd.it/1jibmtc</a>).  300+ devs messaged me or commented wanting to try it out, so I\u2019ve been spending the past weeks refining it into Paladin, and excited to release it today!<p>How it works:<p>Paladin hooks into your application\u2019s error handling with an SDK, triggering a \u201crun\u201d when an exception is thrown.  During the run, Paladin pulls your code on Github and uses LLMs to fix the error, sending you the fix as a PR over Slack in ~90 seconds.   Here\u2019s a two minute demo: <a href=\"https://youtu.be/0bm8nq99Nrw\" rel=\"nofollow\">https://youtu.be/0bm8nq99Nrw</a>.<p>In early testing, Paladin solves over 55% of real <em>production</em> errors on the first try and makes useful progress on many others.  It\u2019s able to do well by supplying deep context to the LLMs: the stack trace, execution state, repo code, and more.  When it works well, it allows you to fix bugs more quickly, meaning less downtime for users and saved engineering time.<p>Eliminating context switching has been an unexpected win for me, because I work best in long, focused stretches.  When a bug hits affecting real users,  I have to drop everything mid-feature to stash changes, debug, and mentally shift contexts, and then try to return. I\u2019ve found PR reviews and tweaks to be much less disruptive.<p>Getting started (Free, no card required)\n1. Sign up at <a href=\"https://app.paladin.run/signup\" rel=\"nofollow\">https://app.paladin.run/signup</a>\n2. Follow instructions to connect your Github and Slack (or just email)\n3. Choose and install the correct SDK into your app\n4. Configure to send errors to Paladin\n5. Done!<p>Paladin supports React, React Native, Laravel, Flutter, Django, Node, Next, Vanilla Javascript, <em>Express</em>, FastAPI, PHP, Vanilla Python, Nest, Vue, Android, iOS, Rails, Flask, and many more  thanks to Sentry\u2019s MIT licensed client SDKs (your errors do not go to Sentry, they are just used to capture errors).  If you have a client and server, I\u2019d start with your server.<p>Notes on privacy, performance, and future plans below:<p>Paladin will never abuse repo access for any type of training or sharing, and only pulls it for making fixes.  An LLM provider (Google/Anthropic/OpenAI) processes part of your code, so if you can\u2019t use tools like Cursor/Windsurf, you probably can\u2019t use Paladin.<p>On performance, my personal set is admittedly very limited, but I think the performance makes sense to me given current bests on benchmarks like Aider Polyglot and SWE-bench Verified.  I\u2019d expect these numbers to get much better as models progress. I\u2019d also expect Paladin to fall short where current frontier LLMs do: uncommon frameworks, libraries or languages.<p>In the future, I am planning on having two usage options:\n- Free: if you bring your own OpenRouter API key\n- Paid: if Paladin pays for the model costs<p>Really looking forward to hearing feedback and ideas!"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Show HN: Paladin \u2013 An AI trigger to fix your sh*t <em>production</em> bugs"}}, "_tags": ["story", "author_mike210", "story_43906288", "show_hn"], "author": "mike210", "created_at": "2025-05-06T15:32:21Z", "created_at_i": 1746545541, "num_comments": 0, "objectID": "43906288", "points": 5, "story_id": 43906288, "story_text": "Everyone hates production bugs. Users get frustrated.  Engineers get paged.  Development gets delayed.  But what if many of those bugs could be fixed automatically?<p>Enter Paladin, a tool I built that automatically sends you a pull request to fix bugs shortly after they occur.<p>A little over a month ago, I posted my hacky but effective AI setup for fixing production bugs to Reddit (<a href=\"https:&#x2F;&#x2F;redd.it&#x2F;1jibmtc\" rel=\"nofollow\">https:&#x2F;&#x2F;redd.it&#x2F;1jibmtc</a>).  300+ devs messaged me or commented wanting to try it out, so I\u2019ve been spending the past weeks refining it into Paladin, and excited to release it today!<p>How it works:<p>Paladin hooks into your application\u2019s error handling with an SDK, triggering a \u201crun\u201d when an exception is thrown.  During the run, Paladin pulls your code on Github and uses LLMs to fix the error, sending you the fix as a PR over Slack in ~90 seconds.   Here\u2019s a two minute demo: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;0bm8nq99Nrw\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;0bm8nq99Nrw</a>.<p>In early testing, Paladin solves over 55% of real production errors on the first try and makes useful progress on many others.  It\u2019s able to do well by supplying deep context to the LLMs: the stack trace, execution state, repo code, and more.  When it works well, it allows you to fix bugs more quickly, meaning less downtime for users and saved engineering time.<p>Eliminating context switching has been an unexpected win for me, because I work best in long, focused stretches.  When a bug hits affecting real users,  I have to drop everything mid-feature to stash changes, debug, and mentally shift contexts, and then try to return. I\u2019ve found PR reviews and tweaks to be much less disruptive.<p>Getting started (Free, no card required)\n1. Sign up at <a href=\"https:&#x2F;&#x2F;app.paladin.run&#x2F;signup\" rel=\"nofollow\">https:&#x2F;&#x2F;app.paladin.run&#x2F;signup</a>\n2. Follow instructions to connect your Github and Slack (or just email)\n3. Choose and install the correct SDK into your app\n4. Configure to send errors to Paladin\n5. Done!<p>Paladin supports React, React Native, Laravel, Flutter, Django, Node, Next, Vanilla Javascript, Express, FastAPI, PHP, Vanilla Python, Nest, Vue, Android, iOS, Rails, Flask, and many more  thanks to Sentry\u2019s MIT licensed client SDKs (your errors do not go to Sentry, they are just used to capture errors).  If you have a client and server, I\u2019d start with your server.<p>Notes on privacy, performance, and future plans below:<p>Paladin will never abuse repo access for any type of training or sharing, and only pulls it for making fixes.  An LLM provider (Google&#x2F;Anthropic&#x2F;OpenAI) processes part of your code, so if you can\u2019t use tools like Cursor&#x2F;Windsurf, you probably can\u2019t use Paladin.<p>On performance, my personal set is admittedly very limited, but I think the performance makes sense to me given current bests on benchmarks like Aider Polyglot and SWE-bench Verified.  I\u2019d expect these numbers to get much better as models progress. I\u2019d also expect Paladin to fall short where current frontier LLMs do: uncommon frameworks, libraries or languages.<p>In the future, I am planning on having two usage options:\n- Free: if you bring your own OpenRouter API key\n- Paid: if Paladin pays for the model costs<p>Really looking forward to hearing feedback and ideas!", "title": "Show HN: Paladin \u2013 An AI trigger to fix your sh*t production bugs", "updated_at": "2025-05-06T16:19:46Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "graposaymaname"}, "story_text": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "We're currently trying to build a <em>production</em> level REST API service. Which would be the best choice and why?"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["express"], "value": "Ask HN: <em>Express</em> vs. Restify vs. Loopback"}}, "_tags": ["story", "author_graposaymaname", "story_17490157", "ask_hn"], "author": "graposaymaname", "created_at": "2018-07-09T13:57:38Z", "created_at_i": 1531144658, "num_comments": 0, "objectID": "17490157", "points": 3, "story_id": 17490157, "story_text": "We&#x27;re currently trying to build a production level REST API service. Which would be the best choice and why?", "title": "Ask HN: Express vs. Restify vs. Loopback", "updated_at": "2024-09-20T02:46:53Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "borjapazr"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "<em>Production</em>-ready template for back ends created with Node.js, TS and <em>Express</em>"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["express"], "value": "https://github.com/borjapazr/<em>express</em>-typescript-skeleton"}}, "_tags": ["story", "author_borjapazr", "story_29329398"], "author": "borjapazr", "children": [29329399], "created_at": "2021-11-24T12:41:56Z", "created_at_i": 1637757716, "num_comments": 1, "objectID": "29329398", "points": 2, "story_id": 29329398, "title": "Production-ready template for back ends created with Node.js, TS and Express", "updated_at": "2024-09-20T09:50:20Z", "url": "https://github.com/borjapazr/express-typescript-skeleton"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "mariuz"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["express"], "value": "AWS Announcing Amazon ECS <em>Express</em> Mode"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "https://aws.amazon.com/blogs/aws/build-<em>production</em>-ready-applications-without-infrastructure-complexity-using-amazon-ecs-<em>express</em>-mode/"}}, "_tags": ["story", "author_mariuz", "story_46034866"], "author": "mariuz", "children": [46034982], "created_at": "2025-11-24T15:02:11Z", "created_at_i": 1763996531, "num_comments": 1, "objectID": "46034866", "points": 1, "story_id": 46034866, "title": "AWS Announcing Amazon ECS Express Mode", "updated_at": "2025-11-24T15:20:28Z", "url": "https://aws.amazon.com/blogs/aws/build-production-ready-applications-without-infrastructure-complexity-using-amazon-ecs-express-mode/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "hammadh"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["express", "production"], "value": "Hey HN, we are Mahmoud and Hammad, co-founders of Play.ht, a text-to-speech synthesis platform. We're building Large Language Speech Models across all languages with a focus on voice expressiveness and control.<p>Today, we are excited to share beta access to our latest model, Parrot, that is capable of cloning any voice with a few seconds of audio and generating expressive speech from text.<p>You can try it out here: <a href=\"https://playground.play.ht\">https://playground.play.ht</a>. And there are demo videos at <a href=\"https://www.youtube.com/watch?v=aL_hmxTLHiM\">https://www.youtube.com/watch?v=aL_hmxTLHiM</a> and <a href=\"https://www.youtube.com/watch?v=fdEEoODd6Kk\">https://www.youtube.com/watch?v=fdEEoODd6Kk</a>.<p>The model also captures accents well and is able to speak in all English accents. Even more interesting, it can make non-English speakers speak English while preserving their original accent. Just upload a non-English speaker clip and try it yourself.<p>Existing text to speech models either lack expressiveness, control or directability of the voice. For example, making a voice speak in a specific way, or emphasizing on a certain word or parts of the speech. Our goal is to solve these across all languages. Since the voices are built on LLMs they are able to <em>express</em> emotions based on the context of the text.<p>Our previous speech model, Peregrine, which we released last September, is able to laugh, scream and <em>express</em> other emotions: <a href=\"https://play.ht/blog/introducing-truly-realistic-text-to-speech-with-emotion-and-laughter/\">https://play.ht/blog/introducing-truly-realistic-text-to-spe...</a>. We posted it to HN here: <a href=\"https://news.ycombinator.com/item?id=32945504\" rel=\"nofollow\">https://news.ycombinator.com/item?id=32945504</a>.<p>With Parrot, we've taken a slightly different approach and trained it on a much larger data set. Both Parrot and Peregrine only speak English at the moment but we are working on other languages and are seeing impressive early results that we plan to share soon.<p>Content creators of all kinds (gaming, media <em>production</em>, elearning) spend a lot of time and effort recording and editing high-quality audio. We solve that and make it as simple as writing and editing text. Our users range from individual creators looking to voice their videos, podcasts, etc to teams at various companies creating dynamic audio content.<p>We initially built this product for ourselves to listen to books and articles online and then found the quality of TTS is very low, so we started working on this product until, eventually we trained our own models and built a business around it. There are many robotic TTS services out there, but ours allows people to generate truly human-level expressive speech and allows anyone to clone voices instantly with strong resemblance. We initially used existing TTS models and APIs but when we started talking to our customers in gaming, media <em>production</em>, and others, people didn't like the monotone robotic TTS style. So we doubled down in training a new model based on the new emerging architectures using transformers and self supervised learning.<p>On our platform, we offer two types of voice cloning: high-fidelity and zero-shot. High-fidelity voice cloning requires around 20 minutes of audio data and creates an expressive voice that is more robust and captures the accent of the target voice with all its nuances. Zero-shot clones the voice with only a few seconds of audio and captures most of the accent and tone, but isn\u2019t as nuanced because it has less data to work with. We also offer a diverse library of over a hundred voices for various use cases.<p>We offer two ways to use these models on the platform: (1) our text to voice editor, that allows users to create and manage their audio files in projects, etc.; and (2) our API - <a href=\"https://docs.play.ht/reference/api-getting-started\">https://docs.play.ht/reference/api-getting-started</a>. The API supports streaming and polling and we are working on reducing the latency to make it real time. We have a free plan and transparent pricing available for anyone to upgrade.<p>We are thrilled to be sharing our new model, and look forward to feedback!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: Play.ht (YC W23) \u2013 Generate and clone voices from 20 seconds of audio"}}, "_tags": ["story", "author_hammadh", "story_35328698", "launch_hn"], "author": "hammadh", "children": [35328760, 35328775, 35328797, 35328849, 35328855, 35328866, 35328869, 35328899, 35328990, 35329051, 35329123, 35329226, 35329279, 35329335, 35329345, 35329372, 35329435, 35329448, 35329457, 35329494, 35329498, 35329533, 35329548, 35329570, 35329578, 35329580, 35329617, 35329620, 35329674, 35329678, 35329692, 35329736, 35329745, 35329874, 35329989, 35330019, 35330123, 35330145, 35330161, 35330194, 35330230, 35330326, 35330344, 35330351, 35330403, 35330416, 35330431, 35330448, 35330450, 35330455, 35330457, 35330494, 35330555, 35330678, 35330889, 35330954, 35331008, 35331017, 35331034, 35331039, 35331072, 35331290, 35331354, 35331470, 35331679, 35331686, 35331872, 35331928, 35332058, 35332350, 35332474, 35332529, 35332738, 35332759, 35333171, 35333194, 35333402, 35333601, 35333608, 35333623, 35333675, 35333739, 35333743, 35333845, 35333941, 35334055, 35334062, 35334303, 35334384, 35334510, 35334520, 35334802, 35334824, 35335197, 35335246, 35335309, 35335616, 35336035, 35336443, 35336930, 35337149, 35337370, 35338449, 35338512, 35338745, 35338840, 35339295, 35339309, 35339417, 35345168, 35345946, 35347408, 35357149, 35389456, 35492014], "created_at": "2023-03-27T16:27:20Z", "created_at_i": 1679934440, "num_comments": 458, "objectID": "35328698", "points": 459, "story_id": 35328698, "story_text": "Hey HN, we are Mahmoud and Hammad, co-founders of Play.ht, a text-to-speech synthesis platform. We&#x27;re building Large Language Speech Models across all languages with a focus on voice expressiveness and control.<p>Today, we are excited to share beta access to our latest model, Parrot, that is capable of cloning any voice with a few seconds of audio and generating expressive speech from text.<p>You can try it out here: <a href=\"https:&#x2F;&#x2F;playground.play.ht\">https:&#x2F;&#x2F;playground.play.ht</a>. And there are demo videos at <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=aL_hmxTLHiM\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=aL_hmxTLHiM</a> and <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=fdEEoODd6Kk\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=fdEEoODd6Kk</a>.<p>The model also captures accents well and is able to speak in all English accents. Even more interesting, it can make non-English speakers speak English while preserving their original accent. Just upload a non-English speaker clip and try it yourself.<p>Existing text to speech models either lack expressiveness, control or directability of the voice. For example, making a voice speak in a specific way, or emphasizing on a certain word or parts of the speech. Our goal is to solve these across all languages. Since the voices are built on LLMs they are able to express emotions based on the context of the text.<p>Our previous speech model, Peregrine, which we released last September, is able to laugh, scream and express other emotions: <a href=\"https:&#x2F;&#x2F;play.ht&#x2F;blog&#x2F;introducing-truly-realistic-text-to-speech-with-emotion-and-laughter&#x2F;\">https:&#x2F;&#x2F;play.ht&#x2F;blog&#x2F;introducing-truly-realistic-text-to-spe...</a>. We posted it to HN here: <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=32945504\" rel=\"nofollow\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=32945504</a>.<p>With Parrot, we&#x27;ve taken a slightly different approach and trained it on a much larger data set. Both Parrot and Peregrine only speak English at the moment but we are working on other languages and are seeing impressive early results that we plan to share soon.<p>Content creators of all kinds (gaming, media production, elearning) spend a lot of time and effort recording and editing high-quality audio. We solve that and make it as simple as writing and editing text. Our users range from individual creators looking to voice their videos, podcasts, etc to teams at various companies creating dynamic audio content.<p>We initially built this product for ourselves to listen to books and articles online and then found the quality of TTS is very low, so we started working on this product until, eventually we trained our own models and built a business around it. There are many robotic TTS services out there, but ours allows people to generate truly human-level expressive speech and allows anyone to clone voices instantly with strong resemblance. We initially used existing TTS models and APIs but when we started talking to our customers in gaming, media production, and others, people didn&#x27;t like the monotone robotic TTS style. So we doubled down in training a new model based on the new emerging architectures using transformers and self supervised learning.<p>On our platform, we offer two types of voice cloning: high-fidelity and zero-shot. High-fidelity voice cloning requires around 20 minutes of audio data and creates an expressive voice that is more robust and captures the accent of the target voice with all its nuances. Zero-shot clones the voice with only a few seconds of audio and captures most of the accent and tone, but isn\u2019t as nuanced because it has less data to work with. We also offer a diverse library of over a hundred voices for various use cases.<p>We offer two ways to use these models on the platform: (1) our text to voice editor, that allows users to create and manage their audio files in projects, etc.; and (2) our API - <a href=\"https:&#x2F;&#x2F;docs.play.ht&#x2F;reference&#x2F;api-getting-started\">https:&#x2F;&#x2F;docs.play.ht&#x2F;reference&#x2F;api-getting-started</a>. The API supports streaming and polling and we are working on reducing the latency to make it real time. We have a free plan and transparent pricing available for anyone to upgrade.<p>We are thrilled to be sharing our new model, and look forward to feedback!", "title": "Launch HN: Play.ht (YC W23) \u2013 Generate and clone voices from 20 seconds of audio", "updated_at": "2025-12-19T05:10:26Z"}], "hitsPerPage": 15, "nbHits": 63, "nbPages": 5, "page": 0, "params": "query=express+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 13, "processingTimingsMS": {"_request": {"queue": 1, "roundTrip": 16}, "afterFetch": {"format": {"highlighting": 1, "total": 1}, "merge": {"mergeLoop": {"total": 1}, "total": 1}, "total": 1}, "fetch": {"query": 8, "scanning": 2, "total": 11}, "total": 13}, "query": "express production", "serverTimeMS": 16}}