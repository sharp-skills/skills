{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "aleclarsoniv"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["pg", "production"], "value": "Hey HN! I'm the creator of <em>pg</em>-nano. It's not an ORM, a query builder, or a basic query driver, but it's closest to the last one. The twist is, it's also a migration tool <i>and</i> a code generator. It's not <em>production</em>-ready yet (more on that below).<p>The link: https://github.com/<em>pg</em>-nano/<em>pg</em>-nano/<p>It generates TypeScript bindings for your native Postgres routines (think `CREATE FUNCTION` or `CREATE PROCEDURE`, sorry for yelling). For views (e.g. CREATE VIEW), <em>pg</em>-nano can infer each column's \u201cnullability\u201d via static analysis. I plan to extend that inference to user-defined routines in the near future, but the generated types are already quite good.<p>From your TypeScript application server, you call your Postgres routines with 100% type safety. The query driver uses libpq, the official C driver, under the hood. I've implemented a connection pool, auto-reconnect with exponential backoff, and query streaming on top of libpq.<p>It scans a directory for `.sql` files and instantly updates your local database instance by diffing the current schema with the desired schema. It only drops data if absolutely necessary. Note that I haven't implemented <em>production</em> migrations yet, which will of course err on the safe side.<p>I use a combination of static analysis (parsing your SQL) and introspection (querying Postgres system tables) at compile time to both generate the TypeScript bindings and the migration plan.<p>The link again: https://github.com/<em>pg</em>-nano/<em>pg</em>-nano/<p>~~~<p>I posted all this to get your feedback:<p>- Could you see yourself using <em>pg</em>-nano? Why or why not?<p>- Are there specific features you\u2019d like to see, or concerns you have?<p>I could really use some beta testers, but even your thoughts would help a great deal.<p>~~~<p>In order to get <em>pg</em>-nano <em>production</em> ready, I have a few things left to do.<p>1. Database seeding<p>2. Migrations in <em>production</em><p>3. Transactions"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: Seeking feedback on my Postgres TypeScript thing"}}, "_tags": ["story", "author_aleclarsoniv", "story_42425283", "ask_hn"], "author": "aleclarsoniv", "children": [42426884], "created_at": "2024-12-15T19:11:11Z", "created_at_i": 1734289871, "num_comments": 1, "objectID": "42425283", "points": 4, "story_id": 42425283, "story_text": "Hey HN! I&#x27;m the creator of pg-nano. It&#x27;s not an ORM, a query builder, or a basic query driver, but it&#x27;s closest to the last one. The twist is, it&#x27;s also a migration tool <i>and</i> a code generator. It&#x27;s not production-ready yet (more on that below).<p>The link: https:&#x2F;&#x2F;github.com&#x2F;pg-nano&#x2F;pg-nano&#x2F;<p>It generates TypeScript bindings for your native Postgres routines (think `CREATE FUNCTION` or `CREATE PROCEDURE`, sorry for yelling). For views (e.g. CREATE VIEW), pg-nano can infer each column&#x27;s \u201cnullability\u201d via static analysis. I plan to extend that inference to user-defined routines in the near future, but the generated types are already quite good.<p>From your TypeScript application server, you call your Postgres routines with 100% type safety. The query driver uses libpq, the official C driver, under the hood. I&#x27;ve implemented a connection pool, auto-reconnect with exponential backoff, and query streaming on top of libpq.<p>It scans a directory for `.sql` files and instantly updates your local database instance by diffing the current schema with the desired schema. It only drops data if absolutely necessary. Note that I haven&#x27;t implemented production migrations yet, which will of course err on the safe side.<p>I use a combination of static analysis (parsing your SQL) and introspection (querying Postgres system tables) at compile time to both generate the TypeScript bindings and the migration plan.<p>The link again: https:&#x2F;&#x2F;github.com&#x2F;pg-nano&#x2F;pg-nano&#x2F;<p>~~~<p>I posted all this to get your feedback:<p>- Could you see yourself using pg-nano? Why or why not?<p>- Are there specific features you\u2019d like to see, or concerns you have?<p>I could really use some beta testers, but even your thoughts would help a great deal.<p>~~~<p>In order to get pg-nano production ready, I have a few things left to do.<p>1. Database seeding<p>2. Migrations in production<p>3. Transactions", "title": "Ask HN: Seeking feedback on my Postgres TypeScript thing", "updated_at": "2024-12-16T00:10:02Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "aleclarsoniv"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["pg", "production"], "value": "Hey all, I'm the creator of @<em>pg</em>-nano/<em>pg</em>-parser. I'm using it in <em>pg</em>-nano[1] to statically analyze Postgres schemas spread across multiple SQL files for a couple of reasons:<p>1. Each CREATE statement needs to be in topological order, so <em>pg</em>-nano's dev command can execute them without issue.<p>2. <em>pg</em>-nano has a plugin system like Vite that allows SQL generation based on the parsed schema.<p>Probably to the surprise of no one, working with an untyped AST feels like you're back in the days of JavaScript, because well... you are. Most of you know by now just how great TypeScript and static types in general are, especially if you appreciate SQL.<p>So why is this project worth sharing with you?<p>Well, writing the AST type definitions by hand would have taken me way too much time. It would also be a bear to keep up-to-date as Postgres continues to evolve.<p>To my surprise, I discovered that libpg_query, the C library used under-the-hood, includes JSON definitions in their /srcdata/ folder. I figured I could use them to <i>generate</i> the type definitions. Genius, right? Okay... maybe not <i>genius</i>, but still cool, I think.<p>You see, those JSON definitions provided by libpg_query? They don't exactly contain the TypeScript definitions (was that obvious?). No, no. I had to <i>translate</i> them into TypeScript definitions. (I'm sure <i>you</i> could have done it, yes yes. But did you? No siree bob)<p>It was pain-staking, but overall really not too hard. Time-consuming? Yes, but not as much as writing the type definitions by hand. So... was it worth it? Only time will tell. I hope you find it as useful as I do. And that's all I've got, so thanks for reading.<p>P.S. The build for Windows is broken, so if anyone could lend a hand, you would be a true hero.<p>[1]: <a href=\"https://github.com/pg-nano/pg-nano\">https://github.com/<em>pg</em>-nano/<em>pg</em>-nano</a> (not ready for <em>production</em> use)"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Parse your Postgres queries into a fully-typed AST in TypeScript"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["pg"], "value": "https://github.com/<em>pg</em>-nano/<em>pg</em>-parser"}}, "_tags": ["story", "author_aleclarsoniv", "story_41576956", "show_hn"], "author": "aleclarsoniv", "children": [41582274, 41612650, 41613569, 41613768, 41614979, 41617540, 41618528, 41619472, 41619783, 41621946, 41628854], "created_at": "2024-09-18T07:49:34Z", "created_at_i": 1726645774, "num_comments": 21, "objectID": "41576956", "points": 116, "story_id": 41576956, "story_text": "Hey all, I&#x27;m the creator of @pg-nano&#x2F;pg-parser. I&#x27;m using it in pg-nano[1] to statically analyze Postgres schemas spread across multiple SQL files for a couple of reasons:<p>1. Each CREATE statement needs to be in topological order, so pg-nano&#x27;s dev command can execute them without issue.<p>2. pg-nano has a plugin system like Vite that allows SQL generation based on the parsed schema.<p>Probably to the surprise of no one, working with an untyped AST feels like you&#x27;re back in the days of JavaScript, because well... you are. Most of you know by now just how great TypeScript and static types in general are, especially if you appreciate SQL.<p>So why is this project worth sharing with you?<p>Well, writing the AST type definitions by hand would have taken me way too much time. It would also be a bear to keep up-to-date as Postgres continues to evolve.<p>To my surprise, I discovered that libpg_query, the C library used under-the-hood, includes JSON definitions in their &#x2F;srcdata&#x2F; folder. I figured I could use them to <i>generate</i> the type definitions. Genius, right? Okay... maybe not <i>genius</i>, but still cool, I think.<p>You see, those JSON definitions provided by libpg_query? They don&#x27;t exactly contain the TypeScript definitions (was that obvious?). No, no. I had to <i>translate</i> them into TypeScript definitions. (I&#x27;m sure <i>you</i> could have done it, yes yes. But did you? No siree bob)<p>It was pain-staking, but overall really not too hard. Time-consuming? Yes, but not as much as writing the type definitions by hand. So... was it worth it? Only time will tell. I hope you find it as useful as I do. And that&#x27;s all I&#x27;ve got, so thanks for reading.<p>P.S. The build for Windows is broken, so if anyone could lend a hand, you would be a true hero.<p>[1]: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;pg-nano&#x2F;pg-nano\">https:&#x2F;&#x2F;github.com&#x2F;pg-nano&#x2F;pg-nano</a> (not ready for production use)", "title": "Show HN: Parse your Postgres queries into a fully-typed AST in TypeScript", "updated_at": "2025-07-10T23:20:38Z", "url": "https://github.com/pg-nano/pg-parser"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "rastignack"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["pg", "production"], "value": "The <em>Pg</em>_tde Extension Is Now Ready for <em>Production</em>"}, "url": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["pg", "production"], "value": "https://www.percona.com/blog/the-<em>pg</em>_tde-extension-is-now-ready-for-<em>production</em>/"}}, "_tags": ["story", "author_rastignack", "story_44464724"], "author": "rastignack", "created_at": "2025-07-04T14:08:59Z", "created_at_i": 1751638139, "num_comments": 0, "objectID": "44464724", "points": 2, "story_id": 44464724, "title": "The Pg_tde Extension Is Now Ready for Production", "updated_at": "2025-10-18T14:39:58Z", "url": "https://www.percona.com/blog/the-pg_tde-extension-is-now-ready-for-production/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "denchick"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "SPQR 1.3.0: a <em>production</em>-ready system for horizontal scaling of PostgreSQL"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["pg"], "value": "https://github.com/<em>pg</em>-sharding/spqr/discussions/569"}}, "_tags": ["story", "author_denchick", "story_39814877"], "author": "denchick", "children": [39815013, 39815083, 39815115, 39815367, 39815375, 39815419, 39816027, 39816129, 39816976, 39820394], "created_at": "2024-03-25T11:24:39Z", "created_at_i": 1711365879, "num_comments": 71, "objectID": "39814877", "points": 185, "story_id": 39814877, "title": "SPQR 1.3.0: a production-ready system for horizontal scaling of PostgreSQL", "updated_at": "2025-09-13T20:56:37Z", "url": "https://github.com/pg-sharding/spqr/discussions/569"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "BlackCherry"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["pg"], "value": "NSCAI Eric Schmidt says Mass Surveillance killer tool/opportunity <em>pg</em> 88-99 [PDF] (2019)"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "https://epic.org/foia/epic-v-ai-commission/EPIC-19-09-11-NSCAI-FOIA-20200331-3rd-<em>Production</em>-pt9.pdf"}}, "_tags": ["story", "author_BlackCherry", "story_24145148"], "author": "BlackCherry", "children": [24145880, 24146737, 24146775, 24148210, 24148233, 24152109], "created_at": "2020-08-13T16:29:14Z", "created_at_i": 1597336154, "num_comments": 12, "objectID": "24145148", "points": 40, "story_id": 24145148, "title": "NSCAI Eric Schmidt says Mass Surveillance killer tool/opportunity pg 88-99 [PDF] (2019)", "updated_at": "2024-09-20T06:46:41Z", "url": "https://epic.org/foia/epic-v-ai-commission/EPIC-19-09-11-NSCAI-FOIA-20200331-3rd-Production-pt9.pdf"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "denchick"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "SPQR 1.5.0: a <em>production</em>-ready system for horizontal scaling of PostgreSQL"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["pg"], "value": "https://github.com/<em>pg</em>-sharding/spqr/discussions/724"}}, "_tags": ["story", "author_denchick", "story_41007281"], "author": "denchick", "children": [41007282, 41007467, 41007475, 41007511, 41007618, 41008551, 41009055], "created_at": "2024-07-19T15:07:44Z", "created_at_i": 1721401664, "num_comments": 4, "objectID": "41007281", "points": 12, "story_id": 41007281, "title": "SPQR 1.5.0: a production-ready system for horizontal scaling of PostgreSQL", "updated_at": "2024-09-20T17:23:48Z", "url": "https://github.com/pg-sharding/spqr/discussions/724"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "moomoo11"}, "story_text": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["pg"], "value": "Please share any experiences. I'm specifically evaluating Neo4j and my sandbox testing is going well so far but I'm curious to hear from people who have far more experience.<p>FWIW I have a graph use case implemented with <em>pg</em> where I'm running into issues with recursive queries, whereas the neo4j queries are far better performant and easier to reason."}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Ask HN: Anyone use graph db in <em>production</em>/at scale? Like Neo4j or Arangodb?"}}, "_tags": ["story", "author_moomoo11", "story_40695570", "ask_hn"], "author": "moomoo11", "children": [40698065, 40702926, 40715270], "created_at": "2024-06-16T08:27:09Z", "created_at_i": 1718526429, "num_comments": 6, "objectID": "40695570", "points": 4, "story_id": 40695570, "story_text": "Please share any experiences. I&#x27;m specifically evaluating Neo4j and my sandbox testing is going well so far but I&#x27;m curious to hear from people who have far more experience.<p>FWIW I have a graph use case implemented with pg where I&#x27;m running into issues with recursive queries, whereas the neo4j queries are far better performant and easier to reason.", "title": "Ask HN: Anyone use graph db in production/at scale? Like Neo4j or Arangodb?", "updated_at": "2024-12-17T02:17:48Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "shayonj"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Rails Postgres ActiveRecord patches for common <em>production</em> workloads"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["pg"], "value": "https://github.com/tines/rails-<em>pg</em>-adapter"}}, "_tags": ["story", "author_shayonj", "story_35360327"], "author": "shayonj", "created_at": "2023-03-29T17:22:56Z", "created_at_i": 1680110576, "num_comments": 0, "objectID": "35360327", "points": 4, "story_id": 35360327, "title": "Rails Postgres ActiveRecord patches for common production workloads", "updated_at": "2024-09-20T13:39:56Z", "url": "https://github.com/tines/rails-pg-adapter"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "jeremy_k"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["pg", "production"], "value": "Lately, I've seen a lot of companies with offerings for remote development environments and preview / ephemeral environments (disclaimer, I work for one of these companies).<p>However because so many people seem to have solved this issue (each with their own twist though), I've been thinking about that creating the environments and deploying them may not be the important part? Perhaps it is the DX around the data that is supplied to these environments. I think the data can come in a few different manners:<p>* A brand new database with the correct schema attached, however there is no data. This is useful to be able to use the environment, but a pain if you have to insert a lot of data to be able to use the environment. This is probably the easiest and could be done through a container running Postgres/Mysql/etc<p>* A database with the correct schema and some seed data. This fixes the scaffolding issue so the environment is immediately usable but doesn't allow for reproducing bugs from <em>production</em>. Again, this could be done through a container.<p>* A <em>production</em> cloned database. This allows for debugging any <em>production</em> bugs or issues. However without being able to scrub PII from the data, this opens security concerns. This approach could be done through a container, but doing say <em>pg</em>_restore into a container is going to make the startup time for this environment a lot slower. Another approach is to use something like RDS and backup snapshots to create the clones and have them ready to be used by an environment before hand.<p>* A scrubbed <em>production</em> clone. Same as above, but with all the PII removed. I think this is the top tier and would give the most benefits to developers without the security concerns.<p>I'm curious what other peoples thoughts are around this topic and how / if your company is providing <em>production</em> like data to the development process?"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Ask HN: How important is <em>production</em> like data to your development process?"}}, "_tags": ["story", "author_jeremy_k", "story_36632953", "ask_hn"], "author": "jeremy_k", "children": [36633328, 36634077], "created_at": "2023-07-07T15:13:43Z", "created_at_i": 1688742823, "num_comments": 5, "objectID": "36632953", "points": 3, "story_id": 36632953, "story_text": "Lately, I&#x27;ve seen a lot of companies with offerings for remote development environments and preview &#x2F; ephemeral environments (disclaimer, I work for one of these companies).<p>However because so many people seem to have solved this issue (each with their own twist though), I&#x27;ve been thinking about that creating the environments and deploying them may not be the important part? Perhaps it is the DX around the data that is supplied to these environments. I think the data can come in a few different manners:<p>* A brand new database with the correct schema attached, however there is no data. This is useful to be able to use the environment, but a pain if you have to insert a lot of data to be able to use the environment. This is probably the easiest and could be done through a container running Postgres&#x2F;Mysql&#x2F;etc<p>* A database with the correct schema and some seed data. This fixes the scaffolding issue so the environment is immediately usable but doesn&#x27;t allow for reproducing bugs from production. Again, this could be done through a container.<p>* A production cloned database. This allows for debugging any production bugs or issues. However without being able to scrub PII from the data, this opens security concerns. This approach could be done through a container, but doing say pg_restore into a container is going to make the startup time for this environment a lot slower. Another approach is to use something like RDS and backup snapshots to create the clones and have them ready to be used by an environment before hand.<p>* A scrubbed production clone. Same as above, but with all the PII removed. I think this is the top tier and would give the most benefits to developers without the security concerns.<p>I&#x27;m curious what other peoples thoughts are around this topic and how &#x2F; if your company is providing production like data to the development process?", "title": "Ask HN: How important is production like data to your development process?", "updated_at": "2024-09-20T14:33:59Z"}, {"_highlightResult": {"author": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["pg"], "value": "<em>pg</em>_1234"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Sam Altman wants 'trillions of dollars' to jumpstart global AI chip <em>production</em>"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "https://nypost.com/2024/02/09/business/sam-altman-wants-trillions-of-dollars-to-jumpstart-global-ai-chip-<em>production</em>-report/"}}, "_tags": ["story", "author_pg_1234", "story_39318010"], "author": "pg_1234", "children": [39318065], "created_at": "2024-02-09T17:57:18Z", "created_at_i": 1707501438, "num_comments": 1, "objectID": "39318010", "points": 3, "story_id": 39318010, "title": "Sam Altman wants 'trillions of dollars' to jumpstart global AI chip production", "updated_at": "2024-09-20T16:22:36Z", "url": "https://nypost.com/2024/02/09/business/sam-altman-wants-trillions-of-dollars-to-jumpstart-global-ai-chip-production-report/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "stupidcar"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Reinventing <em>Production</em> at Tesla"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["pg"], "value": "http://www.mljournal-digital.com/meleadershipjournal/october_2016?<em>pg</em>=10#pg10"}}, "_tags": ["story", "author_stupidcar", "story_13390537"], "author": "stupidcar", "created_at": "2017-01-13T13:13:20Z", "created_at_i": 1484313200, "num_comments": 0, "objectID": "13390537", "points": 3, "story_id": 13390537, "title": "Reinventing Production at Tesla", "updated_at": "2024-09-20T00:18:01Z", "url": "http://www.mljournal-digital.com/meleadershipjournal/october_2016?pg=10#pg10"}, {"_highlightResult": {"author": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["pg"], "value": "<em>pg</em>_1234"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "FAA says Boeing 737 MAX 9 planes can fly; <em>production</em> ramp-up halted \u2013 Nasdaq"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "https://www.nasdaq.com/articles/faa-says-boeing-737-max-9-planes-can-fly-<em>production</em>-ramp-up-halted"}}, "_tags": ["story", "author_pg_1234", "story_39124505"], "author": "pg_1234", "children": [39125708], "created_at": "2024-01-25T00:17:14Z", "created_at_i": 1706141834, "num_comments": 1, "objectID": "39124505", "points": 2, "story_id": 39124505, "title": "FAA says Boeing 737 MAX 9 planes can fly; production ramp-up halted \u2013 Nasdaq", "updated_at": "2024-09-20T16:12:10Z", "url": "https://www.nasdaq.com/articles/faa-says-boeing-737-max-9-planes-can-fly-production-ramp-up-halted"}, {"_highlightResult": {"author": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["pg"], "value": "<em>pg</em>_1234"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Volkswagen hit by IT outage, VW vehicle <em>production</em> in Germany halted"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://www.reuters.com/business/autos-transportation/it-disruption-paralyses-volkswagens-central-infrastructure-2023-09-27/"}}, "_tags": ["story", "author_pg_1234", "story_37687088"], "author": "pg_1234", "children": [37687092], "created_at": "2023-09-28T09:01:30Z", "created_at_i": 1695891690, "num_comments": 1, "objectID": "37687088", "points": 2, "story_id": 37687088, "title": "Volkswagen hit by IT outage, VW vehicle production in Germany halted", "updated_at": "2024-09-20T15:17:20Z", "url": "https://www.reuters.com/business/autos-transportation/it-disruption-paralyses-volkswagens-central-infrastructure-2023-09-27/"}, {"_highlightResult": {"author": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["pg"], "value": "<em>pg</em>_1234"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Machinist strike at Spirit in Wichita could shut down Boeing <em>production</em>"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "https://www.seattletimes.com/business/boeing-aerospace/machinist-strike-at-spirit-in-wichita-could-shut-down-boeing-<em>production</em>/"}}, "_tags": ["story", "author_pg_1234", "story_36434989"], "author": "pg_1234", "created_at": "2023-06-22T16:47:08Z", "created_at_i": 1687452428, "num_comments": 0, "objectID": "36434989", "points": 1, "story_id": 36434989, "title": "Machinist strike at Spirit in Wichita could shut down Boeing production", "updated_at": "2024-09-20T14:24:59Z", "url": "https://www.seattletimes.com/business/boeing-aerospace/machinist-strike-at-spirit-in-wichita-could-shut-down-boeing-production/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "bootload"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Free, as in Beer (Lessig: superflex, nonmarket peer <em>production</em>, make consumers producers)"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["pg"], "value": "http://www.wired.com/wired/archive/14.09/posts.html?<em>pg</em>=6"}}, "_tags": ["story", "author_bootload", "story_31844"], "author": "bootload", "created_at": "2007-07-01T07:27:53Z", "created_at_i": 1183274873, "num_comments": 0, "objectID": "31844", "points": 1, "story_id": 31844, "title": "Free, as in Beer (Lessig: superflex, nonmarket peer production, make consumers producers)", "updated_at": "2024-09-19T16:20:15Z", "url": "http://www.wired.com/wired/archive/14.09/posts.html?pg=6"}], "hitsPerPage": 15, "nbHits": 38, "nbPages": 3, "page": 0, "params": "query=pg+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 6, "processingTimingsMS": {"_request": {"roundTrip": 18}, "fetch": {"query": 3, "scanning": 1, "total": 5}, "total": 6}, "query": "pg production", "serverTimeMS": 7}}