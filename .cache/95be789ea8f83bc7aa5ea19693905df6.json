{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "RobTheFrog"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["puppeteer", "production"], "value": "Hey HN,<p>I built a REST API for capturing screenshots and generating PDFs from URLs.<p>Why: I got tired of managing <em>Puppeteer</em>/Playwright in <em>production</em>. Memory leaks, zombie processes, Docker issues. So I wrapped it in an API.<p><pre><code>  Stack:\n  - Node.js + Fastify\n  - Playwright (more stable than <em>Puppeteer</em> in my experience)\n  - Self-hosted on Hetzner\n\n  Features:\n  - Screenshots: PNG, JPEG, WebP\n  - PDFs: A4, Letter, custom sizes\n  - Full-page capture, custom viewports\n  - Cookie consent auto-accept\n  - Lazy-load handling\n</code></pre>\nAPI example:<p><pre><code>      curl -X POST &quot;https://www.screencraftapi.com/api/v1/screenshots&quot; \\\n        -H &quot;Authorization: Bearer YOUR_KEY&quot; \\\n        -d '{&quot;url&quot;: &quot;https://example.com&quot;}'\n\n  Free tier: 250 requests/month\n  Docs: https://www.screencraftapi.com/docs\n</code></pre>\nWould love technical feedback. What's missing? What would make this useful for your projects?"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["puppeteer"], "value": "Show HN: ScreenCraft \u2013 Screenshot and PDF API Without the <em>Puppeteer</em> Headaches"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://screencraftapi.com/"}}, "_tags": ["story", "author_RobTheFrog", "story_46428944", "show_hn"], "author": "RobTheFrog", "children": [46428966], "created_at": "2025-12-30T02:46:02Z", "created_at_i": 1767062762, "num_comments": 4, "objectID": "46428944", "points": 5, "story_id": 46428944, "story_text": "Hey HN,<p>I built a REST API for capturing screenshots and generating PDFs from URLs.<p>Why: I got tired of managing Puppeteer&#x2F;Playwright in production. Memory leaks, zombie processes, Docker issues. So I wrapped it in an API.<p><pre><code>  Stack:\n  - Node.js + Fastify\n  - Playwright (more stable than Puppeteer in my experience)\n  - Self-hosted on Hetzner\n\n  Features:\n  - Screenshots: PNG, JPEG, WebP\n  - PDFs: A4, Letter, custom sizes\n  - Full-page capture, custom viewports\n  - Cookie consent auto-accept\n  - Lazy-load handling\n</code></pre>\nAPI example:<p><pre><code>      curl -X POST &quot;https:&#x2F;&#x2F;www.screencraftapi.com&#x2F;api&#x2F;v1&#x2F;screenshots&quot; \\\n        -H &quot;Authorization: Bearer YOUR_KEY&quot; \\\n        -d &#x27;{&quot;url&quot;: &quot;https:&#x2F;&#x2F;example.com&quot;}&#x27;\n\n  Free tier: 250 requests&#x2F;month\n  Docs: https:&#x2F;&#x2F;www.screencraftapi.com&#x2F;docs\n</code></pre>\nWould love technical feedback. What&#x27;s missing? What would make this useful for your projects?", "title": "Show HN: ScreenCraft \u2013 Screenshot and PDF API Without the Puppeteer Headaches", "updated_at": "2026-01-08T23:26:04Z", "url": "https://screencraftapi.com/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "prasenjit_pro"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["puppeteer", "production"], "value": "Background<p>Proxies API is a rotating proxies API that developers use to fetch hard to scrape data at scale and consistently. We auto-rotate millions of proxy servers, and also handle auto retries, rotate user agent strings, handle cookies, CAPTCHAs behind the scenes.<p>The Constraints<p>The service has to scale to millions of URL fetches a day without lagging on speed and should work out of a single API like this.<p>curl \u201chttp://api.proxiesapi.com/?key=API_KEY&amp;url=https://example.com&quot;<p>The Architecture<p>The architecture looks somewhat like this.<p>A more in-depth look at this architecture is provided in this article.<p>Load balancing &amp; Serving<p>The whole infrastructure is on Amazon EC2. The load balancer plays a significant role in calling the right service based on just the variables passed and the API KEY that holds some secret information like what pool of servers are assigned for them etc.<p>Our plans have higher concurrency as customers pay more, so we need to pass them to more reliable, dedicated servers as they have higher concurrency needs.<p>Luckily amazon elastic load balancer can make this using rules you can set, which look at the URL patterns and direct them to different pools of servers intelligently.<p>Without this exact combination of facilities, we would not have been able to create it all using a single API call without compromising speed and performance somewhere.<p>We use Apache if there is a need for HTTP servers. Many of these are super optimized to be able to crawl data concurrently using multiple cores. We will soon write an article on how we can get the most amount of crawling ability out of Apache instances.<p>Proxy Components<p>For CGI, we use a combination of Python and even PHP where required.<p>Memcache is used to monitor and throttle concurrencies gracefully, so some rouge code by one of our clients doesn\u2019t bring down the entire setup.<p>As I described earlier, most of this throttling happens in the way we route out requests from the load balancer.<p>We use the Node Js/<em>Puppeteer</em> library extensively as an interface to connect to Browserless docker instances located on multiple servers. Browserless is optimized to run as many ready-to-go instances of Chromium as possible, so there is no lag in loading any of them for our clients.<p>Database<p>We use good old MySQL in a Master/Slave configuration to hold user info, cache info, millions of proxy info, quality metrics for each, etc.<p>Maintenance tools<p>We have a pool pruner that\u2019s written in Python running as a Cronjob. Uses Scrapy and Scrapyd extensively in making calls, monitoring, benchmarking, and pruning proxies from our database.<p>We use the Beanstalk library for Queues. We use Datadog for monitoring and PagerDuty for alerts.<p>The author is the founder of Proxies API, a proxy rotation API service.<p>This article originally appeared here:https://www.proxiesapi.com/blog/The-Stack-Behind-A-<em>Production</em>-Level-Rotating-Proxy-Service.php"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "The Stack Behind a <em>Production</em> Level Rotating Proxy Service"}}, "_tags": ["story", "author_prasenjit_pro", "story_33187751", "ask_hn"], "author": "prasenjit_pro", "children": [33187915, 33189247], "created_at": "2022-10-13T05:59:07Z", "created_at_i": 1665640747, "num_comments": 2, "objectID": "33187751", "points": 2, "story_id": 33187751, "story_text": "Background<p>Proxies API is a rotating proxies API that developers use to fetch hard to scrape data at scale and consistently. We auto-rotate millions of proxy servers, and also handle auto retries, rotate user agent strings, handle cookies, CAPTCHAs behind the scenes.<p>The Constraints<p>The service has to scale to millions of URL fetches a day without lagging on speed and should work out of a single API like this.<p>curl \u201chttp:&#x2F;&#x2F;api.proxiesapi.com&#x2F;?key=API_KEY&amp;url=https:&#x2F;&#x2F;example.com&quot;<p>The Architecture<p>The architecture looks somewhat like this.<p>A more in-depth look at this architecture is provided in this article.<p>Load balancing &amp; Serving<p>The whole infrastructure is on Amazon EC2. The load balancer plays a significant role in calling the right service based on just the variables passed and the API KEY that holds some secret information like what pool of servers are assigned for them etc.<p>Our plans have higher concurrency as customers pay more, so we need to pass them to more reliable, dedicated servers as they have higher concurrency needs.<p>Luckily amazon elastic load balancer can make this using rules you can set, which look at the URL patterns and direct them to different pools of servers intelligently.<p>Without this exact combination of facilities, we would not have been able to create it all using a single API call without compromising speed and performance somewhere.<p>We use Apache if there is a need for HTTP servers. Many of these are super optimized to be able to crawl data concurrently using multiple cores. We will soon write an article on how we can get the most amount of crawling ability out of Apache instances.<p>Proxy Components<p>For CGI, we use a combination of Python and even PHP where required.<p>Memcache is used to monitor and throttle concurrencies gracefully, so some rouge code by one of our clients doesn\u2019t bring down the entire setup.<p>As I described earlier, most of this throttling happens in the way we route out requests from the load balancer.<p>We use the Node Js&#x2F;Puppeteer library extensively as an interface to connect to Browserless docker instances located on multiple servers. Browserless is optimized to run as many ready-to-go instances of Chromium as possible, so there is no lag in loading any of them for our clients.<p>Database<p>We use good old MySQL in a Master&#x2F;Slave configuration to hold user info, cache info, millions of proxy info, quality metrics for each, etc.<p>Maintenance tools<p>We have a pool pruner that\u2019s written in Python running as a Cronjob. Uses Scrapy and Scrapyd extensively in making calls, monitoring, benchmarking, and pruning proxies from our database.<p>We use the Beanstalk library for Queues. We use Datadog for monitoring and PagerDuty for alerts.<p>The author is the founder of Proxies API, a proxy rotation API service.<p>This article originally appeared here:https:&#x2F;&#x2F;www.proxiesapi.com&#x2F;blog&#x2F;The-Stack-Behind-A-Production-Level-Rotating-Proxy-Service.php", "title": "The Stack Behind a Production Level Rotating Proxy Service", "updated_at": "2024-09-20T12:18:04Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "jgalvez"}, "story_text": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "<a href=\"https://gist.github.com/galvez/0b4f0bc752b1e6cf4d4b15343dee1020\" rel=\"nofollow\">https://gist.github.com/galvez/0b4f0bc752b1e6cf4d4b15343dee1...</a><p>I couldn't find any example of this so I thought I would share one I put together. It's a mind dump of code used in <em>production</em>, although this particular bit is untested, it shows the idea. I used it for a PDF generation pool (Launching new chromium instances on every request was making the server run out of memory)"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["puppeteer"], "value": "Show HN: Minimal <em>puppeteer</em> pool"}}, "_tags": ["story", "author_jgalvez", "story_16418046", "show_hn"], "author": "jgalvez", "children": [16421035], "created_at": "2018-02-20T05:24:35Z", "created_at_i": 1519104275, "num_comments": 1, "objectID": "16418046", "points": 2, "story_id": 16418046, "story_text": "<a href=\"https:&#x2F;&#x2F;gist.github.com&#x2F;galvez&#x2F;0b4f0bc752b1e6cf4d4b15343dee1020\" rel=\"nofollow\">https:&#x2F;&#x2F;gist.github.com&#x2F;galvez&#x2F;0b4f0bc752b1e6cf4d4b15343dee1...</a><p>I couldn&#x27;t find any example of this so I thought I would share one I put together. It&#x27;s a mind dump of code used in production, although this particular bit is untested, it shows the idea. I used it for a PDF generation pool (Launching new chromium instances on every request was making the server run out of memory)", "title": "Show HN: Minimal puppeteer pool", "updated_at": "2024-09-20T02:01:19Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "jancurn"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["puppeteer", "production"], "value": "Hey HN,<p>This is Jan, founder of Apify, a web scraping and automation platform. Drawing on our team's years of experience, today we're launching Crawlee [1], the web scraping and browser automation library for Node.js that's designed for the fastest development and maximum reliability in <em>production</em>.<p>For details, see the short video [2] or read the announcement blog post [3].<p>Main features:<p>-  Supports headless browsers with Playwright or <em>Puppeteer</em><p>-  Supports raw HTTP crawling with Cheerio or JSDOM<p>-  Automated parallelization and scaling of crawlers for best performance<p>-  Avoids blocking using smart sessions, proxies, and browser fingerprints<p>-  Simple management and persistence of queues of URLs to crawl<p>-  Written completely in TypeScript for type safety and code autocompletion<p>-  Comprehensive documentation, code examples, and tutorials<p>-  Actively maintained and developed by Apify\u2014we use it ourselves!<p>-  Lively community on Discord<p>To get started, visit <a href=\"https://crawlee.dev\" rel=\"nofollow\">https://crawlee.dev</a> or run the following command: npx crawlee create my-crawler<p>If you have any questions or comments, our team will be happy to answer them here.<p>[1] <a href=\"https://crawlee.dev/\" rel=\"nofollow\">https://crawlee.dev/</a><p>[2] <a href=\"https://www.youtube.com/watch?v=g1Ll9OlFwEQ\" rel=\"nofollow\">https://www.youtube.com/watch?v=g1Ll9OlFwEQ</a><p>[3] <a href=\"https://blog.apify.com/announcing-crawlee-the-web-scraping-and-browser-automation-library/\" rel=\"nofollow\">https://blog.apify.com/announcing-crawlee-the-web-scraping-a...</a>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Crawlee \u2013 Web scraping and browser automation library for Node.js"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://crawlee.dev/"}}, "_tags": ["story", "author_jancurn", "story_32561127", "show_hn"], "author": "jancurn", "children": [32561219, 32561435, 32561621, 32561804, 32561840, 32561982, 32562035, 32562129, 32562206, 32562216, 32562238, 32562400, 32562887, 32563071, 32563337, 32564004, 32564084, 32564711, 32565174, 32566021, 32566243, 32567025, 32567953, 32568318, 32569492, 32570745, 32583079], "created_at": "2022-08-23T06:25:39Z", "created_at_i": 1661235939, "num_comments": 80, "objectID": "32561127", "points": 282, "story_id": 32561127, "story_text": "Hey HN,<p>This is Jan, founder of Apify, a web scraping and automation platform. Drawing on our team&#x27;s years of experience, today we&#x27;re launching Crawlee [1], the web scraping and browser automation library for Node.js that&#x27;s designed for the fastest development and maximum reliability in production.<p>For details, see the short video [2] or read the announcement blog post [3].<p>Main features:<p>-  Supports headless browsers with Playwright or Puppeteer<p>-  Supports raw HTTP crawling with Cheerio or JSDOM<p>-  Automated parallelization and scaling of crawlers for best performance<p>-  Avoids blocking using smart sessions, proxies, and browser fingerprints<p>-  Simple management and persistence of queues of URLs to crawl<p>-  Written completely in TypeScript for type safety and code autocompletion<p>-  Comprehensive documentation, code examples, and tutorials<p>-  Actively maintained and developed by Apify\u2014we use it ourselves!<p>-  Lively community on Discord<p>To get started, visit <a href=\"https:&#x2F;&#x2F;crawlee.dev\" rel=\"nofollow\">https:&#x2F;&#x2F;crawlee.dev</a> or run the following command: npx crawlee create my-crawler<p>If you have any questions or comments, our team will be happy to answer them here.<p>[1] <a href=\"https:&#x2F;&#x2F;crawlee.dev&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;crawlee.dev&#x2F;</a><p>[2] <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=g1Ll9OlFwEQ\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=g1Ll9OlFwEQ</a><p>[3] <a href=\"https:&#x2F;&#x2F;blog.apify.com&#x2F;announcing-crawlee-the-web-scraping-and-browser-automation-library&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;blog.apify.com&#x2F;announcing-crawlee-the-web-scraping-a...</a>", "title": "Show HN: Crawlee \u2013 Web scraping and browser automation library for Node.js", "updated_at": "2025-07-24T17:40:33Z", "url": "https://crawlee.dev/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "Gabriel_h"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["puppeteer", "production"], "value": "Hey HN, I'm Gabriel, founder of Meticulous (<a href=\"https://www.meticulous.ai\" rel=\"nofollow\">https://www.meticulous.ai</a>). We're building an API for replay testing. That is, we enable developers to record sessions in their web apps, then replay those sessions against <i>new</i> frontend code, in order to catch regressions before the code is released.<p>I was inspired to start Meticulous from my time at Dropbox, where we had regular 'bug bashes' for our UX. Five or six engineers would go to a meeting room and click through different flows to try to break what we built. These were effective but time consuming\u2014they required us to click through the same set of actions each time prior to a release.<p>This prompted me to start thinking about replaying sessions to automatically catch regressions. You can't replay against <em>production</em> since you might mutate <em>production</em> data or cause side effects. You could replay against staging, but a lot of companies don't have a staging environment that is representative of <em>production</em>. In addition, you need a mechanism to reset state after each replayed session (imagine replaying a user signing up to your web application).<p>We designed Meticulous with a focus on regressions, which I think are a particularly painful class of bug. They tend to occur in flows which users are actively using, and the number of regressions generally scales with the size and complexity of a codebase, which tends to always increase.<p>You can use Meticulous on any website, not just your own. For example, you can start recording a session, then go sign up to (say) amazon.com, then create a simple test which consists of replaying against amazon.com twice and comparing the resulting screenshots. You can also watch recordings and replays on the Meticulous dashboard. Of course, normally you would replay against the base commit and head commit of a PR, as opposed to the <em>production</em> site twice.<p>Our API is currently quite low-level. The Meticulous CLI allows you to do three things:<p>1) You can use 'yarn meticulous record' to open a browser which you can then use to record a session on a URL of your choice, like localhost. You can also inject our JS snippet onto staging, local, dev and QA environments if you want to capture a larger pool of sessions. This is intended for testing your own stuff! If you inject our snippet, please ask for the consent of your colleagues before recording their workflows. I would advise against <em>production</em> deployments, because our redaction is currently very basic.<p>2) You can use 'yarn meticulous replay' to replay a session against a URL of your choice. During replay, we spin up a browser and simulate click events with <em>Puppeteer</em>. A list of exceptions and network logs are written to disk. A screenshot is taken at the end of the replay and written to disk.<p>3) You can use 'yarn meticulous screenshot-diff' to diff two screenshots.<p>There are lots of potential use cases here. You could build a system on top of the screenshot diffing to detect major regressions with a UX flow. You could also try to diff exceptions encountered during replay to detect new uncaught JS exceptions. We plan to build a higher-level product which will provide some testing out of the box.<p>Meticulous captures network traffic at record-time and mocks out network calls at replay-time. This isolates the frontend and avoids causing any side effects. However, this approach does have a few problems. The first is that you can't test backend changes or integration changes, only frontend changes. (We are going to make network-stubbing optional, though, so that you can replay against a staging environment if you wish.) The second problem with our approach is that if your API significantly changes, you will need to record a new set of sessions to test against. A third problem is that we don't yet support web applications which rely heavily upon server-side rendering. However, we felt these trade-offs were worth it to make Meticulous agnostic of the backend environment.<p>Meticulous is not going to replace all your testing, of course. I would recommend using it in conjunction with existing testing tools and practices, and viewing it as an additional layer of defense.<p>We have a free plan where you can replay 20 sessions per month. I've temporarily changed our limit to 250 for the HN launch. Our basic plan is $100/month. The CLI itself is open-source under ISC. We're actively discussing open sourcing the record+replay code.<p>I'd love for you to play around with Meticulous! You can try it out at <a href=\"https://docs.meticulous.ai\" rel=\"nofollow\">https://docs.meticulous.ai</a>. It's rough around the edges, but we wanted to get this out to HN as early as possible. Please let us know what you might want us to build on top of this (visual diffs? perf regressions? dead code analysis? preventing regressions?). We would also love to hear from people who have built any sort of replay testing out at their company. Thank you for reading and I look forward to the comments!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Launch HN: Meticulous (YC S21) \u2013 Catch JavaScript errors before they hit prod"}}, "_tags": ["story", "author_Gabriel_h", "story_31236066", "launch_hn"], "author": "Gabriel_h", "children": [31236511, 31236552, 31236955, 31237170, 31237819, 31237998, 31238486, 31238535, 31238997, 31239179, 31239265, 31239287, 31239330, 31240022, 31244000, 31244471, 31245831, 31246122, 31246628, 31247148], "created_at": "2022-05-02T15:06:49Z", "created_at_i": 1651504009, "num_comments": 40, "objectID": "31236066", "points": 122, "story_id": 31236066, "story_text": "Hey HN, I&#x27;m Gabriel, founder of Meticulous (<a href=\"https:&#x2F;&#x2F;www.meticulous.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;www.meticulous.ai</a>). We&#x27;re building an API for replay testing. That is, we enable developers to record sessions in their web apps, then replay those sessions against <i>new</i> frontend code, in order to catch regressions before the code is released.<p>I was inspired to start Meticulous from my time at Dropbox, where we had regular &#x27;bug bashes&#x27; for our UX. Five or six engineers would go to a meeting room and click through different flows to try to break what we built. These were effective but time consuming\u2014they required us to click through the same set of actions each time prior to a release.<p>This prompted me to start thinking about replaying sessions to automatically catch regressions. You can&#x27;t replay against production since you might mutate production data or cause side effects. You could replay against staging, but a lot of companies don&#x27;t have a staging environment that is representative of production. In addition, you need a mechanism to reset state after each replayed session (imagine replaying a user signing up to your web application).<p>We designed Meticulous with a focus on regressions, which I think are a particularly painful class of bug. They tend to occur in flows which users are actively using, and the number of regressions generally scales with the size and complexity of a codebase, which tends to always increase.<p>You can use Meticulous on any website, not just your own. For example, you can start recording a session, then go sign up to (say) amazon.com, then create a simple test which consists of replaying against amazon.com twice and comparing the resulting screenshots. You can also watch recordings and replays on the Meticulous dashboard. Of course, normally you would replay against the base commit and head commit of a PR, as opposed to the production site twice.<p>Our API is currently quite low-level. The Meticulous CLI allows you to do three things:<p>1) You can use &#x27;yarn meticulous record&#x27; to open a browser which you can then use to record a session on a URL of your choice, like localhost. You can also inject our JS snippet onto staging, local, dev and QA environments if you want to capture a larger pool of sessions. This is intended for testing your own stuff! If you inject our snippet, please ask for the consent of your colleagues before recording their workflows. I would advise against production deployments, because our redaction is currently very basic.<p>2) You can use &#x27;yarn meticulous replay&#x27; to replay a session against a URL of your choice. During replay, we spin up a browser and simulate click events with Puppeteer. A list of exceptions and network logs are written to disk. A screenshot is taken at the end of the replay and written to disk.<p>3) You can use &#x27;yarn meticulous screenshot-diff&#x27; to diff two screenshots.<p>There are lots of potential use cases here. You could build a system on top of the screenshot diffing to detect major regressions with a UX flow. You could also try to diff exceptions encountered during replay to detect new uncaught JS exceptions. We plan to build a higher-level product which will provide some testing out of the box.<p>Meticulous captures network traffic at record-time and mocks out network calls at replay-time. This isolates the frontend and avoids causing any side effects. However, this approach does have a few problems. The first is that you can&#x27;t test backend changes or integration changes, only frontend changes. (We are going to make network-stubbing optional, though, so that you can replay against a staging environment if you wish.) The second problem with our approach is that if your API significantly changes, you will need to record a new set of sessions to test against. A third problem is that we don&#x27;t yet support web applications which rely heavily upon server-side rendering. However, we felt these trade-offs were worth it to make Meticulous agnostic of the backend environment.<p>Meticulous is not going to replace all your testing, of course. I would recommend using it in conjunction with existing testing tools and practices, and viewing it as an additional layer of defense.<p>We have a free plan where you can replay 20 sessions per month. I&#x27;ve temporarily changed our limit to 250 for the HN launch. Our basic plan is $100&#x2F;month. The CLI itself is open-source under ISC. We&#x27;re actively discussing open sourcing the record+replay code.<p>I&#x27;d love for you to play around with Meticulous! You can try it out at <a href=\"https:&#x2F;&#x2F;docs.meticulous.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.meticulous.ai</a>. It&#x27;s rough around the edges, but we wanted to get this out to HN as early as possible. Please let us know what you might want us to build on top of this (visual diffs? perf regressions? dead code analysis? preventing regressions?). We would also love to hear from people who have built any sort of replay testing out at their company. Thank you for reading and I look forward to the comments!", "title": "Launch HN: Meticulous (YC S21) \u2013 Catch JavaScript errors before they hit prod", "updated_at": "2024-09-20T11:02:55Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "galaxyeye"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["puppeteer", "production"], "value": "Hi HN,<p>I\u2019d like to share an open-source project we\u2019ve been working on for a while: <i>Browser4</i>.<p>The motivation came from a recurring frustration: most browser automation tools (Playwright, Selenium, <em>Puppeteer</em>) are excellent for <i>human-written scripts</i>, but start to show friction when used as a <i>core execution layer for AI agents</i> or at very high concurrency.<p>So instead of building \u201canother wrapper around Playwright\u201d, we experimented with a different direction:\n<i>designing a browser engine where AI agents are first-class citizens.</i><p>### What Browser4 is<p>Browser4 is a browser automation engine built on <i>native Chrome DevTools Protocol (CDP)</i>, with a focus on:<p>* <i>Coroutine-safe concurrency</i> (designed to run many browser sessions in parallel)<p>* <i>Agent-oriented APIs</i> (navigation, interaction, extraction as composable actions)<p>* <i>Hybrid extraction</i>: ML agent driven extraction + LLM extraction + structured selectors + an SQL-like DOM query language (X-SQL)<p>* <i>Low-level control</i> without Playwright-style abstraction overhead<p>It\u2019s written in <i>Kotlin/JVM</i>, mainly because we needed predictable concurrency behavior and long-running stability under load.<p>The project is fully open-source (Apache 2.0).<p>### What it\u2019s <i>not</i><p>* It\u2019s not a drop-in Playwright replacement.<p>* It\u2019s not a no-code RPA tool.<p>* It\u2019s not \u201cLLM magic\u201d \u2014 LLMs sit <i>outside</i> the browser engine.<p>Browser4 intentionally stays close to the browser execution layer and leaves planning/reasoning to external agent loops.<p>### Current use cases we\u2019re testing<p>* Large-scale web data extraction<p>* Agentic workflows (search \u2192 navigate \u2192 extract \u2192 summarize)<p>* Price / content monitoring with frequent revisits<p>* High-concurrency crawling where browser startup and context switching are bottlenecks<p>On a single machine, we can sustain <i>very high daily page visits</i>, though we\u2019re still validating benchmarks across different workloads.<p>### Open questions (where I\u2019d love feedback)<p>* For agentic systems, does it make sense to bypass Playwright entirely and work closer to CDP?<p>* Where do you see the biggest pain points when combining LLMs with browser automation today?<p>* Is JVM a reasonable choice here, or is Python still the better tradeoff despite concurrency limits<p>* What abstractions would <i>you</i> want in a browser engine built for AI agents?<p>### Links<p>* GitHub: <a href=\"https://github.com/platonai/browser4\" rel=\"nofollow\">https://github.com/platonai/browser4</a><p>* Website (light overview): <a href=\"https://browser4.io\" rel=\"nofollow\">https://browser4.io</a><p>Happy to answer technical questions or hear criticism \u2014 especially from people running browser automation or agent systems in <em>production</em>.<p>Thanks for reading."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Browser4 \u2013 an open-source browser engine for agents and concurrency"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/platonai/Browser4"}}, "_tags": ["story", "author_galaxyeye", "story_46252251", "show_hn"], "author": "galaxyeye", "children": [46252924, 46254130, 46271047], "created_at": "2025-12-13T05:25:54Z", "created_at_i": 1765603554, "num_comments": 6, "objectID": "46252251", "points": 7, "story_id": 46252251, "story_text": "Hi HN,<p>I\u2019d like to share an open-source project we\u2019ve been working on for a while: <i>Browser4</i>.<p>The motivation came from a recurring frustration: most browser automation tools (Playwright, Selenium, Puppeteer) are excellent for <i>human-written scripts</i>, but start to show friction when used as a <i>core execution layer for AI agents</i> or at very high concurrency.<p>So instead of building \u201canother wrapper around Playwright\u201d, we experimented with a different direction:\n<i>designing a browser engine where AI agents are first-class citizens.</i><p>### What Browser4 is<p>Browser4 is a browser automation engine built on <i>native Chrome DevTools Protocol (CDP)</i>, with a focus on:<p>* <i>Coroutine-safe concurrency</i> (designed to run many browser sessions in parallel)<p>* <i>Agent-oriented APIs</i> (navigation, interaction, extraction as composable actions)<p>* <i>Hybrid extraction</i>: ML agent driven extraction + LLM extraction + structured selectors + an SQL-like DOM query language (X-SQL)<p>* <i>Low-level control</i> without Playwright-style abstraction overhead<p>It\u2019s written in <i>Kotlin&#x2F;JVM</i>, mainly because we needed predictable concurrency behavior and long-running stability under load.<p>The project is fully open-source (Apache 2.0).<p>### What it\u2019s <i>not</i><p>* It\u2019s not a drop-in Playwright replacement.<p>* It\u2019s not a no-code RPA tool.<p>* It\u2019s not \u201cLLM magic\u201d \u2014 LLMs sit <i>outside</i> the browser engine.<p>Browser4 intentionally stays close to the browser execution layer and leaves planning&#x2F;reasoning to external agent loops.<p>### Current use cases we\u2019re testing<p>* Large-scale web data extraction<p>* Agentic workflows (search \u2192 navigate \u2192 extract \u2192 summarize)<p>* Price &#x2F; content monitoring with frequent revisits<p>* High-concurrency crawling where browser startup and context switching are bottlenecks<p>On a single machine, we can sustain <i>very high daily page visits</i>, though we\u2019re still validating benchmarks across different workloads.<p>### Open questions (where I\u2019d love feedback)<p>* For agentic systems, does it make sense to bypass Playwright entirely and work closer to CDP?<p>* Where do you see the biggest pain points when combining LLMs with browser automation today?<p>* Is JVM a reasonable choice here, or is Python still the better tradeoff despite concurrency limits<p>* What abstractions would <i>you</i> want in a browser engine built for AI agents?<p>### Links<p>* GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;platonai&#x2F;browser4\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;platonai&#x2F;browser4</a><p>* Website (light overview): <a href=\"https:&#x2F;&#x2F;browser4.io\" rel=\"nofollow\">https:&#x2F;&#x2F;browser4.io</a><p>Happy to answer technical questions or hear criticism \u2014 especially from people running browser automation or agent systems in production.<p>Thanks for reading.", "title": "Show HN: Browser4 \u2013 an open-source browser engine for agents and concurrency", "updated_at": "2025-12-23T06:00:18Z", "url": "https://github.com/platonai/Browser4"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "tonyspiro"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["puppeteer", "production"], "value": "Hi HN, I'm Tony, founder of Cosmic (a headless CMS). We just open-sourced a CLI that covers the full lifecycle of a content-driven app from creating the content model to deploying to <em>production</em> to updating the codebase all without leaving the terminal.<p>Here's what the full workflow looks like:<p><pre><code>  # Create a project with an AI-generated content model\n  cosmic projects create\n  # \u2192 &quot;A recipe blog with recipes, categories, and authors&quot;\n\n  # Generate content\n  cosmic content -p &quot;Create 5 recipes with images across different categories&quot;\n\n  # Build a full-stack app wired to your content\n  cosmic build -p &quot;A modern recipe blog with search and category filtering&quot;\n  # \u2192 Generates a Next.js app, pushes to GitHub\n\n  # Deploy\n  cosmic deploy start --watch\n  # \u2192 Deployed to Vercel\n\n  # Later: update the existing codebase with natural language\n  cosmic update recipe-blog -p &quot;Add dark mode and a favorites feature&quot; -b feature-branch\n\n  # Create a PR and merge\n  cosmic repos pr create &lt;repoId&gt;\n  cosmic repos pr merge &lt;repoId&gt; 1\n  # \u2192 Auto-deploys to <em>production</em>\n</code></pre>\nThat's the part I think is interesting: it's not just one step, it's the full loop. Create content, build the app, ship it, iterate on it, merge and redeploy. Each step is a single command.<p>A few of the more technically interesting pieces:<p>AI agents. You can create three types: content agents (CMS operations), repository agents (code changes on branches), and computer use agents (browser automation via <em>Puppeteer</em> with AI vision). Chain them into multi-step workflows with scheduling.<p>Interactive shell. &quot;cosmic shell&quot; drops into a REPL where you navigate workspaces and projects like a filesystem: cd, ls, pwd. System commands with ! prefix. No cosmic prefix needed.<p>Multi-model. Supports Claude Opus/Sonnet/Haiku, GPT-5/5.2/5-mini/4o, and Gemini 3 Pro. Set a default or specify per-command.<p>It also handles the day-to-day stuff you'd normally do in a dashboard: billing, team roles, webhooks, domain/DNS config, environment variables.<p>Built with TypeScript and Commander.js. MIT licensed.<p>Install: npm install -g @cosmicjs/cli<p>GitHub: <a href=\"https://github.com/cosmicjs/cli\" rel=\"nofollow\">https://github.com/cosmicjs/cli</a><p>Docs: <a href=\"https://www.cosmicjs.com/docs/cli\" rel=\"nofollow\">https://www.cosmicjs.com/docs/cli</a><p>Happy to answer questions."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Cosmic CLI \u2013 Build, deploy, and manage apps from your terminal with AI"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/cosmicjs/cli"}}, "_tags": ["story", "author_tonyspiro", "story_46965065", "show_hn"], "author": "tonyspiro", "created_at": "2026-02-10T19:01:50Z", "created_at_i": 1770750110, "num_comments": 0, "objectID": "46965065", "points": 2, "story_id": 46965065, "story_text": "Hi HN, I&#x27;m Tony, founder of Cosmic (a headless CMS). We just open-sourced a CLI that covers the full lifecycle of a content-driven app from creating the content model to deploying to production to updating the codebase all without leaving the terminal.<p>Here&#x27;s what the full workflow looks like:<p><pre><code>  # Create a project with an AI-generated content model\n  cosmic projects create\n  # \u2192 &quot;A recipe blog with recipes, categories, and authors&quot;\n\n  # Generate content\n  cosmic content -p &quot;Create 5 recipes with images across different categories&quot;\n\n  # Build a full-stack app wired to your content\n  cosmic build -p &quot;A modern recipe blog with search and category filtering&quot;\n  # \u2192 Generates a Next.js app, pushes to GitHub\n\n  # Deploy\n  cosmic deploy start --watch\n  # \u2192 Deployed to Vercel\n\n  # Later: update the existing codebase with natural language\n  cosmic update recipe-blog -p &quot;Add dark mode and a favorites feature&quot; -b feature-branch\n\n  # Create a PR and merge\n  cosmic repos pr create &lt;repoId&gt;\n  cosmic repos pr merge &lt;repoId&gt; 1\n  # \u2192 Auto-deploys to production\n</code></pre>\nThat&#x27;s the part I think is interesting: it&#x27;s not just one step, it&#x27;s the full loop. Create content, build the app, ship it, iterate on it, merge and redeploy. Each step is a single command.<p>A few of the more technically interesting pieces:<p>AI agents. You can create three types: content agents (CMS operations), repository agents (code changes on branches), and computer use agents (browser automation via Puppeteer with AI vision). Chain them into multi-step workflows with scheduling.<p>Interactive shell. &quot;cosmic shell&quot; drops into a REPL where you navigate workspaces and projects like a filesystem: cd, ls, pwd. System commands with ! prefix. No cosmic prefix needed.<p>Multi-model. Supports Claude Opus&#x2F;Sonnet&#x2F;Haiku, GPT-5&#x2F;5.2&#x2F;5-mini&#x2F;4o, and Gemini 3 Pro. Set a default or specify per-command.<p>It also handles the day-to-day stuff you&#x27;d normally do in a dashboard: billing, team roles, webhooks, domain&#x2F;DNS config, environment variables.<p>Built with TypeScript and Commander.js. MIT licensed.<p>Install: npm install -g @cosmicjs&#x2F;cli<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;cosmicjs&#x2F;cli\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;cosmicjs&#x2F;cli</a><p>Docs: <a href=\"https:&#x2F;&#x2F;www.cosmicjs.com&#x2F;docs&#x2F;cli\" rel=\"nofollow\">https:&#x2F;&#x2F;www.cosmicjs.com&#x2F;docs&#x2F;cli</a><p>Happy to answer questions.", "title": "Show HN: Cosmic CLI \u2013 Build, deploy, and manage apps from your terminal with AI", "updated_at": "2026-02-11T14:29:28Z", "url": "https://github.com/cosmicjs/cli"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "hongyeon"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["puppeteer", "production"], "value": "Hi HN,<p>I\u2019m an archaeologist-turned-engineer. I switched careers to solve the &quot;manual labor&quot; problem of academic research through technology.<p>I built this toolkit to automate &quot;Research Radar&quot; (my cultural heritage newsletter). It currently maintains a 15% CTR with near-zero maintenance, costing just $0.20 per issue via optimized model usage.<p>My Design Philosophy: &quot;Logic in code, reasoning in AI, connections in architecture.&quot;<p>I believe deterministic workflows belong in type-safe code, while intelligent analysis belongs to LLMs. This separation allows for advanced workflows (self-reflection loops, multi-step verification) that are often impossible in no-code tools.<p>Key Features:<p>- Type-First &amp; DI-Based: Fully swappable providers (Crawling, Analysis, Generation).<p>- Bring Your Own Scraper: Inject <em>Puppeteer</em>, Cheerio, or AI parsers asynchronously. No lock-in.<p>- <em>Production</em> Ready: 100% test coverage, built-in observability, and TypeScript.<p>Links:<p>- Repo: <a href=\"https://github.com/kimhongyeon/llm-newsletter-kit-core\" rel=\"nofollow\">https://github.com/kimhongyeon/llm-newsletter-kit-core</a><p>- Live Service: <a href=\"https://heripo.com/research-radar/subscribe\" rel=\"nofollow\">https://heripo.com/research-radar/subscribe</a><p>- Output Example: <a href=\"https://heripo.com/research-radar-newsletter-example.html\" rel=\"nofollow\">https://heripo.com/research-radar-newsletter-example.html</a>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: LLM Newsletter Kit \u2013 Automate expert newsletters for $0.20/issue"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/kimhongyeon/llm-newsletter-kit-core"}}, "_tags": ["story", "author_hongyeon", "story_46191460", "show_hn"], "author": "hongyeon", "created_at": "2025-12-08T12:25:31Z", "created_at_i": 1765196731, "num_comments": 0, "objectID": "46191460", "points": 2, "story_id": 46191460, "story_text": "Hi HN,<p>I\u2019m an archaeologist-turned-engineer. I switched careers to solve the &quot;manual labor&quot; problem of academic research through technology.<p>I built this toolkit to automate &quot;Research Radar&quot; (my cultural heritage newsletter). It currently maintains a 15% CTR with near-zero maintenance, costing just $0.20 per issue via optimized model usage.<p>My Design Philosophy: &quot;Logic in code, reasoning in AI, connections in architecture.&quot;<p>I believe deterministic workflows belong in type-safe code, while intelligent analysis belongs to LLMs. This separation allows for advanced workflows (self-reflection loops, multi-step verification) that are often impossible in no-code tools.<p>Key Features:<p>- Type-First &amp; DI-Based: Fully swappable providers (Crawling, Analysis, Generation).<p>- Bring Your Own Scraper: Inject Puppeteer, Cheerio, or AI parsers asynchronously. No lock-in.<p>- Production Ready: 100% test coverage, built-in observability, and TypeScript.<p>Links:<p>- Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;kimhongyeon&#x2F;llm-newsletter-kit-core\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;kimhongyeon&#x2F;llm-newsletter-kit-core</a><p>- Live Service: <a href=\"https:&#x2F;&#x2F;heripo.com&#x2F;research-radar&#x2F;subscribe\" rel=\"nofollow\">https:&#x2F;&#x2F;heripo.com&#x2F;research-radar&#x2F;subscribe</a><p>- Output Example: <a href=\"https:&#x2F;&#x2F;heripo.com&#x2F;research-radar-newsletter-example.html\" rel=\"nofollow\">https:&#x2F;&#x2F;heripo.com&#x2F;research-radar-newsletter-example.html</a>", "title": "Show HN: LLM Newsletter Kit \u2013 Automate expert newsletters for $0.20/issue", "updated_at": "2025-12-08T12:35:34Z", "url": "https://github.com/kimhongyeon/llm-newsletter-kit-core"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "ajith-joseph"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["puppeteer", "production"], "value": "Hello HN! We\u2019re excited to share PerfAgents, a synthetic monitoring tool built for startups and enterprises seeking robust and proactive monitoring across global regions.<p>TL;DR:<p>PerfAgents is a synthetic monitoring platform that uses your existing E2E automation scripts (Playwright, <em>Puppeteer</em>, Cypress, and Selenium) for web app monitoring, reducing setup time by 80%. No complex integrations, no vendor lock-in, and proactive alerts that let you catch bugs before users do.<p>Problem We\u2019re Solving:<p>Ensuring application reliability across all regions is tough, especially when existing monitoring tools either require extensive DevOps/QA setup or lock users into proprietary workflows. This results in inefficient workflows, delayed issue detection, and, often, user-facing bugs in <em>production</em> environments.<p>How We Solved It:<p>PerfAgents offers a multi-framework approach that lets you monitor app functionality without needing new integrations or script re-recording. By reusing existing end-to-end scripts, PerfAgents makes setup fast, keeps monitoring flexible, and allows teams to detect and resolve issues faster.<p>Features include:<p>-&gt; Multi-framework support for Playwright, <em>Puppeteer</em>, Cypress, and Selenium<p>-&gt; AI-driven monitoring script generation to automate monitoring setups with no code<p>-&gt; Global test execution for instant insights across regions<p>-&gt; Real-time alerts integrated with popular tools (Slack, PagerDuty, Jira)<p>-&gt; Flexible pricing based on execution frequency, not script complexity<p>How It Works:<p>-&gt; Setup: Connect your GitHub repository to import existing scripts, or use our built-in AI tools for zero-code setups.<p>-&gt; Monitor &amp; Alert: Configure regional monitoring and alert channels, with real-time notifications when an issue occurs.<p>-&gt; Optimize &amp; Scale: Review logs, performance reports, and leverage our multi-framework support to refine application flow monitoring.<p>Key Benefits:<p>-&gt; Faster issue resolution: Early detection and instant alerts prevent downtime and improve stability.<p>-&gt; Cross-team collaboration: Centralized data helps DevOps, QA, and product teams collaborate more effectively.<p>-&gt; Flexible framework support: Avoid vendor lock-in with multi-framework compatibility.<p>-&gt; High scalability: Configurable monitoring counts ensure you\u2019re only paying for what you use.<p>PerfAgents is already in use by Fortune 500 companies and has helped SaaS and e-commerce teams reduce downtime by 40% and cut support tickets by nearly 57%.<p>Who It\u2019s For:<p>-&gt; DevOps, QA, and Engineering leaders looking to optimize monitoring setup and execution<p>-&gt; Teams already using frameworks like Playwright, <em>Puppeteer</em>, Cypress, or Selenium<p>-&gt; SaaS and e-commerce platforms where reliable, global user flows are critical<p>PerfAgents is available for a free trial now. We\u2019d love to hear your thoughts, and if you have any questions, feel free to ask!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: PerfAgents \u2013 Find Issues Before Your Users Do with Synthetic Monitoring"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://www.perfagents.com/"}}, "_tags": ["story", "author_ajith-joseph", "story_42149010", "show_hn"], "author": "ajith-joseph", "created_at": "2024-11-15T17:36:39Z", "created_at_i": 1731692199, "num_comments": 0, "objectID": "42149010", "points": 2, "story_id": 42149010, "story_text": "Hello HN! We\u2019re excited to share PerfAgents, a synthetic monitoring tool built for startups and enterprises seeking robust and proactive monitoring across global regions.<p>TL;DR:<p>PerfAgents is a synthetic monitoring platform that uses your existing E2E automation scripts (Playwright, Puppeteer, Cypress, and Selenium) for web app monitoring, reducing setup time by 80%. No complex integrations, no vendor lock-in, and proactive alerts that let you catch bugs before users do.<p>Problem We\u2019re Solving:<p>Ensuring application reliability across all regions is tough, especially when existing monitoring tools either require extensive DevOps&#x2F;QA setup or lock users into proprietary workflows. This results in inefficient workflows, delayed issue detection, and, often, user-facing bugs in production environments.<p>How We Solved It:<p>PerfAgents offers a multi-framework approach that lets you monitor app functionality without needing new integrations or script re-recording. By reusing existing end-to-end scripts, PerfAgents makes setup fast, keeps monitoring flexible, and allows teams to detect and resolve issues faster.<p>Features include:<p>-&gt; Multi-framework support for Playwright, Puppeteer, Cypress, and Selenium<p>-&gt; AI-driven monitoring script generation to automate monitoring setups with no code<p>-&gt; Global test execution for instant insights across regions<p>-&gt; Real-time alerts integrated with popular tools (Slack, PagerDuty, Jira)<p>-&gt; Flexible pricing based on execution frequency, not script complexity<p>How It Works:<p>-&gt; Setup: Connect your GitHub repository to import existing scripts, or use our built-in AI tools for zero-code setups.<p>-&gt; Monitor &amp; Alert: Configure regional monitoring and alert channels, with real-time notifications when an issue occurs.<p>-&gt; Optimize &amp; Scale: Review logs, performance reports, and leverage our multi-framework support to refine application flow monitoring.<p>Key Benefits:<p>-&gt; Faster issue resolution: Early detection and instant alerts prevent downtime and improve stability.<p>-&gt; Cross-team collaboration: Centralized data helps DevOps, QA, and product teams collaborate more effectively.<p>-&gt; Flexible framework support: Avoid vendor lock-in with multi-framework compatibility.<p>-&gt; High scalability: Configurable monitoring counts ensure you\u2019re only paying for what you use.<p>PerfAgents is already in use by Fortune 500 companies and has helped SaaS and e-commerce teams reduce downtime by 40% and cut support tickets by nearly 57%.<p>Who It\u2019s For:<p>-&gt; DevOps, QA, and Engineering leaders looking to optimize monitoring setup and execution<p>-&gt; Teams already using frameworks like Playwright, Puppeteer, Cypress, or Selenium<p>-&gt; SaaS and e-commerce platforms where reliable, global user flows are critical<p>PerfAgents is available for a free trial now. We\u2019d love to hear your thoughts, and if you have any questions, feel free to ask!", "title": "Show HN: PerfAgents \u2013 Find Issues Before Your Users Do with Synthetic Monitoring", "updated_at": "2024-11-15T18:08:38Z", "url": "https://www.perfagents.com/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "PrimeStark"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["puppeteer", "production"], "value": "Hey HN,<p>I quit my engineering manager job last week. Family of 4, no safety net. Built and launched AccessiGuard in 6 days \u2014 first commit to <em>production</em>.<p>It's a WCAG 2.1 scanner that checks websites for accessibility issues and gives you actual fix suggestions (code snippets, not just &quot;fix this&quot;).<p>How it works:\n- Fetches your page, parses the HTML with Cheerio, runs 22 custom checks against WCAG 2.1 AA criteria\n- Crawls linked pages on the same domain for multi-page scans\n- AI fix suggestions via OpenAI \u2014 points you to the exact element and tells you what to change\n- PDF reports, score tracking over time, monitoring for regressions<p>What it catches:\nMissing alt text, form labels, heading structure, ARIA issues, viewport zoom blocking, skip nav, duplicate IDs, generic link text, table headers, and more. Full list: <a href=\"https://accessiguard.app/scan-coverage\" rel=\"nofollow\">https://accessiguard.app/scan-coverage</a><p>What it doesn't catch (being honest):\nNo color contrast checking yet \u2014 that needs computed styles which requires a real browser. Currently on the roadmap alongside <em>Puppeteer</em> integration. Same goes for keyboard trap detection and SPA rendering.<p>Stack: Next.js 15, Supabase, Cheerio, OpenAI, Stripe, Vercel.<p>Pricing: Free tier is 5 scans/month. Paid starts at $29/mo. Agency plan is $99/mo for 50 sites.<p>Why another scanner? Most tools are either enterprise-priced, overlays that don't actually fix anything (the FTC fined accessiBe for this), or black boxes that don't tell you what they test. I wanted something transparent, affordable, and useful for developers who actually want to fix their code.<p>Would love feedback on scan accuracy, things I'm missing, or if the reports are actually useful. Happy to answer architecture questions."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: AccessiGuard \u2013 Web accessibility scanner with AI fix suggestions"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://accessiguard.app"}}, "_tags": ["story", "author_PrimeStark", "story_47007846", "show_hn"], "author": "PrimeStark", "created_at": "2026-02-13T21:08:14Z", "created_at_i": 1771016894, "num_comments": 0, "objectID": "47007846", "points": 1, "story_id": 47007846, "story_text": "Hey HN,<p>I quit my engineering manager job last week. Family of 4, no safety net. Built and launched AccessiGuard in 6 days \u2014 first commit to production.<p>It&#x27;s a WCAG 2.1 scanner that checks websites for accessibility issues and gives you actual fix suggestions (code snippets, not just &quot;fix this&quot;).<p>How it works:\n- Fetches your page, parses the HTML with Cheerio, runs 22 custom checks against WCAG 2.1 AA criteria\n- Crawls linked pages on the same domain for multi-page scans\n- AI fix suggestions via OpenAI \u2014 points you to the exact element and tells you what to change\n- PDF reports, score tracking over time, monitoring for regressions<p>What it catches:\nMissing alt text, form labels, heading structure, ARIA issues, viewport zoom blocking, skip nav, duplicate IDs, generic link text, table headers, and more. Full list: <a href=\"https:&#x2F;&#x2F;accessiguard.app&#x2F;scan-coverage\" rel=\"nofollow\">https:&#x2F;&#x2F;accessiguard.app&#x2F;scan-coverage</a><p>What it doesn&#x27;t catch (being honest):\nNo color contrast checking yet \u2014 that needs computed styles which requires a real browser. Currently on the roadmap alongside Puppeteer integration. Same goes for keyboard trap detection and SPA rendering.<p>Stack: Next.js 15, Supabase, Cheerio, OpenAI, Stripe, Vercel.<p>Pricing: Free tier is 5 scans&#x2F;month. Paid starts at $29&#x2F;mo. Agency plan is $99&#x2F;mo for 50 sites.<p>Why another scanner? Most tools are either enterprise-priced, overlays that don&#x27;t actually fix anything (the FTC fined accessiBe for this), or black boxes that don&#x27;t tell you what they test. I wanted something transparent, affordable, and useful for developers who actually want to fix their code.<p>Would love feedback on scan accuracy, things I&#x27;m missing, or if the reports are actually useful. Happy to answer architecture questions.", "title": "Show HN: AccessiGuard \u2013 Web accessibility scanner with AI fix suggestions", "updated_at": "2026-02-13T21:13:20Z", "url": "https://accessiguard.app"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "nihalwashere"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["puppeteer", "production"], "value": "I've been building AI agents that needed web access and kept hitting the same wall: <em>production</em> scraping is hard. You start with <em>Puppeteer</em>, then add stealth plugins, then fight Cloudflare, then manage proxies, then handle browser pooling and it still breaks.<p>I kept solving this problem from scratch on different projects, so I packaged it up as Reader, hoping it saves others the same headaches...<p>Two primitives:<p><pre><code>  const reader = new ReaderClient();\n  \n  // Scrape URLs \u2192 clean markdown\n  const result = await reader.scrape({ urls: [&quot;https://example.com&quot;] });\n  \n  // Crawl a site \u2192 discover + scrape pages\n  const pages = await reader.crawl({ url: &quot;https://example.com&quot;, depth: 2 });\n</code></pre>\nUnder the hood it's built on Ulixee Hero, a headless browser designed for \nanti-detection. The hard stuff like TLS fingerprinting, Cloudflare/Turnstile bypass, browser pool recycling, proxy rotation is built in.<p>The HTML-to-markdown conversion uses supermarkdown, a Rust engine I built \nspecifically for messy real world HTML. Clean output, no artifacts.<p>TypeScript first, full type safety, works as CLI or library. Apache 2.0 license.<p>GitHub: <a href=\"https://github.com/vakra-dev/reader\" rel=\"nofollow\">https://github.com/vakra-dev/reader</a><p>Happy to answer questions about the architecture, approach, or tradeoffs I made.<p>Would love feedback from anyone doing web scraping at scale, especially on edge cases where it breaks. That's how I can make this better."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Reader \u2013 open-source web scraping engine built for LLMs"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/vakra-dev/reader"}}, "_tags": ["story", "author_nihalwashere", "story_46908355", "show_hn"], "author": "nihalwashere", "created_at": "2026-02-06T02:42:29Z", "created_at_i": 1770345749, "num_comments": 0, "objectID": "46908355", "points": 1, "story_id": 46908355, "story_text": "I&#x27;ve been building AI agents that needed web access and kept hitting the same wall: production scraping is hard. You start with Puppeteer, then add stealth plugins, then fight Cloudflare, then manage proxies, then handle browser pooling and it still breaks.<p>I kept solving this problem from scratch on different projects, so I packaged it up as Reader, hoping it saves others the same headaches...<p>Two primitives:<p><pre><code>  const reader = new ReaderClient();\n  \n  &#x2F;&#x2F; Scrape URLs \u2192 clean markdown\n  const result = await reader.scrape({ urls: [&quot;https:&#x2F;&#x2F;example.com&quot;] });\n  \n  &#x2F;&#x2F; Crawl a site \u2192 discover + scrape pages\n  const pages = await reader.crawl({ url: &quot;https:&#x2F;&#x2F;example.com&quot;, depth: 2 });\n</code></pre>\nUnder the hood it&#x27;s built on Ulixee Hero, a headless browser designed for \nanti-detection. The hard stuff like TLS fingerprinting, Cloudflare&#x2F;Turnstile bypass, browser pool recycling, proxy rotation is built in.<p>The HTML-to-markdown conversion uses supermarkdown, a Rust engine I built \nspecifically for messy real world HTML. Clean output, no artifacts.<p>TypeScript first, full type safety, works as CLI or library. Apache 2.0 license.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;vakra-dev&#x2F;reader\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;vakra-dev&#x2F;reader</a><p>Happy to answer questions about the architecture, approach, or tradeoffs I made.<p>Would love feedback from anyone doing web scraping at scale, especially on edge cases where it breaks. That&#x27;s how I can make this better.", "title": "Show HN: Reader \u2013 open-source web scraping engine built for LLMs", "updated_at": "2026-02-06T02:47:02Z", "url": "https://github.com/vakra-dev/reader"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "migambi"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["puppeteer", "production"], "value": "Hey HN,\nI built Fileloom because I kept running into the same problems with PDF generation: font rendering breaks on Linux servers, <em>Puppeteer</em> setup is painful, and most services charge $15-30/month for only a few hundred PDFs.\nFileloom is a simple PDF generation API. Send HTML (or use saved templates with Handlebars syntax), get a PDF back in under 2 seconds.\nWhat's included:<p>Single endpoint: POST to /v1/pdf/generate\n70+ built-in Handlebars helpers (currency formatting, dates, loops, conditionals, math)\nAutomatic font handling - no more debugging why fonts work locally but not in <em>production</em>\nStore PDFs on our infrastructure or yours (S3, Supabase)\nWebhooks for pdf.generated and pdf.failed events<p>Free tier is 200 PDFs/month, no credit card required. Paid plans start at $7.20/month.\nI'd appreciate feedback on the API design and developer experience."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Fileloom \u2013 HTML to PDF API with 70 Handlebars Helpers"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://fileloom.io/"}}, "_tags": ["story", "author_migambi", "story_46390719", "show_hn"], "author": "migambi", "created_at": "2025-12-26T09:53:12Z", "created_at_i": 1766742792, "num_comments": 0, "objectID": "46390719", "points": 1, "story_id": 46390719, "story_text": "Hey HN,\nI built Fileloom because I kept running into the same problems with PDF generation: font rendering breaks on Linux servers, Puppeteer setup is painful, and most services charge $15-30&#x2F;month for only a few hundred PDFs.\nFileloom is a simple PDF generation API. Send HTML (or use saved templates with Handlebars syntax), get a PDF back in under 2 seconds.\nWhat&#x27;s included:<p>Single endpoint: POST to &#x2F;v1&#x2F;pdf&#x2F;generate\n70+ built-in Handlebars helpers (currency formatting, dates, loops, conditionals, math)\nAutomatic font handling - no more debugging why fonts work locally but not in production\nStore PDFs on our infrastructure or yours (S3, Supabase)\nWebhooks for pdf.generated and pdf.failed events<p>Free tier is 200 PDFs&#x2F;month, no credit card required. Paid plans start at $7.20&#x2F;month.\nI&#x27;d appreciate feedback on the API design and developer experience.", "title": "Show HN: Fileloom \u2013 HTML to PDF API with 70 Handlebars Helpers", "updated_at": "2025-12-26T09:56:02Z", "url": "https://fileloom.io/"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "hongyeon"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["puppeteer", "production"], "value": "Hi HN,<p>I'm releasing LLM Newsletter Kit, a <em>production</em>-tested TypeScript toolkit designed to build AI-driven newsletter pipelines. It handles the full lifecycle: crawling \u2192 analysis \u2192 generation \u2192 delivery.<p>The Context: I\u2019m an archaeologist-turned-engineer. I built this engine for &quot;Research Radar&quot; (a cultural heritage newsletter) to automate my own manual research aggregation. It currently maintains a 15% CTR with near-zero maintenance, costing ~$0.20-1 per issue.<p>Core Features:<p>&quot;Bring Your Own Scraper&quot;: Async injection lets you use Cheerio, <em>Puppeteer</em>, or LLM-based parsers without framework lock-in.<p>Provider-based DI: Swap out crawling, analysis, or storage components via clean interfaces.<p><em>Production</em>-First: 100% test coverage, built-in retries, cost controls, and observability baked in.<p>Tech Stack: TypeScript ESM, LangChain runnables, Vercel AI SDK (structured outputs), and Zod.<p>Why Code instead of No-Code? To optimize costs and quality, you need granular control over context windows, token limits, and retry strategies. This toolkit allows for advanced workflows (e.g., self-reflection loops) that are often prohibitively expensive or impossible in drag-and-drop tools.<p>Links:<p>Code (GitHub): <a href=\"https://github.com/kimhongyeon/heripo-research-radar\" rel=\"nofollow\">https://github.com/kimhongyeon/heripo-research-radar</a><p>Live Example: <a href=\"https://heripo.com/research-radar-newsletter-example.html\" rel=\"nofollow\">https://heripo.com/research-radar-newsletter-example.html</a><p>npm: @llm-newsletter-kit/core<p>I'd love your feedback on the architecture and DX!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: LLM Newsletter Kit \u2013 A TypeScript Framework for AI Newsletters"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/kimhongyeon/llm-newsletter-kit-core"}}, "_tags": ["story", "author_hongyeon", "story_46094018", "show_hn"], "author": "hongyeon", "created_at": "2025-11-30T05:16:16Z", "created_at_i": 1764479776, "num_comments": 0, "objectID": "46094018", "points": 1, "story_id": 46094018, "story_text": "Hi HN,<p>I&#x27;m releasing LLM Newsletter Kit, a production-tested TypeScript toolkit designed to build AI-driven newsletter pipelines. It handles the full lifecycle: crawling \u2192 analysis \u2192 generation \u2192 delivery.<p>The Context: I\u2019m an archaeologist-turned-engineer. I built this engine for &quot;Research Radar&quot; (a cultural heritage newsletter) to automate my own manual research aggregation. It currently maintains a 15% CTR with near-zero maintenance, costing ~$0.20-1 per issue.<p>Core Features:<p>&quot;Bring Your Own Scraper&quot;: Async injection lets you use Cheerio, Puppeteer, or LLM-based parsers without framework lock-in.<p>Provider-based DI: Swap out crawling, analysis, or storage components via clean interfaces.<p>Production-First: 100% test coverage, built-in retries, cost controls, and observability baked in.<p>Tech Stack: TypeScript ESM, LangChain runnables, Vercel AI SDK (structured outputs), and Zod.<p>Why Code instead of No-Code? To optimize costs and quality, you need granular control over context windows, token limits, and retry strategies. This toolkit allows for advanced workflows (e.g., self-reflection loops) that are often prohibitively expensive or impossible in drag-and-drop tools.<p>Links:<p>Code (GitHub): <a href=\"https:&#x2F;&#x2F;github.com&#x2F;kimhongyeon&#x2F;heripo-research-radar\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;kimhongyeon&#x2F;heripo-research-radar</a><p>Live Example: <a href=\"https:&#x2F;&#x2F;heripo.com&#x2F;research-radar-newsletter-example.html\" rel=\"nofollow\">https:&#x2F;&#x2F;heripo.com&#x2F;research-radar-newsletter-example.html</a><p>npm: @llm-newsletter-kit&#x2F;core<p>I&#x27;d love your feedback on the architecture and DX!", "title": "Show HN: LLM Newsletter Kit \u2013 A TypeScript Framework for AI Newsletters", "updated_at": "2025-11-30T05:20:48Z", "url": "https://github.com/kimhongyeon/llm-newsletter-kit-core"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "Kikobeats"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["puppeteer", "production"], "value": "Browserless, a <em>puppeter</em>-like Node.js library for <em>production</em> scenarios"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://browserless.js.org"}}, "_tags": ["story", "author_Kikobeats", "story_19013440"], "author": "Kikobeats", "created_at": "2019-01-27T19:51:28Z", "created_at_i": 1548618688, "num_comments": 0, "objectID": "19013440", "points": 4, "story_id": 19013440, "title": "Browserless, a puppeter-like Node.js library for production scenarios", "updated_at": "2024-09-20T03:38:06Z", "url": "https://browserless.js.org"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "tomneijman"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["puppeteer", "production"], "value": "I built an open format for self-contained knowledge cards.<p>Each card is a single directory:\n- standalone HTML (no CDN, no external fonts)\n- bundled CSS + assets\n- print-ready PDF\n- JSON-LD metadata<p>No account. No platform. No external dependencies.\nThe card itself is the product.<p>Goal: use LLMs to distill practical knowledge into small independent units \u2014 then make those units survive without the technology that created them.<p>&quot;The best use of AI is not automation, but preservation \u2014 helping humans rebuild when machines are gone.&quot;<p>---<p>Identifier model:<p>Each card receives a 128-bit ULID.\nThe bits are mapped to A/C/G/T, <em>producin</em>g a 64-character DNA-like sequence.<p>The first 9 characters map to three craft \u201ccodon\u201d words from a fixed vocabulary (e.g. klei\u00b7vuur\u00b7rots).<p>Properties:\n- Globally unique\n- Chronologically sortable\n- Bidirectionally decodable\n- No central registry<p>The DNA appears in the URL, footer, and print version.<p>---<p>Integrity:<p>Each build generates a SHA-256 manifest of all cards, signed with Ed25519.\nVerification happens client-side using the Web Crypto API (no server round-trip).<p>Verify here:\n<a href=\"https://stoutenburger.com/verify/\" rel=\"nofollow\">https://stoutenburger.com/verify/</a><p>---<p>Edition 1 is live (10 cards):\nWater purification, fire, clay, basic metallurgy.<p>Five card types:\nKnowledge (why), Instruction (how), Product (what), Maker (who), Network (connections).<p>Build pipeline:\nMarkdown + YAML \u2192 JSON Schema \u2192 Nunjucks \u2192 <em>Puppeteer</em> \u2192 signed manifest.<p>Cards are designed to roam: USB stick, any domain, or printed in a drawer.<p>The format is open.\n<a href=\"https://stoutenburger.com\" rel=\"nofollow\">https://stoutenburger.com</a>"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Self-contained offline knowledge cards with ULID-DNA and IDsEd25519"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://stoutenburger.com"}}, "_tags": ["story", "author_tomneijman", "story_47167429", "show_hn"], "author": "tomneijman", "created_at": "2026-02-26T15:31:30Z", "created_at_i": 1772119890, "num_comments": 0, "objectID": "47167429", "points": 1, "story_id": 47167429, "story_text": "I built an open format for self-contained knowledge cards.<p>Each card is a single directory:\n- standalone HTML (no CDN, no external fonts)\n- bundled CSS + assets\n- print-ready PDF\n- JSON-LD metadata<p>No account. No platform. No external dependencies.\nThe card itself is the product.<p>Goal: use LLMs to distill practical knowledge into small independent units \u2014 then make those units survive without the technology that created them.<p>&quot;The best use of AI is not automation, but preservation \u2014 helping humans rebuild when machines are gone.&quot;<p>---<p>Identifier model:<p>Each card receives a 128-bit ULID.\nThe bits are mapped to A&#x2F;C&#x2F;G&#x2F;T, producing a 64-character DNA-like sequence.<p>The first 9 characters map to three craft \u201ccodon\u201d words from a fixed vocabulary (e.g. klei\u00b7vuur\u00b7rots).<p>Properties:\n- Globally unique\n- Chronologically sortable\n- Bidirectionally decodable\n- No central registry<p>The DNA appears in the URL, footer, and print version.<p>---<p>Integrity:<p>Each build generates a SHA-256 manifest of all cards, signed with Ed25519.\nVerification happens client-side using the Web Crypto API (no server round-trip).<p>Verify here:\n<a href=\"https:&#x2F;&#x2F;stoutenburger.com&#x2F;verify&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;stoutenburger.com&#x2F;verify&#x2F;</a><p>---<p>Edition 1 is live (10 cards):\nWater purification, fire, clay, basic metallurgy.<p>Five card types:\nKnowledge (why), Instruction (how), Product (what), Maker (who), Network (connections).<p>Build pipeline:\nMarkdown + YAML \u2192 JSON Schema \u2192 Nunjucks \u2192 Puppeteer \u2192 signed manifest.<p>Cards are designed to roam: USB stick, any domain, or printed in a drawer.<p>The format is open.\n<a href=\"https:&#x2F;&#x2F;stoutenburger.com\" rel=\"nofollow\">https:&#x2F;&#x2F;stoutenburger.com</a>", "title": "Show HN: Self-contained offline knowledge cards with ULID-DNA and IDsEd25519", "updated_at": "2026-02-26T15:36:20Z", "url": "https://stoutenburger.com"}], "hitsPerPage": 15, "nbHits": 15, "nbPages": 1, "page": 0, "params": "query=puppeteer+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 10, "processingTimingsMS": {"_request": {"roundTrip": 16}, "afterFetch": {"format": {"highlighting": 2, "total": 2}}, "fetch": {"query": 8, "scanning": 1, "total": 10}, "total": 11}, "query": "puppeteer production", "serverTimeMS": 13}}