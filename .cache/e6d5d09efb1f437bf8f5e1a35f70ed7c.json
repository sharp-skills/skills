{"d": {"exhaustive": {"nbHits": false, "typo": false}, "exhaustiveNbHits": false, "exhaustiveTypo": false, "hits": [{"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "toshvelaga"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["openai", "production"], "value": "Created an app that connect <em>OpenAI</em> to my <em>production</em> postgres DB using langchain.<p>App: https://askmydb.vercel.app/<p>Check out the demo: https://www.loom.com/share/108e23873cfc41edbb8923cc86edccb3<p>Built using Next JS, Vercel, AWS Lambda and langchain. Everything is stored locally on the user's computer."}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["openai"], "value": "Connected <em>OpenAI</em> to My Postgres DB"}}, "_tags": ["story", "author_toshvelaga", "story_35781371", "ask_hn"], "author": "toshvelaga", "children": [35821040], "created_at": "2023-05-02T00:24:10Z", "created_at_i": 1682987050, "num_comments": 1, "objectID": "35781371", "points": 8, "story_id": 35781371, "story_text": "Created an app that connect OpenAI to my production postgres DB using langchain.<p>App: https:&#x2F;&#x2F;askmydb.vercel.app&#x2F;<p>Check out the demo: https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;108e23873cfc41edbb8923cc86edccb3<p>Built using Next JS, Vercel, AWS Lambda and langchain. Everything is stored locally on the user&#x27;s computer.", "title": "Connected OpenAI to My Postgres DB", "updated_at": "2024-09-20T14:03:40Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "cjohnsonpr"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["openai", "production"], "value": "Building AI agents shouldn't require weeks of setup and boilerplate code. So our Metis Analytics team is releasing our Metis OS Agentic Orchestration Framework as Open Source that will get you from idea to working agent in minutes, not days.<p>What it solves: Instead of spending days wiring up LLM APIs, memory systems, and tool integrations, you get a working agent in ~5 minutes.<p>Get started:\npip install metis-agent<p>Key features:<p>Templates for common agent types (research, coding, customer support)\nEncrypted API key management (stores locally, never in code)\nAdaptive memory system that learns what's important<p>Works with Groq, <em>OpenAI</em>, Anthropic, HuggingFace\n<em>Production</em> deployment examples (CLI, web API, embedded)<p>Why it matters: Most AI agent tutorials give you toy examples. This gives you something you can actually ship.<p>The starter kit repo has 10+ working examples and customizable templates. Everything's Apache 2.0 licensed.<p>PyPI: https://pypi.org/project/metis-agent/\nGitHub:https://github.com/metisos/metisos_agentV1\nWould love feedback from the community - especially if you've built similar tooling or have ideas for additional agent templates."}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Metis Agent Starter Kit \u2013 Build <em>production</em> AI agents in minutes, not weeks"}}, "_tags": ["story", "author_cjohnsonpr", "story_44620860", "ask_hn"], "author": "cjohnsonpr", "created_at": "2025-07-20T00:41:23Z", "created_at_i": 1752972083, "num_comments": 0, "objectID": "44620860", "points": 4, "story_id": 44620860, "story_text": "Building AI agents shouldn&#x27;t require weeks of setup and boilerplate code. So our Metis Analytics team is releasing our Metis OS Agentic Orchestration Framework as Open Source that will get you from idea to working agent in minutes, not days.<p>What it solves: Instead of spending days wiring up LLM APIs, memory systems, and tool integrations, you get a working agent in ~5 minutes.<p>Get started:\npip install metis-agent<p>Key features:<p>Templates for common agent types (research, coding, customer support)\nEncrypted API key management (stores locally, never in code)\nAdaptive memory system that learns what&#x27;s important<p>Works with Groq, OpenAI, Anthropic, HuggingFace\nProduction deployment examples (CLI, web API, embedded)<p>Why it matters: Most AI agent tutorials give you toy examples. This gives you something you can actually ship.<p>The starter kit repo has 10+ working examples and customizable templates. Everything&#x27;s Apache 2.0 licensed.<p>PyPI: https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;metis-agent&#x2F;\nGitHub:https:&#x2F;&#x2F;github.com&#x2F;metisos&#x2F;metisos_agentV1\nWould love feedback from the community - especially if you&#x27;ve built similar tooling or have ideas for additional agent templates.", "title": "Metis Agent Starter Kit \u2013 Build production AI agents in minutes, not weeks", "updated_at": "2025-07-21T06:13:34Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "lforster"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["openai", "production"], "value": "Hi HN! I built Treyspace, an SDK that turns Excalidraw canvases into queryable knowledge graphs using RAG (Retrieval Augmented Generation).<p>What it does:\n- Ingests canvas data and mirrors it into a graph-vector database (Helix)\n- Performs semantic, relational, and spatial clustering of canvas elements\n- Lets you query your diagrams with natural language via LLM-powered analysis<p>Why I built it: I found myself creating complex diagrams in Excalidraw but struggling to extract insights from them later. Traditional search doesn't understand spatial relationships or semantic connections between elements. Treyspace bridges that gap by treating your canvas as a knowledge graph.<p>Demo: <a href=\"https://app.treyspace.app/\" rel=\"nofollow\">https://app.treyspace.app/</a> (no API key required)<p>Key features:\n- Works with in-memory mode by default (no DB setup needed)\n- Optional Helix DB backend for <em>production</em> use\n- <em>OpenAI</em>-compatible responses API\n- SSE streaming for real-time analysis\n- Use as a library or standalone server<p>Example use case: Load an architecture diagram, ask &quot;What are the security vulnerabilities in this design?&quot; and get context-aware answers based on spatial proximity, element relationships, and semantic understanding.<p>The SDK and source code is MIT licensed and designed to be hacked on. I\u2019ve tried to make it as simple as possible to set up (all you should need is an <em>OpenAI</em> API key)<p>Repo: <a href=\"https://github.com/L-Forster/treyspace-sdk\" rel=\"nofollow\">https://github.com/L-Forster/treyspace-sdk</a><p>Would love feedback on the approach and hear how you might use canvas-based RAG!"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Treyspace \u2500 Open Source Graph RAG on Your Excalidraw Canvas"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/L-Forster/treyspace-sdk"}}, "_tags": ["story", "author_lforster", "story_45945462", "show_hn"], "author": "lforster", "created_at": "2025-11-16T14:40:34Z", "created_at_i": 1763304034, "num_comments": 0, "objectID": "45945462", "points": 2, "story_id": 45945462, "story_text": "Hi HN! I built Treyspace, an SDK that turns Excalidraw canvases into queryable knowledge graphs using RAG (Retrieval Augmented Generation).<p>What it does:\n- Ingests canvas data and mirrors it into a graph-vector database (Helix)\n- Performs semantic, relational, and spatial clustering of canvas elements\n- Lets you query your diagrams with natural language via LLM-powered analysis<p>Why I built it: I found myself creating complex diagrams in Excalidraw but struggling to extract insights from them later. Traditional search doesn&#x27;t understand spatial relationships or semantic connections between elements. Treyspace bridges that gap by treating your canvas as a knowledge graph.<p>Demo: <a href=\"https:&#x2F;&#x2F;app.treyspace.app&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;app.treyspace.app&#x2F;</a> (no API key required)<p>Key features:\n- Works with in-memory mode by default (no DB setup needed)\n- Optional Helix DB backend for production use\n- OpenAI-compatible responses API\n- SSE streaming for real-time analysis\n- Use as a library or standalone server<p>Example use case: Load an architecture diagram, ask &quot;What are the security vulnerabilities in this design?&quot; and get context-aware answers based on spatial proximity, element relationships, and semantic understanding.<p>The SDK and source code is MIT licensed and designed to be hacked on. I\u2019ve tried to make it as simple as possible to set up (all you should need is an OpenAI API key)<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;L-Forster&#x2F;treyspace-sdk\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;L-Forster&#x2F;treyspace-sdk</a><p>Would love feedback on the approach and hear how you might use canvas-based RAG!", "title": "Show HN: Treyspace \u2500 Open Source Graph RAG on Your Excalidraw Canvas", "updated_at": "2025-11-16T17:07:43Z", "url": "https://github.com/L-Forster/treyspace-sdk"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "universesquid"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["openai", "production"], "value": "Hey everyone,<p>is your company using a fine-tuned Open Source Model instead of <em>OpenAI</em> products for <em>production</em> tasks or thinking about it? How are your experiences with that?"}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Ask HN: Using Open Source LLMs in your company"}}, "_tags": ["story", "author_universesquid", "story_35861643", "ask_hn"], "author": "universesquid", "created_at": "2023-05-08T14:06:43Z", "created_at_i": 1683554803, "num_comments": 0, "objectID": "35861643", "points": 2, "story_id": 35861643, "story_text": "Hey everyone,<p>is your company using a fine-tuned Open Source Model instead of OpenAI products for production tasks or thinking about it? How are your experiences with that?", "title": "Ask HN: Using Open Source LLMs in your company", "updated_at": "2024-09-20T14:03:49Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "sukit"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["openai", "production"], "value": "I'm exploring building a simple agent-based app and came across <em>OpenAI</em>'s Agent SDK: https://<em>openai</em>.github.io/<em>openai</em>-agents-js/ . From what I understand, it wraps a lot of functionality \u2014 like the agent loop, function calling, and integration with the <em>OpenAI</em> MCP server \u2014 which could potentially save me a lot of work compared to using the plain <em>OpenAI</em> SDK.<p>However, I'm wondering:<p>Is the Agent SDK too abstracted or hard to debug?<p>Has anyone actually used it in a real <em>production</em> app yet?<p>Would I be better off just implementing the logic myself on top of the plain <em>OpenAI</em> SDK for more control and transparency?<p>Appreciate any insights."}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["openai", "production"], "value": "Ask HN: Anyone using <em>OpenAI</em>'s Agent SDK in <em>production</em>?"}}, "_tags": ["story", "author_sukit", "story_44353964", "ask_hn"], "author": "sukit", "children": [44354618, 44359557, 44386335], "created_at": "2025-06-23T09:49:43Z", "created_at_i": 1750672183, "num_comments": 3, "objectID": "44353964", "points": 8, "story_id": 44353964, "story_text": "I&#x27;m exploring building a simple agent-based app and came across OpenAI&#x27;s Agent SDK: https:&#x2F;&#x2F;openai.github.io&#x2F;openai-agents-js&#x2F; . From what I understand, it wraps a lot of functionality \u2014 like the agent loop, function calling, and integration with the OpenAI MCP server \u2014 which could potentially save me a lot of work compared to using the plain OpenAI SDK.<p>However, I&#x27;m wondering:<p>Is the Agent SDK too abstracted or hard to debug?<p>Has anyone actually used it in a real production app yet?<p>Would I be better off just implementing the logic myself on top of the plain OpenAI SDK for more control and transparency?<p>Appreciate any insights.", "title": "Ask HN: Anyone using OpenAI's Agent SDK in production?", "updated_at": "2025-06-26T11:30:43Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "radhakrsna"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["openai", "production"], "value": "Hi HN,<p>Today, we are excited to be open-sourcing GPTRouter, an LLMOps tool we have been using internally at Writesonic for handling millions of monthly requests for our users.<p>Universal API for 30+ LLMs, Vision and Image Models\n Smart Fallbacks based on latency and uptime\n Automatic Retries\n Supports streaming<p>Since embracing <em>OpenAI</em> GPT-3 in <em>production</em> in 2020, we at Writesonic have been serving millions of users and faced the typical scaling pains with generative AI models:<p>1. Dependency on a single model risked total downtime.\n2. Latency issues with models like GPT-4 affected user experience.\n3. Integrating various models was tough due to different APIs and SDKs.<p>Early this year at Writesonic, we set out with a clear vision: to become model agnostic.<p>Faced with single-model limitations and diverse AI challenges, we began building GPTRouter - our bespoke solution to navigate and thrive in a multi-model AI world.<p>With GPTRouter's Universal API, you're the master of AI models.\nSwap between <em>OpenAI</em>, Azure, Anthropic, Replicate, Cohere &amp; more with just one line of code.\nIt simplifies model management to a great extent.<p>Downtime isn't an option.\nGPTRouter's Smart Fallbacks mean your service is always on.\nYou can define a hierarchy of models for each use case. GPTRouter will constantly check for uptime/downtime, latency and other factors, and automatically fallback to the next best model with zero interruption.<p>Say goodbye to manual retries.\nGPTRouter does the heavy lifting with Automatic Retries for failed requests, keeping your AI services sharp and consistent.<p>GPTRouter's Edge:\n Universal API for seamless model switching.\n Smart, automatic fallbacks for continuous service.\n Reduced latencies for quick interactions.<p>Additionally, we will also be open sourcing our frontend LLMOps layer that provides a playground to test multiple models in parallel, keep a tab on the latencies for each model, track tokens and costs for each model and user all in one place.<p>We are looking forward to seeing how developers leverage GPTRouter in their own use cases.<p>Thank you!"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["openai"], "value": "Show HN: GPT Router \u2013 Open-Source API Gateway for LLMs (<em>OpenAI</em>, Anthropic, etc.)"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://github.com/Writesonic/GPTRouter"}}, "_tags": ["story", "author_radhakrsna", "story_38733891", "show_hn"], "author": "radhakrsna", "children": [38733926, 38733941, 38733951, 38733953, 38733959, 38733960, 38733965, 38733978, 38733995, 38734010, 38734054, 38734139, 38736848, 38742877], "created_at": "2023-12-22T13:24:32Z", "created_at_i": 1703251472, "num_comments": 11, "objectID": "38733891", "points": 15, "story_id": 38733891, "story_text": "Hi HN,<p>Today, we are excited to be open-sourcing GPTRouter, an LLMOps tool we have been using internally at Writesonic for handling millions of monthly requests for our users.<p>Universal API for 30+ LLMs, Vision and Image Models\n Smart Fallbacks based on latency and uptime\n Automatic Retries\n Supports streaming<p>Since embracing OpenAI GPT-3 in production in 2020, we at Writesonic have been serving millions of users and faced the typical scaling pains with generative AI models:<p>1. Dependency on a single model risked total downtime.\n2. Latency issues with models like GPT-4 affected user experience.\n3. Integrating various models was tough due to different APIs and SDKs.<p>Early this year at Writesonic, we set out with a clear vision: to become model agnostic.<p>Faced with single-model limitations and diverse AI challenges, we began building GPTRouter - our bespoke solution to navigate and thrive in a multi-model AI world.<p>With GPTRouter&#x27;s Universal API, you&#x27;re the master of AI models.\nSwap between OpenAI, Azure, Anthropic, Replicate, Cohere &amp; more with just one line of code.\nIt simplifies model management to a great extent.<p>Downtime isn&#x27;t an option.\nGPTRouter&#x27;s Smart Fallbacks mean your service is always on.\nYou can define a hierarchy of models for each use case. GPTRouter will constantly check for uptime&#x2F;downtime, latency and other factors, and automatically fallback to the next best model with zero interruption.<p>Say goodbye to manual retries.\nGPTRouter does the heavy lifting with Automatic Retries for failed requests, keeping your AI services sharp and consistent.<p>GPTRouter&#x27;s Edge:\n Universal API for seamless model switching.\n Smart, automatic fallbacks for continuous service.\n Reduced latencies for quick interactions.<p>Additionally, we will also be open sourcing our frontend LLMOps layer that provides a playground to test multiple models in parallel, keep a tab on the latencies for each model, track tokens and costs for each model and user all in one place.<p>We are looking forward to seeing how developers leverage GPTRouter in their own use cases.<p>Thank you!", "title": "Show HN: GPT Router \u2013 Open-Source API Gateway for LLMs (OpenAI, Anthropic, etc.)", "updated_at": "2025-08-14T22:50:02Z", "url": "https://github.com/Writesonic/GPTRouter"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "shotwellj"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["openai", "production"], "value": "We built AIR Blackbox \u2014 open-source compliance infrastructure for AI agents targeting the EU AI Act enforcement deadline on August 2, 2026.\nIf you're deploying LLM-based agents (LangChain, CrewAI, AutoGen, <em>OpenAI</em> Agents SDK) into <em>production</em>, the EU AI Act requires tamper-evident audit trails, human oversight mechanisms, data governance controls, and injection defense \u2014 for any system classified as high-risk.\nMost teams we've talked to either don't know about the deadline or assume their existing logging is enough. It's not. Article 12 specifically requires logs that regulators can mathematically verify haven't been altered. Article 14 requires the ability to interrupt agent execution. Article 15 requires defense against prompt injection and data poisoning.\nWhat we built:<p>Trust layers for LangChain, CrewAI, AutoGen, <em>OpenAI</em> Agents SDK, and RAG pipelines \u2014 each is a pip install that hooks into your existing agent code with ~3 lines of setup\nHMAC-SHA256 tamper-evident audit chains \u2014 every agent decision, tool call, and LLM interaction gets logged to a chain that regulators can verify\nConsentGate \u2014 risk-classifies tool calls and blocks critical operations until approved\nInjectionDetector \u2014 15+ weighted patterns scanning prompts before they reach the model\nWriteGate + DriftDetector (for RAG) \u2014 prevents knowledge base poisoning and detects retrieval anomalies\nCompliance scanner \u2014 pip install air-compliance &amp;&amp; air-compliance scan ./my-project tells you exactly which articles you're missing<p>Everything maps to specific EU AI Act articles (9, 10, 11, 12, 14, 15). Zero vendor lock-in, Apache 2.0, zero core dependencies on the trust layers.\nThe scanner is probably the fastest way to understand where your gaps are. It takes about 3 seconds to run on a typical project.\nGitHub: <a href=\"https://github.com/airblackbox\" rel=\"nofollow\">https://github.com/airblackbox</a>\nPyPI: pip install air-compliance\nHappy to answer questions about what the EU AI Act actually requires for AI agent deployments \u2014 we've read the full regulation and mapped it to specific technical controls."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: Open-source EU AI Act compliance layer for AI agents (8/2026 deadline)"}}, "_tags": ["story", "author_shotwellj", "story_47141347", "show_hn"], "author": "shotwellj", "children": [47142266, 47163737], "created_at": "2026-02-24T19:15:45Z", "created_at_i": 1771960545, "num_comments": 2, "objectID": "47141347", "points": 2, "story_id": 47141347, "story_text": "We built AIR Blackbox \u2014 open-source compliance infrastructure for AI agents targeting the EU AI Act enforcement deadline on August 2, 2026.\nIf you&#x27;re deploying LLM-based agents (LangChain, CrewAI, AutoGen, OpenAI Agents SDK) into production, the EU AI Act requires tamper-evident audit trails, human oversight mechanisms, data governance controls, and injection defense \u2014 for any system classified as high-risk.\nMost teams we&#x27;ve talked to either don&#x27;t know about the deadline or assume their existing logging is enough. It&#x27;s not. Article 12 specifically requires logs that regulators can mathematically verify haven&#x27;t been altered. Article 14 requires the ability to interrupt agent execution. Article 15 requires defense against prompt injection and data poisoning.\nWhat we built:<p>Trust layers for LangChain, CrewAI, AutoGen, OpenAI Agents SDK, and RAG pipelines \u2014 each is a pip install that hooks into your existing agent code with ~3 lines of setup\nHMAC-SHA256 tamper-evident audit chains \u2014 every agent decision, tool call, and LLM interaction gets logged to a chain that regulators can verify\nConsentGate \u2014 risk-classifies tool calls and blocks critical operations until approved\nInjectionDetector \u2014 15+ weighted patterns scanning prompts before they reach the model\nWriteGate + DriftDetector (for RAG) \u2014 prevents knowledge base poisoning and detects retrieval anomalies\nCompliance scanner \u2014 pip install air-compliance &amp;&amp; air-compliance scan .&#x2F;my-project tells you exactly which articles you&#x27;re missing<p>Everything maps to specific EU AI Act articles (9, 10, 11, 12, 14, 15). Zero vendor lock-in, Apache 2.0, zero core dependencies on the trust layers.\nThe scanner is probably the fastest way to understand where your gaps are. It takes about 3 seconds to run on a typical project.\nGitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;airblackbox\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;airblackbox</a>\nPyPI: pip install air-compliance\nHappy to answer questions about what the EU AI Act actually requires for AI agent deployments \u2014 we&#x27;ve read the full regulation and mapped it to specific technical controls.", "title": "Show HN: Open-source EU AI Act compliance layer for AI agents (8/2026 deadline)", "updated_at": "2026-02-26T09:13:32Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "josharsh"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["openai", "production"], "value": "I spent months watching AI tutorials on YouTube. Took notes. Felt like I learned a ton. Then I sat down to build something and... couldn't. \nI didn't actually understand a lot of stuff!<p>The problem: Passive learning doesn't work for engineering skills.<p>What makes this different:<p>\u2022 You TYPE every command (no copy-paste)\n\u2022 You SEE real API responses (not fake demos)\n\u2022 You PAY real costs (~$10 total)\n\u2022 Terminal-only (no context switching)<p>Think vimtutor, but for AI engineering.<p>20 modules covering:\n- Tokens, embeddings, RAG\n- Structured outputs, tool calling, agents\n- Cost optimisation, evals, <em>production</em> monitoring\n- Real <em>OpenAI</em>/Anthropic API calls<p>Try it:\nnpx ai-terminal-course<p>No installation. Just run it."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: AI Terminal Course \u2013 Learn AI Engineering Like Learning Vim"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://www.npmjs.com/package/ai-terminal-course"}}, "_tags": ["story", "author_josharsh", "story_45897246", "show_hn"], "author": "josharsh", "children": [45898617], "created_at": "2025-11-12T07:19:21Z", "created_at_i": 1762931961, "num_comments": 1, "objectID": "45897246", "points": 1, "story_id": 45897246, "story_text": "I spent months watching AI tutorials on YouTube. Took notes. Felt like I learned a ton. Then I sat down to build something and... couldn&#x27;t. \nI didn&#x27;t actually understand a lot of stuff!<p>The problem: Passive learning doesn&#x27;t work for engineering skills.<p>What makes this different:<p>\u2022 You TYPE every command (no copy-paste)\n\u2022 You SEE real API responses (not fake demos)\n\u2022 You PAY real costs (~$10 total)\n\u2022 Terminal-only (no context switching)<p>Think vimtutor, but for AI engineering.<p>20 modules covering:\n- Tokens, embeddings, RAG\n- Structured outputs, tool calling, agents\n- Cost optimisation, evals, production monitoring\n- Real OpenAI&#x2F;Anthropic API calls<p>Try it:\nnpx ai-terminal-course<p>No installation. Just run it.", "title": "Show HN: AI Terminal Course \u2013 Learn AI Engineering Like Learning Vim", "updated_at": "2025-11-12T10:48:12Z", "url": "https://www.npmjs.com/package/ai-terminal-course"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "gniting"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["openai", "production"], "value": "<em>OpenAI</em> set to start mass <em>production</em> of its own AI chips with Broadcom"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://www.ft.com/content/e8cc6d99-d06e-4e9b-a54f-29317fa68d6f"}}, "_tags": ["story", "author_gniting", "story_45152767"], "author": "gniting", "children": [45153249, 45153552, 45154984], "created_at": "2025-09-06T20:56:20Z", "created_at_i": 1757192180, "num_comments": 4, "objectID": "45152767", "points": 31, "story_id": 45152767, "title": "OpenAI set to start mass production of its own AI chips with Broadcom", "updated_at": "2025-09-07T22:29:46Z", "url": "https://www.ft.com/content/e8cc6d99-d06e-4e9b-a54f-29317fa68d6f"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "ohong"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["openai", "production"], "value": "<em>OpenAI</em> set to start mass <em>production</em> of its own AI chips with Broadcom"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://www.ft.com/content/e8cc6d99-d06e-4e9b-a54f-29317fa68d6f"}}, "_tags": ["story", "author_ohong", "story_45134079"], "author": "ohong", "children": [45134080], "created_at": "2025-09-05T01:15:13Z", "created_at_i": 1757034913, "num_comments": 1, "objectID": "45134079", "points": 5, "story_id": 45134079, "title": "OpenAI set to start mass production of its own AI chips with Broadcom", "updated_at": "2025-09-05T05:15:37Z", "url": "https://www.ft.com/content/e8cc6d99-d06e-4e9b-a54f-29317fa68d6f"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "alephnerd"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["openai", "production"], "value": "<em>OpenAI</em> set to start mass <em>production</em> of its own AI chips with Broadcom"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://www.ft.com/content/e8cc6d99-d06e-4e9b-a54f-29317fa68d6f"}}, "_tags": ["story", "author_alephnerd", "story_45134200"], "author": "alephnerd", "created_at": "2025-09-05T01:35:27Z", "created_at_i": 1757036127, "num_comments": 0, "objectID": "45134200", "points": 2, "story_id": 45134200, "title": "OpenAI set to start mass production of its own AI chips with Broadcom", "updated_at": "2025-09-05T05:15:37Z", "url": "https://www.ft.com/content/e8cc6d99-d06e-4e9b-a54f-29317fa68d6f"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "justvugg"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["openai", "production"], "value": "Hi HN,<p>I built PolyMCP, an open-source framework around the Model Context Protocol (MCP) that lets you expose existing Python functions as AI-callable tools \u2014 without rewriting them or adopting a custom SDK.<p>The goal is simple:\nIf you already have working Python code, you should be able to make it accessible to LLM agents in minutes.<p>What it does<p>PolyMCP introspects regular Python functions and exposes them as MCP tools automatically. No decorators required. No framework lock-in.<p>It grew into a small ecosystem:\n \u2022 PolyMCP (core) \u2013 Turn Python functions into MCP tools\n \u2022 PolyMCP Inspector \u2013 A visual UI to browse, test, and debug MCP servers\n \u2022 MCP SDK Apps \u2013 A lightweight way to build AI-powered apps with tools + UI resources<p>Why I built this<p>While experimenting with MCP and AI agents, I found that integrating existing codebases was often the painful part.\nMost solutions require rewriting logic around a specific SDK or heavily annotating functions.<p>PolyMCP focuses on:\n \u2022 Minimal intrusion into existing code\n \u2022 Clean separation between business logic and AI tooling\n \u2022 Easy debugging via a visual inspector<p>Example use cases\n \u2022 Expose internal APIs or legacy scripts to LLM agents\n \u2022 Automate operational workflows\n \u2022 Build internal copilots over real systems\n \u2022 Prototype AI agents that interact with <em>production</em> services<p>Works with <em>OpenAI</em>, Anthropic, and Ollama (including local models).<p>It\u2019s still evolving and I\u2019m actively iterating.\nI\u2019d really appreciate feedback \u2014 especially from people building agents or experimenting with MCP in <em>production</em> environments.<p>GitHub:\n \u2022 Core: <a href=\"https://github.com/poly-mcp/PolyMCP\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP</a>\n \u2022 Inspector: <a href=\"https://github.com/poly-mcp/PolyMCP-Inspector\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP-Inspector</a>\n \u2022 SDK Apps: <a href=\"https://github.com/poly-mcp/PolyMCP-MCP-SDK-Apps\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP-MCP-SDK-Apps</a><p>Happy to answer technical questions."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: PolyMCP \u2013 Expose Python functions as MCP tools"}}, "_tags": ["story", "author_justvugg", "story_46980134", "show_hn"], "author": "justvugg", "created_at": "2026-02-11T20:06:17Z", "created_at_i": 1770840377, "num_comments": 0, "objectID": "46980134", "points": 2, "story_id": 46980134, "story_text": "Hi HN,<p>I built PolyMCP, an open-source framework around the Model Context Protocol (MCP) that lets you expose existing Python functions as AI-callable tools \u2014 without rewriting them or adopting a custom SDK.<p>The goal is simple:\nIf you already have working Python code, you should be able to make it accessible to LLM agents in minutes.<p>What it does<p>PolyMCP introspects regular Python functions and exposes them as MCP tools automatically. No decorators required. No framework lock-in.<p>It grew into a small ecosystem:\n \u2022 PolyMCP (core) \u2013 Turn Python functions into MCP tools\n \u2022 PolyMCP Inspector \u2013 A visual UI to browse, test, and debug MCP servers\n \u2022 MCP SDK Apps \u2013 A lightweight way to build AI-powered apps with tools + UI resources<p>Why I built this<p>While experimenting with MCP and AI agents, I found that integrating existing codebases was often the painful part.\nMost solutions require rewriting logic around a specific SDK or heavily annotating functions.<p>PolyMCP focuses on:\n \u2022 Minimal intrusion into existing code\n \u2022 Clean separation between business logic and AI tooling\n \u2022 Easy debugging via a visual inspector<p>Example use cases\n \u2022 Expose internal APIs or legacy scripts to LLM agents\n \u2022 Automate operational workflows\n \u2022 Build internal copilots over real systems\n \u2022 Prototype AI agents that interact with production services<p>Works with OpenAI, Anthropic, and Ollama (including local models).<p>It\u2019s still evolving and I\u2019m actively iterating.\nI\u2019d really appreciate feedback \u2014 especially from people building agents or experimenting with MCP in production environments.<p>GitHub:\n \u2022 Core: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP</a>\n \u2022 Inspector: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-Inspector\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-Inspector</a>\n \u2022 SDK Apps: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-MCP-SDK-Apps\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-MCP-SDK-Apps</a><p>Happy to answer technical questions.", "title": "Show HN: PolyMCP \u2013 Expose Python functions as MCP tools", "updated_at": "2026-02-11T20:47:00Z"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "mmegger"}, "title": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["openai", "production"], "value": "Show HN: <em>Production</em>-Ready Agents with the <em>OpenAI</em> Agents SDK and Temporal"}, "url": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["openai"], "value": "https://temporal.io/blog/announcing-<em>openai</em>-agents-sdk-integration"}}, "_tags": ["story", "author_mmegger", "story_44734374", "show_hn"], "author": "mmegger", "created_at": "2025-07-30T14:03:36Z", "created_at_i": 1753884216, "num_comments": 0, "objectID": "44734374", "points": 28, "story_id": 44734374, "title": "Show HN: Production-Ready Agents with the OpenAI Agents SDK and Temporal", "updated_at": "2025-07-31T09:29:27Z", "url": "https://temporal.io/blog/announcing-openai-agents-sdk-integration"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "adiraja"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["openai", "production"], "value": "Hello HackerNews!<p>I\u2019m excited to share what we\u2019ve been working on at nCompass Technologies: an AI inference* platform that gives you a scalable and reliable API to access any open-source AI model \u2014 with no rate limits. We don't have rate limits as optimizations we made to our AI model serving software enable us to support a high number of concurrent requests without degrading quality of service for you as a user.<p>If you\u2019re thinking, well aren\u2019t there a bunch of these already? So were we when we started nCompass. When using other APIs, we found that they weren\u2019t reliable enough to be able to use open source models in <em>production</em> environments. To resolve this, we're building an AI inference engine that enable you, as an end user, to reliably use open source models in <em>production</em>.<p>Underlying this API, we\u2019re building optimizations at the hosting, scheduling and kernel levels with the single goal of minimizing the number of GPUs required to maximize the number of concurrent requests you can serve, without degrading quality of service.<p>We\u2019re still building a lot of our optimizations, but we\u2019ve released what we have so far via our API. Compared to vLLM, we currently keep time-to-first-token (TTFT) 2-4x lower than vLLM at the equivalent concurrent request rate. You can check out a demo of our API here:<p><a href=\"https://www.loom.com/share/c92f825ac0af4ab18296a16546a75be3\" rel=\"nofollow\">https://www.loom.com/share/c92f825ac0af4ab18296a16546a75be3</a><p>As a result of the optimizations we\u2019ve rolled out so far, we\u2019re releasing a few unique features on our API:<p>1. Rate-Limits: we don\u2019t have any<p>Most other API\u2019s out there have strict rate limits and can be rather unreliable. We don\u2019t want API\u2019s for open source models to remain as a solution for prototypes only. We want people to use these APIs like they do <em>OpenAI</em>\u2019s or Anthropic\u2019s and actually make <em>production</em> grade products on top of open source models.<p>2. Underserved models: we have them<p>There are a ton of models out there, but not all of them are readily available for people to use if they don\u2019t have access to GPUs. We envision our API becoming a system where anyone can  launch any custom model of their choice with minimal cold starts and run the model as a simple API call. Our cold starts for any 8B or 70B model are only 40s and we\u2019ll keep improving this.<p>Towards this goal, we already have models like `ai4bharat/hercule-hi` hosted on our API to support non-english language use cases and models like `Qwen/QwQ-32B-Preview` to support reasoning based use cases. You can find the other models that we host here: <a href=\"https://console.ncompass.tech/public-models\">https://console.ncompass.tech/public-models</a> for public ones, and <a href=\"https://console.ncompass.tech/models\">https://console.ncompass.tech/models</a>  for private ones that work once you've created an account.<p>We\u2019d love for you to try out our API by following the steps here: <a href=\"https://www.ncompass.tech/docs/llm_inference/quickstart\">https://www.ncompass.tech/docs/llm_inference/quickstart</a>. We provide $100 of free credit on sign up to run models, and like we said, go crazy with your requests, we\u2019d love to see if you can break our system :)<p>We\u2019re still actively building out features and optimizations and your input can help shape the future of nCompass. If you have thoughts on our platform or want us to host a specific model, let us know at hello@ncompass.tech.<p>Happy Hacking!<p>* it's called inference because the process of taking a query, running it through the model and providing a result is referred to as &quot;inference&quot; in the AI / machine learning world. It's as opposed to &quot;training&quot; or &quot;finetuning&quot; which are processes used to actually develop the AI models that you then run &quot;inference&quot; on."}, "title": {"matchLevel": "none", "matchedWords": [], "value": "Show HN: NCompass Technologies \u2013 yet another AI Inference API, but hear us out"}, "url": {"matchLevel": "none", "matchedWords": [], "value": "https://www.ncompass.tech/about"}}, "_tags": ["story", "author_adiraja", "story_42430296", "show_hn"], "author": "adiraja", "children": [42430297, 42430368, 42433696, 42434243, 42434639, 42434837, 42436024, 42436245, 42436246, 42441732, 42449358], "created_at": "2024-12-16T12:07:18Z", "created_at_i": 1734350838, "num_comments": 34, "objectID": "42430296", "points": 37, "story_id": 42430296, "story_text": "Hello HackerNews!<p>I\u2019m excited to share what we\u2019ve been working on at nCompass Technologies: an AI inference* platform that gives you a scalable and reliable API to access any open-source AI model \u2014 with no rate limits. We don&#x27;t have rate limits as optimizations we made to our AI model serving software enable us to support a high number of concurrent requests without degrading quality of service for you as a user.<p>If you\u2019re thinking, well aren\u2019t there a bunch of these already? So were we when we started nCompass. When using other APIs, we found that they weren\u2019t reliable enough to be able to use open source models in production environments. To resolve this, we&#x27;re building an AI inference engine that enable you, as an end user, to reliably use open source models in production.<p>Underlying this API, we\u2019re building optimizations at the hosting, scheduling and kernel levels with the single goal of minimizing the number of GPUs required to maximize the number of concurrent requests you can serve, without degrading quality of service.<p>We\u2019re still building a lot of our optimizations, but we\u2019ve released what we have so far via our API. Compared to vLLM, we currently keep time-to-first-token (TTFT) 2-4x lower than vLLM at the equivalent concurrent request rate. You can check out a demo of our API here:<p><a href=\"https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;c92f825ac0af4ab18296a16546a75be3\" rel=\"nofollow\">https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;c92f825ac0af4ab18296a16546a75be3</a><p>As a result of the optimizations we\u2019ve rolled out so far, we\u2019re releasing a few unique features on our API:<p>1. Rate-Limits: we don\u2019t have any<p>Most other API\u2019s out there have strict rate limits and can be rather unreliable. We don\u2019t want API\u2019s for open source models to remain as a solution for prototypes only. We want people to use these APIs like they do OpenAI\u2019s or Anthropic\u2019s and actually make production grade products on top of open source models.<p>2. Underserved models: we have them<p>There are a ton of models out there, but not all of them are readily available for people to use if they don\u2019t have access to GPUs. We envision our API becoming a system where anyone can  launch any custom model of their choice with minimal cold starts and run the model as a simple API call. Our cold starts for any 8B or 70B model are only 40s and we\u2019ll keep improving this.<p>Towards this goal, we already have models like `ai4bharat&#x2F;hercule-hi` hosted on our API to support non-english language use cases and models like `Qwen&#x2F;QwQ-32B-Preview` to support reasoning based use cases. You can find the other models that we host here: <a href=\"https:&#x2F;&#x2F;console.ncompass.tech&#x2F;public-models\">https:&#x2F;&#x2F;console.ncompass.tech&#x2F;public-models</a> for public ones, and <a href=\"https:&#x2F;&#x2F;console.ncompass.tech&#x2F;models\">https:&#x2F;&#x2F;console.ncompass.tech&#x2F;models</a>  for private ones that work once you&#x27;ve created an account.<p>We\u2019d love for you to try out our API by following the steps here: <a href=\"https:&#x2F;&#x2F;www.ncompass.tech&#x2F;docs&#x2F;llm_inference&#x2F;quickstart\">https:&#x2F;&#x2F;www.ncompass.tech&#x2F;docs&#x2F;llm_inference&#x2F;quickstart</a>. We provide $100 of free credit on sign up to run models, and like we said, go crazy with your requests, we\u2019d love to see if you can break our system :)<p>We\u2019re still actively building out features and optimizations and your input can help shape the future of nCompass. If you have thoughts on our platform or want us to host a specific model, let us know at hello@ncompass.tech.<p>Happy Hacking!<p>* it&#x27;s called inference because the process of taking a query, running it through the model and providing a result is referred to as &quot;inference&quot; in the AI &#x2F; machine learning world. It&#x27;s as opposed to &quot;training&quot; or &quot;finetuning&quot; which are processes used to actually develop the AI models that you then run &quot;inference&quot; on.", "title": "Show HN: NCompass Technologies \u2013 yet another AI Inference API, but hear us out", "updated_at": "2024-12-21T02:03:34Z", "url": "https://www.ncompass.tech/about"}, {"_highlightResult": {"author": {"matchLevel": "none", "matchedWords": [], "value": "calebkaiser"}, "story_text": {"fullyHighlighted": false, "matchLevel": "full", "matchedWords": ["openai", "production"], "value": "I write about ML in <em>production</em>\u2014working with models like <em>OpenAI</em>'s GPT-2, Hugging Face's DistilBERT, AllenNLP's ELMo-BiDAF, etc\u2014at cortex.dev. What other pre-trained models should I be looking at? Are there any you've used in <em>production</em>?"}, "title": {"fullyHighlighted": false, "matchLevel": "partial", "matchedWords": ["production"], "value": "Ask HN: What pre-trained models have you used in <em>production</em>?"}}, "_tags": ["story", "author_calebkaiser", "story_21599573", "ask_hn"], "author": "calebkaiser", "children": [21600400, 21600432], "created_at": "2019-11-21T21:01:44Z", "created_at_i": 1574370104, "num_comments": 3, "objectID": "21599573", "points": 14, "story_id": 21599573, "story_text": "I write about ML in production\u2014working with models like OpenAI&#x27;s GPT-2, Hugging Face&#x27;s DistilBERT, AllenNLP&#x27;s ELMo-BiDAF, etc\u2014at cortex.dev. What other pre-trained models should I be looking at? Are there any you&#x27;ve used in production?", "title": "Ask HN: What pre-trained models have you used in production?", "updated_at": "2024-09-20T05:14:45Z"}], "hitsPerPage": 15, "nbHits": 242, "nbPages": 17, "page": 0, "params": "query=openai+production&tags=story&hitsPerPage=15&advancedSyntax=true&analyticsTags=backend", "processingTimeMS": 13, "processingTimingsMS": {"_request": {"roundTrip": 15}, "afterFetch": {"format": {"highlighting": 1, "total": 1}}, "fetch": {"query": 7, "scanning": 4, "total": 12}, "total": 13}, "query": "openai production", "serverTimeMS": 15}}